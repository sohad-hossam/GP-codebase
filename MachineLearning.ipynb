{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from imports import *\n",
        "from FeatureExtraction import *\n",
        "from PreProcessor import *\n",
        "# download_folder = 'C:/nltk_data' \n",
        "# nltk.download('words')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Preprocessor"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "</h3>Train </h3>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "_PreProcessor_train = PreProcessor()\n",
        "UC_documents_train, UC_to_index_train,Vocab_UC_train= _PreProcessor_train.setupUC(\"./Dataset/teiid_dataset/train_UC\")\n",
        "code_documents_train, CC_to_index_train,Vocab_CC_train = _PreProcessor_train.setupCC(\"./Dataset/teiid_dataset/train_CC\")\n",
        "\n",
        "_PreProcessor_test = PreProcessor()\n",
        "UC_documents_test, UC_to_index_test,Vocab_UC_test= _PreProcessor_test.setupUC(\"./Dataset/teiid_dataset/test_UC\")\n",
        "code_documents_test, CC_to_index_test,Vocab_CC_test = _PreProcessor_test.setupCC(\"./Dataset/teiid_dataset/test_CC\")\n",
        "\n",
        "Vocab_UC_train.update(Vocab_CC_train)\n",
        "print(\"Vocab_UC_train\",Vocab_UC_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "with open('./pickles/UC_documents_train.pkl', 'wb') as f:\n",
        "       pickle.dump(UC_documents_train, f)\n",
        "with open('./pickles/code_documents_train.pkl', 'wb') as f:\n",
        "        pickle.dump(code_documents_train, f)\n",
        "with open('./pickles/UCindex_train.pkl', 'wb') as f:\n",
        "        pickle.dump(UC_to_index_train, f)\n",
        "with open('./pickles/CCindex_train.pkl', 'wb') as f:\n",
        "        pickle.dump(CC_to_index_train, f)\n",
        "with open('./pickles/UCTokens_train.pkl', 'wb') as f:\n",
        "        pickle.dump(Vocab_UC_train, f)\n",
        "with open('./pickles/CodeTokens_train.pkl', 'wb') as f:\n",
        "        pickle.dump(Vocab_CC_train, f)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "</h3>Test</h3>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "with open('./pickles/UC_documents_test.pkl', 'wb') as f:\n",
        "       pickle.dump(UC_documents_test, f)\n",
        "with open('./pickles/code_documents_test.pkl', 'wb') as f:\n",
        "        pickle.dump(code_documents_test, f)\n",
        "with open('./pickles/UCindex_test.pkl', 'wb') as f:\n",
        "        pickle.dump(UC_to_index_test, f)\n",
        "with open('./pickles/CCindex_test.pkl', 'wb') as f:\n",
        "        pickle.dump(CC_to_index_test, f)\n",
        "with open('./pickles/UCTokens_test.pkl', 'wb') as f:\n",
        "        pickle.dump(Vocab_UC_test, f)\n",
        "with open('./pickles/CodeTokens_test.pkl', 'wb') as f:\n",
        "        pickle.dump(Vocab_CC_test, f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "UC_documents_train = np.load('./pickles/UC_documents_train.pkl',allow_pickle=True)\n",
        "Vocab_UC_train = np.load('./pickles/UCTokens_train.pkl',allow_pickle=True)\n",
        "code_documents_train = np.load('./pickles/code_documents_train.pkl',allow_pickle=True)\n",
        "Vocab_CC_train = np.load('./pickles/CodeTokens_train.pkl',allow_pickle=True)\n",
        "UC_to_index_train = np.load('./pickles/UCindex_train.pkl',allow_pickle=True)\n",
        "CC_to_index_train = np.load('./pickles/CCindex_train.pkl',allow_pickle=True)\n",
        "\n",
        "\n",
        "UC_documents_test = np.load('./pickles/UC_documents_test.pkl',allow_pickle=True)\n",
        "Vocab_UC_test = np.load('./pickles/UCTokens_test.pkl',allow_pickle=True)\n",
        "code_documents_test = np.load('./pickles/code_documents_test.pkl',allow_pickle=True)\n",
        "Vocab_CC_test = np.load('./pickles/CodeTokens_test.pkl',allow_pickle=True)\n",
        "UC_to_index_test = np.load('./pickles/UCindex_test.pkl',allow_pickle=True)\n",
        "CC_to_index_test = np.load('./pickles/CCindex_test.pkl',allow_pickle=True)\n",
        "\n",
        "\n",
        "\n",
        "Vocab_UC_train.update(Vocab_CC_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Initialize Normalizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "normalizer = MinMaxScaler(copy=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Adjuting the csv file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "_PreProcessor_train.setupCSV(\"Dataset/teiid_dataset/train.csv\", \"Dataset/teiid_dataset/train_modified.csv\",UC_to_index_train,CC_to_index_train)\n",
        "_PreProcessor_test.setupCSV(\"Dataset/teiid_dataset/test.csv\", \"Dataset/teiid_dataset/test_modified.csv\",UC_to_index_test,CC_to_index_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Collecting the 131 features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "featureExtraction = FeatureExtraction(Vocab_UC_train)\n",
        "\n",
        "# Feature extraction for training set\n",
        "tfidf_matrix_uc_train, tfidf_matrix_code_train, idf_uc_dict_train, idf_code_dict_train, feature_names_uc_train, feature_names_code_train, df_uc_dict_train, df_code_dict_train = featureExtraction.TFIDFVectorizer(UC_documents_train, code_documents_train,train_or_test='train')\n",
        "UC_count_matrix_train, code_count_matrix_train, tf_uc_dict_train, tf_code_dict_train = featureExtraction.CountVectorizerModel(UC_documents_train, code_documents_train, 'train')\n",
        "idf_uc_train, idf_code_train = featureExtraction.IDFPreProcessing(UC_documents_train, idf_code_dict_train, code_documents_train, idf_uc_dict_train)\n",
        "ictf_uc_train, ictf_code_train = featureExtraction.ICTFPreProcessing(UC_documents_train, tf_code_dict_train, code_documents_train, tf_uc_dict_train)\n",
        "\n",
        "# Feature extraction for testing set\n",
        "tfidf_matrix_uc_test, tfidf_matrix_code_test, idf_uc_dict_test, idf_code_dict_test, feature_names_uc_test, feature_names_code_test, df_uc_dict_test, df_code_dict_test = featureExtraction.TFIDFVectorizer(UC_documents_test, code_documents_test,train_or_test='test')\n",
        "UC_count_matrix_test, code_count_matrix_test, tf_uc_dict_test, tf_code_dict_test = featureExtraction.CountVectorizerModel(UC_documents_test, code_documents_test, 'test')\n",
        "idf_uc_test, idf_code_test = featureExtraction.IDFPreProcessing(UC_documents_test, idf_code_dict_test, code_documents_test, idf_uc_dict_test)\n",
        "ictf_uc_test, ictf_code_test = featureExtraction.ICTFPreProcessing(UC_documents_test, tf_code_dict_test, code_documents_test, tf_uc_dict_test)\n",
        "# # the values of the count matrices are normalized"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "entropy_uc_train,entropy_code_train,variance_uc_train,variance_code_train=featureExtraction.EntropyPreProcessing(UC_documents_train,code_documents_train,idf_uc_dict_train,idf_code_dict_train,df_uc_dict_train,df_code_dict_train)\n",
        "entropy_uc_test,entropy_code_test,variance_uc_test,variance_code_test=featureExtraction.EntropyPreProcessing(UC_documents_test,code_documents_test,idf_uc_dict_test,idf_code_dict_test,df_uc_dict_test,df_code_dict_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "with open('./pickles/entropy_uc_train.pkl', 'wb') as f:\n",
        "       pickle.dump(entropy_uc_train, f)\n",
        "with open('./pickles/entropy_code_train.pkl', 'wb') as f:\n",
        "        pickle.dump(entropy_code_train, f)\n",
        "with open('./pickles/variance_uc_train.pkl', 'wb') as f:\n",
        "        pickle.dump(variance_uc_train, f)\n",
        "with open('./pickles/variance_code_train.pkl', 'wb') as f:\n",
        "        pickle.dump(variance_code_train, f)\n",
        "\n",
        "with open('./pickles/entropy_uc_test.pkl', 'wb') as f:\n",
        "       pickle.dump(entropy_uc_test, f)\n",
        "with open('./pickles/entropy_code_test.pkl', 'wb') as f:\n",
        "        pickle.dump(entropy_code_test, f)\n",
        "with open('./pickles/variance_uc_test.pkl', 'wb') as f:\n",
        "        pickle.dump(variance_uc_test, f)\n",
        "with open('./pickles/variance_code_test.pkl', 'wb') as f:\n",
        "        pickle.dump(variance_code_test, f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "entropy_uc_train = np.load('./pickles/entropy_uc_train.pkl',allow_pickle=True)\n",
        "entropy_code_train = np.load('./pickles/entropy_code_train.pkl',allow_pickle=True)\n",
        "variance_uc_train = np.load('./pickles/variance_uc_train.pkl',allow_pickle=True)\n",
        "variance_code_train = np.load('./pickles/variance_code_train.pkl',allow_pickle=True)\n",
        "entropy_uc_test = np.load('./pickles/entropy_uc_test.pkl',allow_pickle=True)\n",
        "entropy_code_test = np.load('./pickles/entropy_code_test.pkl',allow_pickle=True)\n",
        "variance_uc_test = np.load('./pickles/variance_uc_test.pkl',allow_pickle=True)\n",
        "variance_code_test = np.load('./pickles/variance_code_test.pkl',allow_pickle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# variance_uc_train,variance_code_train= featureExtraction.VarPreProcessing(UC_documents_train,code_documents_train,idf_uc_dict_train,idf_code_dict_train)\n",
        "PMI_uc_train,PMI_code_train=featureExtraction.PMIPreProcessing(code_documents_train,UC_documents_train)\n",
        "SCQ_uc_train,SCQ_code_train = featureExtraction.SCQPreProcessing(UC_documents_train,code_documents_train,tf_uc_dict_train,tf_code_dict_train,idf_uc_dict_train,idf_code_dict_train)\n",
        "\n",
        "# variance_uc_test,variance_code_test= featureExtraction.VarPreProcessing(UC_documents_test,code_documents_test,idf_uc_dict_test,idf_code_dict_test)\n",
        "PMI_uc_test,PMI_code_test=featureExtraction.PMIPreProcessing(code_documents_test,UC_documents_test)\n",
        "SCQ_uc_test,SCQ_code_test = featureExtraction.SCQPreProcessing(UC_documents_test,code_documents_test,tf_uc_dict_test,tf_code_dict_test,idf_uc_dict_test,idf_code_dict_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "with open('./pickles/PMI_uc_train.pkl', 'wb') as f:\n",
        "       pickle.dump(PMI_uc_train, f)\n",
        "with open('./pickles/PMI_code_train.pkl', 'wb') as f:\n",
        "        pickle.dump(PMI_code_train, f)\n",
        "\n",
        "with open('./pickles/SCQ_uc_train.pkl', 'wb') as f:\n",
        "         pickle.dump(SCQ_uc_train, f)\n",
        "with open('./pickles/SCQ_code_train.pkl', 'wb') as f:\n",
        "        pickle.dump(SCQ_code_train, f)\n",
        "\n",
        "with open('./pickles/PMI_uc_test.pkl', 'wb') as f:\n",
        "    pickle.dump(PMI_uc_test, f)\n",
        "\n",
        "with open('./pickles/PMI_code_test.pkl', 'wb') as f:\n",
        "    pickle.dump(PMI_code_test, f)\n",
        "\n",
        "with open('./pickles/SCQ_uc_test.pkl', 'wb') as f:\n",
        "    pickle.dump(SCQ_uc_test, f)\n",
        "\n",
        "with open('./pickles/SCQ_code_test.pkl', 'wb') as f:\n",
        "    pickle.dump(SCQ_code_test, f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "PMI_uc_train = np.load('./pickles/PMI_uc_train.pkl',allow_pickle=True)\n",
        "PMI_code_train = np.load('./pickles/PMI_code_train.pkl',allow_pickle=True)\n",
        "SCQ_uc_train = np.load('./pickles/SCQ_uc_train.pkl',allow_pickle=True)\n",
        "SCQ_code_train = np.load('./pickles/SCQ_code_train.pkl',allow_pickle=True)\n",
        "PMI_uc_test = np.load('./pickles/PMI_uc_test.pkl',allow_pickle=True)\n",
        "PMI_code_test = np.load('./pickles/PMI_code_test.pkl',allow_pickle=True)\n",
        "SCQ_uc_test = np.load('./pickles/SCQ_uc_test.pkl',allow_pickle=True)\n",
        "SCQ_code_test = np.load('./pickles/SCQ_code_test.pkl',allow_pickle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#-------------------------14 IR based features Train--------------------------#\n",
        "\n",
        "# 1) Vector space model\n",
        "cosine_similarities_feature_train = featureExtraction.VectorSpaceModel(tfidf_matrix_uc_train, tfidf_matrix_code_train)\n",
        "print(\"cosine_similarities_feature_train\", cosine_similarities_feature_train.shape)\n",
        "\n",
        "# Our model will classify based on the ranks of the data rather than their actual values.\n",
        "cosine_similarity_UC_train = rankdata(-cosine_similarities_feature_train, method='dense', axis=1)\n",
        "print(\"cosine_similarity_UC_train\", cosine_similarity_UC_train.shape)\n",
        "cosine_similarity_CC_train = rankdata(-cosine_similarities_feature_train, method='dense', axis=0)\n",
        "print(\"cosine_similarity_CC_train\", cosine_similarity_CC_train.shape)\n",
        "\n",
        "normalizer.fit_transform(cosine_similarity_UC_train)\n",
        "normalizer.fit_transform(cosine_similarity_CC_train)\n",
        "\n",
        "np.save('./pickles/cosine_similarity_UC_train.npy', cosine_similarity_UC_train)\n",
        "np.save('./pickles/cosine_similarity_CC_train.npy', cosine_similarity_CC_train)\n",
        "\n",
        "# 2) Latent semantic analysis\n",
        "LSA_similarities_feature_train = featureExtraction.LSA(tfidf_matrix_uc_train, tfidf_matrix_code_train)\n",
        "print('LSA similarity', LSA_similarities_feature_train.shape)\n",
        "\n",
        "LSA_similarities_UC_train = rankdata(-LSA_similarities_feature_train, method='dense', axis=1)\n",
        "print(\"LSA_similarities_UC_train\", LSA_similarities_UC_train.shape)\n",
        "LSA_similarities_CC_train = rankdata(-LSA_similarities_feature_train, method='dense', axis=0)\n",
        "print(\"LSA_similarities_CC_train\", LSA_similarities_CC_train.shape)\n",
        "\n",
        "normalizer.fit_transform(LSA_similarities_UC_train)\n",
        "normalizer.fit_transform(LSA_similarities_CC_train)\n",
        "\n",
        "np.save('./pickles/LSA_similarities_UC_train.npy', LSA_similarities_UC_train)\n",
        "np.save('./pickles/LSA_similarities_CC_train.npy', LSA_similarities_CC_train)\n",
        "\n",
        "# 3) Latent Dirichlet Allocation\n",
        "DocumentTopicDisUC_dense_train, DocumentTopicDisCode_dense_train, cosine_similarities_LDA_train = featureExtraction.LDA(UC_documents_train, code_documents_train, Vocab_UC_train)\n",
        "print('LDA similarity', cosine_similarities_LDA_train.shape)\n",
        "\n",
        "LDA_similarities_UC_train = rankdata(-cosine_similarities_LDA_train, method='dense', axis=1)\n",
        "print(\"LDA_similarities_UC_train\", LDA_similarities_UC_train.shape)\n",
        "LDA_similarities_CC_train = rankdata(-cosine_similarities_LDA_train, 'dense', axis=0)\n",
        "print(\"LDA_similarities_CC_train\", LDA_similarities_CC_train.shape)\n",
        "\n",
        "normalizer.fit_transform(LDA_similarities_UC_train)\n",
        "normalizer.fit_transform(LDA_similarities_CC_train)\n",
        "\n",
        "np.save('./pickles/LDA_similarities_UC_train.npy', LDA_similarities_UC_train)\n",
        "np.save('./pickles/LDA_similarities_CC_train.npy', LDA_similarities_CC_train)\n",
        "\n",
        "# 4) Jensen-Shannon(JS)\n",
        "JS_features_train = featureExtraction.JensenShannon(UC_count_matrix_train, code_count_matrix_train)\n",
        "print('JS', JS_features_train.shape)\n",
        "\n",
        "JS_UC_train = rankdata(-JS_features_train, method='dense', axis=1)\n",
        "print('JS_UC_train', JS_UC_train.shape)\n",
        "JS_CC_train = rankdata(-JS_features_train, method='dense', axis=0)\n",
        "print('JS_CC_train', JS_CC_train.shape)\n",
        "\n",
        "normalizer.fit_transform(JS_UC_train)\n",
        "normalizer.fit_transform(JS_CC_train)\n",
        "\n",
        "np.save('./pickles/JS_UC_train.npy', JS_UC_train)\n",
        "np.save('./pickles/JS_CC_train.npy', JS_CC_train)\n",
        "\n",
        "# 5)  Okapi BM25\n",
        "# UC means query is UC and document is code\n",
        "BM25_UC_train = featureExtraction.BM25(UC_documents_train, code_documents_train, idf_code_dict_train, code_count_matrix_train)\n",
        "BM25_CC_train = featureExtraction.BM25(code_documents_train, UC_documents_train, idf_uc_dict_train, UC_count_matrix_train)\n",
        "\n",
        "BM25_UC_train = rankdata(-BM25_UC_train, method='dense', axis=0)\n",
        "print(\"BM25_UC_train\", BM25_UC_train.shape)\n",
        "BM25_CC_train = rankdata(-BM25_CC_train, method='dense', axis=0)\n",
        "print(\"BM25_CC_train\", BM25_CC_train.shape)\n",
        "\n",
        "normalizer.fit_transform(BM25_UC_train)\n",
        "normalizer.fit_transform(cosine_similarity_CC_train)\n",
        "\n",
        "np.save('./pickles/BM25_UC_train.npy', BM25_UC_train)\n",
        "np.save('./pickles/BM25_CC_train.npy', BM25_CC_train)\n",
        "\n",
        "# 6) Language Model with Dirichlet\n",
        "# UC means UC is query and code is doc\n",
        "JM_UC_train = featureExtraction.SmoothingMethods(UC_documents_train, code_documents_train, code_count_matrix_train, tf_code_dict_train, JM_or_DP=True)\n",
        "JM_CC_train = featureExtraction.SmoothingMethods(code_documents_train, UC_documents_train, UC_count_matrix_train, tf_uc_dict_train, True)\n",
        "\n",
        "DP_UC_train = featureExtraction.SmoothingMethods(UC_documents_train, code_documents_train, code_count_matrix_train, tf_code_dict_train, JM_or_DP=False)\n",
        "DP_CC_train = featureExtraction.SmoothingMethods(code_documents_train, UC_documents_train, UC_count_matrix_train, tf_uc_dict_train, False)\n",
        "\n",
        "JM_UC_train = rankdata(-JM_UC_train, method='dense', axis=0)\n",
        "print(\"JM_UC_train\", JM_UC_train.shape)\n",
        "JM_CC_train = rankdata(-JM_CC_train, method='dense', axis=0)\n",
        "print(\"JM_CC_train\", JM_CC_train.shape)\n",
        "DP_UC_train = rankdata(-DP_UC_train, method='dense', axis=0)\n",
        "print(\"DP_UC_train\", DP_UC_train.shape)\n",
        "DP_CC_train = rankdata(-DP_CC_train, method='dense', axis=0)\n",
        "print(\"DP_CC_train\", DP_CC_train.shape)\n",
        "\n",
        "normalizer.fit_transform(JM_UC_train)\n",
        "normalizer.fit_transform(JM_CC_train)\n",
        "\n",
        "np.save('./pickles/JM_UC_train.npy', JM_UC_train)\n",
        "np.save('./pickles/JM_CC_train.npy', JM_CC_train)\n",
        "\n",
        "normalizer.fit_transform(DP_UC_train)\n",
        "normalizer.fit_transform(DP_CC_train)\n",
        "\n",
        "np.save('./pickles/DP_UC_train.npy', DP_UC_train)\n",
        "np.save('./pickles/DP_CC_train.npy', DP_CC_train)\n",
        "\n",
        "\n",
        "#-------------------------14 IR based features Test--------------------------#\n",
        "\n",
        "# 1) Vector space model\n",
        "cosine_similarities_feature_test = featureExtraction.VectorSpaceModel(tfidf_matrix_uc_test, tfidf_matrix_code_test)\n",
        "print(\"cosine_similarities_feature_test\", cosine_similarities_feature_test.shape)\n",
        "\n",
        "# Our model will classify based on the ranks of the data rather than their actual values.\n",
        "cosine_similarity_UC_test = rankdata(-cosine_similarities_feature_test, method='dense', axis=1)\n",
        "print(\"cosine_similarity_UC_test\", cosine_similarity_UC_test.shape)\n",
        "cosine_similarity_CC_test = rankdata(-cosine_similarities_feature_test, method='dense', axis=0)\n",
        "print(\"cosine_similarity_CC_test\", cosine_similarity_CC_test.shape)\n",
        "\n",
        "normalizer.fit_transform(cosine_similarity_UC_test)\n",
        "normalizer.fit_transform(cosine_similarity_CC_test)\n",
        "\n",
        "np.save('./pickles/cosine_similarity_UC_test.npy', cosine_similarity_UC_test)\n",
        "np.save('./pickles/cosine_similarity_CC_test.npy', cosine_similarity_CC_test)\n",
        "\n",
        "# 2) Latent semantic analysis\n",
        "LSA_similarities_feature_test = featureExtraction.LSA(tfidf_matrix_uc_test, tfidf_matrix_code_test)\n",
        "print('LSA similarity', LSA_similarities_feature_test.shape)\n",
        "\n",
        "LSA_similarities_UC_test = rankdata(-LSA_similarities_feature_test, method='dense', axis=1)\n",
        "print(\"LSA_similarities_UC_test\", LSA_similarities_UC_test.shape)\n",
        "LSA_similarities_CC_test = rankdata(-LSA_similarities_feature_test, method='dense', axis=0)\n",
        "print(\"LSA_similarities_CC_test\", LSA_similarities_CC_test.shape)\n",
        "\n",
        "normalizer.fit_transform(LSA_similarities_UC_test)\n",
        "normalizer.fit_transform(LSA_similarities_CC_test)\n",
        "\n",
        "np.save('./pickles/LSA_similarities_UC_test.npy', LSA_similarities_UC_test)\n",
        "np.save('./pickles/LSA_similarities_CC_test.npy', LSA_similarities_CC_test)\n",
        "\n",
        "# 3) Latent Dirichlet Allocation\n",
        "DocumentTopicDisUC_dense_test, DocumentTopicDisCode_dense_test, cosine_similarities_LDA_test = featureExtraction.LDA(UC_documents_test, code_documents_test, Vocab_UC_test)\n",
        "print('LDA similarity', cosine_similarities_LDA_test.shape)\n",
        "\n",
        "LDA_similarities_UC_test = rankdata(-cosine_similarities_LDA_test, method='dense', axis=1)\n",
        "print(\"LDA_similarities_UC_test\", LDA_similarities_UC_test.shape)\n",
        "LDA_similarities_CC_test = rankdata(-cosine_similarities_LDA_test, 'dense', axis=0)\n",
        "print(\"LDA_similarities_CC_test\", LDA_similarities_CC_test.shape)\n",
        "\n",
        "normalizer.fit_transform(LDA_similarities_UC_test)\n",
        "normalizer.fit_transform(LDA_similarities_CC_test)\n",
        "\n",
        "np.save('./pickles/LDA_similarities_UC_test.npy', LDA_similarities_UC_test)\n",
        "np.save('./pickles/LDA_similarities_CC_test.npy', LDA_similarities_CC_test)\n",
        "\n",
        "# 4) Jensen-Shannon(JS)\n",
        "JS_features_test = featureExtraction.JensenShannon(UC_count_matrix_test, code_count_matrix_test)\n",
        "print('JS', JS_features_test.shape)\n",
        "\n",
        "JS_UC_test = rankdata(-JS_features_test, method='dense', axis=1)\n",
        "print('JS_UC_test', JS_UC_test.shape)\n",
        "JS_CC_test = rankdata(-JS_features_test, method='dense', axis=0)\n",
        "print('JS_CC_test', JS_CC_test.shape)\n",
        "\n",
        "normalizer.fit_transform(JS_UC_test)\n",
        "normalizer.fit_transform(JS_CC_test)\n",
        "\n",
        "np.save('./pickles/JS_UC_test.npy', JS_UC_test)\n",
        "np.save('./pickles/JS_CC_test.npy', JS_CC_test)\n",
        "\n",
        "# 5)  Okapi BM25\n",
        "# UC means query is UC and document is code\n",
        "BM25_UC_test = featureExtraction.BM25(UC_documents_test, code_documents_test, idf_code_dict_test, code_count_matrix_test)\n",
        "BM25_CC_test = featureExtraction.BM25(code_documents_test, UC_documents_test, idf_uc_dict_test, UC_count_matrix_test)\n",
        "\n",
        "BM25_UC_test = rankdata(-BM25_UC_test, method='dense', axis=0)\n",
        "print(\"BM25_UC_test\", BM25_UC_test.shape)\n",
        "BM25_CC_test = rankdata(-BM25_CC_test, method='dense', axis=0)\n",
        "print(\"BM25_CC_test\", BM25_CC_test.shape)\n",
        "\n",
        "normalizer.fit_transform(BM25_UC_test)\n",
        "normalizer.fit_transform(BM25_CC_test)\n",
        "\n",
        "np.save('./pickles/BM25_UC_test.npy', BM25_UC_test)\n",
        "np.save('./pickles/BM25_CC_test.npy', BM25_CC_test)\n",
        "\n",
        "# 6) Language Model with Dirichlet\n",
        "# UC means UC is query and code is doc\n",
        "JM_UC_test = featureExtraction.SmoothingMethods(UC_documents_test, code_documents_test, code_count_matrix_test, tf_code_dict_test, JM_or_DP=True)\n",
        "JM_CC_test = featureExtraction.SmoothingMethods(code_documents_test, UC_documents_test, UC_count_matrix_test, tf_uc_dict_test, True)\n",
        "\n",
        "DP_UC_test = featureExtraction.SmoothingMethods(UC_documents_test, code_documents_test, code_count_matrix_test, tf_code_dict_test, JM_or_DP=False)\n",
        "DP_CC_test = featureExtraction.SmoothingMethods(code_documents_test, UC_documents_test, UC_count_matrix_test, tf_uc_dict_test, False)\n",
        "\n",
        "JM_UC_test = rankdata(-JM_UC_test, method='dense', axis=0)\n",
        "print(\"JM_UC_test\", JM_UC_test.shape)\n",
        "JM_CC_test = rankdata(-JM_CC_test, method='dense', axis=0)\n",
        "print(\"JM_CC_test\", JM_CC_test.shape)\n",
        "DP_UC_test = rankdata(-DP_UC_test, method='dense', axis=0)\n",
        "print(\"DP_UC_test\", DP_UC_test.shape)\n",
        "DP_CC_test = rankdata(-DP_CC_test, method='dense', axis=0)\n",
        "print(\"DP_CC_test\", DP_CC_test.shape)\n",
        "\n",
        "normalizer.fit_transform(JM_UC_test)\n",
        "normalizer.fit_transform(JM_CC_test)\n",
        "\n",
        "np.save('./pickles/JM_UC_test.npy', JM_UC_test)\n",
        "np.save('./pickles/JM_CC_test.npy', JM_CC_test)\n",
        "\n",
        "normalizer.fit_transform(DP_UC_test)\n",
        "normalizer.fit_transform(DP_CC_test)\n",
        "\n",
        "np.save('./pickles/DP_UC_test.npy', DP_UC_test)\n",
        "np.save('./pickles/DP_CC_test.npy', DP_CC_test)\n",
        "\n",
        "\n",
        "#200 MIN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ------------------------pre-retrieval (21 metrics) Train--------------------------#\n",
        "# 1) IDF Features\n",
        "avg_idf_uc_train = featureExtraction.AvgIDF(idf_uc_train).reshape(1,-1) \n",
        "avg_idf_code_train = featureExtraction.AvgIDF(idf_code_train).reshape(1,-1) \n",
        "\n",
        "normalizer.fit_transform(avg_idf_uc_train)\n",
        "normalizer.fit_transform(avg_idf_code_train)\n",
        "\n",
        "\n",
        "print('avg_idf_uc_train_shape', avg_idf_uc_train.shape) \n",
        "print('avg_idf_code_train_shape', avg_idf_code_train.shape) \n",
        "\n",
        "max_idf_uc_train = featureExtraction.MaxIDF(idf_uc_train).reshape(1,-1) \n",
        "max_idf_code_train = featureExtraction.MaxIDF(idf_code_train).reshape(1,-1) \n",
        "\n",
        "normalizer.fit_transform(max_idf_uc_train)\n",
        "normalizer.fit_transform(max_idf_code_train)\n",
        "\n",
        "\n",
        "\n",
        "print('max_idf_uc_train_shape', max_idf_uc_train.shape) \n",
        "print('max_idf_code_train_shape', max_idf_code_train.shape) \n",
        "\n",
        "dev_idf_uc_train = featureExtraction.DevIDF(idf_uc_train).reshape(1,-1) \n",
        "dev_idf_code_train = featureExtraction.DevIDF(idf_code_train).reshape(1,-1) \n",
        "\n",
        "normalizer.fit_transform(dev_idf_uc_train)\n",
        "normalizer.fit_transform(dev_idf_code_train)\n",
        "\n",
        "\n",
        "\n",
        "print('dev_idf_uc_train_shape', dev_idf_uc_train.shape) \n",
        "print('dev_idf_code_train_shape', dev_idf_code_train.shape) \n",
        "\n",
        "# 2) ICTF Features\n",
        "avg_ictf_uc_train = featureExtraction.AvgICTF(ictf_uc_train).reshape(1,-1) \n",
        "avg_ictf_code_train = featureExtraction.AvgICTF(ictf_code_train).reshape(1,-1) \n",
        "\n",
        "normalizer.fit_transform(avg_ictf_uc_train)\n",
        "normalizer.fit_transform(avg_ictf_code_train)\n",
        "\n",
        "\n",
        "\n",
        "print('avg_ictf_uc_train_shape', avg_ictf_uc_train.shape)\n",
        "print('avg_ictf_code_train_shape', avg_ictf_code_train.shape)\n",
        "\n",
        "max_ictf_uc_train = featureExtraction.MaxICTF(ictf_uc_train).reshape(1,-1) \n",
        "max_ictf_code_train = featureExtraction.MaxICTF(ictf_code_train).reshape(1,-1) \n",
        "\n",
        "normalizer.fit_transform(max_ictf_uc_train)\n",
        "normalizer.fit_transform(max_ictf_code_train)\n",
        "\n",
        "\n",
        "\n",
        "print('max_ictf_uc_train_shape', max_ictf_uc_train.shape)\n",
        "print('max_ictf_code_train_shape', max_ictf_code_train.shape)\n",
        "\n",
        "dev_ictf_uc_train = featureExtraction.DevICTF(ictf_uc_train).reshape(1,-1) \n",
        "dev_ictf_code_train = featureExtraction.DevICTF(ictf_code_train).reshape(1,-1) \n",
        "\n",
        "normalizer.fit_transform(dev_ictf_uc_train)\n",
        "normalizer.fit_transform(dev_ictf_code_train)\n",
        "\n",
        "\n",
        "\n",
        "print('dev_ictf_uc_train_shape', dev_ictf_uc_train.shape)\n",
        "print('dev_ictf_code_train_shape', dev_ictf_code_train.shape)\n",
        "# 3) Entropy Features\n",
        "\n",
        "avg_entropy_uc_train = featureExtraction.AvgEntropy(entropy_uc_train).reshape(1,-1) \n",
        "avg_entropy_code_train = featureExtraction.AvgEntropy(entropy_code_train).reshape(1,-1) \n",
        "\n",
        "normalizer.fit_transform(avg_entropy_uc_train)\n",
        "normalizer.fit_transform(avg_entropy_code_train)\n",
        "\n",
        "\n",
        "print('avg_entropy_uc_train_shape', avg_entropy_uc_train.shape)\n",
        "print('avg_entropy_code_train_shape', avg_entropy_code_train.shape)\n",
        "\n",
        "max_entropy_uc_train = featureExtraction.MaxEntropy(entropy_uc_train).reshape(1,-1) \n",
        "max_entropy_code_train = featureExtraction.MaxEntropy(entropy_code_train).reshape(1,-1) \n",
        "\n",
        "normalizer.fit_transform(max_entropy_uc_train)\n",
        "normalizer.fit_transform(max_entropy_code_train)\n",
        "\n",
        "\n",
        "print('max_entropy_uc_train_shape', max_entropy_uc_train.shape)\n",
        "print('max_entropy_code_train_shape', max_entropy_code_train.shape)\n",
        "\n",
        "med_entropy_uc_train = featureExtraction.MedEntropy(entropy_uc_train).reshape(1,-1) \n",
        "med_entropy_code_train = featureExtraction.MedEntropy(entropy_code_train).reshape(1,-1) \n",
        "\n",
        "\n",
        "normalizer.fit_transform(med_entropy_uc_train)\n",
        "normalizer.fit_transform(med_entropy_code_train)\n",
        "\n",
        "\n",
        "print('med_entropy_uc_train_shape', med_entropy_uc_train.shape)\n",
        "print('med_entropy_code_train_shape', med_entropy_code_train.shape)\n",
        "\n",
        "dev_entropy_uc_train = featureExtraction.DevEntropy(entropy_uc_train).reshape(1,-1) \n",
        "dev_entropy_code_train = featureExtraction.DevEntropy(entropy_code_train).reshape(1,-1) \n",
        "\n",
        "normalizer.fit_transform(dev_entropy_uc_train)\n",
        "normalizer.fit_transform(dev_entropy_code_train)\n",
        "\n",
        "\n",
        "print('dev_entropy_uc_train_shape', dev_entropy_uc_train.shape)\n",
        "print('dev_entropy_code_train_shape', dev_entropy_code_train.shape)\n",
        "      \n",
        "\n",
        "# 4) Variance Features\n",
        "\n",
        "avg_variance_uc_train = featureExtraction.AvgVariance(variance_uc_train).reshape(1,-1) \n",
        "avg_variance_code_train = featureExtraction.AvgVariance(variance_code_train).reshape(1,-1) \n",
        "\n",
        "normalizer.fit_transform(avg_variance_uc_train)\n",
        "normalizer.fit_transform(avg_variance_code_train)\n",
        "\n",
        "\n",
        "print('avg_variance_uc_train_shape', avg_variance_uc_train.shape)\n",
        "print('avg_variance_code_train_shape', avg_variance_code_train.shape)\n",
        "\n",
        "max_variance_uc_train = featureExtraction.MaxVariance(variance_uc_train).reshape(1,-1) \n",
        "max_variance_code_train = featureExtraction.MaxVariance(variance_code_train).reshape(1,-1) \n",
        "\n",
        "normalizer.fit_transform(max_variance_uc_train)\n",
        "normalizer.fit_transform(max_variance_code_train)\n",
        "\n",
        "\n",
        "print('max_variance_uc_train_shape', max_variance_uc_train.shape)\n",
        "print('max_variance_code_train_shape', max_variance_code_train.shape)\n",
        "\n",
        "sum_variance_uc_train = featureExtraction.SumVariance(variance_uc_train).reshape(1,-1) \n",
        "sum_variance_code_train = featureExtraction.SumVariance(variance_code_train).reshape(1,-1) \n",
        "\n",
        "normalizer.fit_transform(sum_variance_uc_train)\n",
        "normalizer.fit_transform(sum_variance_code_train)\n",
        "\n",
        "print('sum_variance_uc_train_shape', sum_variance_uc_train.shape)\n",
        "print('sum_variance_code_train_shape', sum_variance_code_train.shape)\n",
        "# 5) SCQ Features\n",
        "avg_scq_uc_train = featureExtraction.AvgSCQ(SCQ_uc_train).reshape(1,-1) \n",
        "avg_scq_code_train = featureExtraction.AvgSCQ(SCQ_code_train).reshape(1,-1) \n",
        "\n",
        "normalizer.fit_transform(avg_scq_uc_train)\n",
        "normalizer.fit_transform(avg_scq_code_train)\n",
        "\n",
        "\n",
        "print('avg_scq_uc_train_shape', avg_scq_uc_train.shape)\n",
        "print('avg_scq_code_train_shape', avg_scq_code_train.shape)\n",
        "\n",
        "max_scq_uc_train = featureExtraction.MaxSCQ(SCQ_uc_train).reshape(1,-1) \n",
        "max_scq_code_train = featureExtraction.MaxSCQ(SCQ_code_train).reshape(1,-1) \n",
        "\n",
        "normalizer.fit_transform(max_scq_uc_train)\n",
        "normalizer.fit_transform(max_scq_code_train)\n",
        "\n",
        "\n",
        "\n",
        "print('max_scq_uc_train_shape', max_scq_uc_train.shape)\n",
        "print('max_scq_code_train_shape', max_scq_code_train.shape)\n",
        "\n",
        "sum_sqc_uc_train = featureExtraction.SumSCQ(SCQ_uc_train).reshape(1,-1) \n",
        "sum_sqc_code_train = featureExtraction.SumSCQ(SCQ_code_train).reshape(1,-1) \n",
        "\n",
        "normalizer.fit_transform(sum_sqc_uc_train)\n",
        "normalizer.fit_transform(sum_sqc_code_train)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "print('sum_sqc_uc_train_shape', sum_sqc_uc_train.shape)\n",
        "print('sum_sqc_code_train_shape', sum_sqc_code_train.shape)\n",
        "\n",
        "# 6) PMI Features\n",
        "\n",
        "avg_pmi_uc_train = featureExtraction.AvgPMI(PMI_uc_train).reshape(1,-1) \n",
        "avg_pmi_code_train = featureExtraction.AvgPMI(PMI_code_train).reshape(1,-1) \n",
        "\n",
        "normalizer.fit_transform(avg_pmi_uc_train)\n",
        "normalizer.fit_transform(avg_pmi_code_train)\n",
        "\n",
        "\n",
        "\n",
        "print('avg_pmi_uc_train_shape', avg_pmi_uc_train.shape)\n",
        "print('avg_pmi_code_train_shape', avg_pmi_code_train.shape)\n",
        "\n",
        "max_pmi_uc_train = featureExtraction.MaxPMI(PMI_uc_train).reshape(1,-1) \n",
        "max_pmi_code_train = featureExtraction.MaxPMI(PMI_code_train).reshape(1,-1) \n",
        "\n",
        "normalizer.fit_transform(max_pmi_uc_train)\n",
        "normalizer.fit_transform(max_pmi_code_train)\n",
        "\n",
        "\n",
        "print('max_pmi_uc_train_shape', max_pmi_uc_train.shape)\n",
        "print('max_pmi_code_train_shape', max_pmi_code_train.shape)\n",
        "# 7) QS Features\n",
        "\n",
        "qs_uc_train = featureExtraction.QS(UC_documents_train, code_documents_train).reshape(1,-1) \n",
        "qs_code_train = featureExtraction.QS(code_documents_train, UC_documents_train).reshape(1,-1) \n",
        "\n",
        "normalizer.fit_transform(qs_uc_train)\n",
        "normalizer.fit_transform(qs_code_train)\n",
        "\n",
        "\n",
        "print('qs_uc_train_shape', qs_uc_train.shape)\n",
        "print('qs_code_train_shape', qs_code_train.shape)\n",
        "\n",
        "# 8) SCS Features\n",
        "UC_SCS_train = featureExtraction.simplifiedClarityScore(UC_documents_train, UC_count_matrix_train, tf_code_dict_train).reshape(1,-1) \n",
        "CC_SCS_train = featureExtraction.simplifiedClarityScore(code_documents_train, code_count_matrix_train, tf_uc_dict_train).reshape(1,-1) \n",
        "\n",
        "normalizer.fit_transform(UC_SCS_train)\n",
        "normalizer.fit_transform(CC_SCS_train)\n",
        "\n",
        "print('UC_SCS_train_shape', UC_SCS_train.shape)\n",
        "print('CC_SCS_train_shape', CC_SCS_train.shape)\n",
        "\n",
        "# 9) Coherence Score Features\n",
        "UC_CoherenceScore_train = featureExtraction.CoherenceScore(UC_documents_train, tfidf_matrix_code_train).reshape(1,-1) \n",
        "CC_CoherenceScore_train = featureExtraction.CoherenceScore(code_documents_train, tfidf_matrix_uc_train).reshape(1,-1) \n",
        "\n",
        "normalizer.fit_transform(UC_CoherenceScore_train)\n",
        "normalizer.fit_transform(CC_CoherenceScore_train)\n",
        "\n",
        "print('UC_CoherenceScore_train_shape', UC_CoherenceScore_train.shape)\n",
        "print('CC_CoherenceScore_train_shape', CC_CoherenceScore_train.shape)\n",
        "\n",
        "# ------------------------pre-retrieval (21 metrics) Test--------------------------#\n",
        "# 1) IDF Features\n",
        "avg_idf_uc_test = featureExtraction.AvgIDF(idf_uc_test).reshape(1,-1)\n",
        "avg_idf_code_test = featureExtraction.AvgIDF(idf_code_test).reshape(1,-1)\n",
        "\n",
        "normalizer.fit_transform(avg_idf_uc_test)\n",
        "normalizer.fit_transform(avg_idf_code_test)\n",
        "\n",
        "print('avg_idf_uc_test_shape', avg_idf_uc_test.shape)\n",
        "print('avg_idf_code_test_shape', avg_idf_code_test.shape)\n",
        "\n",
        "max_idf_uc_test = featureExtraction.MaxIDF(idf_uc_test).reshape(1,-1)\n",
        "max_idf_code_test = featureExtraction.MaxIDF(idf_code_test).reshape(1,-1)\n",
        "\n",
        "normalizer.fit_transform(max_idf_uc_test)\n",
        "normalizer.fit_transform(max_idf_code_test)\n",
        "\n",
        "print('max_idf_uc_test_shape', max_idf_uc_test.shape)\n",
        "print('max_idf_code_test_shape', max_idf_code_test.shape)\n",
        "\n",
        "dev_idf_uc_test = featureExtraction.DevIDF(idf_uc_test).reshape(1,-1)\n",
        "dev_idf_code_test = featureExtraction.DevIDF(idf_code_test).reshape(1,-1)\n",
        "\n",
        "normalizer.fit_transform(dev_idf_uc_test)\n",
        "normalizer.fit_transform(dev_idf_code_test)\n",
        "\n",
        "print('dev_idf_uc_test_shape', dev_idf_uc_test.shape)\n",
        "print('dev_idf_code_test_shape', dev_idf_code_test.shape)\n",
        "\n",
        "# 2) ICTF Features\n",
        "avg_ictf_uc_test = featureExtraction.AvgICTF(ictf_uc_test).reshape(1,-1)\n",
        "avg_ictf_code_test = featureExtraction.AvgICTF(ictf_code_test).reshape(1,-1)\n",
        "\n",
        "normalizer.fit_transform(avg_ictf_uc_test)\n",
        "normalizer.fit_transform(avg_ictf_code_test)\n",
        "\n",
        "print('avg_ictf_uc_test_shape', avg_ictf_uc_test.shape)\n",
        "print('avg_ictf_code_test_shape', avg_ictf_code_test.shape)\n",
        "\n",
        "max_ictf_uc_test = featureExtraction.MaxICTF(ictf_uc_test).reshape(1,-1)\n",
        "max_ictf_code_test = featureExtraction.MaxICTF(ictf_code_test).reshape(1,-1)\n",
        "\n",
        "normalizer.fit_transform(max_ictf_uc_test)\n",
        "normalizer.fit_transform(max_ictf_code_test)\n",
        "\n",
        "print('max_ictf_uc_test_shape', max_ictf_uc_test.shape)\n",
        "print('max_ictf_code_test_shape', max_ictf_code_test.shape)\n",
        "\n",
        "dev_ictf_uc_test = featureExtraction.DevICTF(ictf_uc_test).reshape(1,-1)\n",
        "dev_ictf_code_test = featureExtraction.DevICTF(ictf_code_test).reshape(1,-1)\n",
        "\n",
        "normalizer.fit_transform(dev_ictf_uc_test)\n",
        "normalizer.fit_transform(dev_ictf_code_test)\n",
        "\n",
        "print('dev_ictf_uc_test_shape', dev_ictf_uc_test.shape)\n",
        "print('dev_ictf_code_test_shape', dev_ictf_code_test.shape)\n",
        "\n",
        "# 3) Entropy Features\n",
        "avg_entropy_uc_test = featureExtraction.AvgEntropy(entropy_uc_test).reshape(1,-1)\n",
        "avg_entropy_code_test = featureExtraction.AvgEntropy(entropy_code_test).reshape(1,-1)\n",
        "\n",
        "normalizer.fit_transform(avg_entropy_uc_test)\n",
        "normalizer.fit_transform(avg_entropy_code_test)\n",
        "\n",
        "print('avg_entropy_uc_test_shape', avg_entropy_uc_test.shape)\n",
        "print('avg_entropy_code_test_shape', avg_entropy_code_test.shape)\n",
        "\n",
        "max_entropy_uc_test = featureExtraction.MaxEntropy(entropy_uc_test).reshape(1,-1)\n",
        "max_entropy_code_test = featureExtraction.MaxEntropy(entropy_code_test).reshape(1,-1)\n",
        "\n",
        "normalizer.fit_transform(max_entropy_uc_test)\n",
        "normalizer.fit_transform(max_entropy_code_test)\n",
        "\n",
        "print('max_entropy_uc_test_shape', max_entropy_uc_test.shape)\n",
        "print('max_entropy_code_test_shape', max_entropy_code_test.shape)\n",
        "\n",
        "med_entropy_uc_test = featureExtraction.MedEntropy(entropy_uc_test).reshape(1,-1)\n",
        "med_entropy_code_test = featureExtraction.MedEntropy(entropy_code_test).reshape(1,-1)\n",
        "\n",
        "normalizer.fit_transform(med_entropy_uc_test)\n",
        "normalizer.fit_transform(med_entropy_code_test)\n",
        "\n",
        "print('med_entropy_uc_test_shape', med_entropy_uc_test.shape)\n",
        "print('med_entropy_code_test_shape', med_entropy_code_test.shape)\n",
        "\n",
        "dev_entropy_uc_test = featureExtraction.DevEntropy(entropy_uc_test).reshape(1,-1)\n",
        "dev_entropy_code_test = featureExtraction.DevEntropy(entropy_code_test).reshape(1,-1)\n",
        "\n",
        "normalizer.fit_transform(dev_entropy_uc_test)\n",
        "normalizer.fit_transform(dev_entropy_code_test)\n",
        "\n",
        "print('dev_entropy_uc_test_shape', dev_entropy_uc_test.shape)\n",
        "print('dev_entropy_code_test_shape', dev_entropy_code_test.shape)\n",
        "\n",
        "# 4) Variance Features\n",
        "\n",
        "avg_variance_uc_test = featureExtraction.AvgVariance(variance_uc_test).reshape(1,-1) \n",
        "avg_variance_code_test = featureExtraction.AvgVariance(variance_code_test).reshape(1,-1) \n",
        "\n",
        "normalizer.fit_transform(avg_variance_uc_test)\n",
        "normalizer.fit_transform(avg_variance_code_test)\n",
        "\n",
        "print('avg_variance_uc_test_shape', avg_variance_uc_test.shape)\n",
        "print('avg_variance_code_test_shape', avg_variance_code_test.shape)\n",
        "\n",
        "max_variance_uc_test = featureExtraction.MaxVariance(variance_uc_test).reshape(1,-1) \n",
        "max_variance_code_test = featureExtraction.MaxVariance(variance_code_test).reshape(1,-1) \n",
        "\n",
        "normalizer.fit_transform(max_variance_uc_test)\n",
        "normalizer.fit_transform(max_variance_code_test)\n",
        "\n",
        "print('max_variance_uc_test_shape', max_variance_uc_test.shape)\n",
        "print('max_variance_code_test_shape', max_variance_code_test.shape)\n",
        "\n",
        "sum_variance_uc_test = featureExtraction.SumVariance(variance_uc_test).reshape(1,-1) \n",
        "sum_variance_code_test = featureExtraction.SumVariance(variance_code_test).reshape(1,-1) \n",
        "\n",
        "normalizer.fit_transform(sum_variance_uc_test)\n",
        "normalizer.fit_transform(sum_variance_code_test)\n",
        "\n",
        "print('sum_variance_uc_test_shape', sum_variance_uc_test.shape)\n",
        "print('sum_variance_code_test_shape', sum_variance_code_test.shape)\n",
        "\n",
        "# 5) SCQ Features\n",
        "avg_scq_uc_test = featureExtraction.AvgSCQ(SCQ_uc_test).reshape(1,-1) \n",
        "avg_scq_code_test = featureExtraction.AvgSCQ(SCQ_code_test).reshape(1,-1) \n",
        "\n",
        "normalizer.fit_transform(avg_scq_uc_test)\n",
        "normalizer.fit_transform(avg_scq_code_test)\n",
        "\n",
        "print('avg_scq_uc_test_shape', avg_scq_uc_test.shape)\n",
        "print('avg_scq_code_test_shape', avg_scq_code_test.shape)\n",
        "\n",
        "max_scq_uc_test = featureExtraction.MaxSCQ(SCQ_uc_test).reshape(1,-1) \n",
        "max_scq_code_test = featureExtraction.MaxSCQ(SCQ_code_test).reshape(1,-1) \n",
        "\n",
        "normalizer.fit_transform(max_scq_uc_test)\n",
        "normalizer.fit_transform(max_scq_code_test)\n",
        "\n",
        "print('max_scq_uc_test_shape', max_scq_uc_test.shape)\n",
        "print('max_scq_code_test_shape', max_scq_code_test.shape)\n",
        "\n",
        "sum_sqc_uc_test = featureExtraction.SumSCQ(SCQ_uc_test).reshape(1,-1) \n",
        "sum_sqc_code_test = featureExtraction.SumSCQ(SCQ_code_test).reshape(1,-1) \n",
        "\n",
        "normalizer.fit_transform(sum_sqc_uc_test)\n",
        "normalizer.fit_transform(sum_sqc_code_test)\n",
        "\n",
        "print('sum_sqc_uc_test_shape', sum_sqc_uc_test.shape)\n",
        "print('sum_sqc_code_test_shape', sum_sqc_code_test.shape)\n",
        "\n",
        "# 6) PMI Features\n",
        "\n",
        "avg_pmi_uc_test = featureExtraction.AvgPMI(PMI_uc_test).reshape(1,-1) \n",
        "avg_pmi_code_test = featureExtraction.AvgPMI(PMI_code_test).reshape(1,-1) \n",
        "\n",
        "normalizer.fit_transform(avg_pmi_uc_test)\n",
        "normalizer.fit_transform(avg_pmi_code_test)\n",
        "\n",
        "print('avg_pmi_uc_test_shape', avg_pmi_uc_test.shape)\n",
        "print('avg_pmi_code_test_shape', avg_pmi_code_test.shape)\n",
        "\n",
        "max_pmi_uc_test = featureExtraction.MaxPMI(PMI_uc_test).reshape(1,-1) \n",
        "max_pmi_code_test = featureExtraction.MaxPMI(PMI_code_test).reshape(1,-1) \n",
        "\n",
        "normalizer.fit_transform(max_pmi_uc_test)\n",
        "normalizer.fit_transform(max_pmi_code_test)\n",
        "\n",
        "print('max_pmi_uc_test_shape', max_pmi_uc_test.shape)\n",
        "print('max_pmi_code_test_shape', max_pmi_code_test.shape)\n",
        "\n",
        "# 7) QS Features\n",
        "\n",
        "qs_uc_test = featureExtraction.QS(UC_documents_test, code_documents_test).reshape(1,-1) \n",
        "qs_code_test = featureExtraction.QS(code_documents_test, UC_documents_test).reshape(1,-1) \n",
        "\n",
        "normalizer.fit_transform(qs_uc_test)\n",
        "normalizer.fit_transform(qs_code_test)\n",
        "\n",
        "print('qs_uc_test_shape', qs_uc_test.shape)\n",
        "print('qs_code_test_shape', qs_code_test.shape)\n",
        "\n",
        "# 8) SCS Features\n",
        "UC_SCS_test = featureExtraction.simplifiedClarityScore(UC_documents_test, UC_count_matrix_test, tf_code_dict_test).reshape(1,-1) \n",
        "CC_SCS_test = featureExtraction.simplifiedClarityScore(code_documents_test, code_count_matrix_test, tf_uc_dict_test).reshape(1,-1) \n",
        "\n",
        "normalizer.fit_transform(UC_SCS_test)\n",
        "normalizer.fit_transform(CC_SCS_test)\n",
        "\n",
        "print('UC_SCS_test_shape', UC_SCS_test.shape)\n",
        "print('CC_SCS_test_shape', CC_SCS_test.shape)\n",
        "\n",
        "# 9) Coherence Score Features\n",
        "UC_CoherenceScore_test = featureExtraction.CoherenceScore(UC_documents_test, tfidf_matrix_code_test).reshape(1,-1) \n",
        "CC_CoherenceScore_test = featureExtraction.CoherenceScore(code_documents_test, tfidf_matrix_uc_test).reshape(1,-1) \n",
        "\n",
        "normalizer.fit_transform(UC_CoherenceScore_test)\n",
        "normalizer.fit_transform(CC_CoherenceScore_test)\n",
        "\n",
        "print('UC_CoherenceScore_test_shape', UC_CoherenceScore_test.shape)\n",
        "print('CC_CoherenceScore_test_shape', CC_CoherenceScore_test.shape)\n",
        "\n",
        "#66min"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "np.save('./pickles/avg_idf_uc_train.npy', avg_idf_uc_train)\n",
        "np.save('./pickles/avg_idf_code_train.npy', avg_idf_code_train)\n",
        "\n",
        "np.save('./pickles/max_idf_uc_train.npy', max_idf_uc_train)\n",
        "np.save('./pickles/max_idf_code_train.npy', max_idf_code_train)\n",
        "\n",
        "np.save('./pickles/dev_idf_uc_train.npy', dev_idf_uc_train)\n",
        "np.save('./pickles/dev_idf_code_train.npy', dev_idf_code_train)\n",
        "\n",
        "\n",
        "np.save('./pickles/avg_ictf_uc_train.npy', avg_ictf_uc_train)\n",
        "np.save('./pickles/avg_ictf_code_train.npy', avg_ictf_code_train)\n",
        "\n",
        "\n",
        "np.save('./pickles/max_ictf_uc_train.npy', max_ictf_uc_train)\n",
        "np.save('./pickles/max_ictf_code_train.npy', max_ictf_code_train)\n",
        "\n",
        "\n",
        "np.save('./pickles/dev_ictf_uc_train.npy', dev_ictf_uc_train)\n",
        "np.save('./pickles/dev_ictf_code_train.npy', dev_ictf_code_train)\n",
        "\n",
        "np.save('./pickles/avg_entropy_uc_train.npy', avg_entropy_uc_train)\n",
        "np.save('./pickles/avg_entropy_code_train.npy', avg_entropy_code_train)\n",
        "\n",
        "\n",
        "np.save('./pickles/max_entropy_uc_train.npy', max_entropy_uc_train)\n",
        "np.save('./pickles/max_entropy_code_train.npy', max_entropy_code_train)\n",
        "\n",
        "\n",
        "np.save('./pickles/max_entropy_uc_train.npy', max_entropy_uc_train)\n",
        "np.save('./pickles/max_entropy_code_train.npy', max_entropy_code_train)\n",
        "\n",
        "np.save('./pickles/med_entropy_uc_train.npy', med_entropy_uc_train)\n",
        "np.save('./pickles/med_entropy_code_train.npy', med_entropy_code_train)\n",
        "\n",
        "np.save('./pickles/dev_entropy_uc_train.npy', dev_entropy_uc_train)\n",
        "np.save('./pickles/dev_entropy_code_train.npy', dev_entropy_code_train)\n",
        "\n",
        "np.save('./pickles/avg_variance_uc_train.npy', avg_variance_uc_train)\n",
        "np.save('./pickles/avg_variance_code_train.npy', avg_variance_code_train)\n",
        "\n",
        "np.save('./pickles/max_variance_uc_train.npy', max_variance_uc_train)\n",
        "np.save('./pickles/max_variance_code_train.npy', max_variance_code_train)\n",
        "\n",
        "np.save('./pickles/sum_variance_uc_train.npy', sum_variance_uc_train)\n",
        "np.save('./pickles/sum_variance_code_train.npy', sum_variance_code_train)\n",
        "\n",
        "np.save('./pickles/avg_scq_uc_train.npy', avg_scq_uc_train)\n",
        "np.save('./pickles/avg_scq_code_train.npy', avg_scq_code_train)\n",
        "\n",
        "np.save('./pickles/max_scq_uc_train.npy', max_scq_uc_train)\n",
        "np.save('./pickles/max_scq_code_train.npy', max_scq_code_train)\n",
        "\n",
        "\n",
        "np.save('./pickles/sum_sqc_uc_train.npy', sum_sqc_uc_train)\n",
        "np.save('./pickles/sum_sqc_code_train.npy', sum_sqc_code_train)\n",
        "\n",
        "np.save('./pickles/avg_pmi_uc_train.npy', avg_pmi_uc_train)\n",
        "np.save('./pickles/avg_pmi_code_train.npy', avg_pmi_code_train)\n",
        "\n",
        "np.save('./pickles/max_pmi_uc_train.npy', max_pmi_uc_train)\n",
        "np.save('./pickles/max_pmi_code_train.npy', max_pmi_code_train)\n",
        "\n",
        "np.save('./pickles/qs_uc_train.npy', qs_uc_train)\n",
        "np.save('./pickles/qs_code_train.npy', qs_code_train)\n",
        "\n",
        "np.save('./pickles/UC_SCS_train.npy', UC_SCS_train)\n",
        "np.save('./pickles/CC_SCS_train.npy', CC_SCS_train)\n",
        "\n",
        "np.save('./pickles/UC_CoherenceScore_train.npy', UC_CoherenceScore_train)\n",
        "np.save('./pickles/CC_CoherenceScore_train.npy', CC_CoherenceScore_train)\n",
        "\n",
        "np.save('./pickles/avg_idf_uc_test.npy', avg_idf_uc_test)\n",
        "np.save('./pickles/avg_idf_code_test.npy', avg_idf_code_test)\n",
        "\n",
        "np.save('./pickles/max_idf_uc_test.npy', max_idf_uc_test)\n",
        "np.save('./pickles/max_idf_code_test.npy', max_idf_code_test)\n",
        "\n",
        "np.save('./pickles/dev_idf_uc_test.npy', dev_idf_uc_test)\n",
        "np.save('./pickles/dev_idf_code_test.npy', dev_idf_code_test)\n",
        "\n",
        "np.save('./pickles/avg_ictf_uc_test.npy', avg_ictf_uc_test)\n",
        "np.save('./pickles/avg_ictf_code_test.npy', avg_ictf_code_test)\n",
        "\n",
        "np.save('./pickles/max_ictf_uc_test.npy', max_ictf_uc_test)\n",
        "np.save('./pickles/max_ictf_code_test.npy', max_ictf_code_test)\n",
        "\n",
        "np.save('./pickles/dev_ictf_uc_test.npy', dev_ictf_uc_test)\n",
        "np.save('./pickles/dev_ictf_code_test.npy', dev_ictf_code_test)\n",
        "\n",
        "np.save('./pickles/avg_entropy_uc_test.npy', avg_entropy_uc_test)\n",
        "np.save('./pickles/avg_entropy_code_test.npy', avg_entropy_code_test)\n",
        "\n",
        "np.save('./pickles/max_entropy_uc_test.npy', max_entropy_uc_test)\n",
        "np.save('./pickles/max_entropy_code_test.npy', max_entropy_code_test)\n",
        "\n",
        "np.save('./pickles/med_entropy_uc_test.npy', med_entropy_uc_test)\n",
        "np.save('./pickles/med_entropy_code_test.npy', med_entropy_code_test)\n",
        "\n",
        "np.save('./pickles/dev_entropy_uc_test.npy', dev_entropy_uc_test)\n",
        "np.save('./pickles/dev_entropy_code_test.npy', dev_entropy_code_test)\n",
        "\n",
        "np.save('./pickles/avg_variance_uc_test.npy', avg_variance_uc_test)\n",
        "np.save('./pickles/avg_variance_code_test.npy', avg_variance_code_test)\n",
        "\n",
        "np.save('./pickles/max_variance_uc_test.npy', max_variance_uc_test)\n",
        "np.save('./pickles/max_variance_code_test.npy', max_variance_code_test)\n",
        "\n",
        "np.save('./pickles/sum_variance_uc_test.npy', sum_variance_uc_test)\n",
        "np.save('./pickles/sum_variance_code_test.npy', sum_variance_code_test)\n",
        "\n",
        "np.save('./pickles/avg_scq_uc_test.npy', avg_scq_uc_test)\n",
        "np.save('./pickles/avg_scq_code_test.npy', avg_scq_code_test)\n",
        "\n",
        "np.save('./pickles/max_scq_uc_test.npy', max_scq_uc_test)\n",
        "np.save('./pickles/max_scq_code_test.npy', max_scq_code_test)\n",
        "\n",
        "np.save('./pickles/sum_sqc_uc_test.npy', sum_sqc_uc_test)\n",
        "np.save('./pickles/sum_sqc_code_test.npy', sum_sqc_code_test)\n",
        "\n",
        "np.save('./pickles/avg_pmi_uc_test.npy', avg_pmi_uc_test)\n",
        "np.save('./pickles/avg_pmi_code_test.npy', avg_pmi_code_test)\n",
        "\n",
        "np.save('./pickles/max_pmi_uc_test.npy', max_pmi_uc_test)\n",
        "np.save('./pickles/max_pmi_code_test.npy', max_pmi_code_test)\n",
        "\n",
        "np.save('./pickles/qs_uc_test.npy', qs_uc_test)\n",
        "np.save('./pickles/qs_code_test.npy', qs_code_test)\n",
        "\n",
        "np.save('./pickles/UC_SCS_test.npy', UC_SCS_test)\n",
        "np.save('./pickles/CC_SCS_test.npy', CC_SCS_test)\n",
        "\n",
        "np.save('./pickles/UC_CoherenceScore_test.npy', UC_CoherenceScore_test)\n",
        "np.save('./pickles/CC_CoherenceScore_test.npy', CC_CoherenceScore_test)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Post Retrieval features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#BASSANT COMMENTED THIS\n",
        "# #------------------------post-retrieval (7 metrics) Train --------------------------#\n",
        "# # 1.1) Subquery overlap using jensenShannon\n",
        "# code_queries_score_JensenShannon_train = featureExtraction.SubqueryOverlap(code_documents_train, featureExtraction.JensenShannon,\"JS\", UC_count_matrix_train, code_count_matrix_train)\n",
        "# UC_queries_score_JensenShannon_train = featureExtraction.SubqueryOverlap(UC_documents_train, featureExtraction.JensenShannon,\"JS\",code_count_matrix_train, UC_count_matrix_train)\n",
        "\n",
        "# print('code_queries_score_JensenShannon_train', code_queries_score_JensenShannon_train.shape)\n",
        "# print('UC_queries_score_JensenShannon_train', UC_queries_score_JensenShannon_train.shape)\n",
        "\n",
        "# # 1.2) Subquery overlap using VSM\n",
        "# code_queries_score_VSM_train = featureExtraction.SubqueryOverlap(code_documents_train, featureExtraction.VectorSpaceModel,\"VSM\", UC_count_matrix_train, code_count_matrix_train)\n",
        "# UC_queries_score_VSM_train = featureExtraction.SubqueryOverlap(UC_documents_train, featureExtraction.VectorSpaceModel,\"VSM\", code_count_matrix_train, UC_count_matrix_train)\n",
        "\n",
        "# print('code_queries_score_VSM_train', code_queries_score_VSM_train.shape)\n",
        "# print('UC_queries_score_VSM_train', UC_queries_score_VSM_train.shape)\n",
        "\n",
        "# #1.3) Subquery overlap using BM25\n",
        "# code_queries_score_BM25_train = featureExtraction.SubqueryOverlap(code_documents_train, featureExtraction.BM25,\"BM\", UC_documents_train,idf_uc_dict_train,UC_count_matrix_train)\n",
        "# UC_queries_score_BM25_train = featureExtraction.SubqueryOverlap(UC_documents_train, featureExtraction.BM25,\"BM\", code_documents_train,idf_code_dict_train, code_count_matrix_train)\n",
        "\n",
        "# print('code_queries_score_BM25_train', code_queries_score_BM25_train.shape)\n",
        "# print('UC_queries_score_BM25_train', UC_queries_score_BM25_train.shape)\n",
        "\n",
        "# #1.4) Subquery overlap using JM smoothing\n",
        "# code_queries_score_JM_train = featureExtraction.SubqueryOverlap(code_documents_train, featureExtraction.SmoothingMethods,\"SM\", UC_documents_train,UC_count_matrix_train,tf_uc_dict_train,True)\n",
        "# UC_queries_score_JM_train = featureExtraction.SubqueryOverlap(UC_documents_train, featureExtraction.SmoothingMethods,\"SM\", code_documents_train,code_count_matrix_train,tf_code_dict_train,True)\n",
        "\n",
        "# print('code_queries_score_JM_train', code_queries_score_JM_train.shape)\n",
        "# print('UC_queries_score_JM_train', UC_queries_score_JM_train.shape)\n",
        "\n",
        "# # 1.5) Subquery overlap using DP smoothing\n",
        "# code_queries_score_DP_train = featureExtraction.SubqueryOverlap(code_documents_train, featureExtraction.SmoothingMethods,\"SM\", UC_documents_train, UC_count_matrix_train,tf_uc_dict_train,False)\n",
        "# UC_queries_score_DP_train = featureExtraction.SubqueryOverlap(UC_documents_train, featureExtraction.SmoothingMethods,\"SM\", code_documents_train, code_count_matrix_train,tf_code_dict_train,False)\n",
        "\n",
        "# print('code_queries_score_DP_train', code_queries_score_DP_train.shape)\n",
        "# print('UC_queries_score_DP_train', UC_queries_score_DP_train.shape)\n",
        "\n",
        "# #------------------------post-retrieval (7 metrics) Test --------------------------#\n",
        "# # 1.1) Subquery overlap using jensenShannon\n",
        "# code_queries_score_JensenShannon_test = featureExtraction.SubqueryOverlap(code_documents_test, featureExtraction.JensenShannon,\"JS\", UC_count_matrix_test, code_count_matrix_test)\n",
        "# UC_queries_score_JensenShannon_test = featureExtraction.SubqueryOverlap(UC_documents_test, featureExtraction.JensenShannon,\"JS\",code_count_matrix_test, UC_count_matrix_test)\n",
        "\n",
        "# print('code_queries_score_JensenShannon_test', code_queries_score_JensenShannon_test.shape)\n",
        "# print('UC_queries_score_JensenShannon_test', UC_queries_score_JensenShannon_test.shape)\n",
        "\n",
        "# # 1.2) Subquery overlap using VSM\n",
        "# code_queries_score_VSM_test = featureExtraction.SubqueryOverlap(code_documents_test, featureExtraction.VectorSpaceModel,\"VSM\", UC_count_matrix_test, code_count_matrix_test)\n",
        "# UC_queries_score_VSM_test = featureExtraction.SubqueryOverlap(UC_documents_test, featureExtraction.VectorSpaceModel,\"VSM\", code_count_matrix_test, UC_count_matrix_test)\n",
        "\n",
        "# print('code_queries_score_VSM_test', code_queries_score_VSM_test.shape)\n",
        "# print('UC_queries_score_VSM_test', UC_queries_score_VSM_test.shape)\n",
        "\n",
        "# #1.3) Subquery overlap using BM25\n",
        "# code_queries_score_BM25_test = featureExtraction.SubqueryOverlap(code_documents_test, featureExtraction.BM25,\"BM\", UC_documents_test,idf_uc_dict_test,UC_count_matrix_test)\n",
        "# UC_queries_score_BM25_test = featureExtraction.SubqueryOverlap(UC_documents_test, featureExtraction.BM25,\"BM\", code_documents_test,idf_code_dict_test, code_count_matrix_test)\n",
        "\n",
        "# print('code_queries_score_BM25_test', code_queries_score_BM25_test.shape)\n",
        "# print('UC_queries_score_BM25_test', UC_queries_score_BM25_test.shape)\n",
        "\n",
        "# #1.4) Subquery overlap using JM smoothing\n",
        "# code_queries_score_JM_test = featureExtraction.SubqueryOverlap(code_documents_test, featureExtraction.SmoothingMethods,\"SM\", UC_documents_test,UC_count_matrix_test,tf_uc_dict_test,True)\n",
        "# UC_queries_score_JM_test = featureExtraction.SubqueryOverlap(UC_documents_test, featureExtraction.SmoothingMethods,\"SM\", code_documents_test,code_count_matrix_test,tf_code_dict_test,True)\n",
        "\n",
        "# print('code_queries_score_JM_test', code_queries_score_JM_test.shape)\n",
        "# print('UC_queries_score_JM_test', UC_queries_score_JM_test.shape)\n",
        "\n",
        "# # 1.5) Subquery overlap using DP smoothing\n",
        "# code_queries_score_DP_test = featureExtraction.SubqueryOverlap(code_documents_test, featureExtraction.SmoothingMethods,\"SM\", UC_documents_test, UC_count_matrix_test,tf_uc_dict_test,False)\n",
        "# UC_queries_score_DP_test = featureExtraction.SubqueryOverlap(UC_documents_test, featureExtraction.SmoothingMethods,\"SM\", code_documents_test, code_count_matrix_test,tf_code_dict_test,False)\n",
        "\n",
        "# print('code_queries_score_DP_test', code_queries_score_DP_test.shape)\n",
        "# print('UC_queries_score_DP_test', UC_queries_score_DP_test.shape)\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#--------------------------------Train-------------------------------------------------------#\n",
        "\n",
        "# 2.1) Robustness Score using jensenShannon\n",
        "UC_RS_JS_train, UC_FRC_JS_train = featureExtraction.RobustnessScore(UC_documents_train,code_documents_train,\"JS\")\n",
        "code_RS_JS_train, code_FRC_JS_train = featureExtraction.RobustnessScore(code_documents_train,UC_documents_train,\"JS\")\n",
        "\n",
        "print('UC_RS_JS_train', UC_RS_JS_train.shape)\n",
        "print('code_RS_JS_train', code_RS_JS_train.shape)\n",
        "\n",
        "print('UC_FRC_JS_train', UC_FRC_JS_train.shape)\n",
        "print('code_FRC_JS_train', code_FRC_JS_train.shape)\n",
        "\n",
        "np.save('./pickles/UC_RS_JS_train.npy', UC_RS_JS_train)\n",
        "np.save('./pickles/code_RS_JS_train.npy', code_RS_JS_train)\n",
        "\n",
        "np.save('./pickles/UC_FRC_JS_train.npy', UC_FRC_JS_train)\n",
        "np.save('./pickles/code_FRC_JS_train.npy', code_FRC_JS_train)\n",
        "\n",
        "# 2.2) Robustness Score using VSM\n",
        "UC_RS_VSM_train, UC_FRC_VSM_train = featureExtraction.RobustnessScore(UC_documents_train,code_documents_train,\"VSM\")\n",
        "code_RS_VSM_train, code_FRC_VSM_train = featureExtraction.RobustnessScore(code_documents_train,UC_documents_train,\"VSM\")\n",
        "\n",
        "print('UC_RS_VSM_train', UC_RS_VSM_train.shape)\n",
        "print('code_RS_VSM_train', code_RS_VSM_train.shape)\n",
        "\n",
        "print('UC_FRC_VSM_train', UC_FRC_VSM_train.shape)\n",
        "print('code_FRC_VSM_train', code_FRC_VSM_train.shape)\n",
        "\n",
        "np.save('./pickles/UC_RS_VSM_train.npy', UC_RS_VSM_train)\n",
        "np.save('./pickles/code_RS_VSM_train.npy', code_RS_VSM_train)\n",
        "\n",
        "np.save('./pickles/UC_FRC_VSM_train.npy', UC_FRC_VSM_train)\n",
        "np.save('./pickles/code_FRC_VSM_train.npy', code_FRC_VSM_train)\n",
        "\n",
        "# 2.3) Robustness Score using BM25\n",
        "UC_RS_BM25_train, UC_FRC_BM25_train = featureExtraction.RobustnessScore(UC_documents_train,code_documents_train,\"BM\")\n",
        "code_RS_BM25_train, code_FRC_BM25_train = featureExtraction.RobustnessScore(code_documents_train,UC_documents_train,\"BM\")\n",
        "\n",
        "print('UC_RS_BM25_train', UC_RS_BM25_train.shape)\n",
        "print('code_RS_BM25_train', code_RS_BM25_train.shape)\n",
        "\n",
        "print('UC_FRC_BM25_train', UC_FRC_BM25_train.shape)\n",
        "print('code_FRC_BM25_train', code_FRC_BM25_train.shape)\n",
        "\n",
        "np.save('./pickles/UC_RS_BM25_train.npy', UC_RS_BM25_train)\n",
        "np.save('./pickles/code_RS_BM25_train.npy', code_RS_BM25_train)\n",
        "\n",
        "np.save('./pickles/UC_FRC_BM25_train.npy', UC_FRC_BM25_train)\n",
        "np.save('./pickles/code_FRC_BM25_train.npy', code_FRC_BM25_train)\n",
        "\n",
        "# 2.4) Robustness Score using JM smoothing\n",
        "UC_RS_JM_train, UC_FRC_JM_train = featureExtraction.RobustnessScore(UC_documents_train,code_documents_train,\"JM\")\n",
        "code_RS_JM_train, code_FRC_JM_train = featureExtraction.RobustnessScore(code_documents_train,UC_documents_train,\"JM\")\n",
        "\n",
        "print('UC_RS_JM_train', UC_RS_JM_train.shape)\n",
        "print('code_RS_JM_train', code_RS_JM_train.shape)\n",
        "\n",
        "print('UC_FRC_JM_train', UC_FRC_JM_train.shape)\n",
        "print('code_FRC_JM_train', code_FRC_JM_train.shape)\n",
        "\n",
        "np.save('./pickles/UC_RS_JM_train.npy', UC_RS_JM_train)\n",
        "np.save('./pickles/code_RS_JM_train.npy', code_RS_JM_train)\n",
        "\n",
        "np.save('./pickles/UC_FRC_JM_train.npy', UC_FRC_JM_train)\n",
        "np.save('./pickles/code_FRC_JM_train.npy', code_FRC_JM_train)\n",
        "\n",
        "# 2.5) Robustness Score using DP smoothing\n",
        "UC_RS_DP_train, UC_FRC_DP_train = featureExtraction.RobustnessScore(UC_documents_train,code_documents_train,\"DP\")\n",
        "code_RS_DP_train, code_FRC_DP_train = featureExtraction.RobustnessScore(code_documents_train,UC_documents_train,\"DP\")\n",
        "\n",
        "print('UC_RS_DP_train', UC_RS_DP_train.shape)\n",
        "print('code_RS_DP_train', code_RS_DP_train.shape)\n",
        "\n",
        "print('UC_FRC_DP_train', UC_FRC_DP_train.shape)\n",
        "print('code_FRC_DP_train', code_FRC_DP_train.shape)\n",
        "\n",
        "np.save('./pickles/UC_RS_DP_train.npy', UC_RS_DP_train)\n",
        "np.save('./pickles/code_RS_DP_train.npy', code_RS_DP_train)\n",
        "\n",
        "np.save('./pickles/UC_FRC_DP_train.npy', UC_FRC_DP_train)\n",
        "np.save('./pickles/code_FRC_DP_train.npy', code_FRC_DP_train)\n",
        "\n",
        "#--------------------------------------------------test----------------------------------------------------------------\n",
        "\n",
        "# 2.1) Robustness Score using jensenShannon\n",
        "UC_RS_JS_test, UC_FRC_JS_test = featureExtraction.RobustnessScore(UC_documents_test,code_documents_test,\"JS\")\n",
        "code_RS_JS_test, code_FRC_JS_test = featureExtraction.RobustnessScore(code_documents_test,UC_documents_test,\"JS\")\n",
        "\n",
        "print('UC_RS_JS_test', UC_RS_JS_test.shape)\n",
        "print('code_RS_JS_test', code_RS_JS_test.shape)\n",
        "\n",
        "print('UC_FRC_JS_test', UC_FRC_JS_test.shape)\n",
        "print('code_FRC_JS_test', code_FRC_JS_test.shape)\n",
        "\n",
        "np.save('./pickles/UC_RS_JS_test.npy', UC_RS_JS_test)\n",
        "np.save('./pickles/code_RS_JS_test.npy', code_RS_JS_test)\n",
        "\n",
        "np.save('./pickles/UC_FRC_JS_test.npy', UC_FRC_JS_test)\n",
        "np.save('./pickles/code_FRC_JS_test.npy', code_FRC_JS_test)\n",
        "\n",
        "# 2.2) Robustness Score using VSM\n",
        "UC_RS_VSM_test, UC_FRC_VSM_test = featureExtraction.RobustnessScore(UC_documents_test,code_documents_test,\"VSM\")\n",
        "code_RS_VSM_test, code_FRC_VSM_test = featureExtraction.RobustnessScore(code_documents_test,UC_documents_test,\"VSM\")\n",
        "\n",
        "print('UC_RS_VSM_test', UC_RS_VSM_test.shape)\n",
        "print('code_RS_VSM_test', code_RS_VSM_test.shape)\n",
        "\n",
        "print('UC_FRC_VSM_test', UC_FRC_VSM_test.shape)\n",
        "print('code_FRC_VSM_test', code_FRC_VSM_test.shape)\n",
        "\n",
        "np.save('./pickles/UC_RS_VSM_test.npy', UC_RS_VSM_test)\n",
        "np.save('./pickles/code_RS_VSM_test.npy', code_RS_VSM_test)\n",
        "\n",
        "np.save('./pickles/UC_FRC_VSM_test.npy', UC_FRC_VSM_test)\n",
        "np.save('./pickles/code_FRC_VSM_test.npy', code_FRC_VSM_test)\n",
        "\n",
        "# 2.3) Robustness Score using BM25\n",
        "UC_RS_BM25_test, UC_FRC_BM25_test = featureExtraction.RobustnessScore(UC_documents_test,code_documents_test,\"BM\")\n",
        "code_RS_BM25_test, code_FRC_BM25_test = featureExtraction.RobustnessScore(code_documents_test,UC_documents_test,\"BM\")\n",
        "\n",
        "print('UC_RS_BM25_test', UC_RS_BM25_test.shape)\n",
        "print('code_RS_BM25_test', code_RS_BM25_test.shape)\n",
        "\n",
        "print('UC_FRC_BM25_test', UC_FRC_BM25_test.shape)\n",
        "print('code_FRC_BM25_test', code_FRC_BM25_test.shape)\n",
        "\n",
        "np.save('./pickles/UC_RS_BM25_test.npy', UC_RS_BM25_test)\n",
        "np.save('./pickles/code_RS_BM25_test.npy', code_RS_BM25_test)\n",
        "\n",
        "np.save('./pickles/UC_FRC_BM25_test.npy', UC_FRC_BM25_test)\n",
        "np.save('./pickles/code_FRC_BM25_test.npy', code_FRC_BM25_test)\n",
        "\n",
        "# 2.4) Robustness Score using JM smoothing\n",
        "UC_RS_JM_test, UC_FRC_JM_test = featureExtraction.RobustnessScore(UC_documents_test,code_documents_test,\"JM\")\n",
        "code_RS_JM_test, code_FRC_JM_test = featureExtraction.RobustnessScore(code_documents_test,UC_documents_test,\"JM\")\n",
        "\n",
        "print('UC_RS_JM_test', UC_RS_JM_test.shape)\n",
        "print('code_RS_JM_test', code_RS_JM_test.shape)\n",
        "\n",
        "print('UC_FRC_JM_test', UC_FRC_JM_test.shape)\n",
        "print('code_FRC_JM_test', code_FRC_JM_test.shape)\n",
        "\n",
        "np.save('./pickles/UC_RS_JM_test.npy', UC_RS_JM_test)\n",
        "np.save('./pickles/code_RS_JM_test.npy', code_RS_JM_test)\n",
        "\n",
        "np.save('./pickles/UC_FRC_JM_test.npy', UC_FRC_JM_test)\n",
        "np.save('./pickles/code_FRC_JM_test.npy', code_FRC_JM_test)\n",
        "\n",
        "# 2.5) Robustness Score using DP smoothing\n",
        "UC_RS_DP_test, UC_FRC_DP_test = featureExtraction.RobustnessScore(UC_documents_test,code_documents_test,\"DP\")\n",
        "code_RS_DP_test, code_FRC_DP_test = featureExtraction.RobustnessScore(code_documents_test,UC_documents_test,\"DP\")\n",
        "\n",
        "print('UC_RS_DP_test', UC_RS_DP_test.shape)\n",
        "print('code_RS_DP_test', code_RS_DP_test.shape)\n",
        "\n",
        "print('UC_FRC_DP_test', UC_FRC_DP_test.shape)\n",
        "print('code_FRC_DP_test', code_FRC_DP_test.shape)\n",
        "\n",
        "np.save('./pickles/UC_RS_DP_test.npy', UC_RS_DP_test)\n",
        "np.save('./pickles/code_RS_DP_test.npy', code_RS_DP_test)\n",
        "\n",
        "np.save('./pickles/UC_FRC_DP_test.npy', UC_FRC_DP_test)\n",
        "np.save('./pickles/code_FRC_DP_test.npy', code_FRC_DP_test)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#-------------------------------------------------Train---------------------------------------------\n",
        "# 4.1) Clustering Tendency using JensenShannon\n",
        "UC_CT_JensenShannon_train = featureExtraction.ClusteringTendency(JS_UC_train.T,tfidf_matrix_uc_train,tfidf_matrix_code_train)\n",
        "code_CT_JensenShannon_train = featureExtraction.ClusteringTendency(JS_CC_train,tfidf_matrix_code_train,tfidf_matrix_uc_train)\n",
        "\n",
        "print(\"UC_CT_JensenShannon_train\",UC_CT_JensenShannon_train.shape)\n",
        "print(\"code_CT_JensenShannon_train\",code_CT_JensenShannon_train.shape)\n",
        "\n",
        "# 4.2) Clustering Tendency using VSM\n",
        "UC_CT_VSM_train = featureExtraction.ClusteringTendency(cosine_similarity_UC_train.T,tfidf_matrix_uc_train,tfidf_matrix_code_train)\n",
        "code_CT_VSM_train = featureExtraction.ClusteringTendency(cosine_similarity_CC_train,tfidf_matrix_code_train,tfidf_matrix_uc_train)\n",
        "\n",
        "print(\"UC_CT_VSM_train\",UC_CT_VSM_train.shape)\n",
        "print(\"code_CT_VSM_train\",code_CT_VSM_train.shape)\n",
        "\n",
        "# 4.3) Clustering Tendency using BM25\n",
        "UC_CT_BM25_train = featureExtraction.ClusteringTendency(BM25_UC_train,tfidf_matrix_uc_train,tfidf_matrix_code_train)\n",
        "code_CT_BM25_train = featureExtraction.ClusteringTendency(BM25_CC_train,tfidf_matrix_code_train,tfidf_matrix_uc_train)\n",
        "\n",
        "print(\"UC_CT_BM25_train\",UC_CT_BM25_train.shape)\n",
        "print(\"code_CT_BM25_train\",code_CT_BM25_train.shape)\n",
        "\n",
        "# 4.4) Clustering Tendency using JM\n",
        "UC_CT_JM_train = featureExtraction.ClusteringTendency(JM_UC_train,tfidf_matrix_uc_train,tfidf_matrix_code_train)\n",
        "code_CT_JM_train = featureExtraction.ClusteringTendency(JM_CC_train,tfidf_matrix_code_train,tfidf_matrix_uc_train)\n",
        "\n",
        "print(\"UC_CT_JM_train\",UC_CT_JM_train.shape)\n",
        "print(\"code_CT_JM_train\",code_CT_JM_train.shape)\n",
        "\n",
        "# 4.5) Clustering Tendency using DP\n",
        "UC_CT_DP_train = featureExtraction.ClusteringTendency(DP_UC_train,tfidf_matrix_uc_train,tfidf_matrix_code_train)\n",
        "code_CT_DP_train = featureExtraction.ClusteringTendency(DP_CC_train,tfidf_matrix_code_train,tfidf_matrix_uc_train)\n",
        "\n",
        "print(\"UC_CT_DP_train\",UC_CT_DP_train.shape)\n",
        "print(\"code_CT_DP_train\",code_CT_DP_train.shape)\n",
        "\n",
        "#----------------------------------test-------------------------------------------------\n",
        "# 4.1) Clustering Tendency using JensenShannon\n",
        "UC_CT_JensenShannon_test = featureExtraction.ClusteringTendency(JS_UC_test.T,tfidf_matrix_uc_test,tfidf_matrix_code_test)\n",
        "code_CT_JensenShannon_test = featureExtraction.ClusteringTendency(JS_CC_test,tfidf_matrix_code_test,tfidf_matrix_uc_test)\n",
        "\n",
        "print(\"UC_CT_JensenShannon_test\",UC_CT_JensenShannon_test.shape)\n",
        "print(\"code_CT_JensenShannon_test\",code_CT_JensenShannon_test.shape)\n",
        "\n",
        "# 4.2) Clustering Tendency using VSM\n",
        "UC_CT_VSM_test = featureExtraction.ClusteringTendency(cosine_similarity_UC_test.T,tfidf_matrix_uc_test,tfidf_matrix_code_test)\n",
        "code_CT_VSM_test = featureExtraction.ClusteringTendency(cosine_similarity_CC_test,tfidf_matrix_code_test,tfidf_matrix_uc_test)\n",
        "\n",
        "print(\"UC_CT_VSM_test\",UC_CT_VSM_test.shape)\n",
        "print(\"code_CT_VSM_test\",code_CT_VSM_test.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "BM25_UC_test = np.load('./pickles/BM25_UC_test.npy')\n",
        "BM25_CC_test = np.load('./pickles/BM25_CC_test.npy')\n",
        "\n",
        "# 4.3) Clustering Tendency using BM25\n",
        "UC_CT_BM25_test = featureExtraction.ClusteringTendency(BM25_UC_test,tfidf_matrix_uc_test,tfidf_matrix_code_test)\n",
        "code_CT_BM25_test = featureExtraction.ClusteringTendency(BM25_CC_test,tfidf_matrix_code_test,tfidf_matrix_uc_test)\n",
        "\n",
        "print(\"UC_CT_BM25_test\",UC_CT_BM25_test.shape)\n",
        "print(\"code_CT_BM25_test\",code_CT_BM25_test.shape)\n",
        "\n",
        "np.save('./pickles/UC_CT_BM25_test.npy', UC_CT_BM25_test)\n",
        "np.save('./pickles/code_CT_BM25_test.npy', code_CT_BM25_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "JM_UC_test = np.load('./pickles/JM_UC_test.npy')\n",
        "JM_CC_test = np.load('./pickles/JM_CC_test.npy')\n",
        "\n",
        "# 4.4) Clustering Tendency using JM\n",
        "UC_CT_JM_test = featureExtraction.ClusteringTendency(JM_UC_test,tfidf_matrix_uc_test,tfidf_matrix_code_test)\n",
        "code_CT_JM_test = featureExtraction.ClusteringTendency(JM_CC_test,tfidf_matrix_code_test,tfidf_matrix_uc_test)\n",
        "\n",
        "print(\"UC_CT_JM_test\",UC_CT_JM_test.shape)\n",
        "print(\"code_CT_JM_test\",code_CT_JM_test.shape)\n",
        "\n",
        "np.save('./pickles/UC_CT_JM_test.npy', UC_CT_JM_test)\n",
        "np.save('./pickles/code_CT_JM_test.npy', code_CT_JM_test)\n",
        "\n",
        "DP_UC_test = np.load('./pickles/DP_UC_test.npy')\n",
        "DP_CC_test = np.load('./pickles/DP_CC_test.npy')\n",
        "\n",
        "# 4.5) Clustering Tendency using DP\n",
        "UC_CT_DP_test = featureExtraction.ClusteringTendency(DP_UC_test,tfidf_matrix_uc_test,tfidf_matrix_code_test)\n",
        "code_CT_DP_test = featureExtraction.ClusteringTendency(DP_CC_test,tfidf_matrix_code_test,tfidf_matrix_uc_test)\n",
        "\n",
        "print(\"UC_CT_DP_test\",UC_CT_DP_test.shape)\n",
        "print(\"code_CT_DP_test\",code_CT_DP_test.shape)\n",
        "\n",
        "np.save('./pickles/UC_CT_DP_test.npy', UC_CT_DP_test)\n",
        "np.save('./pickles/code_CT_DP_test.npy', code_CT_DP_test)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "#------------------------------Train-------------------------------------------#\n",
        "# 5.1) Spatial AutoCorrelation using JensenShannon\n",
        "UC_SAC_JS_train = featureExtraction.SpatialAutoCorrelation(JS_UC_train.T,tfidf_matrix_code_train)\n",
        "code_SAC_JS_train = featureExtraction.SpatialAutoCorrelation(JS_CC_train,tfidf_matrix_uc_train)\n",
        "\n",
        "print(\"UC_SAC_JS_train\",UC_SAC_JS_train.shape)\n",
        "print(\"code_SAC_JS_train\",code_SAC_JS_train.shape)\n",
        "\n",
        "np.save('./pickles/UC_SAC_JensenShannon_train.npy',UC_SAC_JS_train)\n",
        "np.save('./pickles/code_SAC_JensenShannon_train.npy',code_SAC_JS_train)\n",
        "\n",
        "# 5.2) Spatial AutoCorrelation using VSM\n",
        "UC_SAC_VSM_train = featureExtraction.SpatialAutoCorrelation(cosine_similarity_UC_train.T,tfidf_matrix_code_train)\n",
        "code_SAC_VSM_train= featureExtraction.SpatialAutoCorrelation(cosine_similarity_CC_train,tfidf_matrix_uc_train)\n",
        "\n",
        "print(\"UC_SAC_VSM_train\",UC_SAC_VSM_train.shape)\n",
        "print(\"code_SAC_VSM_train\",code_SAC_VSM_train.shape)\n",
        "\n",
        "np.save('./pickles/UC_SAC_VSM_train.npy',UC_SAC_VSM_train)\n",
        "np.save('./pickles/code_SAC_VSM_train.npy',code_SAC_VSM_train)\n",
        "# 5.3) Spatial AutoCorrelation using BM25\n",
        "UC_SAC_BM25_train = featureExtraction.SpatialAutoCorrelation(BM25_UC_train,tfidf_matrix_code_train)\n",
        "code_SAC_BM25_train = featureExtraction.SpatialAutoCorrelation(BM25_CC_train,tfidf_matrix_uc_train)\n",
        "\n",
        "print(\"UC_SAC_BM25_train\",UC_SAC_BM25_train.shape)\n",
        "print(\"code_SAC_BM25_train\",code_SAC_BM25_train.shape)\n",
        "\n",
        "np.save('./pickles/UC_SAC_BM25_train.npy',UC_SAC_BM25_train)\n",
        "np.save('./pickles/code_SAC_BM25_train.npy',code_SAC_BM25_train)\n",
        "\n",
        "# 5.4) Spatial AutoCorrelation using JM\n",
        "UC_SAC_JM_train = featureExtraction.SpatialAutoCorrelation(JM_UC_train,tfidf_matrix_code_train)\n",
        "code_SAC_JM_train= featureExtraction.SpatialAutoCorrelation(JM_CC_train,tfidf_matrix_uc_train)\n",
        "\n",
        "print(\"UC_SAC_JM_train\",UC_SAC_JM_train.shape)\n",
        "print(\"code_SAC_JM_train\",code_SAC_JM_train.shape)\n",
        "\n",
        "np.save('./pickles/UC_SAC_JM_train.npy',UC_SAC_JM_train)\n",
        "np.save('./pickles/code_SAC_JM_train.npy',code_SAC_JM_train)\n",
        "# 5.5) Spatial AutoCorrelation using DP\n",
        "UC_SAC_DP_train = featureExtraction.SpatialAutoCorrelation(DP_UC_train,tfidf_matrix_code_train)\n",
        "code_SAC_DP_train= featureExtraction.SpatialAutoCorrelation(DP_CC_train,tfidf_matrix_uc_train)\n",
        "\n",
        "print(\"UC_SAC_DP_train\",UC_SAC_DP_train.shape)\n",
        "print(\"code_SAC_DP_train\",code_SAC_DP_train.shape)\n",
        "\n",
        "np.save('./pickles/UC_SAC_DP_train.npy',UC_SAC_DP_train)\n",
        "np.save('./pickles/code_SAC_DP_train.npy',code_SAC_DP_train)\n",
        "#------------------------------Test-------------------------------------------#\n",
        "# 5.1) Spatial AutoCorrelation using JensenShannon\n",
        "UC_SAC_JS_test = featureExtraction.SpatialAutoCorrelation(JS_UC_test.T,tfidf_matrix_code_test)\n",
        "code_SAC_JS_test = featureExtraction.SpatialAutoCorrelation(JS_CC_test,tfidf_matrix_uc_test)\n",
        "\n",
        "print(\"UC_SAC_JS_test\",UC_SAC_JS_test.shape)\n",
        "print(\"code_SAC_JS_test\",code_SAC_JS_test.shape)\n",
        "\n",
        "np.save('./pickles/UC_SAC_JensenShannon_test.npy',UC_SAC_JS_test)\n",
        "np.save('./pickles/code_SAC_JensenShannon_test.npy',code_SAC_JS_test)\n",
        "# 5.2) Spatial AutoCorrelation using VSM\n",
        "UC_SAC_VSM_test = featureExtraction.SpatialAutoCorrelation(cosine_similarity_UC_test.T,tfidf_matrix_code_test)\n",
        "code_SAC_VSM_test= featureExtraction.SpatialAutoCorrelation(cosine_similarity_CC_test,tfidf_matrix_uc_test)\n",
        "\n",
        "print(\"UC_SAC_VSM_test\",UC_SAC_VSM_test.shape)\n",
        "print(\"code_SAC_VSM_test\",code_SAC_VSM_test.shape)\n",
        "\n",
        "np.save('./pickles/UC_SAC_VSM_test.npy',UC_SAC_VSM_test)\n",
        "np.save('./pickles/code_SAC_VSM_test.npy',code_SAC_VSM_test)\n",
        "#46sec\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#ERROR\n",
        "# 5.3) Spatial AutoCorrelation using BM25\n",
        "UC_SAC_BM25_test = featureExtraction.SpatialAutoCorrelation(BM25_UC_test,tfidf_matrix_code_test)\n",
        "code_SAC_BM25_test = featureExtraction.SpatialAutoCorrelation(BM25_CC_test,tfidf_matrix_uc_test)\n",
        "\n",
        "print(\"UC_SAC_BM25_test\",UC_SAC_BM25_test.shape)\n",
        "print(\"code_SAC_BM25_test\",code_SAC_BM25_test.shape)\n",
        "\n",
        "np.save('./pickles/UC_SAC_BM25_test.npy',UC_SAC_BM25_test)\n",
        "np.save('./pickles/code_SAC_BM25_test.npy',code_SAC_BM25_test)\n",
        "\n",
        "# 5.4) Spatial AutoCorrelation using JM\n",
        "UC_SAC_JM_test = featureExtraction.SpatialAutoCorrelation(JM_UC_test,tfidf_matrix_code_test)\n",
        "code_SAC_JM_test= featureExtraction.SpatialAutoCorrelation(JM_CC_test,tfidf_matrix_uc_test)\n",
        "\n",
        "print(\"UC_SAC_JM_test\",UC_SAC_JM_test.shape)\n",
        "print(\"code_SAC_JM_test\",code_SAC_JM_test.shape)\n",
        "\n",
        "np.save('./pickles/UC_SAC_JM_test.npy',UC_SAC_JM_test)\n",
        "np.save('./pickles/code_SAC_JM_test.npy',code_SAC_JM_test)\n",
        "\n",
        "# 5.5) Spatial AutoCorrelation using DP\n",
        "UC_SAC_DP_test = featureExtraction.SpatialAutoCorrelation(DP_UC_test,tfidf_matrix_code_test)\n",
        "code_SAC_DP_test= featureExtraction.SpatialAutoCorrelation(DP_CC_test,tfidf_matrix_uc_test)\n",
        "\n",
        "print(\"UC_SAC_DP_test\",UC_SAC_DP_test.shape)\n",
        "print(\"code_SAC_DP_test\",code_SAC_DP_test.shape)\n",
        "\n",
        "np.save('./pickles/UC_SAC_DP_test.npy',UC_SAC_DP_test)\n",
        "np.save('./pickles/code_SAC_DP_test.npy',code_SAC_DP_test)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 6.1) WIG using JensenShannon\n",
        "\n",
        "JS_UC_train = np.load('./pickles/JS_UC_train.npy')\n",
        "JS_CC_train = np.load('./pickles/JS_CC_train.npy')\n",
        "\n",
        "UC_WIG_score_JensenShannon_train = featureExtraction.WeightedInformationGain(UC_documents_train,code_documents_train,JS_UC_train.T,tf_code_dict_train,np.sum(list(tf_code_dict_train.values())))\n",
        "code_WIG_score_JensenShannon_train = featureExtraction.WeightedInformationGain(code_documents_train,UC_documents_train,JS_CC_train,tf_uc_dict_train,np.sum(list(tf_uc_dict_train.values())))\n",
        "\n",
        "np.save('./pickles/UC_WIG_score_JensenShannon_train.npy',UC_WIG_score_JensenShannon_train)\n",
        "np.save('./pickles/code_WIG_score_JensenShannon_train.npy',code_WIG_score_JensenShannon_train)\n",
        "\n",
        "JS_UC_test = np.load('./pickles/JS_UC_test.npy')\n",
        "JS_CC_test = np.load('./pickles/JS_CC_test.npy')\n",
        "\n",
        "UC_WIG_score_JensenShannon_test = featureExtraction.WeightedInformationGain(UC_documents_test,code_documents_test,JS_UC_test.T,tf_code_dict_test,np.sum(list(tf_code_dict_test.values())))\n",
        "code_WIG_score_JensenShannon_test = featureExtraction.WeightedInformationGain(code_documents_test,UC_documents_test,JS_CC_test,tf_uc_dict_test,np.sum(list(tf_uc_dict_test.values())))\n",
        "\n",
        "np.save('./pickles/UC_WIG_score_JensenShannon_test.npy',UC_WIG_score_JensenShannon_test)\n",
        "np.save('./pickles/code_WIG_score_JensenShannon_test.npy',code_WIG_score_JensenShannon_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'cosine_similarity_UC_train' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[17], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# 6.2) WIG Score using VSM \u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m UC_WIG_score_VSM_train \u001b[38;5;241m=\u001b[39m featureExtraction\u001b[38;5;241m.\u001b[39mWeightedInformationGain(UC_documents_train,code_documents_train,\u001b[43mcosine_similarity_UC_train\u001b[49m\u001b[38;5;241m.\u001b[39mT,tf_code_dict_train,np\u001b[38;5;241m.\u001b[39msum(\u001b[38;5;28mlist\u001b[39m(tf_code_dict_train\u001b[38;5;241m.\u001b[39mvalues())))\n\u001b[0;32m      3\u001b[0m code_WIG_score_VSM_train \u001b[38;5;241m=\u001b[39m featureExtraction\u001b[38;5;241m.\u001b[39mWeightedInformationGain(code_documents_train,UC_documents_train,cosine_similarity_CC_train,tf_uc_dict_train,np\u001b[38;5;241m.\u001b[39msum(\u001b[38;5;28mlist\u001b[39m(tf_uc_dict_train\u001b[38;5;241m.\u001b[39mvalues())))\n\u001b[0;32m      5\u001b[0m np\u001b[38;5;241m.\u001b[39msave(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./pickles/UC_WIG_score_VSM_train.npy\u001b[39m\u001b[38;5;124m'\u001b[39m,UC_WIG_score_VSM_train)\n",
            "\u001b[1;31mNameError\u001b[0m: name 'cosine_similarity_UC_train' is not defined"
          ]
        }
      ],
      "source": [
        "# 6.2) WIG Score using VSM\n",
        "\n",
        "cosine_similarity_UC_train = np.load('./pickles/cosine_similarity_UC_train.npy')\n",
        "cosine_similarity_CC_train = np.load('./pickles/cosine_similarity_CC_train.npy')\n",
        " \n",
        "UC_WIG_score_VSM_train = featureExtraction.WeightedInformationGain(UC_documents_train,code_documents_train,cosine_similarity_UC_train.T,tf_code_dict_train,np.sum(list(tf_code_dict_train.values())))\n",
        "code_WIG_score_VSM_train = featureExtraction.WeightedInformationGain(code_documents_train,UC_documents_train,cosine_similarity_CC_train,tf_uc_dict_train,np.sum(list(tf_uc_dict_train.values())))\n",
        "\n",
        "np.save('./pickles/UC_WIG_score_VSM_train.npy',UC_WIG_score_VSM_train)\n",
        "np.save('./pickles/code_WIG_score_VSM_train.npy',code_WIG_score_VSM_train)\n",
        "\n",
        "cosine_similarity_UC_test = np.load('./pickles/cosine_similarity_UC_test.npy')\n",
        "cosine_similarity_CC_test = np.load('./pickles/cosine_similarity_CC_test.npy')\n",
        "\n",
        "UC_WIG_score_VSM_test = featureExtraction.WeightedInformationGain(UC_documents_test,code_documents_test,cosine_similarity_UC_test.T,tf_code_dict_test,np.sum(list(tf_code_dict_test.values())))\n",
        "code_WIG_score_VSM_test = featureExtraction.WeightedInformationGain(code_documents_test,UC_documents_test,cosine_similarity_CC_test,tf_uc_dict_test,np.sum(list(tf_uc_dict_test.values())))\n",
        "\n",
        "np.save('./pickles/UC_WIG_score_VSM_test.npy',UC_WIG_score_VSM_test)\n",
        "np.save('./pickles/code_WIG_score_VSM_test.npy',code_WIG_score_VSM_test)\n",
        "\n",
        "#6.3) WIG Score using BM25\n",
        "\n",
        "BM25_UC_train = np.load('./pickles/BM25_UC_train.npy')\n",
        "BM25_CC_train = np.load('./pickles/BM25_CC_train.npy')\n",
        "\n",
        "UC_WIG_score_BM25_train = featureExtraction.WeightedInformationGain(UC_documents_train,code_documents_train,BM25_UC_train,tf_code_dict_train,np.sum(list(tf_code_dict_train.values())))\n",
        "code_WIG_score_BM25_train = featureExtraction.WeightedInformationGain(code_documents_train,UC_documents_train,BM25_CC_train,tf_uc_dict_train,np.sum(list(tf_uc_dict_train.values())))\n",
        "\n",
        "np.save('./pickles/UC_WIG_score_BM25_train.npy',UC_WIG_score_BM25_train)\n",
        "np.save('./pickles/code_WIG_score_BM25_train.npy',code_WIG_score_BM25_train)\n",
        "\n",
        "BM25_UC_test = np.load('./pickles/BM25_UC_test.npy')\n",
        "BM25_CC_test = np.load('./pickles/BM25_CC_test.npy')\n",
        "\n",
        "UC_WIG_score_BM25_test = featureExtraction.WeightedInformationGain(UC_documents_test,code_documents_test,BM25_UC_test,tf_code_dict_test,np.sum(list(tf_code_dict_test.values())))\n",
        "code_WIG_score_BM25_test = featureExtraction.WeightedInformationGain(code_documents_test,UC_documents_test,BM25_CC_test,tf_uc_dict_test,np.sum(list(tf_uc_dict_test.values())))\n",
        "\n",
        "np.save('./pickles/UC_WIG_score_BM25_test.npy',UC_WIG_score_BM25_test)\n",
        "np.save('./pickles/code_WIG_score_BM25_test.npy',code_WIG_score_BM25_test)\n",
        "\n",
        "#6.4) WIG Score using JM\n",
        "\n",
        "JM_UC_train = np.load('./pickles/JM_UC_train.npy')\n",
        "JM_CC_train = np.load('./pickles/JM_CC_train.npy')\n",
        "\n",
        "UC_WIG_score_JM_train = featureExtraction.WeightedInformationGain(UC_documents_train,code_documents_train,JM_UC_train,tf_code_dict_train,np.sum(list(tf_code_dict_train.values())))\n",
        "code_WIG_score_JM_train = featureExtraction.WeightedInformationGain(code_documents_train,UC_documents_train,JM_CC_train,tf_uc_dict_train,np.sum(list(tf_uc_dict_train.values())))\n",
        "\n",
        "np.save('./pickles/UC_WIG_score_JM_train.npy',UC_WIG_score_JM_train)\n",
        "np.save('./pickles/code_WIG_score_JM_train.npy',code_WIG_score_JM_train)\n",
        "\n",
        "JM_UC_test = np.load('./pickles/JM_UC_test.npy')\n",
        "JM_CC_test = np.load('./pickles/JM_CC_test.npy')\n",
        "\n",
        "UC_WIG_score_JM_test = featureExtraction.WeightedInformationGain(UC_documents_test,code_documents_test,JM_UC_test,tf_code_dict_test,np.sum(list(tf_code_dict_test.values())))\n",
        "code_WIG_score_JM_test = featureExtraction.WeightedInformationGain(code_documents_test,UC_documents_test,JM_CC_test,tf_uc_dict_test,np.sum(list(tf_uc_dict_test.values())))\n",
        "\n",
        "np.save('./pickles/UC_WIG_score_JM_test.npy',UC_WIG_score_JM_test)\n",
        "np.save('./pickles/code_WIG_score_JM_test.npy',code_WIG_score_JM_test)\n",
        "\n",
        "#6.5) WIG Score using DP\n",
        "\n",
        "DP_UC_train = np.load('./pickles/DP_UC_train.npy')\n",
        "DP_CC_train = np.load('./pickles/DP_CC_train.npy')\n",
        "\n",
        "UC_WIG_score_DP_train = featureExtraction.WeightedInformationGain(UC_documents_train,code_documents_train,DP_UC_train,tf_code_dict_train,np.sum(list(tf_code_dict_train.values())))\n",
        "code_WIG_score_DP_train = featureExtraction.WeightedInformationGain(code_documents_train,UC_documents_train,DP_CC_train,tf_uc_dict_train,np.sum(list(tf_uc_dict_train.values())))\n",
        "\n",
        "np.save('./pickles/UC_WIG_score_DP_train.npy',UC_WIG_score_DP_train)\n",
        "np.save('./pickles/code_WIG_score_DP_train.npy',code_WIG_score_DP_train)\n",
        "\n",
        "DP_UC_test = np.load('./pickles/DP_UC_test.npy')\n",
        "DP_CC_test = np.load('./pickles/DP_CC_test.npy')\n",
        "\n",
        "UC_WIG_score_DP_test = featureExtraction.WeightedInformationGain(UC_documents_test,code_documents_test,DP_UC_test,tf_code_dict_test,np.sum(list(tf_code_dict_test.values())))\n",
        "code_WIG_score_DP_test = featureExtraction.WeightedInformationGain(code_documents_test,UC_documents_test,DP_CC_test,tf_uc_dict_test,np.sum(list(tf_uc_dict_test.values())))\n",
        "\n",
        "np.save('./pickles/UC_WIG_score_DP_test.npy',UC_WIG_score_DP_test)\n",
        "np.save('./pickles/code_WIG_score_DP_test.npy',code_WIG_score_DP_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 7.1) NQC using JensenShannon\n",
        "UC_NQC_JensenShannon_train = featureExtraction.NormalizedQueryCommitment(JS_UC_train.T)\n",
        "code_NQC_JensenShannon_train = featureExtraction.NormalizedQueryCommitment(JS_CC_train)\n",
        "\n",
        "UC_NQC_JensenShannon_test = featureExtraction.NormalizedQueryCommitment(JS_UC_test.T)\n",
        "code_NQC_JensenShannon_test = featureExtraction.NormalizedQueryCommitment(JS_CC_test)\n",
        "\n",
        "# 7.2) NQC using VSM\n",
        "UC_NQC_VSM_train = featureExtraction.NormalizedQueryCommitment(cosine_similarity_UC_train.T)\n",
        "code_NQC_VSM_train = featureExtraction.NormalizedQueryCommitment(cosine_similarity_CC_train)\n",
        "\n",
        "UC_NQC_VSM_test = featureExtraction.NormalizedQueryCommitment(cosine_similarity_UC_test.T)\n",
        "code_NQC_VSM_test = featureExtraction.NormalizedQueryCommitment(cosine_similarity_CC_test)\n",
        "\n",
        "# 7.3) NQC using BM25\n",
        "UC_NQC_BM25_train = featureExtraction.NormalizedQueryCommitment(BM25_UC_train)\n",
        "code_NQC_BM25_train = featureExtraction.NormalizedQueryCommitment(BM25_CC_train)\n",
        "\n",
        "UC_NQC_BM25_test = featureExtraction.NormalizedQueryCommitment(BM25_UC_test)\n",
        "code_NQC_BM25_test = featureExtraction.NormalizedQueryCommitment(BM25_CC_test)\n",
        "\n",
        "# 7.4) NQC using JM\n",
        "UC_NQC_JM_train = featureExtraction.NormalizedQueryCommitment(JM_UC_train)\n",
        "code_NQC_JM_train = featureExtraction.NormalizedQueryCommitment(JM_CC_train)\n",
        "\n",
        "UC_NQC_JM_test = featureExtraction.NormalizedQueryCommitment(JM_UC_test)\n",
        "code_NQC_JM_test = featureExtraction.NormalizedQueryCommitment(JM_CC_test)\n",
        "\n",
        "# 7.5) NQC using DP\n",
        "UC_NQC_DP_train = featureExtraction.NormalizedQueryCommitment(DP_UC_train)\n",
        "code_NQC_DP_train = featureExtraction.NormalizedQueryCommitment(DP_CC_train)\n",
        "\n",
        "UC_NQC_DP_test = featureExtraction.NormalizedQueryCommitment(DP_UC_test)\n",
        "code_NQC_DP_test = featureExtraction.NormalizedQueryCommitment(DP_CC_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### saving the post retrieval features into pickles"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "np.save('./pickles/UC_CT_JensenShannon_train.npy', UC_CT_JensenShannon_train)\n",
        "np.save('./pickles/code_CT_JensenShannon_train.npy', code_CT_JensenShannon_train)\n",
        "\n",
        "np.save('./pickles/UC_CT_JensenShannon_test.npy', UC_CT_JensenShannon_test)\n",
        "np.save('./pickles/code_CT_JensenShannon_test.npy', code_CT_JensenShannon_test)\n",
        "\n",
        "np.save('./pickles/UC_CT_VSM_train.npy', UC_CT_VSM_train)\n",
        "np.save('./pickles/code_CT_VSM_train.npy', code_CT_VSM_train)\n",
        "\n",
        "np.save('./pickles/UC_CT_VSM_test.npy', UC_CT_VSM_test)\n",
        "np.save('./pickles/code_CT_VSM_test.npy', code_CT_VSM_test)\n",
        "\n",
        "np.save('./pickles/UC_CT_BM25_train.npy', UC_CT_BM25_train)\n",
        "np.save('./pickles/code_CT_BM25_train.npy', code_CT_BM25_train)\n",
        "\n",
        "np.save('./pickles/UC_CT_BM25_test.npy', UC_CT_BM25_test)\n",
        "np.save('./pickles/code_CT_BM25_test.npy', code_CT_BM25_test)\n",
        "\n",
        "np.save('./pickles/UC_CT_JM_train.npy', UC_CT_JM_train)\n",
        "np.save('./pickles/code_CT_JM_train.npy', code_CT_JM_train)\n",
        "\n",
        "np.save('./pickles/UC_CT_JM_test.npy', UC_CT_JM_test)\n",
        "np.save('./pickles/code_CT_JM_test.npy', code_CT_JM_test)\n",
        "\n",
        "np.save('./pickles/UC_CT_DP_train.npy', UC_CT_DP_train)\n",
        "np.save('./pickles/code_CT_DP_train.npy', code_CT_DP_train)\n",
        "\n",
        "np.save('./pickles/UC_CT_DP_test.npy', UC_CT_DP_test)\n",
        "np.save('./pickles/code_CT_DP_test.npy', code_CT_DP_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "np.save('./pickles/UC_NQC_JensenShannon_train.npy',UC_NQC_JensenShannon_train)\n",
        "np.save('./pickles/code_NQC_JensenShannon_train.npy',code_NQC_JensenShannon_train)\n",
        "\n",
        "np.save('./pickles/UC_NQC_JensenShannon_test.npy',UC_NQC_JensenShannon_test)\n",
        "np.save('./pickles/code_NQC_JensenShannon_test.npy',code_NQC_JensenShannon_test)\n",
        "\n",
        "np.save('./pickles/UC_NQC_VSM_train.npy',UC_NQC_VSM_train)\n",
        "np.save('./pickles/code_NQC_VSM_train.npy',code_NQC_VSM_train)\n",
        "\n",
        "np.save('./pickles/UC_NQC_VSM_test.npy',UC_NQC_VSM_test)\n",
        "np.save('./pickles/code_NQC_VSM_test.npy',code_NQC_VSM_test)\n",
        "\n",
        "np.save('./pickles/UC_NQC_BM25_train.npy',UC_NQC_BM25_train)\n",
        "np.save('./pickles/code_NQC_BM25_train.npy',code_NQC_BM25_train)\n",
        "\n",
        "np.save('./pickles/UC_NQC_BM25_test.npy',UC_NQC_BM25_test)\n",
        "np.save('./pickles/code_NQC_BM25_test.npy',code_NQC_BM25_test)\n",
        "\n",
        "np.save('./pickles/UC_NQC_JM_train.npy',UC_NQC_JM_train)\n",
        "np.save('./pickles/code_NQC_JM_train.npy',code_NQC_JM_train)\n",
        "\n",
        "np.save('./pickles/UC_NQC_JM_test.npy',UC_NQC_JM_test)\n",
        "np.save('./pickles/code_NQC_JM_test.npy',code_NQC_JM_test)\n",
        "\n",
        "np.save('./pickles/UC_NQC_DP_train.npy',UC_NQC_DP_train)\n",
        "np.save('./pickles/code_NQC_DP_train.npy',code_NQC_DP_train)\n",
        "\n",
        "np.save('./pickles/UC_NQC_DP_test.npy',UC_NQC_DP_test)\n",
        "np.save('./pickles/code_NQC_DP_test.npy',code_NQC_DP_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Document Statistics Features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pickle\n",
        "with open('pickles_railo/UC_documents.pkl', 'rb') as f:\n",
        "    UC_documents = pickle.load(f)\n",
        "with open('pickles_railo/code_documents.pkl', 'rb') as f:\n",
        "    code_documents = pickle.load(f)\n",
        "with open('pickles_railo/UCTokens.pkl', 'rb') as f:\n",
        "    UCTokens = pickle.load(f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from FeatureExtraction import *\n",
        "featureExtraction = FeatureExtraction(UCTokens)\n",
        "num_terms_code, num_terms_UC, num_unique_terms_code, num_unique_terms_UC, num_overlapping_terms = featureExtraction.DocumentStatistics(UC_documents, code_documents)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Loading the post retrieval features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "normalizer = MinMaxScaler(copy=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "# UC_queries_score_JensenShannon = np.load('./pickles_railo/UC_queries_score_JensenShannon.npy').reshape(-1, 1)\n",
        "# code_queries_score_JensenShannon = np.load('./pickles_railo/code_queries_score_JensenShannon.npy').reshape(-1, 1)\n",
        "# print(code_queries_score_JensenShannon.shape)\n",
        "\n",
        "# normalizer.fit_transform(UC_queries_score_JensenShannon)\n",
        "# normalizer.fit_transform(code_queries_score_JensenShannon)\n",
        "\n",
        "# UC_queries_score_VSM = np.load('./pickles_railo/UC_queries_score_VSM.npy').reshape(1, -1)\n",
        "# code_queries_score_VSM = np.load('./pickles_railo/code_queries_score_VSM.npy').reshape(1, -1)\n",
        "\n",
        "# normalizer.fit_transform(UC_queries_score_VSM)\n",
        "# normalizer.fit_transform(code_queries_score_VSM)\n",
        "\n",
        "# UC_queries_score_BM25 = np.load('./pickles_railo/UC_queries_score_BM25.npy').reshape(1, -1)\n",
        "# code_queries_score_BM25 = np.load('./pickles_railo/code_queries_score_BM25.npy').reshape(1, -1)\n",
        "\n",
        "# normalizer.fit_transform(UC_queries_score_BM25)\n",
        "# normalizer.fit_transform(code_queries_score_BM25)\n",
        "\n",
        "# UC_queries_score_DP = np.load('./pickles_railo/UC_queries_score_DP.npy').reshape(1, -1)\n",
        "# code_queries_score_DP = np.load('./pickles_railo/code_queries_score_DP.npy').reshape(1, -1)\n",
        "\n",
        "# normalizer.fit_transform(UC_queries_score_DP)\n",
        "# normalizer.fit_transform(code_queries_score_DP)\n",
        "\n",
        "# UC_queries_score_JM = np.load('./pickles_railo/UC_queries_score_JM.npy').reshape(1, -1)\n",
        "# code_queries_score_JM = np.load('./pickles_railo/code_queries_score_JM.npy').reshape(1, -1)\n",
        "\n",
        "# normalizer.fit_transform(UC_queries_score_JM)\n",
        "# normalizer.fit_transform(code_queries_score_JM)\n",
        "\n",
        "UC_RS_JS = np.load('./pickles_railo/UC_RS_JS.npy').reshape(1, -1)\n",
        "code_RS_JS = np.load('./pickles_railo/code_RS_JS.npy').reshape(1, -1)\n",
        "\n",
        "normalizer.fit_transform(UC_RS_JS)\n",
        "normalizer.fit_transform(code_RS_JS)\n",
        "\n",
        "UC_RS_VSM = np.load('./pickles_railo/UC_RS_VSM.npy').reshape(1, -1)\n",
        "code_RS_VSM = np.load('./pickles_railo/code_RS_VSM.npy').reshape(1, -1)\n",
        "\n",
        "normalizer.fit_transform(UC_RS_VSM)\n",
        "normalizer.fit_transform(code_RS_VSM)\n",
        "\n",
        "UC_RS_BM25 = np.load('./pickles_railo/UC_RS_BM25.npy').reshape(1, -1)\n",
        "code_RS_BM25 = np.load('./pickles_railo/code_RS_BM25.npy').reshape(1, -1)\n",
        "\n",
        "normalizer.fit_transform(UC_RS_BM25)\n",
        "normalizer.fit_transform(code_RS_BM25)\n",
        "\n",
        "UC_RS_JM = np.load('./pickles_railo/UC_RS_JM.npy').reshape(1, -1)\n",
        "code_RS_JM = np.load('./pickles_railo/code_RS_JM.npy').reshape(1, -1)\n",
        "\n",
        "normalizer.fit_transform(UC_RS_JM)\n",
        "normalizer.fit_transform(code_RS_JM)\n",
        "\n",
        "UC_RS_DP = np.load('./pickles_railo/UC_RS_DP.npy').reshape(1, -1)\n",
        "code_RS_DP = np.load('./pickles_railo/code_RS_DP.npy').reshape(1, -1)\n",
        "\n",
        "normalizer.fit_transform(UC_RS_DP)\n",
        "normalizer.fit_transform(code_RS_DP)\n",
        "\n",
        "UC_FRC_JS = np.load('./pickles_railo/UC_FRC_JS.npy').reshape(1, -1)\n",
        "code_FRC_JS = np.load('./pickles_railo/code_FRC_JS.npy').reshape(1, -1)\n",
        "\n",
        "normalizer.fit_transform(UC_FRC_JS)\n",
        "normalizer.fit_transform(code_FRC_JS)\n",
        "\n",
        "UC_FRC_VSM = np.load('./pickles_railo/UC_FRC_VSM.npy').reshape(1, -1)\n",
        "code_FRC_VSM = np.load('./pickles_railo/code_FRC_VSM.npy').reshape(1, -1)\n",
        "\n",
        "normalizer.fit_transform(UC_FRC_VSM)\n",
        "normalizer.fit_transform(code_FRC_VSM)\n",
        "\n",
        "UC_FRC_BM25 = np.load('./pickles_railo/UC_FRC_BM25.npy').reshape(1, -1)\n",
        "code_FRC_BM25 = np.load('./pickles_railo/code_FRC_BM25.npy').reshape(1, -1)\n",
        "\n",
        "normalizer.fit_transform(UC_FRC_BM25)\n",
        "normalizer.fit_transform(code_FRC_BM25)\n",
        "\n",
        "UC_FRC_JM = np.load('./pickles_railo/UC_FRC_JM.npy').reshape(1, -1)\n",
        "code_FRC_JM = np.load('./pickles_railo/code_FRC_JM.npy').reshape(1, -1)\n",
        "\n",
        "normalizer.fit_transform(UC_FRC_JM)\n",
        "normalizer.fit_transform(code_FRC_JM)\n",
        "\n",
        "UC_FRC_DP = np.load('./pickles_railo/UC_FRC_DP.npy').reshape(1, -1)\n",
        "code_FRC_DP = np.load('./pickles_railo/code_FRC_DP.npy').reshape(1, -1)\n",
        "\n",
        "normalizer.fit_transform(UC_FRC_DP)\n",
        "normalizer.fit_transform(code_FRC_DP)\n",
        "\n",
        "UC_CT_JensenShannon = np.load('./pickles_railo/UC_CT_JensenShannon.npy').reshape(1, -1)\n",
        "code_CT_JensenShannon = np.load('./pickles_railo/code_CT_JensenShannon.npy').reshape(1, -1)\n",
        "\n",
        "normalizer.fit_transform(UC_CT_JensenShannon)\n",
        "normalizer.fit_transform(code_CT_JensenShannon)\n",
        "\n",
        "UC_CT_VSM = np.load('./pickles_railo/UC_CT_VSM.npy').reshape(1, -1)\n",
        "code_CT_VSM = np.load('./pickles_railo/code_CT_VSM.npy').reshape(1, -1)\n",
        "\n",
        "normalizer.fit_transform(UC_CT_VSM)\n",
        "normalizer.fit_transform(code_CT_VSM)\n",
        "\n",
        "UC_CT_BM25 = np.load('./pickles_railo/UC_CT_BM25.npy').reshape(1, -1)\n",
        "code_CT_BM25 = np.load('./pickles_railo/code_CT_BM25.npy').reshape(1, -1)\n",
        "\n",
        "normalizer.fit_transform(UC_CT_BM25)\n",
        "normalizer.fit_transform(code_CT_BM25)\n",
        "\n",
        "UC_CT_JM = np.load('./pickles_railo/UC_CT_JM.npy').reshape(1, -1)\n",
        "code_CT_JM = np.load('./pickles_railo/code_CT_JM.npy').reshape(1, -1)\n",
        "\n",
        "normalizer.fit_transform(UC_CT_JM)\n",
        "normalizer.fit_transform(code_CT_JM)\n",
        "\n",
        "UC_CT_DP = np.load('./pickles_railo/UC_CT_DP.npy').reshape(1, -1)\n",
        "code_CT_DP = np.load('./pickles_railo/code_CT_DP.npy').reshape(1, -1)\n",
        "\n",
        "normalizer.fit_transform(UC_CT_DP)\n",
        "normalizer.fit_transform(code_CT_DP)\n",
        "\n",
        "UC_SAC_JS = np.load('./pickles_railo/UC_SAC_JensenShannon.npy')\n",
        "code_SAC_JS = np.load('./pickles_railo/code_SAC_JensenShannon.npy')\n",
        "\n",
        "normalizer.fit_transform(UC_SAC_JS)\n",
        "normalizer.fit_transform(code_SAC_JS)\n",
        "\n",
        "UC_SAC_VSM = np.load('./pickles_railo/UC_SAC_VSM.npy')\n",
        "code_SAC_VSM = np.load('./pickles_railo/code_SAC_VSM.npy')\n",
        "\n",
        "normalizer.fit_transform(UC_SAC_VSM)\n",
        "normalizer.fit_transform(code_SAC_VSM)\n",
        "\n",
        "UC_SAC_BM25 = np.load('./pickles_railo/UC_SAC_BM25.npy')\n",
        "code_SAC_BM25 = np.load('./pickles_railo/code_SAC_BM25.npy')\n",
        "\n",
        "normalizer.fit_transform(UC_SAC_BM25)\n",
        "normalizer.fit_transform(code_SAC_BM25)\n",
        "\n",
        "UC_SAC_JM = np.load('./pickles_railo/UC_SAC_JM.npy')\n",
        "code_SAC_JM = np.load('./pickles_railo/code_SAC_JM.npy')\n",
        "\n",
        "normalizer.fit_transform(UC_SAC_JM)\n",
        "normalizer.fit_transform(code_SAC_JM)\n",
        "\n",
        "UC_SAC_DP = np.load('./pickles_railo/UC_SAC_DP.npy')\n",
        "code_SAC_DP = np.load('./pickles_railo/code_SAC_DP.npy')\n",
        "\n",
        "normalizer.fit_transform(UC_SAC_DP)\n",
        "normalizer.fit_transform(code_SAC_DP)\n",
        "\n",
        "UC_WIG_score_JensenShannon = np.load('./pickles_railo/UC_WIG_score_JensenShannon.npy')\n",
        "code_WIG_score_JensenShannon = np.load('./pickles_railo/code_WIG_score_JensenShannon.npy')\n",
        "\n",
        "normalizer.fit_transform(UC_WIG_score_JensenShannon)\n",
        "normalizer.fit_transform(code_WIG_score_JensenShannon)\n",
        "\n",
        "UC_WIG_score_VSM = np.load('./pickles_railo/UC_WIG_score_VSM.npy')\n",
        "code_WIG_score_VSM = np.load('./pickles_railo/code_WIG_score_VSM.npy')\n",
        "\n",
        "normalizer.fit_transform(UC_WIG_score_VSM)\n",
        "normalizer.fit_transform(code_WIG_score_VSM)\n",
        "\n",
        "UC_WIG_score_BM25 = np.load('./pickles_railo/UC_WIG_score_BM25.npy')\n",
        "code_WIG_score_BM25 = np.load('./pickles_railo/code_WIG_score_BM25.npy')\n",
        "\n",
        "normalizer.fit_transform(UC_WIG_score_BM25)\n",
        "normalizer.fit_transform(code_WIG_score_BM25)\n",
        "\n",
        "UC_WIG_score_JM = np.load('./pickles_railo/UC_WIG_score_JM.npy')\n",
        "code_WIG_score_JM = np.load('./pickles_railo/code_WIG_score_JM.npy')\n",
        "\n",
        "normalizer.fit_transform(UC_WIG_score_JM)\n",
        "normalizer.fit_transform(code_WIG_score_JM)\n",
        "\n",
        "UC_WIG_score_DP = np.load('./pickles_railo/UC_WIG_score_DP.npy')\n",
        "code_WIG_score_DP = np.load('./pickles_railo/code_WIG_score_DP.npy')\n",
        "\n",
        "normalizer.fit_transform(UC_WIG_score_DP)\n",
        "normalizer.fit_transform(code_WIG_score_DP)\n",
        "\n",
        "UC_NQC_JensenShannon = np.load('./pickles_railo/UC_NQC_JensenShannon.npy')\n",
        "code_NQC_JensenShannon = np.load('./pickles_railo/code_NQC_JensenShannon.npy')\n",
        "\n",
        "normalizer.fit_transform(UC_NQC_JensenShannon)\n",
        "normalizer.fit_transform(code_NQC_JensenShannon)\n",
        "\n",
        "UC_NQC_VSM = np.load('./pickles_railo/UC_NQC_VSM.npy')\n",
        "code_NQC_VSM = np.load('./pickles_railo/code_NQC_VSM.npy')\n",
        "\n",
        "normalizer.fit_transform(UC_NQC_VSM)\n",
        "normalizer.fit_transform(code_NQC_VSM)\n",
        "\n",
        "UC_NQC_BM25 = np.load('./pickles_railo/UC_NQC_BM25.npy')\n",
        "code_NQC_BM25 = np.load('./pickles_railo/code_NQC_BM25.npy')\n",
        "\n",
        "normalizer.fit_transform(UC_NQC_BM25)\n",
        "normalizer.fit_transform(code_NQC_BM25)\n",
        "\n",
        "UC_NQC_JM = np.load('./pickles_railo/UC_NQC_JM.npy')\n",
        "code_NQC_JM = np.load('./pickles_railo/code_NQC_JM.npy')\n",
        "\n",
        "normalizer.fit_transform(UC_NQC_JM)\n",
        "normalizer.fit_transform(code_NQC_JM)\n",
        "\n",
        "UC_NQC_DP = np.load('./pickles_railo/UC_NQC_DP.npy')\n",
        "code_NQC_DP = np.load('./pickles_railo/code_NQC_DP.npy')\n",
        "\n",
        "normalizer.fit_transform(UC_NQC_DP)\n",
        "normalizer.fit_transform(code_NQC_DP)\n",
        "\n",
        "avg_idf_uc=np.load('./pickles_railo/avg_idf_uc.npy')\n",
        "avg_idf_code=np.load('./pickles_railo/avg_idf_code.npy')\n",
        "\n",
        "max_idf_uc=np.load('./pickles_railo/max_idf_uc.npy')\n",
        "max_idf_code=np.load('./pickles_railo/max_idf_code.npy')\n",
        "\n",
        "dev_idf_uc=np.load('./pickles_railo/dev_idf_uc.npy')\n",
        "dev_idf_code=np.load('./pickles_railo/dev_idf_code.npy')\n",
        "\n",
        "avg_ictf_uc=np.load('./pickles_railo/avg_ictf_uc.npy')\n",
        "avg_ictf_code=np.load('./pickles_railo/avg_ictf_code.npy')\n",
        "\n",
        "max_ictf_uc=np.load('./pickles_railo/max_ictf_uc.npy')\n",
        "max_ictf_code=np.load('./pickles_railo/max_ictf_code.npy')\n",
        "\n",
        "dev_ictf_uc=np.load('./pickles_railo/dev_ictf_uc.npy')\n",
        "dev_ictf_code=np.load('./pickles_railo/dev_ictf_code.npy')\n",
        "\n",
        "avg_entropy_uc=np.load('./pickles_railo/avg_entropy_uc.npy')\n",
        "avg_entropy_code=np.load('./pickles_railo/avg_entropy_code.npy')\n",
        "\n",
        "max_entropy_uc=np.load('./pickles_railo/max_entropy_uc.npy')\n",
        "max_entropy_code=np.load('./pickles_railo/max_entropy_code.npy')\n",
        "\n",
        "med_entropy_uc=np.load('./pickles_railo/med_entropy_uc.npy')\n",
        "med_entropy_code=np.load('./pickles_railo/med_entropy_code.npy')\n",
        "\n",
        "\n",
        "dev_entropy_uc=np.load('./pickles_railo/dev_entropy_uc.npy')\n",
        "dev_entropy_code=np.load('./pickles_railo/dev_entropy_code.npy')\n",
        "\n",
        "avg_variance_uc=np.load('./pickles_railo/avg_variance_uc.npy')\n",
        "avg_variance_code=np.load('./pickles_railo/avg_variance_code.npy')\n",
        "\n",
        "max_variance_uc=np.load('./pickles_railo/max_variance_uc.npy')\n",
        "max_variance_code=np.load('./pickles_railo/max_variance_code.npy')\n",
        "\n",
        "sum_variance_uc=np.load('./pickles_railo/sum_variance_uc.npy')\n",
        "sum_variance_code=np.load('./pickles_railo/sum_variance_code.npy')\n",
        "\n",
        "avg_scq_uc=np.load('./pickles_railo/avg_scq_uc.npy')\n",
        "avg_scq_code=np.load('./pickles_railo/avg_scq_code.npy')\n",
        "\n",
        "max_scq_uc=np.load('./pickles_railo/max_scq_uc.npy')\n",
        "max_scq_code=np.load('./pickles_railo/max_scq_code.npy')\n",
        "\n",
        "sum_sqc_uc=np.load('./pickles_railo/sum_sqc_uc.npy')\n",
        "sum_sqc_code=np.load('./pickles_railo/sum_sqc_code.npy')\n",
        "\n",
        "avg_pmi_uc=np.load('./pickles_railo/avg_pmi_uc.npy')\n",
        "avg_pmi_code=np.load('./pickles_railo/avg_pmi_code.npy')\n",
        "\n",
        "max_pmi_uc=np.load('./pickles_railo/max_pmi_uc.npy')\n",
        "max_pmi_code=np.load('./pickles_railo/max_pmi_code.npy')\n",
        "\n",
        "\n",
        "qs_uc=np.load('./pickles_railo/qs_uc.npy')\n",
        "qs_code=np.load('./pickles_railo/qs_code.npy')\n",
        "\n",
        "UC_SCS = np.load('./pickles_railo/UC_SCS.npy')\n",
        "CC_SCS = np.load('./pickles_railo/CC_SCS.npy')\n",
        "\n",
        "UC_CoherenceScore = np.load('./pickles_railo/UC_CoherenceScore.npy')\n",
        "CC_CoherenceScore = np.load('./pickles_railo/CC_CoherenceScore.npy')\n",
        "\n",
        "cosine_similarity_UC = np.load('./pickles_railo/cosine_similarity_UC.npy')\n",
        "cosine_similarity_CC = np.load('./pickles_railo/cosine_similarity_CC.npy')\n",
        "\n",
        "LSA_similraities_UC = np.load('./pickles_railo/LSA_similraities_UC.npy')\n",
        "LSA_similraities_CC = np.load('./pickles_railo/LSA_similraities_CC.npy')\n",
        "\n",
        "JS_UC = np.load('./pickles_railo/JS_UC.npy')\n",
        "JS_CC = np.load('./pickles_railo/JS_CC.npy')\n",
        "\n",
        "BM25_UC = np.load('./pickles_railo/BM25_UC.npy')\n",
        "BM25_CC = np.load('./pickles_railo/BM25_CC.npy')\n",
        "\n",
        "LDA_similraities_UC = np.load('./pickles_railo/LDA_similraities_UC.npy')\n",
        "LDA_similraities_CC = np.load('./pickles_railo/LDA_similraities_CC.npy')\n",
        "\n",
        "JM_UC = np.load('./pickles_railo/JM_UC.npy')\n",
        "JM_CC = np.load('./pickles_railo/JM_CC.npy')\n",
        "\n",
        "DP_UC = np.load('./pickles_railo/DP_UC.npy')\n",
        "DP_CC = np.load('./pickles_railo/DP_CC.npy')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "###### Remove hardcoded sizing with the size captured from the data set.\n",
        "avg_idf_uc = avg_idf_uc.reshape(avg_idf_uc.shape[0] * avg_idf_uc.shape[1])\n",
        "avg_idf_code = avg_idf_code.reshape(avg_idf_code.shape[0] * avg_idf_code.shape[1])\n",
        "avg_idf_uc_reshaped = np.tile(avg_idf_uc, (avg_idf_code.shape[0],1))\n",
        "avg_idf_code_reshaped = np.tile(avg_idf_code, (avg_idf_uc.shape[0],1))\n",
        "\n",
        "\n",
        "max_idf_uc = max_idf_uc.reshape(max_idf_uc.shape[0] * max_idf_uc.shape[1])\n",
        "max_idf_code = max_idf_code.reshape(max_idf_code.shape[0] * max_idf_code.shape[1])\n",
        "max_idf_uc_reshaped = np.tile(max_idf_uc, (max_idf_code.shape[0],1))\n",
        "max_idf_code_reshaped = np.tile(max_idf_code, (max_idf_uc.shape[0],1))\n",
        "\n",
        "\n",
        "dev_idf_uc = dev_idf_uc.reshape(dev_idf_uc.shape[0] * dev_idf_uc.shape[1])\n",
        "dev_idf_code = dev_idf_code.reshape(dev_idf_code.shape[0] * dev_idf_code.shape[1])\n",
        "dev_idf_uc_reshaped = np.tile(dev_idf_uc, (dev_idf_code.shape[0],1))\n",
        "dev_idf_code_reshaped = np.tile(dev_idf_code, (dev_idf_uc.shape[0],1))\n",
        "\n",
        "avg_ictf_uc = avg_ictf_uc.reshape(avg_ictf_uc.shape[0] * avg_ictf_uc.shape[1])\n",
        "avg_ictf_code = avg_ictf_code.reshape(avg_ictf_code.shape[0] * avg_ictf_code.shape[1])\n",
        "avg_ictf_uc_reshaped = np.tile(avg_ictf_uc, (avg_ictf_code.shape[0],1))\n",
        "avg_ictf_code_reshaped = np.tile(avg_ictf_code, (avg_ictf_uc.shape[0],1))\n",
        "\n",
        "\n",
        "max_ictf_uc = max_ictf_uc.reshape(max_ictf_uc.shape[0] * max_ictf_uc.shape[1])\n",
        "max_ictf_code = avg_idf_code.reshape(max_ictf_code.shape[0] * max_ictf_code.shape[1])\n",
        "max_ictf_uc_reshaped = np.tile(max_ictf_uc, (max_ictf_code.shape[0],1))\n",
        "max_ictf_code_reshaped = np.tile(max_ictf_code, (max_ictf_uc.shape[0],1))\n",
        "\n",
        "dev_ictf_uc = dev_ictf_uc.reshape(dev_ictf_uc.shape[0] * dev_ictf_uc.shape[1])\n",
        "dev_ictf_code = dev_ictf_code.reshape(dev_ictf_code.shape[0] * dev_ictf_code.shape[1])\n",
        "dev_ictf_uc_reshaped = np.tile(dev_ictf_uc, (dev_ictf_code.shape[0],1))\n",
        "dev_ictf_code_reshaped = np.tile(dev_ictf_code, (dev_ictf_uc.shape[0],1))\n",
        "\n",
        "avg_entropy_uc = avg_entropy_uc.reshape(avg_entropy_uc.shape[0] * avg_entropy_uc.shape[1])\n",
        "avg_entropy_code = avg_entropy_code.reshape(avg_entropy_code.shape[0] * avg_entropy_code.shape[1])\n",
        "avg_entropy_uc_reshaped = np.tile(avg_entropy_uc, (avg_entropy_code.shape[0],1))\n",
        "avg_entropy_code_reshaped = np.tile(avg_entropy_code, (avg_entropy_uc.shape[0],1))\n",
        "\n",
        "max_entropy_uc = max_entropy_uc.reshape(max_entropy_uc.shape[0] * max_entropy_uc.shape[1])\n",
        "max_entropy_code = max_entropy_code.reshape(max_entropy_code.shape[0] * max_entropy_code.shape[1])\n",
        "max_entropy_uc_reshaped = np.tile(max_entropy_uc, (max_entropy_code.shape[0],1)) # ------> gets removed, 2nd round\n",
        "max_entropy_code_reshaped = np.tile(max_entropy_code, (max_entropy_uc.shape[0],1)) # ------> gets removed, 2nd round\n",
        "\n",
        "med_entropy_uc = med_entropy_uc.reshape(med_entropy_uc.shape[0] * med_entropy_uc.shape[1])\n",
        "med_entropy_code = med_entropy_code.reshape(med_entropy_code.shape[0] * med_entropy_code.shape[1])\n",
        "med_entropy_uc_reshaped = np.tile(med_entropy_uc, (med_entropy_code.shape[0],1))\n",
        "med_entropy_code_reshaped = np.tile(med_entropy_code, (med_entropy_uc.shape[0],1))\n",
        "\n",
        "dev_entropy_uc = dev_entropy_uc.reshape(dev_entropy_uc.shape[0] * dev_entropy_uc.shape[1])\n",
        "dev_entropy_code = dev_entropy_code.reshape(dev_entropy_code.shape[0] * dev_entropy_code.shape[1])\n",
        "dev_entropy_uc_reshaped = np.tile(dev_entropy_uc, (dev_entropy_code.shape[0],1))\n",
        "dev_entropy_code_reshaped = np.tile(dev_entropy_code, (dev_entropy_uc.shape[0],1)) # -------> gets removed\n",
        "\n",
        "avg_variance_uc = avg_variance_uc.reshape(avg_variance_uc.shape[0] * avg_variance_uc.shape[1])\n",
        "avg_variance_code = avg_variance_code.reshape(avg_variance_code.shape[0] * avg_variance_code.shape[1])\n",
        "avg_variance_uc_reshaped = np.tile(avg_variance_uc, (avg_variance_code.shape[0],1))\n",
        "avg_variance_code_reshaped = np.tile(avg_variance_code, (avg_variance_uc.shape[0],1))\n",
        "\n",
        "max_variance_uc = max_variance_uc.reshape(max_variance_uc.shape[0] * max_variance_uc.shape[1])\n",
        "max_variance_code = max_variance_code.reshape(max_variance_code.shape[0] * max_variance_code.shape[1])\n",
        "max_variance_uc_reshaped = np.tile(max_variance_uc, (max_variance_code.shape[0],1))\n",
        "max_variance_code_reshaped = np.tile(max_variance_code, (max_variance_uc.shape[0],1))\n",
        "\n",
        "sum_variance_uc = sum_variance_uc.reshape(sum_variance_uc.shape[0] * sum_variance_uc.shape[1])\n",
        "sum_variance_code = sum_variance_code.reshape(sum_variance_code.shape[0] * sum_variance_code.shape[1])\n",
        "sum_variance_uc_reshaped = np.tile(sum_variance_uc, (sum_variance_code.shape[0],1)) # --------> gets removed\n",
        "sum_variance_code_reshaped = np.tile(sum_variance_code, (sum_variance_uc.shape[0],1)) # -------> gets removed\n",
        "\n",
        "avg_scq_uc = avg_scq_uc.reshape(avg_scq_uc.shape[0] * avg_scq_uc.shape[1])\n",
        "avg_scq_code = avg_scq_code.reshape(avg_scq_code.shape[0] * avg_scq_code.shape[1])\n",
        "avg_scq_uc_reshaped = np.tile(avg_scq_uc, (avg_scq_code.shape[0],1))\n",
        "avg_scq_code_reshaped = np.tile(avg_scq_code, (avg_scq_uc.shape[0],1)) # -------> gets removed\n",
        "\n",
        "max_scq_uc = max_scq_uc.reshape(max_scq_uc.shape[0] * max_scq_uc.shape[1])\n",
        "max_scq_code = max_scq_code.reshape(max_scq_code.shape[0] * max_scq_code.shape[1])\n",
        "max_scq_uc_reshaped = np.tile(max_scq_uc, (max_scq_code.shape[0],1))\n",
        "max_scq_code_reshaped = np.tile(max_scq_code, (max_scq_uc.shape[0],1))\n",
        "\n",
        "sum_sqc_uc = sum_sqc_uc.reshape(sum_sqc_uc.shape[0] * sum_sqc_uc.shape[1])\n",
        "sum_sqc_code = sum_sqc_code.reshape(sum_sqc_code.shape[0] * sum_sqc_code.shape[1])\n",
        "sum_sqc_uc_reshaped = np.tile(sum_sqc_uc, (sum_sqc_code.shape[0],1))# --------> gets removed, 2nd round\n",
        "sum_sqc_code_reshaped = np.tile(sum_sqc_code, (sum_sqc_uc.shape[0],1)) # --------> gets removed, 2nd round\n",
        "\n",
        "avg_pmi_uc = avg_pmi_uc.reshape(avg_pmi_uc.shape[0] * avg_pmi_uc.shape[1])\n",
        "avg_pmi_code = avg_pmi_code.reshape(avg_pmi_code.shape[0] * avg_pmi_code.shape[1])\n",
        "avg_pmi_uc_reshaped = np.tile(avg_pmi_uc, (avg_pmi_code.shape[0],1)) # --------> gets removed \n",
        "avg_pmi_code_reshaped = np.tile(avg_pmi_code, (avg_pmi_uc.shape[0],1)) # --------> gets removed \n",
        "\n",
        "max_pmi_uc = max_pmi_uc.reshape(max_pmi_uc.shape[0] * max_pmi_uc.shape[1])\n",
        "max_pmi_code = max_pmi_code.reshape(max_pmi_code.shape[0] * max_pmi_code.shape[1])\n",
        "max_pmi_uc_reshaped = np.tile(max_pmi_uc, (max_pmi_code.shape[0],1))\n",
        "max_pmi_code_reshaped = np.tile(max_pmi_code, (max_pmi_uc.shape[0],1))\n",
        "\n",
        "qs_uc = qs_uc.reshape(qs_uc.shape[0] * qs_uc.shape[1])\n",
        "qs_code = qs_code.reshape(qs_code.shape[0] * qs_code.shape[1])\n",
        "qs_uc_reshaped = np.tile(qs_uc, (qs_code.shape[0],1)) # --------> gets removed, 2nd round\n",
        "qs_code_reshaped = np.tile(qs_code, (qs_uc.shape[0],1)) # --------> gets removed, 2nd round\n",
        "\n",
        "\n",
        "# UC_queries_score_JensenShannon_reshaped = np.tile(UC_queries_score_JensenShannon, (1,code_queries_score_JensenShannon.shape[0]))\n",
        "# code_queries_score_JensenShannon_reshaped = np.tile(code_queries_score_JensenShannon, (1,UC_queries_score_JensenShannon.shape[0]))\n",
        "\n",
        "# UC_queries_score_VSM_reshaped =  np.tile(UC_queries_score_VSM, (code_queries_score_VSM.shape[0],1))\n",
        "# code_queries_score_VSM_reshaped = np.tile(code_queries_score_VSM, (UC_queries_score_VSM.shape[0],1))\n",
        "\n",
        "# UC_queries_score_BM25_reshaped = np.tile(UC_queries_score_BM25, (code_queries_score_BM25.shape[0],1))\n",
        "# code_queries_score_BM25_reshaped = np.tile(code_queries_score_BM25, (UC_queries_score_BM25.shape[0],1))\n",
        "\n",
        "# UC_queries_score_JM_reshaped = np.tile(UC_queries_score_JM, (code_queries_score_JM.shape[0],1))\n",
        "# code_queries_score_JM_reshaped = np.tile(code_queries_score_JM, (UC_queries_score_JM.shape[0],1))\n",
        "\n",
        "# UC_queries_score_JM_reshaped = np.tile(UC_queries_score_JM, (code_queries_score_JM.shape[0],1))\n",
        "# code_queries_score_JM_reshaped = np.tile(code_queries_score_JM, (UC_queries_score_JM.shape[0],1))\n",
        "\n",
        "# UC_queries_score_DP_reshaped = np.tile(UC_queries_score_DP, (code_queries_score_DP.shape[0],1))\n",
        "# code_queries_score_DP_reshaped = np.tile(code_queries_score_DP, (UC_queries_score_DP.shape[0],1))\n",
        "\n",
        "UC_RS_JS = UC_RS_JS.reshape(UC_RS_JS.shape[0] * UC_RS_JS.shape[1])\n",
        "code_RS_JS = code_RS_JS.reshape(code_RS_JS.shape[0] * code_RS_JS.shape[1])\n",
        "UC_RS_JS_reshaped = np.tile(UC_RS_JS, (code_RS_JS.shape[0],1))\n",
        "code_RS_JS_reshaped = np.tile(code_RS_JS, (UC_RS_JS.shape[0],1))\n",
        "\n",
        "UC_RS_VSM = UC_RS_VSM.reshape(UC_RS_VSM.shape[0] * UC_RS_VSM.shape[1])\n",
        "code_RS_VSM = code_RS_VSM.reshape(code_RS_VSM.shape[0] * code_RS_VSM.shape[1])\n",
        "UC_RS_VSM_reshaped = np.tile(UC_RS_VSM, (code_RS_VSM.shape[0],1))\n",
        "code_RS_VSM_reshaped = np.tile(code_RS_VSM, (UC_RS_VSM.shape[0],1))\n",
        "\n",
        "UC_RS_BM25 = UC_RS_BM25.reshape(UC_RS_BM25.shape[0] * UC_RS_BM25.shape[1])\n",
        "code_RS_BM25 = code_RS_BM25.reshape(code_RS_BM25.shape[0] * code_RS_BM25.shape[1])\n",
        "UC_RS_BM25_reshaped = np.tile(UC_RS_BM25, (code_RS_BM25.shape[0],1))\n",
        "code_RS_BM25_reshaped = np.tile(code_RS_BM25, (UC_RS_BM25.shape[0],1))\n",
        "\n",
        "UC_RS_JM = UC_RS_JM.reshape(UC_RS_JM.shape[0] * UC_RS_JM.shape[1])\n",
        "code_RS_JM = code_RS_JM.reshape(code_RS_JM.shape[0] * code_RS_JM.shape[1])\n",
        "UC_RS_JM_reshaped = np.tile(UC_RS_JM, (code_RS_JM.shape[0],1))\n",
        "code_RS_JM_reshaped = np.tile(code_RS_JM, (UC_RS_JM.shape[0],1))\n",
        "\n",
        "\n",
        "UC_RS_DP = UC_RS_DP.reshape(UC_RS_DP.shape[0] * UC_RS_DP.shape[1])\n",
        "code_RS_DP = code_RS_DP.reshape(code_RS_DP.shape[0] * code_RS_DP.shape[1])\n",
        "UC_RS_DP_reshaped = np.tile(UC_RS_DP,(code_RS_DP.shape[0],1))\n",
        "code_RS_DP_reshaped = np.tile(code_RS_DP, (UC_RS_DP.shape[0],1))\n",
        "\n",
        "UC_FRC_JS = UC_FRC_JS.reshape(UC_FRC_JS.shape[0] * UC_FRC_JS.shape[1])\n",
        "code_FRC_JS = code_FRC_JS.reshape(code_FRC_JS.shape[0] * code_FRC_JS.shape[1])\n",
        "UC_FRC_JS_reshaped = np.tile(UC_FRC_JS,(code_FRC_JS.shape[0],1))\n",
        "code_FRC_JS_reshaped = np.tile(code_FRC_JS, (UC_FRC_JS.shape[0],1))\n",
        "\n",
        "UC_FRC_VSM = UC_FRC_VSM.reshape(UC_FRC_VSM.shape[0] * UC_FRC_VSM.shape[1])\n",
        "code_FRC_VSM = code_FRC_VSM.reshape(code_FRC_VSM.shape[0] * code_FRC_VSM.shape[1])\n",
        "UC_FRC_VSM_reshaped = np.tile(UC_FRC_VSM, (code_FRC_VSM.shape[0],1))\n",
        "code_FRC_VSM_reshaped = np.tile(code_FRC_VSM, (UC_FRC_VSM.shape[0],1))\n",
        "\n",
        "UC_FRC_BM25 = UC_FRC_BM25.reshape(UC_FRC_BM25.shape[0] * UC_FRC_BM25.shape[1])\n",
        "code_FRC_BM25 = code_FRC_BM25.reshape(code_FRC_BM25.shape[0] * code_FRC_BM25.shape[1])\n",
        "UC_FRC_BM25_reshaped = np.tile(UC_FRC_BM25, (code_FRC_BM25.shape[0],1))\n",
        "code_FRC_BM25_reshaped = np.tile(code_FRC_BM25, (UC_FRC_BM25.shape[0],1))\n",
        "\n",
        "UC_FRC_JM = UC_FRC_JM.reshape(UC_FRC_JM.shape[0] * UC_FRC_JM.shape[1])\n",
        "code_FRC_JM = code_FRC_JM.reshape(code_FRC_JM.shape[0] * code_FRC_JM.shape[1])\n",
        "UC_FRC_JM_reshaped = np.tile(UC_FRC_JM, (code_FRC_JM.shape[0],1))\n",
        "code_FRC_JM_reshaped = np.tile(code_FRC_JM, (UC_FRC_JM.shape[0],1))\n",
        "\n",
        "\n",
        "UC_FRC_DP = UC_FRC_DP.reshape(UC_FRC_DP.shape[0] * UC_FRC_DP.shape[1])\n",
        "code_FRC_DP = code_FRC_DP.reshape(code_FRC_DP.shape[0] * code_FRC_DP.shape[1])\n",
        "UC_FRC_DP_reshaped = np.tile(UC_FRC_DP, (code_FRC_DP.shape[0],1))\n",
        "code_FRC_DP_reshaped = np.tile(code_FRC_DP, (UC_FRC_DP.shape[0],1))\n",
        "\n",
        "UC_CT_JensenShannon = UC_CT_JensenShannon.reshape(UC_CT_JensenShannon.shape[0] * UC_CT_JensenShannon.shape[1])\n",
        "code_CT_JensenShannon = code_CT_JensenShannon.reshape(code_CT_JensenShannon.shape[0] * code_CT_JensenShannon.shape[1])\n",
        "UC_CT_JensenShannon_reshaped = np.tile(UC_CT_JensenShannon, (code_CT_JensenShannon.shape[0],1))\n",
        "code_CT_JensenShannon_reshaped = np.tile(code_CT_JensenShannon, (UC_CT_JensenShannon.shape[0],1))\n",
        "\n",
        "UC_CT_VSM = UC_CT_VSM.reshape(UC_CT_VSM.shape[0] * UC_CT_VSM.shape[1])\n",
        "code_CT_VSM = code_CT_VSM.reshape(code_CT_VSM.shape[0] * code_CT_VSM.shape[1])\n",
        "UC_CT_VSM_reshaped = np.tile(UC_CT_VSM, (code_CT_VSM.shape[0],1))\n",
        "code_CT_VSM_reshaped = np.tile(code_CT_VSM, (UC_CT_VSM.shape[0],1))\n",
        "\n",
        "UC_CT_BM25 = UC_CT_BM25.reshape(UC_CT_BM25.shape[0] * UC_CT_BM25.shape[1])\n",
        "code_CT_BM25 = code_CT_BM25.reshape(code_CT_BM25.shape[0] * code_CT_BM25.shape[1])\n",
        "UC_CT_BM25_reshaped = np.tile(UC_CT_BM25, (code_CT_BM25.shape[0],1))\n",
        "code_CT_BM25_reshaped = np.tile(code_CT_BM25, (UC_CT_BM25.shape[0],1))\n",
        "\n",
        "UC_CT_JM = UC_CT_JM.reshape(UC_CT_JM.shape[0] * UC_CT_JM.shape[1])\n",
        "code_CT_JM = code_CT_JM.reshape(code_CT_JM.shape[0] * code_CT_JM.shape[1])\n",
        "UC_CT_JM_reshaped = np.tile(UC_CT_JM, (code_CT_JM.shape[0],1))\n",
        "code_CT_JM_reshaped = np.tile(code_CT_JM, (UC_CT_JM.shape[0],1))\n",
        "\n",
        "UC_CT_DP = UC_CT_DP.reshape(UC_CT_DP.shape[0] * UC_CT_DP.shape[1])\n",
        "code_CT_DP = code_CT_DP.reshape(code_CT_DP.shape[0] * code_CT_DP.shape[1])\n",
        "UC_CT_DP_reshaped = np.tile(UC_CT_DP, (code_CT_DP.shape[0],1))\n",
        "code_CT_DP_reshaped = np.tile(code_CT_DP, (UC_CT_DP.shape[0],1))\n",
        "\n",
        "UC_SAC_JS_reshaped = np.tile(UC_SAC_JS, (1,code_SAC_JS.shape[0]))\n",
        "code_SAC_JS_reshaped = np.tile(code_SAC_JS, (1,UC_SAC_JS.shape[0]))\n",
        "\n",
        "UC_SAC_VSM_reshaped = np.tile(UC_SAC_VSM, (1,code_SAC_VSM.shape[0]))\n",
        "code_SAC_VSM_reshaped = np.tile(code_SAC_VSM, (1,UC_SAC_VSM.shape[0]))\n",
        "\n",
        "UC_SAC_BM25_reshaped = np.tile(UC_SAC_BM25, (1,code_SAC_BM25.shape[0]))\n",
        "code_SAC_BM25_reshaped = np.tile(code_SAC_BM25, (1,UC_SAC_BM25.shape[0]))\n",
        "\n",
        "UC_SAC_JM_reshaped = np.tile(UC_SAC_JM, (1,code_SAC_JM.shape[0]))\n",
        "code_SAC_JM_reshaped = np.tile(code_SAC_JM, (1,UC_SAC_JM.shape[0]))\n",
        "\n",
        "UC_SAC_DP_reshaped = np.tile(UC_SAC_DP, (1,code_SAC_DP.shape[0]))\n",
        "code_SAC_DP_reshaped = np.tile(code_SAC_DP, (1,UC_SAC_DP.shape[0]))\n",
        "\n",
        "UC_WIG_score_JensenShannon_reshaped = np.tile(UC_WIG_score_JensenShannon, (1,code_WIG_score_JensenShannon.shape[0]))\n",
        "code_WIG_score_JensenShannon_reshaped = np.tile(code_WIG_score_JensenShannon, (1,UC_WIG_score_JensenShannon.shape[0]))\n",
        "\n",
        "UC_WIG_score_VSM_reshaped = np.tile(UC_WIG_score_VSM, (1,code_WIG_score_VSM.shape[0]))\n",
        "code_WIG_score_VSM_reshaped = np.tile(code_WIG_score_VSM, (1,UC_WIG_score_VSM.shape[0]))\n",
        "\n",
        "UC_WIG_score_BM25_reshaped = np.tile(UC_WIG_score_BM25, (1,code_WIG_score_BM25.shape[0]))\n",
        "code_WIG_score_BM25_reshaped = np.tile(code_WIG_score_BM25, (1,UC_WIG_score_BM25.shape[0]))\n",
        "\n",
        "UC_WIG_score_JM_reshaped = np.tile(UC_WIG_score_JM, (1,code_WIG_score_JM.shape[0]))\n",
        "code_WIG_score_JM_reshaped = np.tile(code_WIG_score_JM, (1,UC_WIG_score_JM.shape[0]))\n",
        "\n",
        "UC_WIG_score_DP_reshaped = np.tile(UC_WIG_score_DP, (1,code_WIG_score_DP.shape[0]))\n",
        "code_WIG_score_DP_reshaped = np.tile(code_WIG_score_DP, (1,UC_WIG_score_DP.shape[0]))\n",
        "\n",
        "UC_NQC_JensenShannon_reshaped = np.tile(UC_NQC_JensenShannon, (1,code_NQC_JensenShannon.shape[0]))\n",
        "code_NQC_JensenShannon_reshaped = np.tile(code_NQC_JensenShannon, (1,UC_NQC_JensenShannon.shape[0]))\n",
        "\n",
        "UC_NQC_VSM_reshaped = np.tile(UC_NQC_VSM, (1,code_NQC_VSM.shape[0]))\n",
        "code_NQC_VSM_reshaped = np.tile(code_NQC_VSM, (1,UC_NQC_VSM.shape[0]))\n",
        "\n",
        "UC_NQC_BM25_reshaped = np.tile(UC_NQC_BM25, (1,code_NQC_BM25.shape[0]))\n",
        "code_NQC_BM25_reshaped = np.tile(code_NQC_BM25, (1,UC_NQC_BM25.shape[0]))\n",
        "\n",
        "UC_NQC_JM_reshaped = np.tile(UC_NQC_JM, (1,code_NQC_JM.shape[0]))\n",
        "code_NQC_JM_reshaped = np.tile(code_NQC_JM, (1,UC_NQC_JM.shape[0]))\n",
        "\n",
        "UC_NQC_DP_reshaped = np.tile(UC_NQC_DP, (1,code_NQC_DP.shape[0]))\n",
        "code_NQC_DP_reshaped = np.tile(code_NQC_DP, (1,UC_NQC_DP.shape[0]))\n",
        "\n",
        "UC_SCS = UC_SCS.reshape(UC_SCS.shape[0] * UC_SCS.shape[1])\n",
        "CC_SCS = CC_SCS.reshape(CC_SCS.shape[0] * CC_SCS.shape[1])\n",
        "UC_SCS_reshaped = np.tile(UC_SCS, (CC_SCS.shape[0],1))\n",
        "CC_SCS_reshaped = np.tile(CC_SCS, (UC_SCS.shape[0],1))\n",
        "\n",
        "UC_CoherenceScore = UC_CoherenceScore.reshape(UC_CoherenceScore.shape[0] * UC_CoherenceScore.shape[1])\n",
        "CC_CoherenceScore = CC_CoherenceScore.reshape(CC_CoherenceScore.shape[0] * CC_CoherenceScore.shape[1])\n",
        "UC_CoherenceScore_reshaped = np.tile(UC_CoherenceScore, (CC_CoherenceScore.shape[0],1))\n",
        "CC_CoherenceScore_reshaped = np.tile(CC_CoherenceScore, (UC_CoherenceScore.shape[0],1))\n",
        "\n",
        "num_terms_UC_reshaped = np.tile(num_terms_UC, (num_terms_code.shape[0],1))\n",
        "num_terms_code_reshaped = np.tile(num_terms_code, (num_terms_UC.shape[0],1))\n",
        "\n",
        "num_unique_terms_UC_reshaped = np.tile(num_unique_terms_UC, (num_unique_terms_code.shape[0],1))\n",
        "num_unique_terms_code_reshaped = np.tile(num_unique_terms_code, (num_unique_terms_UC.shape[0],1))\n",
        "\n",
        "# Print reshaped sizes for all variables\n",
        "print(\"Reshaped sizes:\")\n",
        "\n",
        "print(\"avg_idf_uc_reshaped:\", avg_idf_uc_reshaped.shape)\n",
        "print(\"avg_idf_code_reshaped:\", avg_idf_code_reshaped.shape)\n",
        "\n",
        "print(\"max_idf_uc_reshaped:\", max_idf_uc_reshaped.shape)\n",
        "print(\"max_idf_code_reshaped:\", max_idf_code_reshaped.shape)\n",
        "\n",
        "print(\"dev_idf_uc_reshaped:\", dev_idf_uc_reshaped.shape)\n",
        "print(\"dev_idf_code_reshaped:\", dev_idf_code_reshaped.shape)\n",
        "\n",
        "print(\"avg_ictf_uc_reshaped:\", avg_ictf_uc_reshaped.shape)\n",
        "print(\"avg_ictf_code_reshaped:\", avg_ictf_code_reshaped.shape)\n",
        "\n",
        "print(\"max_ictf_uc_reshaped:\", max_ictf_uc_reshaped.shape)\n",
        "print(\"max_ictf_code_reshaped:\", max_ictf_code_reshaped.shape)\n",
        "\n",
        "print(\"dev_ictf_uc_reshaped:\", dev_ictf_uc_reshaped.shape)\n",
        "print(\"dev_ictf_code_reshaped:\", dev_ictf_code_reshaped.shape)\n",
        "\n",
        "print(\"avg_entropy_uc_reshaped:\", avg_entropy_uc_reshaped.shape)\n",
        "print(\"avg_entropy_code_reshaped:\", avg_entropy_code_reshaped.shape)\n",
        "\n",
        "print(\"max_entropy_uc_reshaped:\", max_entropy_uc_reshaped.shape)\n",
        "print(\"max_entropy_code_reshaped:\", max_entropy_code_reshaped.shape)\n",
        "\n",
        "print(\"med_entropy_uc_reshaped:\", med_entropy_uc_reshaped.shape)\n",
        "print(\"med_entropy_code_reshaped:\", med_entropy_code_reshaped.shape)\n",
        "\n",
        "print(\"dev_entropy_uc_reshaped:\", dev_entropy_uc_reshaped.shape)\n",
        "print(\"dev_entropy_code_reshaped:\", dev_entropy_code_reshaped.shape)\n",
        "\n",
        "print(\"avg_variance_uc_reshaped:\", avg_variance_uc_reshaped.shape)\n",
        "print(\"avg_variance_code_reshaped:\", avg_variance_code_reshaped.shape)\n",
        "\n",
        "print(\"max_variance_uc_reshaped:\", max_variance_uc_reshaped.shape)\n",
        "print(\"max_variance_code_reshaped:\", max_variance_code_reshaped.shape)\n",
        "\n",
        "print(\"sum_variance_uc_reshaped:\", sum_variance_uc_reshaped.shape)\n",
        "print(\"sum_variance_code_reshaped:\", sum_variance_code_reshaped.shape)\n",
        "\n",
        "print(\"avg_scq_uc_reshaped:\", avg_scq_uc_reshaped.shape)\n",
        "print(\"avg_scq_code_reshaped:\", avg_scq_code_reshaped.shape)\n",
        "\n",
        "print(\"max_scq_uc_reshaped:\", max_scq_uc_reshaped.shape)\n",
        "print(\"max_scq_code_reshaped:\", max_scq_code_reshaped.shape)\n",
        "\n",
        "print(\"sum_sqc_uc_reshaped:\", sum_sqc_uc_reshaped.shape)\n",
        "print(\"sum_sqc_code_reshaped:\", sum_sqc_code_reshaped.shape)\n",
        "\n",
        "print(\"avg_pmi_uc_reshaped:\", avg_pmi_uc_reshaped.shape)\n",
        "print(\"avg_pmi_code_reshaped:\", avg_pmi_code_reshaped.shape)\n",
        "\n",
        "print(\"max_pmi_uc_reshaped:\", max_pmi_uc_reshaped.shape)\n",
        "print(\"max_pmi_code_reshaped:\", max_pmi_code_reshaped.shape)\n",
        "\n",
        "print(\"qs_uc_reshaped:\", qs_uc_reshaped.shape)\n",
        "print(\"qs_code_reshaped:\", qs_code_reshaped.shape)\n",
        "\n",
        "# print(\"UC_queries_score_JensenShannon_reshaped:\", UC_queries_score_JensenShannon_reshaped.shape)\n",
        "# print(\"code_queries_score_JensenShannon_reshaped:\", code_queries_score_JensenShannon_reshaped.shape)\n",
        "\n",
        "# print(\"UC_queries_score_VSM_reshaped:\", UC_queries_score_VSM_reshaped.shape)\n",
        "# print(\"code_queries_score_VSM_reshaped:\", code_queries_score_VSM_reshaped.shape)\n",
        "\n",
        "# print(\"UC_queries_score_BM25_reshaped:\", UC_queries_score_BM25_reshaped.shape)\n",
        "# print(\"code_queries_score_BM25_reshaped:\", code_queries_score_BM25_reshaped.shape)\n",
        "\n",
        "# print(\"UC_queries_score_JM_reshaped:\", UC_queries_score_JM_reshaped.shape)\n",
        "# print(\"code_queries_score_JM_reshaped:\", code_queries_score_JM_reshaped.shape)\n",
        "\n",
        "print(\"UC_RS_JS_reshaped:\", UC_RS_JS_reshaped.shape)\n",
        "print(\"code_RS_JS_reshaped:\", code_RS_JS_reshaped.shape)\n",
        "\n",
        "print(\"UC_RS_VSM_reshaped:\", UC_RS_VSM_reshaped.shape)\n",
        "print(\"code_RS_VSM_reshaped:\", code_RS_VSM_reshaped.shape)\n",
        "\n",
        "print(\"UC_RS_BM25_reshaped:\", UC_RS_BM25_reshaped.shape)\n",
        "print(\"code_RS_BM25_reshaped:\", code_RS_BM25_reshaped.shape)\n",
        "\n",
        "print(\"UC_RS_JM_reshaped:\", UC_RS_JM_reshaped.shape)\n",
        "print(\"code_RS_JM_reshaped:\", code_RS_JM_reshaped.shape)\n",
        "\n",
        "print(\"UC_RS_DP_reshaped:\", UC_RS_DP_reshaped.shape)\n",
        "print(\"code_RS_DP_reshaped:\", code_RS_DP_reshaped.shape)\n",
        "\n",
        "print(\"UC_FRC_JS_reshaped:\", UC_FRC_JS_reshaped.shape)\n",
        "print(\"code_FRC_JS_reshaped:\", code_FRC_JS_reshaped.shape)\n",
        "\n",
        "print(\"UC_FRC_VSM_reshaped:\", UC_FRC_VSM_reshaped.shape)\n",
        "print(\"code_FRC_VSM_reshaped:\", code_FRC_VSM_reshaped.shape)\n",
        "\n",
        "print(\"UC_FRC_BM25_reshaped:\", UC_FRC_BM25_reshaped.shape)\n",
        "print(\"code_FRC_BM25_reshaped:\", code_FRC_BM25_reshaped.shape)\n",
        "\n",
        "print(\"UC_FRC_JM_reshaped:\", UC_FRC_JM_reshaped.shape)\n",
        "print(\"code_FRC_JM_reshaped:\", code_FRC_JM_reshaped.shape)\n",
        "\n",
        "print(\"UC_FRC_DP_reshaped:\", UC_FRC_DP_reshaped.shape)\n",
        "print(\"code_FRC_DP_reshaped:\", code_FRC_DP_reshaped.shape)\n",
        "\n",
        "print(\"UC_CT_JensenShannon_reshaped:\", UC_CT_JensenShannon_reshaped.shape)\n",
        "print(\"code_CT_JensenShannon_reshaped:\", code_CT_JensenShannon_reshaped.shape)\n",
        "\n",
        "print(\"UC_CT_VSM_reshaped:\", UC_CT_VSM_reshaped.shape)\n",
        "print(\"code_CT_VSM_reshaped:\", code_CT_VSM_reshaped.shape)\n",
        "\n",
        "print(\"UC_CT_BM25_reshaped:\", UC_CT_BM25_reshaped.shape)\n",
        "print(\"code_CT_BM25_reshaped:\", code_CT_BM25_reshaped.shape)\n",
        "\n",
        "print(\"UC_CT_JM_reshaped:\", UC_CT_JM_reshaped.shape)\n",
        "print(\"code_CT_JM_reshaped:\", code_CT_JM_reshaped.shape)\n",
        "\n",
        "print(\"UC_CT_DP_reshaped:\", UC_CT_DP_reshaped.shape)\n",
        "print(\"code_CT_DP_reshaped:\", code_CT_DP_reshaped.shape)\n",
        "\n",
        "print(\"UC_SAC_JS_reshaped:\", UC_SAC_JS_reshaped.shape)\n",
        "print(\"code_SAC_JS_reshaped:\", code_SAC_JS_reshaped.shape)\n",
        "\n",
        "print(\"UC_SAC_VSM_reshaped:\", UC_SAC_VSM_reshaped.shape)\n",
        "print(\"code_SAC_VSM_reshaped:\", code_SAC_VSM_reshaped.shape)\n",
        "\n",
        "print(\"UC_SAC_BM25_reshaped:\", UC_SAC_BM25_reshaped.shape)\n",
        "print(\"code_SAC_BM25_reshaped:\", code_SAC_BM25_reshaped.shape)\n",
        "\n",
        "print(\"UC_SAC_JM_reshaped:\", UC_SAC_JM_reshaped.shape)\n",
        "print(\"code_SAC_JM_reshaped:\", code_SAC_JM_reshaped.shape)\n",
        "\n",
        "print(\"UC_SAC_DP_reshaped:\", UC_SAC_DP_reshaped.shape)\n",
        "print(\"code_SAC_DP_reshaped:\", code_SAC_DP_reshaped.shape)\n",
        "\n",
        "print(\"UC_WIG_score_JensenShannon_reshaped:\", UC_WIG_score_JensenShannon_reshaped.shape)\n",
        "print(\"code_WIG_score_JensenShannon_reshaped:\", code_WIG_score_JensenShannon_reshaped.shape)\n",
        "\n",
        "print(\"UC_WIG_score_VSM_reshaped:\", UC_WIG_score_VSM_reshaped.shape)\n",
        "print(\"code_WIG_score_VSM_reshaped:\", code_WIG_score_VSM_reshaped.shape)\n",
        "\n",
        "print(\"UC_WIG_score_BM25_reshaped:\", UC_WIG_score_BM25_reshaped.shape)\n",
        "print(\"code_WIG_score_BM25_reshaped:\", code_WIG_score_BM25_reshaped.shape)\n",
        "\n",
        "print(\"UC_WIG_score_JM_reshaped:\", UC_WIG_score_JM_reshaped.shape)\n",
        "print(\"code_WIG_score_JM_reshaped:\", code_WIG_score_JM_reshaped.shape)\n",
        "\n",
        "print(\"UC_WIG_score_DP_reshaped:\", UC_WIG_score_DP_reshaped.shape)\n",
        "print(\"code_WIG_score_DP_reshaped:\", code_WIG_score_DP_reshaped.shape)\n",
        "\n",
        "print(\"UC_NQC_JensenShannon_reshaped:\", UC_NQC_JensenShannon_reshaped.shape)\n",
        "print(\"code_NQC_JensenShannon_reshaped:\", code_NQC_JensenShannon_reshaped.shape)\n",
        "\n",
        "print(\"UC_NQC_VSM_reshaped:\", UC_NQC_VSM_reshaped.shape)\n",
        "print(\"code_NQC_VSM_reshaped:\", code_NQC_VSM_reshaped.shape)\n",
        "\n",
        "print(\"UC_NQC_BM25_reshaped:\", UC_NQC_BM25_reshaped.shape)\n",
        "print(\"code_NQC_BM25_reshaped:\", code_NQC_BM25_reshaped.shape)\n",
        "\n",
        "print(\"UC_NQC_JM_reshaped:\", UC_NQC_JM_reshaped.shape)\n",
        "print(\"code_NQC_JM_reshaped:\", code_NQC_JM_reshaped.shape)\n",
        "\n",
        "print(\"UC_NQC_DP_reshaped:\", UC_NQC_DP_reshaped.shape)\n",
        "print(\"code_NQC_DP_reshaped:\", code_NQC_DP_reshaped.shape)\n",
        "\n",
        "print(\"UC_SCS_reshaped:\", UC_SCS_reshaped.shape)\n",
        "print(\"CC_SCS_reshaped:\", CC_SCS_reshaped.shape)\n",
        "\n",
        "print(\"UC_CoherenceScore_reshaped:\", UC_CoherenceScore_reshaped.shape)\n",
        "print(\"CC_CoherenceScore_reshaped:\", CC_CoherenceScore_reshaped.shape)\n",
        "\n",
        "print(\"num_terms_UC_reshaped:\", num_terms_UC_reshaped.shape)\n",
        "print(\"num_terms_code_reshaped:\", num_terms_code_reshaped.shape)\n",
        "\n",
        "print(\"num_unique_terms_UC_reshaped:\", num_unique_terms_UC_reshaped.shape)\n",
        "print(\"num_unique_terms_code_reshaped:\", num_unique_terms_code_reshaped.shape)\n",
        "\n",
        "print(cosine_similarity_UC.shape, cosine_similarity_CC.shape, LSA_similraities_UC.shape, LSA_similraities_CC.shape,\n",
        "                            JS_UC.shape, JS_CC.shape, LDA_similraities_UC.shape, LDA_similraities_CC.shape,BM25_UC.T.shape,BM25_CC.shape,JM_UC.T.shape,JM_CC.shape,DP_UC.T.shape,DP_CC.shape)\n",
        "\n",
        "feature_matrix = np.stack(( cosine_similarity_UC, cosine_similarity_CC, LSA_similraities_UC, LSA_similraities_CC,\n",
        "                            JS_UC, JS_CC,LDA_similraities_UC,LDA_similraities_CC,BM25_UC.T,BM25_CC,JM_UC.T,JM_CC,DP_UC.T,DP_CC,\n",
        "                            avg_idf_uc_reshaped.T, avg_idf_code_reshaped, max_idf_uc_reshaped.T,\n",
        "                            max_idf_code_reshaped, dev_idf_uc_reshaped.T, dev_idf_code_reshaped, avg_ictf_uc_reshaped.T,\n",
        "                            avg_ictf_code_reshaped, max_ictf_uc_reshaped.T, max_ictf_code_reshaped, dev_ictf_uc_reshaped.T,\n",
        "                            dev_ictf_code_reshaped, avg_entropy_uc_reshaped.T, avg_entropy_code_reshaped, max_entropy_uc_reshaped.T,\n",
        "                            max_entropy_code_reshaped, med_entropy_uc_reshaped.T, med_entropy_code_reshaped, dev_entropy_uc_reshaped.T, \n",
        "                            dev_entropy_code_reshaped, avg_variance_uc_reshaped.T, avg_variance_code_reshaped, max_variance_uc_reshaped.T,\n",
        "                            max_variance_code_reshaped, sum_variance_uc_reshaped.T, sum_variance_code_reshaped, avg_scq_uc_reshaped.T,\n",
        "                            avg_scq_code_reshaped, max_scq_uc_reshaped.T, max_scq_code_reshaped, sum_sqc_uc_reshaped.T, sum_sqc_code_reshaped,\n",
        "                            avg_pmi_uc_reshaped.T, avg_pmi_code_reshaped, max_pmi_uc_reshaped.T, max_pmi_code_reshaped, qs_uc_reshaped.T, qs_code_reshaped, \n",
        "                     \n",
        "                            UC_RS_JS_reshaped.T, code_RS_JS_reshaped, UC_RS_VSM_reshaped.T, \n",
        "                            code_RS_VSM_reshaped,UC_RS_BM25_reshaped.T,code_RS_BM25_reshaped,UC_RS_JM_reshaped.T,\n",
        "                            code_RS_JM_reshaped,UC_RS_DP_reshaped.T,code_RS_DP_reshaped,\n",
        "                            UC_FRC_JS_reshaped.T,code_FRC_JS_reshaped,\n",
        "                            UC_FRC_VSM_reshaped.T,code_FRC_VSM_reshaped,UC_FRC_BM25_reshaped.T,code_FRC_BM25_reshaped,UC_FRC_JM_reshaped.T,code_FRC_JM_reshaped,UC_FRC_DP_reshaped.T,code_FRC_DP_reshaped,UC_CT_JensenShannon_reshaped.T,code_CT_JensenShannon_reshaped,\n",
        "                            UC_CT_VSM_reshaped.T,code_CT_VSM_reshaped,UC_CT_BM25_reshaped.T,code_CT_BM25_reshaped,UC_CT_JM_reshaped.T,code_CT_JM_reshaped,UC_CT_DP_reshaped.T,code_CT_DP_reshaped,UC_SAC_JS_reshaped,code_SAC_JS_reshaped.T,UC_SAC_VSM_reshaped,code_SAC_VSM_reshaped.T,UC_SAC_BM25_reshaped,\n",
        "                            code_SAC_BM25_reshaped.T,UC_SAC_JM_reshaped,code_SAC_JM_reshaped.T,UC_SAC_DP_reshaped,code_SAC_DP_reshaped.T,UC_WIG_score_JensenShannon_reshaped,code_WIG_score_JensenShannon_reshaped.T,UC_WIG_score_VSM_reshaped,\n",
        "                            code_WIG_score_VSM_reshaped.T,UC_WIG_score_BM25_reshaped,code_WIG_score_BM25_reshaped.T,UC_WIG_score_JM_reshaped,code_WIG_score_JM_reshaped.T,UC_WIG_score_DP_reshaped,code_WIG_score_DP_reshaped.T,UC_NQC_JensenShannon_reshaped,\n",
        "                            code_NQC_JensenShannon_reshaped.T,\n",
        "                            UC_NQC_VSM_reshaped,code_NQC_VSM_reshaped.T\n",
        "                            ,UC_NQC_BM25_reshaped,code_NQC_BM25_reshaped.T,\n",
        "                            UC_NQC_JM_reshaped,code_NQC_JM_reshaped.T,\n",
        "                            UC_NQC_DP_reshaped,code_NQC_DP_reshaped.T,\n",
        "                            UC_CoherenceScore_reshaped.T,CC_CoherenceScore_reshaped,CC_SCS_reshaped,UC_SCS_reshaped.T,\n",
        "                            num_overlapping_terms,num_terms_code_reshaped, num_terms_UC_reshaped.T,\n",
        "                            num_unique_terms_code_reshaped, num_unique_terms_UC_reshaped.T\n",
        "                            ), axis=2)\n",
        "\n",
        "print(feature_matrix.shape)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Feature Selection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# matrix shape = links * features \n",
        "# ----features------\n",
        "#|\n",
        "#links\n",
        "#|\n",
        "feature_matrix_reshaped = feature_matrix.reshape(feature_matrix.shape[0]*feature_matrix.shape[1], -1)\n",
        "print(feature_matrix_reshaped.shape)\n",
        "correlation_features=np.corrcoef(feature_matrix_reshaped,rowvar=False)\n",
        "print(correlation_features.shape)\n",
        "features_excluded=set()\n",
        "\n",
        "for i in range(correlation_features.shape[1]):\n",
        "    for j in range(i+1,correlation_features.shape[0]):\n",
        "        if (correlation_features[j][i] >= 0.9 ):\n",
        "            print(j,i)\n",
        "            features_excluded.add(j)\n",
        "\n",
        "features_links_selected=np.delete(feature_matrix_reshaped, list(features_excluded), axis=1) \n",
        "print(features_excluded)\n",
        "print(features_links_selected.shape)\n",
        "features_links_selected_reshaped = features_links_selected.reshape(feature_matrix.shape[0], feature_matrix.shape[1], -1)\n",
        "print(features_links_selected_reshaped.shape)\n",
        "# correlation_features)\n",
        "# for i in correlation_features:\n",
        "#     print (i)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Mapping Features to Labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "Features = list()\n",
        "DataSet = pd.read_csv('Dataset/teiid_dataset/train_modified.csv')\n",
        "for row in DataSet.index:\n",
        "    index_code = int(DataSet.loc[row, 'CC'])\n",
        "    index_UC = int(DataSet.loc[row, 'UC'])\n",
        "    Features.append(features_links_selected_reshaped[index_UC][index_code])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# print(len(Features[]))\n",
        "# print(len(DataSet['Labels'].to_list()))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Data Imbalancing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from imblearn.over_sampling import BorderlineSMOTE \n",
        "smote = BorderlineSMOTE(random_state=42)\n",
        "Features_SMOTE, Labels_SMOTE = smote.fit_resample(Features, DataSet['Labels'].to_list())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "\n",
        "train_features, test_features, train_labels, test_labels = train_test_split(Features_SMOTE, Labels_SMOTE, test_size = 0.25, random_state = 42)\n",
        "model_random_forest = RandomForestRegressor(n_estimators = 100, random_state = 42, verbose=2, n_jobs=4)\n",
        "model_random_forest.fit(train_features, train_labels)\n",
        "\n",
        "predictions = model_random_forest.predict(test_features)\n",
        "errors = abs(predictions - test_labels)\n",
        "print('mean Absolute Error:', round(np.mean(errors), 2) )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "acc=(test_labels==predictions).sum()\n",
        "print(acc/len(test_labels))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Loading Model and Testing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from joblib import load\n",
        "\n",
        "# Load the model\n",
        "model = load('pickles_teiid/RandomForst_131Features_2nd_trial_tehiid.joblib')\n",
        "\n",
        "# Assuming you have test data in variables X_test and y_test\n",
        "predictions = model.predict(test_features)\n",
        "\n",
        "# Calculate the accuracy of the model on the test data\n",
        "errors = abs(predictions - test_labels)\n",
        "print('mean Absolute Error:', round(np.mean(errors), 2) )\n",
        "\n",
        "acc=(test_labels==predictions).sum()\n",
        "print('Accuracy:',acc/len(test_labels))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"test labels: \", test_labels)\n",
        "print(\"predictions: \")\n",
        "for prediction in predictions:\n",
        "    print(prediction)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# from joblib import dump\n",
        "\n",
        "# # Assuming you have trained a model named 'model'\n",
        "# # You can save it using dump\n",
        "# dump(model_random_forest, 'RandomForst_121Features_1st_trial.joblib')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import csv\n",
        "with open('./dataset/answerSet.csv', newline='') as csvfile:\n",
        "    reader = csv.reader(csvfile, delimiter=' ', quotechar='|')\n",
        "    valid_links_labels = []\n",
        "    for row in reader:\n",
        "        temp=row[0].split(\",\")\n",
        "        #match = re.search(rprint('UC(\\d+)\\.txt', temp[0])\n",
        "        valid_links_labels.append((temp[0],temp[1]))\n",
        "        # if (valid_links_labels.get(temp[1])==None):\n",
        "        # valid_links_labels[temp[1]]=[int(match.group(1))]\n",
        "        # else:\n",
        "        #     valid_links_labels[temp[1]].append(int(match.group(1)))\n",
        "\n",
        "# file_names = list(valid_links_labels.keys())\n",
        "# file_names.sort()\n",
        "# valid_links_labels_sorted = {i: valid_links_labels[i] for i in file_names}\n",
        "            \n",
        "# valid_links_labels_sorted)\n",
        "# len(valid_links_labels_sorted.keys()))\n",
        "print(valid_links_labels)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
