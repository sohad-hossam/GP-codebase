{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "from imports import *\n",
        "from FeatureExtraction import *\n",
        "from PreProcessor import *"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Preprocessor"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "</h3>Train </h3>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Vocab_UC_train {'modelsourc', 'descr', 'ikx', 'calend', 'func', 'dayofweek', 'enter', 'prepend', 'pharma', 'glassfish', 'resolut', 'fashion', 'googl', 'mayb', 'depict', 'chicago', 'tcli', 'name', 'ar', 'yp', 'ultim', 'ebl', 'place', 'toad', 'misspel', 'clean', 'parsetimestamp', 'closer', 're', 'afaigg', 'yw', 'qv', 'assign', 'rrhu', 'wdmm', 'northwind', 'rang', 'webapp', 'ch', 'pnccanvaspck', 'nfn', 'yyy', 'past', 'stage', 'lexi', 'rebuff', 'oasi', 'stringkey', 'area', 'introduct', 'msg', 'owner', 'rect', 'heavi', 'etc', 'silent', 'scott', 'ti', 'smallint', 'may', 'insid', 'chain', 'jmx', 'condef', 'write', 'ide', 'ok', 'ql', 'stringnum', 'truststor', 'ifnul', 'made', 'oj', 'infinispan', 'sinusoid', 'need', 'bb', 'ede', 'acm', 'txn', 'entiti', 'saxon', 'parenthesi', 'resum', 'win', 'array', 'choke', 'di', 'southeast', 'partialresultsmod', 'picomp', 'sqlserver', 'prep', 'poi', 'side', 'twitter', 'yc', 'ylv', 'anon', 'core', 'mmx', 'reach', 'xqueri', 'nz', 'iu', 'togeth', 'concurr', 'jdoyl', 'cours', 'asynchron', 'remotecach', 'pref', 'nul', 'serializ', 'life', 'took', 'easi', 'tctt', 'dyno', 'struct', 'linestr', 'light', 'updat', 'whatev', 'logic', 'qp', 'ado', 'frame', 'appear', 'nationkey', 'nak', 'administr', 'constraint', 'ration', 'upsel', 'tall', 'con', 'revert', 'codec', 'gwt', 'necessari', 'sit', 'gaymz', 'numer', 'circumst', 'linenumb', 'outgo', 'overflow', 'text', 'weaver', 'weight', 'admtim', 'explan', 'corner', 'ci', 'xukmqof', 'alchd', 'pluc', 'accord', 'postgr', 'behavior', 'safe', 'blank', 'explos', 'docker', 'zero', 'tbednh', 'nillabl', 'data', 'mg', 'txt', 'fatal', 'panel', 'junit', 'transform', 'quantiti', 'xu', 'localjdg', 'extrem', 'addr', 'method', 'town', 'polish', 'schemanam', 'bgg', 'prompt', 'sysinfo', 'reduc', 'gjdiq', 'saturday', 'foreignkey', 'udb', 'how', 'store', 'bbefbaaaddbb', 'ajaxjsf', 'walker', 'lambda', 'via', 'claim', 'token', 'dbname', 'bi', 'tweak', 'befor', 'abil', 'aspect', 'wololo', 'psqlodbc', 'test', 'convert', 'nq', 'reddeer', 'salari', 'uk', 'href', 'yk', 'runner', 'newest', 'often', 'care', 'membership', 'action', 'custid', 'krbcc', 'am', 'accomplish', 'gen', 'closedjava', 'clearer', 'promot', 'num', 'he', 'teiidus', 'object', 'metatyp', 'monday', 'simpli', 'junk', 'timestampv', 'jul', 'taken', 'pool', 'ljava', 'asynch', 'datatim', 'offici', 'undefin', 'ref', 'vk', 'consist', 'edu', 'wherefrom', 'btw', 'five', 'presum', 'iqrefbb', 'comparison', 'sysadmin', 'sso', 'excess', 'structur', 'mojo', 'cl', 'wx', 'orderid', 'dbz', 'lost', 'dbcp', 'mani', 'compani', 'resov', 'assertionerror', 'constrain', 'mnt', 'ea', 'doc', 'geom', 'assum', 'string', 'inappropri', 'fact', 'recogn', 'sever', 'softwar', 'somewhat', 'modifi', 'namespac', 'oio', 'timestamptyp', 'channel', 'verifi', 'bittronix', 'oraclebqt', 'qhllcr', 'sens', 'currenc', 'scontrol', 'collat', 'vwey', 'fp', 'address', 'someon', 'numero', 'cbc', 'deep', 'hi', 'clinit', 'futur', 'similarli', 'away', 'work', 'increment', 'kingdom', 'hb', 'provinc', 'indirectli', 'rdbm', 'ijf', 'abnf', 'rare', 'ndv', 'lang', 'unus', 'arg', 'sometim', 'notion', 'pw', 'wi', 'workdir', 'sortutil', 'dynamicvdb', 'year', 'userid', 'suggest', 'holder', 'rod', 'xestacktrac', 'debbi', 'edwdba', 'least', 'jbossweb', 'tmfail', 'pretti', 'resort', 'codehau', 'iqbal', 'inclus', 'bcx', 'keymanag', 'filenam', 'gdqac', 'given', 'treat', 'udaf', 'to', 'statement', 'blindli', 'float', 'nhl', 'batcher', 'label', 'web', 'hot', 'balanc', 'toolkit', 'pub', 'older', 'million', 'sideway', 'metdata', 'portabl', 'thrown', 'cprincip', 'unquot', 'dl', 'instanceof', 'discrimin', 'scan', 'datacom', 'labprinterconfig', 'gss', 'lowercas', 'dummi', 'instr', 'amount', 'shipmod', 'north', 'wsservlet', 'america', 'zth', 'ge', 'commun', 'hard', 'quit', 'bucket', 'tight', 'artifact', 'sw', 'doublenum', 'pioledb', 'net', 'separ', 'gep', 'pkq', 'customfunct', 'weak', 'contyp', 'benefici', 'aw', 'casal', 'multi', 'ssn', 'button', 'modul', 'bug', 'ecb', 'publish', 'qb', 'display', 'limit', 'decis', 'ytd', 'anonym', 'last', 'searchabl', 'ret', 'becaus', 'async', 'col', 'python', 'subqueryfromclaus', 'scrollabl', 'platform', 'sh', 'texttabl', 'creat', 'possibl', 'excel', 'unlik', 'session', 'opu', 'nov', 'choos', 'deca', 'rhel', 'vertica', 'ica', 'copi', 'plate', 'convers', 'moreov', 'orvc', 'bigbigbig', 'earli', 'std', 'hc', 'model', 'schedul', 'style', 'launch', 'prefil', 'they', 'meaning', 'vg', 'unclear', 'met', 'xxxxxxxxxxx', 'bdec', 'machin', 'throwabl', 'much', 'atttypid', 'tv', 'cardin', 'jbosssoa', 'hbase', 'medium', 'code', 'no', 'retri', 'resultgroup', 'pbox', 'legaci', 'recreat', 'catch', 'cbd', 'renderkit', 'submit', 'intnum', 'over', 'eq', 'occasionali', 'help', 'semant', 'ordinari', 'split', 'firstcol', 'rtm', 'jaxw', 'confrelid', 'signeddata', 'credenti', 'conjunct', 'know', 'monthend', 'linear', 'capit', 'zipcod', 'ascii', 'inadvert', 'append', 'believ', 'sz', 'well', 'jn', 'rzz', 'zhsi', 'jimmi', 'shortvalu', 'implicit', 'rais', 'fiscal', 'xt', 'polici', 'spatial', 'jdg', 'supplier', 'messag', 'anymor', 'fetchsiz', 'between', 'lookup', 'evaluat', 'worker', 'subset', 'prone', 'postal', 'ffffbbed', 'vcsm', 'arrayt', 'derbycli', 'sinc', 'onto', 'mcp', 'executor', 'imag', 'hive', 'renam', 'latter', 'it', 'mislead', 'caus', 'delimit', 'root', 'particip', 'prospect', 'ds', 'hello', 'javadoc', 'heap', 'uc', 'rhq', 'csv', 'beanshel', 'base', 'propos', 'url', 'effort', 'dw', 'booleanvalu', 'point', 'ksi', 'readm', 'bu', 'wf', 'agg', 'mode', 'minut', 'henc', 'xo', 'file', 'print', 'primari', 'cola', 'listagg', 'with', 'furthermor', 'parent', 'keeper', 'cli', 'javassist', 'tbl', 'kerbero', 'adrelid', 'pd', 'mistak', 'eppo', 'top', 'monitor', 'mix', 'sourcefinanci', 'alreadi', 'refman', 'sni', 'hashcod', 'rollup', 'qf', 'textagg', 'begin', 'clarifi', 'dimension', 'date', 'develop', 'paradigm', 'ii', 'map', 'nativ', 'maintain', 'respond', 'portfoilo', 'ck', 'sync', 'sourc', 'pl', 'mongodb', 'stringval', 'kit', 'misc', 'sp', 'evtutctod', 'otherwis', 'human', 'report', 'gi', 'pr', 'cleaner', 'accordingli', 'conflict', 'latest', 'tcp', 'tmptbl', 'rel', 'vd', 'lucen', 'serial', 'ward', 'four', 'undertow', 'dap', 'pseudo', 'lk', 'correctli', 'decomposit', 'ejercicio', 'occur', 'jbedsp', 'browser', 'ef', 'proc', 'toast', 'sc', 'improp', 'vraf', 'say', 'sobject', 'unpredict', 'emul', 'tl', 'consum', 'negoti', 'bbea', 'xml', 'person', 'nav', 'kr', 'dest', 'implicitli', 'ccc', 'charvalu', 'thu', 'insensit', 'step', 'eap', 'aria', 'cpe', 'region', 'jr', 'returnflag', 'without', 'go', 'off', 'unmodifi', 'enough', 'jbcpsi', 'yd', 'jbd', 'datum', 'ect', 'timev', 'altern', 'extract', 'matview', 'folder', 'financi', 'bintext', 'vfsfile', 'will', 'ga', 'tpch', 'elaps', 'evict', 'mfgr', 'referenc', 'ym', 'programat', 'addtion', 'outbound', 'order', 'assumpt', 'fasterxml', 'might', 'atom', 'tinyint', 'oxk', 'metamatrix', 'lower', 'vj', 'jre', 'frontend', 'oihi', 'customis', 'viewnam', 'js', 'deeper', 'vt', 'bytem', 'mb', 'lx', 'didnt', 'ime', 'nu', 'abstract', 'rp', 'intend', 'ssl', 'windowfunctionproject', 'boiler', 'attnam', 'bar', 'modeshap', 'understood', 'rx', 'algorithm', 'review', 'fx', 'vkr', 'sect', 'util', 'cuh', 'connectorclasspath', 'alt', 'multipolygon', 'sape', 'regexp', 'cpu', 'support', 'ad', 'whi', 'question', 'uuid', 'fi', 'flag', 'ajp', 'discoveri', 'wflyctl', 'head', 'siz', 'we', 'forth', 'unfold', 'gd', 'exclud', 'inact', 'spread', 'mileston', 'workerpool', 'jhu', 'coord', 'picklist', 'mbean', 'jass', 'datamgr', 'slot', 'mx', 'play', 'greedi', 'thi', 'franc', 'fill', 'xsi', 'characterist', 'custkey', 'three', 'function', 'il', 'optim', 'lcom', 'mmsql', 'bekwhb', 'aiyn', 'fine', 'exhaust', 'nmzi', 'purchas', 'interest', 'dy', 'datevalu', 'track', 'dss', 'traslat', 'iwe', 'product', 'dbn', 'standard', 'admin', 'trail', 'differ', 'overload', 'invok', 'ki', 'fzpec', 'strict', 'perl', 'ne', 'disjunct', 'ffffaa', 'isoft', 'incorrect', 'tr', 'integr', 'tablenam', 'media', 'mile', 'lzqf', 'sock', 'mask', 'set', 'equal', 'regress', 'plantre', 'microsoft', 'consider', 'semicolon', 'krcn', 'jk', 'joda', 'dataj', 'reset', 'fedora', 'er', 'went', 'expand', 'mean', 'throw', 'matter', 'olap', 'vie', 'lyd', 'regexpr', 'clob', 'mysql', 'calendar', 'av', 'agent', 'sysid', 'broadli', 'collaps', 'osq', 'anyinteract', 'meter', 'nux', 'pointer', 'busi', 'relnam', 'tablepostgr', 'peek', 'defect', 'grace', 'nm', 'germani', 'temp', 'upon', 'context', 'consult', 'digest', 'whenev', 'distinct', 'expos', 'ordin', 'defrag', 'mostli', 'nss', 'hawkin', 'recurs', 'lesser', 'prg', 'datamart', 'unsynchron', 'score', 'fiddl', 'fetch', 'ort', 'ed', 'axa', 'email', 'aaa', 'item', 'sqlpanel', 'rmtsampleflight', 'hd', 'translat', 'ynv', 'cv', 'nexu', 'paramet', 'worst', 'nw', 'impli', 'fvlm', 'inject', 'unchalleng', 'ewi', 'xmlpars', 'particular', 'qio', 'jdk', 'tricki', 'easili', 'user', 'ydo', 'nice', 'grc', 'qg', 'mem', 'unnecessari', 'descript', 'word', 'from', 'tomcat', 'fetchrow', 'cid', 'visual', 'ydv', 'descriptor', 'nextval', 'such', 'creation', 'routin', 'dens', 'engin', 'isnul', 'cnt', 'writabl', 'jbosscach', 'wzqz', 'observ', 'wbti', 'length', 'preparedstat', 'makedep', 'degrad', 'thank', 'yr', 'undeclar', 'obj', 'sxe', 'extran', 'nev', 'mobil', 'mediuma', 'dcabc', 'nit', 'footprint', 'jersey', 'even', 'classpath', 'mssql', 'role', 'timeout', 'bpzgp', 'semaphor', 'applianc', 'reorder', 'ex', 'can', 'rubi', 'small', 'untouch', 'selector', 'ke', 'bound', 'floatnum', 'dbd', 'qualifi', 'krp', 'opengeospati', 'week', 'env', 'aliv', 'uniqueidentifi', 'star', 'xhtml', 'tdsparser', 'sampl', 'iso', 'dealloc', 'under', 'zzz', 'ygn', 'subqueryin', 'era', 'wrt', 'div', 'btt', 'appar', 'progress', 'inici', 'abbf', 'for', 'extent', 'saw', 'remot', 'my', 'understand', 'snippet', 'flight', 'yet', 'on', 'click', 'anywher', 'jaxrpc', 'stringfun', 'lazi', 'plan', 'bqd', 'bodi', 'planner', 'deseri', 'jp', 'teiidtest', 'except', 'bk', 'www', 'ac', 'ignor', 'exhibit', 'izisprod', 'foo', 'complain', 'line', 'hit', 'jl', 'special', 'builder', 'nullmyfilesnul', 'inhibit', 'deleg', 'bnxbno', 'undocu', 'shift', 'perf', 'stat', 'dot', 'todo', 'sender', 'glim', 'avoid', 'defin', 'john', 'highlight', 'ansi', 'choic', 'edit', 'njknuxob', 'jar', 'jxqi', 'smalla', 'wp', 'mmuuid', 'unix', 'metric', 'pid', 'jcc', 'ticket', 'demo', 'infocent', 'spnego', 'block', 'cachabl', 'foreign', 'gnji', 'dedic', 'problem', 'mail', 'chanc', 'sax', 'iwgf', 'express', 'children', 'cryptor', 'bare', 'stock', 'comcast', 'home', 'idtestp', 'best', 'jdurani', 'each', 'similar', 'joi', 'send', 'chr', 'wsa', 'lead', 'swagger', 'far', 'mgr', 'conform', 'link', 'hashref', 'ye', 'quarter', 'lpad', 'regionkey', 'ewkb', 'wherea', 'sampled', 'subcommand', 'ust', 'driven', 'pushdown', 'mgd', 'random', 'scanner', 'tx', 'tell', 'statist', 'truli', 'downstream', 'mcc', 'wflysrv', 'usag', 'authent', 'strang', 'higher', 'unhandl', 'sessionid', 'nvarchar', 'pdf', 'lfred', 'doen', 'al', 'drift', 'qoz', 'end', 'stripe', 'australia', 'scram', 'pipelin', 'intermitt', 'europ', 'vault', 'if', 'char', 'dc', 'seem', 'quick', 'bigdecim', 'advertis', 'pars', 'great', 'fast', 'threshold', 'independ', 'manag', 'bind', 'overridden', 'categori', 'mimic', 'apd', 'geojson', 'touch', 'saniti', 'legal', 'ir', 'fut', 'affect', 'decompos', 'found', 'coupl', 'snip', 'qq', 'nomin', 'conf', 'direct', 'naut', 'uncheck', 'non', 'aov', 'fdg', 'proj', 'request', 'back', 'xmlcomment', 'timetyp', 'wr', 'vlz', 'vo', 'seen', 'uy', 'an', 'osisoft', 'properli', 'seq', 'opportun', 'recv', 'xmthreadinfo', 'ask', 'queri', 'olingo', 'wild', 'leav', 'cgi', 'prei', 'versu', 'grow', 'prod', 'dsc', 'zu', 'tostr', 'bytea', 'wider', 'ship', 'vs', 'vm', 'presto', 'eig', 'regex', 'jstastni', 'de', 'axi', 'mnc', 'cross', 'weekday', 'ykkl', 'xmlserial', 'unsaf', 'thumbnail', 'ak', 'nc', 'outer', 'dayofyear', 'accum', 'varchar', 'sm', 'suport', 'servlet', 'gateway', 'bean', 'exec', 'difficult', 'reconnect', 'put', 'err', 'pre', 'vb', 'manner', 'forc', 'starttim', 'lmd', 'amout', 'previou', 'linkag', 'mapper', 'relev', 'pluggabl', 'pad', 'allow', 'of', 'unregist', 'userrol', 'quickli', 'testng', 'checker', 'phone', 'ogc', 'thing', 'sdk', 'scenario', 'aona', 'describ', 'mixin', 'span', 'nnv', 'histor', 'localhost', 'awar', 'debug', 'availqti', 'conn', 'connam', 'kernel', 'honor', 'unfortun', 'buffermanag', 'threw', 'hr', 'dup', 'gcol', 'decim', 'escap', 'examin', 'millsecond', 'latitud', 'critic', 'level', 'piarchiv', 'framework', 'newli', 'bab', 'swap', 'qzq', 'djava', 'press', 'intro', 'rxeba', 'middl', 'sth', 'sqaxeh', 'niap', 'gdata', 'push', 'semi', 'font', 'communitiy', 'parti', 'oversight', 'ruleimplementjoinstrategi', 'duplic', 'usr', 'chose', 'amfm', 'who', 'exceed', 'nx', 'trace', 'kw', 'jbeap', 'yxch', 'daemon', 'tune', 'fdad', 'prob', 'success', 'hundr', 'startup', 'repres', 'warn', 'sdt', 'nci', 'icedtea', 'confus', 'tab', 'preced', 'vw', 'mom', 'keytab', 'mediat', 'cdh', 'constant', 'continu', 'apr', 'io', 'ra', 'rb', 'vr', 'datasourc', 'registr', 'troubl', 'yfg', 'discharg', 'longlat', 'collector', 'cebank', 'inform', 'jdww', 'simul', 'sugar', 'releas', 'kcz', 'xmlelement', 'iy', 'logj', 'kill', 'disassoci', 'configur', 'cmi', 'half', 'ao', 'accumul', 'addresst', 'metada', 'further', 'replic', 'mm', 'os', 'ucas', 'idl', 'thr', 'result', 'design', 'preload', 'checksum', 'whereclaus', 'usm', 'vdbr', 'skip', 'leak', 'htv', 'cluster', 'oid', 'partial', 'expr', 'hdbimplifi', 'nevertheless', 'dayofmonth', 'testrol', 'formattimestamp', 'argument', 'javacc', 'subject', 'ng', 'disallow', 'unsuccess', 'central', 'locat', 'that', 'ccz', 'asgeojson', 'rey', 'jo', 'itritp', 'eb', 'bsh', 'unexpectedli', 'perspect', 'bank', 'despit', 'avail', 'conveni', 'patgroup', 'unrol', 'unsign', 'rv', 'labr', 'airlift', 'form', 'then', 'nullif', 'sprocket', 'peopl', 'charset', 'fc', 'smwpkfvo', 'prepar', 'deflat', 'isbn', 'xac', 'dynamodb', 'calcul', 'wildfli', 'vfe', 'wgrr', 'metadatavalid', 'conkey', 'dataformat', 'confdeltyp', 'move', 'extra', 'wiki', 'afbd', 'provid', 'unmarshal', 'debbiedb', 'particularli', 'fg', 'scalar', 'tzdz', 'edm', 'whitespac', 'node', 'hotdeploy', 'registri', 'bom', 'solv', 'unless', 'dop', 'purpos', 'gt', 'resp', 'gs', 'pattern', 'ib', 'cc', 'ygg', 'zw', 'nma', 'confluenc', 'jaxb', 'visitor', 'lack', 'longnum', 'payload', 'respons', 'fraction', 'sub', 'explain', 'ul', 'fid', 'zc', 'must', 'alter', 'aggreg', 'field', 'modclust', 'shuffl', 'json', 'inser', 'textarea', 'enterpris', 'placement', 'yxv', 'dq', 'facelet', 'privileg', 'pkey', 'appli', 'onli', 'atc', 'jleq', 'page', 'cvxv', 'exp', 'wrong', 'lobworkitem', 'gr', 'doe', 'mdsi', 'policyfkeyxml', 'destroy', 'zbx', 'aa', 'screenshot', 'ww', 'comma', 'mfui', 'hz', 'tech', 'i', 'hidden', 'jtd', 'delet', 'jackson', 'geomfromtext', 'ahead', 'iq', 'interv', 'babc', 'sj', 'interleav', 'yx', 'unzip', 'incid', 'wish', 'mzkt', 'ifx', 'fenc', 'cdff', 'misplac', 'featur', 'dec', 'slave', 'ftp', 'fals', 'java', 'detail', 'threadpool', 'pair', 'vyguo', 'act', 'deliv', 'quirr', 'seri', 'zoo', 'desc', 'deregistr', 'pm', 'idea', 'be', 'gray', 'villa', 'captur', 'wsdlj', 'oogc', 'twice', 'good', 'longer', 'main', 'mkt', 'shut', 'workbench', 'search', 'misura', 'cmgrd', 'individu', 'sforc', 'lv', 'nondeterminist', 'when', 'assert', 'partit', 'coalesc', 'discuss', 'definit', 'properi', 'facebook', 'eg', 'sypyp', 'monitorvalu', 'graem', 'benefit', 'spreadsheet', 'geoserv', 'hint', 'shape', 'ovh', 'initi', 'testschema', 'pogo', 'mechan', 'new', 'citi', 'usd', 'complet', 'card', 'wflyjca', 'bill', 'fffff', 'subq', 'gmi', 'prevent', 'long', 'opt', 'annual', 'metadatafactori', 'ce', 'kox', 'rangecr', 'through', 'cloudera', 'tpcr', 'thrift', 'ca', 'prog', 'yh', 'eabba', 'preview', 'oledb', 'dd', 'szkyk', 'tm', 'geometri', 'ddbdf', 'stacktrac', 'super', 'tag', 'tccl', 'per', 'amt', 'two', 'nameinsourc', 'userbas', 'forum', 'nql', 'day', 'isoweek', 'anoth', 'runtim', 'alway', 'situat', 'determinist', 'subplan', 'matrix', 'ut', 'union', 'zm', 'sid', 'dim', 'pojo', 'resid', 'variabletim', 'sybas', 'mcr', 'jnu', 'standalon', 'baseus', 'overhead', 'meet', 'jbossw', 'cancelationexcept', 'og', 'intent', 'booksinfo', 'helpdata', 'socket', 'reload', 'appnam', 'fit', 'one', 'drop', 'ij', 'endtim', 'receiptd', 'custsal', 'synch', 'portion', 'littl', 'shawkin', 'aris', 'read', 'vss', 'interven', 'trust', 'stderr', 'adapt', 'cxc', 'reddi', 'lexicod', 'xw', 'polygon', 'necessarili', 'download', 'svcmgr', 'openjdk', 'ibm', 'note', 'less', 'eas', 'sheet', 'regardless', 'list', 'finder', 'pump', 'symbol', 'forward', 'financialaccount', 'especi', 'timer', 'pbcast', 'black', 'load', 'rethrow', 'tax', 'gh', 'derbi', 'classload', 'sb', 'zip', 'asdf', 'scheme', 'greater', 'ht', 'next', 'unqualifi', 'rw', 'qz', 'ab', 'oa', 'network', 'our', 'spengo', 'beta', 'bqaq', 'branch', 'alia', 'enforc', 'incorrectli', 'period', 'resultrank', 'could', 'upper', 'daili', 'achiev', 'sort', 'wl', 'assist', 'gui', 'attr', 'ifac', 'equival', 'veri', 'iter', 'summari', 'effect', 'patient', 'case', 'resolutiond', 'pragma', 'jtn', 'default', 'attribut', 'identifi', 'gg', 'qyi', 'wzo', 'diff', 'wm', 'jndi', 'tempdata', 'reader', 'kn', 'composit', 'partsupp', 'built', 'check', 'hm', 'igrav', 'concat', 'incompat', 'adjust', 'passthrough', 'against', 'sum', 'same', 'concaten', 'geospati', 'distanc', 'oc', 'fbd', 'dataset', 'mj', 'easier', 'booter', 'which', 'georss', 'replac', 'below', 'http', 'wildcard', 'qualif', 'prio', 'lenient', 'rpc', 'ibsbino', 'written', 'weather', 'ava', 'mark', 'memori', 'instead', 'introduc', 'refactor', 'sink', 'lw', 'surefir', 'round', 'waxavzo', 'soap', 'netezza', 'digit', 'timelimit', 'bootstrapp', 'groovysh', 'zookeep', 'volum', 'lrp', 'iqg', 'recip', 'master', 'within', 'is', 'disco', 'shorter', 'tjiradb', 'surfac', 'inher', 'slice', 'execut', 'fbcbd', 'crypto', 'profileservic', 'satisfi', 'certif', 'zqo', 'total', 'scroll', 'rxad', 'sruriqv', 'wun', 'sec', 'xmltabl', 'merg', 'full', 'verbos', 'jnpc', 'child', 'tmp', 'whole', 'evttyp', 'cw', 'apm', 'mutual', 'gj', 'plural', 'ticker', 'steigner', 'rewritten', 'supplierkey', 'secondari', 'ownership', 'lock', 'revenu', 'reserv', 'restrict', 'princip', 'canon', 'lj', 'plugin', 'rest', 'jpg', 'nest', 'redund', 'sbrook', 'rn', 'sg', 'plain', 'backspac', 'gist', 'transit', 'option', 'fktabl', 'build', 'bugzilla', 'now', 'ifun', 'par', 'oracl', 'len', 'matcher', 'wsc', 'sourcea', 'pat', 'feel', 'dure', 'in', 'both', 'mfsmfl', 'dzaxou', 'compact', 'geo', 'topic', 'timstamp', 'tb', 'fix', 'grammar', 'numberof', 'maven', 'udp', 'condeferr', 'init', 'colon', 'divis', 'bunch', 'postgi', 'pushd', 'incomplet', 'nyv', 'usual', 'sun', 'cz', 'receiv', 'jaxr', 'ja', 'jax', 'mv', 'modesp', 'storag', 'spatl', 'bigintegervalu', 'wg', 'jdt', 'factori', 'epoch', 'encrypt', 'gpl', 'wgo', 'repo', 'consent', 'corrupt', 'mvn', 'cql', 'abb', 'cassandrad', 'simplif', 'offer', 'cy', 'crit', 'regard', 'activ', 'audit', 'san', 'ba', 'cwiki', 'strip', 'right', 'principl', 'cell', 'stuck', 'hide', 'ah', 'requisit', 'bit', 'errata', 'some', 'ojbect', 'still', 'ipv', 'br', 'manipul', 'jconnect', 'environ', 'neg', 'defer', 'abd', 'famili', 'usecas', 'desir', 'vnl', 'beyond', 'nr', 'syb', 'greatli', 'enhanc', 'backend', 'zjz', 'rtrim', 'app', 'pcqq', 'cafh', 'lo', 'distribut', 'pom', 'pmge', 'enclos', 'xmln', 'rareddi', 'erron', 'plu', 'salestaxr', 'codahal', 'tabglob', 'rouser', 'orderstatu', 'jpa', 'tk', 'isql', 'document', 'dashb', 'select', 'gc', 'buffer', 'ui', 'deassign', 'subselect', 'bigdecimalvalu', 'ko', 'dtp', 'jom', 'break', 'unauthent', 'multisourc', 'netti', 'connect', 'discret', 'sr', 'modif', 'jy', 'na', 'make', 'fattura', 'da', 'came', 'jir', 'paragraph', 'partkey', 'datastax', 'boot', 'bbelov', 'sup', 'hour', 'suppli', 'efbf', 'roo', 'optimist', 'dfet', 'streamabl', 'argv', 'real', 'websit', 'impress', 'ud', 'apex', 'extern', 'afb', 'atm', 'testcas', 'widen', 'hashtabl', 'nearli', 'command', 'ipi', 'ascend', 'take', 'warehous', 'tend', 'mn', 'manel', 'varieti', 'wt', 'contrari', 'indic', 'minimum', 'manifest', 'inner', 'println', 'wvmab', 'delta', 'audidata', 'cover', 'packag', 'visibl', 'excerpt', 'experienc', 'launcher', 'fhmolceoj', 'pop', 'parallel', 'datetyp', 'mandatori', 'retreiv', 'fefbfafececd', 'xmlagg', 'xa', 'explicit', 'listen', 'thm', 'rowid', 'second', 'significantli', 'chunk', 'timestampdiff', 'lastnam', 'stream', 'utz', 'directli', 'kf', 'priorit', 'preserv', 'ewkt', 'hh', 'gx', 'specif', 'underli', 'ibbkk', 'blob', 'binari', 'strategi', 'rlfd', 'hold', 'auto', 'sent', 'price', 'wsaddress', 'wstx', 'createabl', 'queu', 'follow', 'odd', 'pick', 'cud', 'vrg', 'srid', 'instal', 'temporari', 'funct', 'referenza', 'pn', 'oraspatialsrct', 'extendedpric', 'processor', 'cnf', 'tdsa', 'dt', 'die', 'shortnam', 'show', 'content', 'zdmac', 'too', 'webmvc', 'rar', 'int', 'kbqg', 'rownum', 'compat', 'proceed', 'sofa', 'multipl', 'nio', 'tsi', 'unwrap', 'makeind', 'onerror', 'accessnod', 'sqlxml', 'simplic', 'eiz', 'npe', 'wuscl', 'just', 'xyz', 'interpret', 'ran', 'iwfnd', 'edmx', 'earlier', 'undeploy', 'exist', 'cap', 'compon', 'key', 'embeddedconfigur', 'alu', 'leverag', 'unchang', 'ani', 'subsequ', 'atjava', 'repli', 'workaround', 'vfsmemori', 'quantifi', 'adminshel', 'simpledb', 'local', 'reproduc', 'eza', 'northwest', 'tablea', 'citmp', 'expans', 'raf', 'live', 'extens', 'narrow', 'relnamespac', 'grade', 'redo', 'dfcff', 'deploy', 'namedtypepair', 'fq', 'none', 'id', 'gq', 'xtr', 'embed', 'utf', 'reus', 'pass', 'noth', 'backslash', 'includ', 'isol', 'kuoo', 'ybbqu', 'corej', 'kycq', 'compound', 'toler', 'exce', 'imho', 'elig', 'tuplebuff', 'larg', '└──', 'sla', 'zhd', 'abort', 'rank', 'tabletserv', 'impact', 'ulr', 'lifecycl', 'ojdbc', 'collect', 'unspecifi', 'overal', 'cp', 'oper', 'lz', 'emp', 'auth', 'industri', 'loglevel', 'ro', 'mpr', 'fulli', 'bm', 'gasapom', 'teiidm', 'unexpect', 'overrid', 'consolid', 'cq', 'redhat', 'hld', 'ejb', 'mari', 'enabl', 'tra', 'broke', 'archiv', 'datepartofkey', 'serif', 'impl', 'stuff', 'keycolumn', 'acctbal', 'rewrit', 'cele', 'rme', 'unnam', 'serv', 'myvdb', 'biginteg', 'boss', 'hook', 'dockerfil', 'charact', 'front', 'remain', 'ffffa', 'firstsect', 'bbh', 'wq', 'imshealth', 'void', 'lrfu', 'jcr', 'realval', 'salesforc', 'patch', 'arquillian', 'group', 'admiss', 'fffffffff', 'error', 'queue', 'autoincr', 'uxay', 'hand', 'nullabl', 'ur', 'vdbxml', 'crud', 'leagu', 'accur', 'construct', 'rg', 'stmt', 'comp', 'old', 'eval', 'javascript', 'fork', 'outsid', 'clobval', 'datatool', 'grain', 'amcar', 'elmnt', 'prior', 'templat', 'bigger', 'commitd', 'bp', 'ax', 'implifi', 'fli', 'deni', '├──', 'issu', 'hunch', 'known', 'qri', 'ldap', 'syntax', 'redeploy', 'carriag', 'rowcount', 'fil', 'simplecli', 'cassandra', 'surnam', 'rand', 'ijc', 'nightli', 'sic', 'mvstatu', 'prefix', 'partner', 'prioriti', 'rough', 'section', 'ioexcept', 'noformat', 'creator', 'protobuf', 'ip', 'chorusdata', 'ceil', 'hudson', 'retryabl', 'objectvalu', 'not', 'loop', 'jsontoxml', 'customiz', 'chosen', 'unmod', 'nv', 'sipba', 'friendli', 'wake', 'dynam', 'choru', 'quot', 'expens', 'preparedplan', 'jfyw', 'osdq', 'rs', 'gml', 'sa', 'mistakenli', 'width', 'osi', 'dst', 'today', 'dialog', 'substitut', 'fbe', 'jbossatx', 'ct', 'got', 'problemat', 'floatval', 'qpcga', 'attach', 'ml', 'fqn', 'un', 'technolog', 'sq', 'blog', 'account', 'sf', 'author', 'jdv', 'regularli', 'referenti', 'spell', 'flatten', 'save', 'fefaefcce', 'lh', 'vararg', 'view', 'applic', 'ee', 'fk', 'constructor', 'biieywccbfgc', 'natur', 'guess', 'sy', 'htm', 'dsn', 'consol', 'gb', 'red', 'ijt', 'statementimpl', 'selectal', 'race', 'tsl', 'bram', 'book', 'spot', 'unari', 'basic', 'gzr', 'xl', 'precis', 'floor', 'yon', 'confidenti', 'dbq', 'suffici', 'cast', 'dependson', 'experi', 'lq', 'varbinari', 'oom', 'bounc', 'log', 'spring', 'jira', 'fault', 'beg', 'keystor', 'tablemysql', 'header', 'explor', 'sprintf', 'suiss', 'qx', 'employe', 'stack', 'unnecessarili', 'remark', 'idref', 'comment', 'gender', 'ccbe', 'xid', 'analog', 'sap', 'myy', 'disconnect', 'true', 'formatd', 'hgfvb', 'prefetch', 'green', 'deprec', 'connectionmanag', 'saleforc', 'consequ', 'sqlexplor', 'datetim', 'demand', 'invoic', 'return', 'first', 'bytenum', 'linux', 'getg', 'hoc', 'at', 'succeed', 'resclass', 'jdom', 'you', 'obviou', 'lkw', 'join', 'cred', 'guarante', 'unknown', 'us', 'saxonh', 'mod', 'retun', 'gdvp', 'accommod', 'associ', 'newer', 'testm', 'pagin', 'cr', 'absolut', 'broad', 'dsmalla', 'kind', 'subqueri', 'client', 'declar', 'walk', 'graph', 'tabl', 'fail', 'downsid', 'vy', 'loadnumb', 'schem', 'don', 'logger', 'layer', 'dqp', 'procedur', 'see', 'vyr', 'transaltor', 'imposs', 'out', 'teller', 'integerv', 'timezon', 'cmd', 'lib', 'cursornam', 'do', 'vodafon', 'rememb', 'summat', 'dev', 'adminapi', 'demonstr', 'webservic', 'ow', 'yuz', 'saudi', 'so', 'profil', 'multipli', 'disabl', 'neither', 'zy', 'ymmv', 'dump', 'oall', 'enum', 'never', 'pushabl', 'nva', 'abrb', 'broaden', 'input', 'mine', 'sqlsrv', 'poll', 'unixtim', 'hfj', 'omit', 'valid', 'hurt', 'variou', 'prestodb', 'metamatrixadmin', 'needless', 'count', 'these', 'notifi', 'gmt', 'time', 'offend', 'eoebi', 'le', 'white', 'wqz', 'richfac', 'invoc', 'privat', 'loader', 'migrat', 'millisecond', 'fyi', 'ms', 'mpskk', 'column', 'huge', 'cmr', 'unsupport', 'averag', 'yy', 'nih', 'primarykey', 'phoenix', 'swallow', 'starter', 'sibl', 'pu', 'more', 'member', 'nk', 'import', 'ykgg', 'en', 'handler', 'bpr', 'dbtcp', 'sqleditor', 'project', 'brows', 'unord', 'flow', 'parenthes', 'expir', 'chrome', 'ma', 'fall', 'watch', 'fv', 'present', 'held', 'domain', 'entri', 'clearli', 'tinya', 'dad', 'interceptor', 'gcaq', 'bad', 'multipoint', 'cglib', 'greci', 'calcit', 'ez', 'cumul', 'actuat', 'noshad', 'weblog', 'bigkey', 'png', 'exact', 'mart', 'evolut', 'timein', 'tri', 'msr', 'brand', 'modal', 'protocol', 'into', 'sensit', 'attrelid', 'bearer', 'system', 'gssapi', 'tvl', 'primit', 'secondcol', 'saphelp', 'min', 'decid', 'lie', 'vendita', 'ty', 'disjoint', 'exclus', 'estim', 'com', 'builtin', 'post', 'materi', 'basi', 'cdata', 'grep', 'td', 'decor', 'didn', 'helper', 'viabl', 'unrel', 'cat', 'ae', 'goe', 'by', 'pv', 'arabia', 'dn', 'spuriou', 'keyvalu', 'runnabl', 'geomfromgeojson', 'sure', 'trxmo', 'mondrian', 'world', 'pktabl', 'oct', 'zx', 'virt', 'claus', 'instanc', 'lob', 'sunday', 'edh', 'alread', 'bid', 'ada', 'javas', 'depth', 'doublev', 'sqli', 'uid', 'feed', 'banqu', 'stop', 'mar', 'soon', 'projtext', 'userpassword', 'valv', 'workspac', 'exchang', 'largeobject', 'cci', 'jgroup', 'agre', 'vrp', 'almost', 'indexof', 'lr', 'cod', 'ss', 'titl', 'kp', 'coordin', 'login', 'behaviour', 'decod', 'bin', 'ramesh', 'bmw', 'fn', 'dead', 'slightli', 'wqx', 'truncat', 'cohort', 'resourc', 'cond', 'virtual', 'smaller', 'hang', 'hv', 'ddd', 'connectorbindingid', 'conduit', 'confirm', 'resubmit', 'illegalstateexcept', 'recov', 'entir', 'egj', 'although', 'up', 'tableau', 'impala', 'contract', 'contain', 'rc', 'qu', 'trunc', 'const', 'howev', 'seek', 'lbla', 'sfdc', 'zt', 'strictli', 'vtw', 'task', 'xc', 'pend', 'kl', 'bqt', 'pnittel', 'thread', 'depend', 'bool', '<unk>', 'dtm', 'bbb', 'requir', 'exploit', 'regular', 'plug', 'sdo', 'ubuntu', 'jigsaw', 'valuabl', 'toatom', 'makenotdep', 'nd', 'pleas', 'loopback', 'databasemetadata', 'teradata', 'valu', 'mon', 'caught', 'svl', 'expect', 'sl', 'errmsg', 'evtsystod', 'segment', 'tjruspzb', 'cd', 'approxim', 'low', 'cumbersom', 'moment', 'xx', 'bt', 'comodif', 'jt', 'amazon', 'vividsolut', 'serveradmin', 'marketdata', 'transfer', 'ping', 'dispatch', 'lpn', 'ineffici', 'yyyi', 'jacc', 'phi', 'talk', 'yca', 'add', 'itr', 'host', 'unlimit', 'lf', 'warren', 'koord', 'facilit', 'anyway', 'el', 'jopr', 'refin', 'automat', 'resteasi', 'xqt', 'ug', 'signatur', 'jiraissu', 'bz', 'upstream', 'usabl', 'lt', 'simpl', 'jv', 'mainfram', 'coher', 'process', 'fd', 'raw', 'vft', 'condit', 'codic', 'extensionjar', 'apart', 'kstw', 'commandcontext', 'trx', 'tracker', 'unicod', 'nqu', 'insert', 'vdbname', 'accept', 'outh', 'row', 'hibern', 'qdg', 'hardcod', 'tablet', 'the', 'fs', 'inconsist', 'faster', 'simultan', 'wsdl', 'are', 'urn', 'ie', 'zim', 'let', 'bdc', 'jf', 'wide', 'unread', 'bh', 'appropri', 'tel', 'sse', 'lb', 'protect', 'alon', 'compil', 'after', 'hextoraw', 'reaper', 'fr', 'find', 'probabl', 'tp', 'tn', 'realm', 'match', 'customerid', 'bitand', 'expert', 'soa', 'kdc', 'factor', 'suitabl', 'valor', 'blah', 'kda', 'color', 'vq', 'fmt', 'unsatisfi', 'bilan', 'printf', 'alias', 'kb', 'major', 'requestor', 'ironjacamar', 'xb', 'bjornharrtel', 'irlob', 'mc', 'singleton', 'entitl', 'groovi', 'qrq', 'relat', 'complic', 'ddcf', 'ly', 'cs', 'cu', 'distim', 'uq', 'onc', 'simpler', 'cg', 'jiradb', 'attempt', 'cancel', 'avg', 'repositori', 'max', 'lcase', 'increas', 'kqjr', 'consid', 'admissionid', 'intersect', 'csdl', 'establish', 'setclaus', 'tpe', 'gwa', 'varvalu', 'refresh', 'therefor', 'rowset', 'outcom', 'pp', 'transact', 'smallb', 'bdf', 'typic', 'lab', 'logon', 'forcibl', 'xbogvont', 'ns', 'peinh', 'gasaozmp', 'tier', 'orient', 'envelop', 'failur', 'aop', 'encount', 'odbc', 'control', 'mp', 'doesn', 'mbeanserv', 'autocommit', 'shutdown', 'nslator', 'though', 'ideal', 'way', 'snapshot', 'ispn', 'zzzzz', 'what', 'vorh', 'box', 'persist', 'schema', 'uniqu', 'said', 'foreach', 'finer', 'vfag', 'readabl', 'ietdccb', 'bkyxuzecu', 'udf', 'properti', 'abbrevi', 'productid', 'simplifi', 'milli', 'guy', 'xz', 'va', 'mnom', 'retain', 'emf', 'southwest', 'ejer', 'relationship', 'addit', 'obfusc', 'behind', 'webdav', 'aportfolio', 'perform', 'arial', 'vendor', 'bqg', 'quotat', 'cost', 'catalina', 'parsed', 'zd', 'neogiti', 'cxf', 'str', 'pack', 'ws', 'skiptoken', 'bd', 'gk', 'concept', 'catalog', 'byte', 'malform', 'essenti', 'manual', 'figur', 'unavail', 'kbgt', 'tdw', 'orderkey', 'retailpric', 'xom', 'discount', 'ffce', 'bigint', 'apach', 'writer', 'comput', 'bypass', 'bac', 'dom', 'counterpart', 'big', 'done', 'perhap', 'hat', 'incidentsm', 'recent', 'intkey', 'accessor', 'dialect', 'suspect', 'faefbbddcacc', 'resumen', 'look', 'gog', 'sequenc', 'bttp', 'org', 'proxi', 'emb', 'jdbcg', 'lp', 'recommend', 'njgi', 'upsert', 'nation', 'xm', 'kaohr', 'scope', 'histori', 'databind', 'prk', 'thirdparti', 'wb', 'afp', 'vdbf', 'vhr', 'groupdim', 'class', 'springframework', 'somevalu', 'slowli', 'free', 'ingr', 'xerc', 'jsp', 'ioer', 'yyyyad', 'steven', 'sep', 'counter', 'um', 'memorystoragemanag', 'goodi', 'yv', 'filter', 'encod', 'invers', 'presenc', 'openshift', 'odataj', 'eccc', 'global', 'setter', 'qt', 'teiidimport', 'mention', 'represent', 'randomstr', 'hak', 'state', 'maximum', 'datatyp', 'null', 'pg', 'booleantyp', 'teiidkey', 'mall', 'datev', 'kept', 'bamc', 'arjuna', 'rewriten', 'origin', 'callabl', 'number', 'est', 'spec', 'bf', 'portfolio', 'notif', 'mgmt', 'lose', 'parameter', 'anyth', 'cte', 'dhe', 'hope', 'requestid', 'dtal', 'relatt', 'orderd', 'hsql', 'facil', 'implement', 'clear', 'github', 'reformat', 'univers', 'ccb', 'yxeeq', 'everi', 'jbosst', 'javax', 'dynamicportfolio', 'thru', 'tree', 'ensur', 'widget', 'potenti', 'jahoc', 'inherit', 'jan', 'transactionmanag', 'handl', 'stackoverflow', 'els', 'answer', 'pro', 'changeit', 'gxl', 'truphon', 'hostnam', 'wxob', 'regist', 'abo', 'meta', 'weird', 'substr', 'bulk', 'export', 'co', 'matpg', 'tstart', 'dh', 'dbi', 'po', 'modulo', 'lag', 'facad', 'nome', 'im', 'annot', 'slow', 'explicitli', 'bo', 'popul', 'should', 'xmlforest', 'goxbbz', 'jba', 'lot', 'short', 'everywher', 'uber', 'here', 'unit', 'close', 'convey', 'modpr', 'deal', 'aq', 'imvyhntmlq', 'compens', 'tracer', 'countri', 'yield', 'yg', 'cryptograph', 'freed', 'sole', 'program', 'occasion', 'tahoma', 'rollback', 'transferrul', 'minim', 'oy', 'experiment', 'coyot', 'relax', 'rsa', 'contribut', 'visit', 'pacif', 'variableid', 'sda', 'use', 'lifetim', 'zllvpj', 'futterkist', 'ciiu', 'ap', 'exi', 'exit', 'sandbox', 'equinox', 'evtsysid', 'final', 'numwait', 'pictur', 'ltrim', 'caacf', 'get', 'sv', 'variabl', 'practic', 'nl', 'stdout', 'asc', 'usermodel', 'oi', 'testp', 'finish', 'prefer', 'embedd', 'decimalv', 'alloc', 'screen', 'atn', 'teiidd', 'coverag', 'abl', 'et', 'squirrel', 'reli', 'esfruu', 'dir', 'git', 'jb', 'formatt', 'happen', 'spi', 'phantomjinx', 'redshift', 'rhelopenjdk', 'mytab', 'jface', 'while', 'type', 'suffix', 'tejon', 'intermedi', 'whether', 'editor', 'labrestimecast', 'secret', 'crossjoin', 'exc', 'kvjw', 'confupdtyp', 'attnum', 'myct', 'api', 'singl', 'jaa', 'adaptor', 'keysor', 'eye', 'street', 'issuetyp', 'transport', 'run', 'mismatch', 'multipart', 'jwt', 'arjunacor', 'bs', 'bfaa', 'unabl', 'zg', 'team', 'hadoop', 'navig', 'password', 'wrap', 'parsetim', 'pipermail', 'differenti', 'cn', 'custom', 'wrongli', 'wv', 'parsabl', 'signific', 'seemingli', 'pgsql', 'menu', 'vv', 'approach', 'along', 'edg', 'liter', 'wire', 'current', 'zp', 'ajax', 'reflect', 'bridg', 'readili', 'ju', 'realli', 'kptxr', 'dunjslr', 'connectionid', 'teiidfin', 'lar', 'bci', 'around', 'timevalu', 'uiowa', 'all', 'roll', 'xmi', 'qe', 'hg', 'duawp', 'eo', 'nh', 'tran', 'accounthold', 'urebvi', 'amp', 'xmlqueri', 'inlin', 'distinguish', 'most', 'pgapi', 'dzichelp', 'jx', 'hsb', 'ri', 'connector', 'sd', 'guard', 'uj', 'ag', 'cor', 'infinit', 'dbh', 'idtestm', 'maxpages', 'ek', 'vl', 'upload', 'rfrtzx', 'quickstart', 'gz', 'inf', 'intercept', 'hierarchi', 'stabl', 'staff', 'scale', 'tsusiatsoftwar', 'there', 'dbo', 'texttab', 'wgx', 'xs', 'setup', 'ts', 'investig', 'plum', 'somet', 'obtain', 'variad', 'permiss', 'share', 'hana', 'coder', 'ctj', 'cest', 'pisql', 'injector', 'path', 'everyth', 'krb', 'jetti', 'evttypecod', 'resolv', 'ffx', 'broken', 'target', 'wgibson', 'toc', 'extend', 'war', 'garbag', 'contact', 'piec', 'equi', 'notat', 'couldn', 'fah', 'unsearch', 'left', 'grp', 'nil', 'index', 'paul', 'caller', 'subscript', 'jun', 'struggl', 'caresequ', 'zue', 'pk', 'ayhitq', 'integ', 'jta', 'gener', 'tid', 'brittl', 'elimin', 'ld', 'suit', 'unnest', 'xpath', 'capabl', 'somewher', 'ception', 'opengi', 'high', 'jtg', 'isarrayt', 'overrod', 'flush', 'larger', 'improv', 'complex', 'interfac', 'libro', 'disk', 'tool', 'teiid', 'favor', 'arbitrari', 'but', 'accumulo', 'xlsx', 'oo', 'ougj', 'timestampvalu', 'discov', 'xcb', 'overcom', 'poc', 'succe', 'retriev', 'fj', 'mongo', 'doubl', 'stamp', 'bx', 'wa', 'tera', 'curdat', 'statust', 'hagvvtp', 'exactli', 'vari', 'stale', 'term', 'month', 'matadata', 'ufv', 'start', 'incur', 'revers', 'mqu', 'correct', 'zokot', 'swt', 've', 'dsl', 'predic', 'msc', 'solr', 'daptib', 'defici', 'output', 'statu', 'vbuu', 'phj', 'patientid', 'gpdbdev', 'daynam', 'policyid', 'mytabl', 'src', 'sign', 'tableb', 'uncorrel', 'archetyp', 'susi', 'prop', 'documento', 'keep', 'fire', 'hotrod', 'cb', 'uri', 'would', 'para', 'yahoo', 'yii', 'lwk', 'sakila', 'imagin', 'jca', 'static', 'virtproc', 'wrapper', 'sobj', 'as', 'param', 'avaialbl', 'fw', 'proactiv', 'analyz', 'record', 'size', 'eof', 'rather', 'employeefix', 'evalu', 'eeg', 'rdsa', 'shipdat', 'modelgener', 'conrelid', 'trigger', 'mi', 'risk', 'zone', 'immedi', 'fewer', 'access', 'metadata', 'like', 'wait', 'minu', 'repeatedli', 'termin', 'site', 'def', 'hostcontrol', 'correspond', 'reject', 'genentech', 'whose', 'duser', 'mat', 'suppos', 'bootstrap', 'bundl', 'tpc', 'baserul', 'xk', 'shell', 'chimp', 'procesor', 'arni', 'eclips', 'temporarili', 'bring', 'ls', 'analysi', 'credit', 'vf', 'common', 'gl', 'implemnet', 'westport', 'flexibl', 'destinationfinanci', 'respect', 'where', 'awt', 'criteria', 'fnr', 'propag', 'usernam', 'assigne', 'zv', 'fresh', 'nvl', 'fst', 'wh', 'apiimpl', 'alpha', 'xsd', 'nqnx', 'sk', 'sourceforg', 'deb', 'ghu', 'directori', 'servic', 'grant', 'tuplesourc', 'af', 'docbook', 'lxj', 'format', 'li', 'dist', 'viewobjaccess', 'anti', 'speed', 'zxu', 'produc', 'frameset', 'worri', 'guic', 'ec', 'notic', 'wizard', 'iscustom', 'give', 'overwrit', 'linestatu', 'ps', 'better', 'enumer', 'exampl', 'burden', 'batch', 'toward', 'vfszip', 'forev', 'lineitem', 'clone', 'mmadmin', 'pi', 'whiteboard', 'window', 'jaxen', 'longitud', 'spent', 'qgi', 'nsnw', 'mid', 'sale', 'discard', 'incorpor', 'ff', 'face', 'spark', 'loos', 'pull', 'subsystem', 'trunk', 'html', 'shown', 'ha', 'proof', 'greenplum', 'me', 'nrg', 'typo', 'licens', 'oauth', 'decrypt', 'gzip', 'analyt', 'vistor', 'normal', 'rk', 'tricolor', 'bytebuff', 'lm', 'nspname', 'stackabl', 'demodata', 'also', 'sha', 'secur', 'ddl', 'powder', 'callback', 'bnf', 'dvqe', 'se', 'programmat', 'offset', 'refer', 'empti', 'replan', 'pursu', 'timestampadd', 'open', 'among', 'goal', 'fh', 'background', 'fa', 'ssmith', 'ctx', 'ruh', 'infer', 'kss', 'jlu', 'rectangl', 'chapter', 'cru', 'oli', 'pem', 'keyspac', 'repeat', 'stax', 'od', 'ay', 'puf', 'toggl', 'pafp', 'svn', 'pq', 'lgc', 'hokuda', 'couchbas', 'itgroup', 'jasper', 'delay', 'firstnam', 'bat', 'qw', 'sql', 'th', 'ny', 'letter', 'redirect', 'element', 'instruct', 'script', 'dnrb', 'endpoint', 'pj', 'mess', 'localprofil', 'convent', 'tonumb', 'correl', 'pdt', 'rec', 'rate', 'fax', 'vqt', 'lvl', 'reusabl', 'proto', 'var', 'ora', 'sgreen', 'cert', 'timestamp', 'somecolumn', 'and', 'atttypmod', 'facet', 'vbl', 'ejg', 'oq', 'nt', 'had', 'nakack', 'fragment', 'fz', 'jh', 'physic', 'math', 'reason', 'xmlattribut', 'yl', 'svc', 'parser', 'bc', 'kxv', 'wo', 'guid', 'eldest', 'handshak', 'jtsgeojson', 'ext', 'irzln', 'due', 'ttl', 'selectrow', 'xxx', 'incom', 'pubkey', 'restart', 'classif', 'ground', 'te', 'have', 'hash', 'foodmart', 'packet', 'quantita', 'market', 'self', 'seam', 'inventori', 'marshal', 'ast', 'prematur', 'marker', 'eventu', 'kh', 'dimens', 'ft', 'gom', 'focus', 'ident', 'obscur', 'advanc', 'deepli', 'unauthor', 'miidiad', 'steve', 'chang', 'es', 'antlr', 'll', 'bigdata', 'determin', 'crash', 'jdbc', 'eee', 'vdb', 'space', 'callsit', 'codref', 'either', 'sqlref', 'third', 'effici', 'informix', 'hqd', 'ctc', 'cust', 'objectt', 'abc', 'phki', 'ou', 'underscor', 'call', 'want', 'inde', 'bytecod', 'near', 'qcoud', 'gitbook', 'qa', 'detect', 'booleanv', 'librari', 'aace', 'age', 'geomfromwkb', 'dssmalla', 'belong', 'idcust', 'md', 'sequenti', 'mvc', 'reimport', 'pricebook', 'abm', 'trim', 'psql', 'job', 'adxf', 'port', 'evaluatablevisitor', 'ever', 'fulfil', 'posit', 'rlqzu', 'alfr', 'synchron', 'behav', 'strpo', 'mmrofil', 'postgresql', 'specifi', 'bpp', 'rule', 'becom', 'st', 'deriv', 'jc', 'jvm', 'evtcatcod', 'ischildnod', 'miss', 'dmr', 'dep', 'backward', 'arithmet', 'combin', 'partofkey', 'resultset', 'rluttzo', 'copyright', 'uppercas', 'public', 'overlay', 'databas', 'ase', 'elect', 'jdb', 'or', 'tc', 'tix', 'render', 'proper', 'certain', 'czt', 'jbweb', 'compar', 'overlap', 'hql', 'languag', 'switch', 'solut', 'codop', 'info', 'hw', 'randomint', 'encapsul', 'driver', 'cursor', 'gather', 'shipinstruct', 'bq', 'doesnt', 'em', 'descend', 'cf', 'logoff', 'config', 'confkey', 'upgrad', 'minor', 'afterward', 'xd', 'boolean', 'interact', 'cdk', 'objecttyp', 'rwv', 'dm', 'eng', 'kv', 'feder', 'later', 'suppkey', 'pc', 'conclud', 'phase', 'websocket', 'bgkqhki', 'efbfbdefbfbdefbfbd', 'xmlsoap', 'boundari', 'version', 'server', 'subtract', 'cach', 'decreas', 'provis', 'involv', 'unwind', 'mw', 'udfjar', 'tupl', 'concern', 'invalid', 'rperf', 'hapap', 'np', 'actual', 'someth', 'commit', 'part', 'come', 'rt', 'ot', 'destin', 'fillabl', 'remov', 'pt', 'ошибка', 'comm', 'turn', 'fef', 'across', 'cipher', 'val', 'jboss', 'intern', 'db', 'other', 'late', 'paren', 'ambigu', 'csprd', 'ram', 'odata', 'uncaught', 'zdr', 'height', 'keyword', 'dk', 'dv', 'rl', 'px', 'wzvm', 'nohww', 'cleanup', 'settabl', 'cbj', 'tw', 'rd', 'zr', 'forrequest', 'previous', 'event', 'negat', 'crm', 'pboy', 'cycl', 'think', 'op', 'sapdevcent', 'advantag', 'forecast', 'everyon', 'yaml', 'durat', 'illeg', 'ni', 'consumpt', 'asi'}\n"
          ]
        }
      ],
      "source": [
        "_PreProcessor_train = PreProcessor()\n",
        "UC_documents_train, UC_to_index_train,Vocab_UC_train= _PreProcessor_train.setupUC(\"./Dataset/teiid_dataset/train_UC\", 'train')\n",
        "code_documents_train, CC_to_index_train,Vocab_CC_train = _PreProcessor_train.setupCC(\"./Dataset/teiid_dataset/train_CC\", 'train')\n",
        "\n",
        "_PreProcessor_test = PreProcessor()\n",
        "UC_documents_test, UC_to_index_test,Vocab_UC_test= _PreProcessor_test.setupUC(\"./Dataset/teiid_dataset/test_UC\", 'test')\n",
        "code_documents_test, CC_to_index_test,Vocab_CC_test = _PreProcessor_test.setupCC(\"./Dataset/teiid_dataset/test_CC\", 'test')\n",
        "\n",
        "print(\"Vocab_UC_train\",Vocab_UC_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "with open('./pickles/UC_documents_train.pkl', 'wb') as f:\n",
        "       pickle.dump(UC_documents_train, f)\n",
        "with open('./pickles/code_documents_train.pkl', 'wb') as f:\n",
        "        pickle.dump(code_documents_train, f)\n",
        "with open('./pickles/UCindex_train.pkl', 'wb') as f:\n",
        "        pickle.dump(UC_to_index_train, f)\n",
        "with open('./pickles/CCindex_train.pkl', 'wb') as f:\n",
        "        pickle.dump(CC_to_index_train, f)\n",
        "with open('./pickles/UCTokens_train.pkl', 'wb') as f:\n",
        "        pickle.dump(Vocab_UC_train, f)\n",
        "with open('./pickles/CodeTokens_train.pkl', 'wb') as f:\n",
        "        pickle.dump(Vocab_CC_train, f)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "</h3>Test</h3>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "with open('./pickles/UC_documents_test.pkl', 'wb') as f:\n",
        "       pickle.dump(UC_documents_test, f)\n",
        "with open('./pickles/code_documents_test.pkl', 'wb') as f:\n",
        "        pickle.dump(code_documents_test, f)\n",
        "with open('./pickles/UCindex_test.pkl', 'wb') as f:\n",
        "        pickle.dump(UC_to_index_test, f)\n",
        "with open('./pickles/CCindex_test.pkl', 'wb') as f:\n",
        "        pickle.dump(CC_to_index_test, f)\n",
        "with open('./pickles/UCTokens_test.pkl', 'wb') as f:\n",
        "        pickle.dump(Vocab_UC_test, f)\n",
        "with open('./pickles/CodeTokens_test.pkl', 'wb') as f:\n",
        "        pickle.dump(Vocab_CC_test, f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "UC_documents_train = np.load('./pickles/UC_documents_train.pkl',allow_pickle=True)\n",
        "Vocab_UC_train = np.load('./pickles/UCTokens_train.pkl',allow_pickle=True)\n",
        "code_documents_train = np.load('./pickles/code_documents_train.pkl',allow_pickle=True)\n",
        "Vocab_CC_train = np.load('./pickles/CodeTokens_train.pkl',allow_pickle=True)\n",
        "UC_to_index_train = np.load('./pickles/UCindex_train.pkl',allow_pickle=True)\n",
        "CC_to_index_train = np.load('./pickles/CCindex_train.pkl',allow_pickle=True)\n",
        "\n",
        "\n",
        "UC_documents_test = np.load('./pickles/UC_documents_test.pkl',allow_pickle=True)\n",
        "Vocab_UC_test = np.load('./pickles/UCTokens_test.pkl',allow_pickle=True)\n",
        "code_documents_test = np.load('./pickles/code_documents_test.pkl',allow_pickle=True)\n",
        "Vocab_CC_test = np.load('./pickles/CodeTokens_test.pkl',allow_pickle=True)\n",
        "UC_to_index_test = np.load('./pickles/UCindex_test.pkl',allow_pickle=True)\n",
        "CC_to_index_test = np.load('./pickles/CCindex_test.pkl',allow_pickle=True)\n",
        "\n",
        "\n",
        "\n",
        "Vocab_UC_train.update(Vocab_CC_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Initialize Normalizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "normalizer = MinMaxScaler(copy=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Adjuting the csv file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "_PreProcessor_train.setupCSV(\"Dataset/teiid_dataset/train.csv\", \"Dataset/teiid_dataset/train_modified.csv\",UC_to_index_train,CC_to_index_train)\n",
        "_PreProcessor_test.setupCSV(\"Dataset/teiid_dataset/test.csv\", \"Dataset/teiid_dataset/test_modified.csv\",UC_to_index_test,CC_to_index_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Collecting the 131 features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "featureExtraction = FeatureExtraction(Vocab_UC_train)\n",
        "\n",
        "# Feature extraction for training set\n",
        "tfidf_matrix_uc_train, tfidf_matrix_code_train, idf_uc_dict_train, idf_code_dict_train, feature_names_uc_train, feature_names_code_train, df_uc_dict_train, df_code_dict_train = featureExtraction.TFIDFVectorizer(UC_documents_train, code_documents_train,train_or_test='train')\n",
        "UC_count_matrix_train, code_count_matrix_train, tf_uc_dict_train, tf_code_dict_train = featureExtraction.CountVectorizerModel(UC_documents_train, code_documents_train, 'train')\n",
        "idf_uc_train, idf_code_train = featureExtraction.IDFPreProcessing(UC_documents_train, idf_code_dict_train, code_documents_train, idf_uc_dict_train)\n",
        "ictf_uc_train, ictf_code_train = featureExtraction.ICTFPreProcessing(UC_documents_train, tf_code_dict_train, code_documents_train, tf_uc_dict_train)\n",
        "\n",
        "# Feature extraction for testing set\n",
        "tfidf_matrix_uc_test, tfidf_matrix_code_test, idf_uc_dict_test, idf_code_dict_test, feature_names_uc_test, feature_names_code_test, df_uc_dict_test, df_code_dict_test = featureExtraction.TFIDFVectorizer(UC_documents_test, code_documents_test,train_or_test='test')\n",
        "UC_count_matrix_test, code_count_matrix_test, tf_uc_dict_test, tf_code_dict_test = featureExtraction.CountVectorizerModel(UC_documents_test, code_documents_test, 'test')\n",
        "idf_uc_test, idf_code_test = featureExtraction.IDFPreProcessing(UC_documents_test, idf_code_dict_test, code_documents_test, idf_uc_dict_test)\n",
        "ictf_uc_test, ictf_code_test = featureExtraction.ICTFPreProcessing(UC_documents_test, tf_code_dict_test, code_documents_test, tf_uc_dict_test)\n",
        "# # the values of the count matrices are normalized"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "need log memori condit server startup defect tracker instal server start in consol increas <unk> max min heap size then bounc server didnt come back went server box tri <unk> script server still didnt come look server log error after <unk> figur server box <unk> alloc enough memori decreas heap restart ok there realli need kind log messag indic memori except\n"
          ]
        }
      ],
      "source": [
        "# print(len(UC_documents_test))\n",
        "for i in UC_documents_train:\n",
        "    if('<unk>' in i):\n",
        "        print(i)\n",
        "        break\n",
        "# if('<unk>' in featureExtraction.count_vocab_index.keys()):\n",
        "#     print('unk')\n",
        "# print(featureExtraction.count_vectorizer.vocabulary_)\n",
        "# print(tf_code_dict_train['<unk>'])\n",
        "# print(featureExtraction.count_vectorizer.vocabulary_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "entropy_uc_train,entropy_code_train,variance_uc_train,variance_code_train=featureExtraction.EntropyPreProcessing(UC_documents_train,code_documents_train,idf_uc_dict_train,idf_code_dict_train,df_uc_dict_train,df_code_dict_train)\n",
        "entropy_uc_test,entropy_code_test,variance_uc_test,variance_code_test=featureExtraction.EntropyPreProcessing(UC_documents_test,code_documents_test,idf_uc_dict_test,idf_code_dict_test,df_uc_dict_test,df_code_dict_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "with open('./pickles/entropy_uc_train.pkl', 'wb') as f:\n",
        "       pickle.dump(entropy_uc_train, f)\n",
        "with open('./pickles/entropy_code_train.pkl', 'wb') as f:\n",
        "        pickle.dump(entropy_code_train, f)\n",
        "with open('./pickles/variance_uc_train.pkl', 'wb') as f:\n",
        "        pickle.dump(variance_uc_train, f)\n",
        "with open('./pickles/variance_code_train.pkl', 'wb') as f:\n",
        "        pickle.dump(variance_code_train, f)\n",
        "\n",
        "with open('./pickles/entropy_uc_test.pkl', 'wb') as f:\n",
        "       pickle.dump(entropy_uc_test, f)\n",
        "with open('./pickles/entropy_code_test.pkl', 'wb') as f:\n",
        "        pickle.dump(entropy_code_test, f)\n",
        "with open('./pickles/variance_uc_test.pkl', 'wb') as f:\n",
        "        pickle.dump(variance_uc_test, f)\n",
        "with open('./pickles/variance_code_test.pkl', 'wb') as f:\n",
        "        pickle.dump(variance_code_test, f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "entropy_uc_train = np.load('./pickles/entropy_uc_train.pkl',allow_pickle=True)\n",
        "entropy_code_train = np.load('./pickles/entropy_code_train.pkl',allow_pickle=True)\n",
        "variance_uc_train = np.load('./pickles/variance_uc_train.pkl',allow_pickle=True)\n",
        "variance_code_train = np.load('./pickles/variance_code_train.pkl',allow_pickle=True)\n",
        "entropy_uc_test = np.load('./pickles/entropy_uc_test.pkl',allow_pickle=True)\n",
        "entropy_code_test = np.load('./pickles/entropy_code_test.pkl',allow_pickle=True)\n",
        "variance_uc_test = np.load('./pickles/variance_uc_test.pkl',allow_pickle=True)\n",
        "variance_code_test = np.load('./pickles/variance_code_test.pkl',allow_pickle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# variance_uc_train,variance_code_train= featureExtraction.VarPreProcessing(UC_documents_train,code_documents_train,idf_uc_dict_train,idf_code_dict_train)\n",
        "PMI_uc_train,PMI_code_train=featureExtraction.PMIPreProcessing(code_documents_train,UC_documents_train)\n",
        "SCQ_uc_train,SCQ_code_train = featureExtraction.SCQPreProcessing(UC_documents_train,code_documents_train,tf_uc_dict_train,tf_code_dict_train,idf_uc_dict_train,idf_code_dict_train)\n",
        "\n",
        "# variance_uc_test,variance_code_test= featureExtraction.VarPreProcessing(UC_documents_test,code_documents_test,idf_uc_dict_test,idf_code_dict_test)\n",
        "PMI_uc_test,PMI_code_test=featureExtraction.PMIPreProcessing(code_documents_test,UC_documents_test)\n",
        "SCQ_uc_test,SCQ_code_test = featureExtraction.SCQPreProcessing(UC_documents_test,code_documents_test,tf_uc_dict_test,tf_code_dict_test,idf_uc_dict_test,idf_code_dict_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "with open('./pickles/PMI_uc_train.pkl', 'wb') as f:\n",
        "       pickle.dump(PMI_uc_train, f)\n",
        "with open('./pickles/PMI_code_train.pkl', 'wb') as f:\n",
        "        pickle.dump(PMI_code_train, f)\n",
        "\n",
        "with open('./pickles/SCQ_uc_train.pkl', 'wb') as f:\n",
        "         pickle.dump(SCQ_uc_train, f)\n",
        "with open('./pickles/SCQ_code_train.pkl', 'wb') as f:\n",
        "        pickle.dump(SCQ_code_train, f)\n",
        "\n",
        "with open('./pickles/PMI_uc_test.pkl', 'wb') as f:\n",
        "    pickle.dump(PMI_uc_test, f)\n",
        "\n",
        "with open('./pickles/PMI_code_test.pkl', 'wb') as f:\n",
        "    pickle.dump(PMI_code_test, f)\n",
        "\n",
        "with open('./pickles/SCQ_uc_test.pkl', 'wb') as f:\n",
        "    pickle.dump(SCQ_uc_test, f)\n",
        "\n",
        "with open('./pickles/SCQ_code_test.pkl', 'wb') as f:\n",
        "    pickle.dump(SCQ_code_test, f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "PMI_uc_train = np.load('./pickles/PMI_uc_train.pkl',allow_pickle=True)\n",
        "PMI_code_train = np.load('./pickles/PMI_code_train.pkl',allow_pickle=True)\n",
        "SCQ_uc_train = np.load('./pickles/SCQ_uc_train.pkl',allow_pickle=True)\n",
        "SCQ_code_train = np.load('./pickles/SCQ_code_train.pkl',allow_pickle=True)\n",
        "PMI_uc_test = np.load('./pickles/PMI_uc_test.pkl',allow_pickle=True)\n",
        "PMI_code_test = np.load('./pickles/PMI_code_test.pkl',allow_pickle=True)\n",
        "SCQ_uc_test = np.load('./pickles/SCQ_uc_test.pkl',allow_pickle=True)\n",
        "SCQ_code_test = np.load('./pickles/SCQ_code_test.pkl',allow_pickle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#-------------------------14 IR based features Train--------------------------#\n",
        "\n",
        "# 1) Vector space model\n",
        "cosine_similarities_feature_train = featureExtraction.VectorSpaceModel(tfidf_matrix_uc_train, tfidf_matrix_code_train)\n",
        "print(\"cosine_similarities_feature_train\", cosine_similarities_feature_train.shape)\n",
        "\n",
        "# Our model will classify based on the ranks of the data rather than their actual values.\n",
        "cosine_similarity_UC_train = rankdata(-cosine_similarities_feature_train, method='dense', axis=1)\n",
        "print(\"cosine_similarity_UC_train\", cosine_similarity_UC_train.shape)\n",
        "cosine_similarity_CC_train = rankdata(-cosine_similarities_feature_train, method='dense', axis=0)\n",
        "print(\"cosine_similarity_CC_train\", cosine_similarity_CC_train.shape)\n",
        "\n",
        "\n",
        "np.save('./pickles/cosine_similarity_UC_train.npy', cosine_similarity_UC_train)\n",
        "np.save('./pickles/cosine_similarity_CC_train.npy', cosine_similarity_CC_train)\n",
        "\n",
        "# 2) Latent semantic analysis\n",
        "LSA_similarities_feature_train = featureExtraction.LSA(tfidf_matrix_uc_train, tfidf_matrix_code_train)\n",
        "print('LSA similarity', LSA_similarities_feature_train.shape)\n",
        "\n",
        "LSA_similarities_UC_train = rankdata(-LSA_similarities_feature_train, method='dense', axis=1)\n",
        "print(\"LSA_similarities_UC_train\", LSA_similarities_UC_train.shape)\n",
        "LSA_similarities_CC_train = rankdata(-LSA_similarities_feature_train, method='dense', axis=0)\n",
        "print(\"LSA_similarities_CC_train\", LSA_similarities_CC_train.shape)\n",
        "\n",
        "\n",
        "np.save('./pickles/LSA_similarities_UC_train.npy', LSA_similarities_UC_train)\n",
        "np.save('./pickles/LSA_similarities_CC_train.npy', LSA_similarities_CC_train)\n",
        "\n",
        "# 3) Latent Dirichlet Allocation\n",
        "DocumentTopicDisUC_dense_train, DocumentTopicDisCode_dense_train, cosine_similarities_LDA_train = featureExtraction.LDA(UC_documents_train, code_documents_train, Vocab_UC_train)\n",
        "print('LDA similarity', cosine_similarities_LDA_train.shape)\n",
        "\n",
        "LDA_similarities_UC_train = rankdata(-cosine_similarities_LDA_train, method='dense', axis=1)\n",
        "print(\"LDA_similarities_UC_train\", LDA_similarities_UC_train.shape)\n",
        "LDA_similarities_CC_train = rankdata(-cosine_similarities_LDA_train, 'dense', axis=0)\n",
        "print(\"LDA_similarities_CC_train\", LDA_similarities_CC_train.shape)\n",
        "\n",
        "np.save('./pickles/LDA_similarities_UC_train.npy', LDA_similarities_UC_train)\n",
        "np.save('./pickles/LDA_similarities_CC_train.npy', LDA_similarities_CC_train)\n",
        "\n",
        "# 4) Jensen-Shannon(JS)\n",
        "JS_features_train = featureExtraction.JensenShannon(UC_count_matrix_train, code_count_matrix_train)\n",
        "print('JS', JS_features_train.shape)\n",
        "\n",
        "JS_UC_train = rankdata(-JS_features_train, method='dense', axis=1)\n",
        "print('JS_UC_train', JS_UC_train.shape)\n",
        "JS_CC_train = rankdata(-JS_features_train, method='dense', axis=0)\n",
        "print('JS_CC_train', JS_CC_train.shape)\n",
        "\n",
        "np.save('./pickles/JS_UC_train.npy', JS_UC_train)\n",
        "np.save('./pickles/JS_CC_train.npy', JS_CC_train)\n",
        "\n",
        "# 5)  Okapi BM25\n",
        "# UC means query is UC and document is code\n",
        "BM25_UC_train = featureExtraction.BM25(UC_documents_train, code_documents_train, idf_code_dict_train, code_count_matrix_train)\n",
        "BM25_CC_train = featureExtraction.BM25(code_documents_train, UC_documents_train, idf_uc_dict_train, UC_count_matrix_train)\n",
        "\n",
        "BM25_UC_train = rankdata(-BM25_UC_train, method='dense', axis=0)\n",
        "print(\"BM25_UC_train\", BM25_UC_train.shape)\n",
        "BM25_CC_train = rankdata(-BM25_CC_train, method='dense', axis=0)\n",
        "print(\"BM25_CC_train\", BM25_CC_train.shape)\n",
        "\n",
        "np.save('./pickles/BM25_UC_train.npy', BM25_UC_train)\n",
        "np.save('./pickles/BM25_CC_train.npy', BM25_CC_train)\n",
        "\n",
        "# 6) Language Model with Dirichlet\n",
        "# UC means UC is query and code is doc\n",
        "JM_UC_train = featureExtraction.SmoothingMethods(UC_documents_train, code_documents_train, code_count_matrix_train, tf_code_dict_train, JM_or_DP=True)\n",
        "JM_CC_train = featureExtraction.SmoothingMethods(code_documents_train, UC_documents_train, UC_count_matrix_train, tf_uc_dict_train, True)\n",
        "\n",
        "DP_UC_train = featureExtraction.SmoothingMethods(UC_documents_train, code_documents_train, code_count_matrix_train, tf_code_dict_train, JM_or_DP=False)\n",
        "DP_CC_train = featureExtraction.SmoothingMethods(code_documents_train, UC_documents_train, UC_count_matrix_train, tf_uc_dict_train, False)\n",
        "\n",
        "JM_UC_train = rankdata(-JM_UC_train, method='dense', axis=0)\n",
        "print(\"JM_UC_train\", JM_UC_train.shape)\n",
        "JM_CC_train = rankdata(-JM_CC_train, method='dense', axis=0)\n",
        "print(\"JM_CC_train\", JM_CC_train.shape)\n",
        "DP_UC_train = rankdata(-DP_UC_train, method='dense', axis=0)\n",
        "print(\"DP_UC_train\", DP_UC_train.shape)\n",
        "DP_CC_train = rankdata(-DP_CC_train, method='dense', axis=0)\n",
        "print(\"DP_CC_train\", DP_CC_train.shape)\n",
        "\n",
        "\n",
        "np.save('./pickles/JM_UC_train.npy', JM_UC_train)\n",
        "np.save('./pickles/JM_CC_train.npy', JM_CC_train)\n",
        "\n",
        "\n",
        "np.save('./pickles/DP_UC_train.npy', DP_UC_train)\n",
        "np.save('./pickles/DP_CC_train.npy', DP_CC_train)\n",
        "\n",
        "\n",
        "#-------------------------14 IR based features Test--------------------------#\n",
        "\n",
        "# 1) Vector space model\n",
        "cosine_similarities_feature_test = featureExtraction.VectorSpaceModel(tfidf_matrix_uc_test, tfidf_matrix_code_test)\n",
        "print(\"cosine_similarities_feature_test\", cosine_similarities_feature_test.shape)\n",
        "\n",
        "# Our model will classify based on the ranks of the data rather than their actual values.\n",
        "cosine_similarity_UC_test = rankdata(-cosine_similarities_feature_test, method='dense', axis=1)\n",
        "print(\"cosine_similarity_UC_test\", cosine_similarity_UC_test.shape)\n",
        "cosine_similarity_CC_test = rankdata(-cosine_similarities_feature_test, method='dense', axis=0)\n",
        "print(\"cosine_similarity_CC_test\", cosine_similarity_CC_test.shape)\n",
        "\n",
        "\n",
        "np.save('./pickles/cosine_similarity_UC_test.npy', cosine_similarity_UC_test)\n",
        "np.save('./pickles/cosine_similarity_CC_test.npy', cosine_similarity_CC_test)\n",
        "\n",
        "# 2) Latent semantic analysis\n",
        "LSA_similarities_feature_test = featureExtraction.LSA(tfidf_matrix_uc_test, tfidf_matrix_code_test)\n",
        "print('LSA similarity', LSA_similarities_feature_test.shape)\n",
        "\n",
        "LSA_similarities_UC_test = rankdata(-LSA_similarities_feature_test, method='dense', axis=1)\n",
        "print(\"LSA_similarities_UC_test\", LSA_similarities_UC_test.shape)\n",
        "LSA_similarities_CC_test = rankdata(-LSA_similarities_feature_test, method='dense', axis=0)\n",
        "print(\"LSA_similarities_CC_test\", LSA_similarities_CC_test.shape)\n",
        "\n",
        "np.save('./pickles/LSA_similarities_UC_test.npy', LSA_similarities_UC_test)\n",
        "np.save('./pickles/LSA_similarities_CC_test.npy', LSA_similarities_CC_test)\n",
        "\n",
        "# 3) Latent Dirichlet Allocation\n",
        "DocumentTopicDisUC_dense_test, DocumentTopicDisCode_dense_test, cosine_similarities_LDA_test = featureExtraction.LDA(UC_documents_test, code_documents_test, Vocab_UC_test)\n",
        "print('LDA similarity', cosine_similarities_LDA_test.shape)\n",
        "\n",
        "LDA_similarities_UC_test = rankdata(-cosine_similarities_LDA_test, method='dense', axis=1)\n",
        "print(\"LDA_similarities_UC_test\", LDA_similarities_UC_test.shape)\n",
        "LDA_similarities_CC_test = rankdata(-cosine_similarities_LDA_test, 'dense', axis=0)\n",
        "print(\"LDA_similarities_CC_test\", LDA_similarities_CC_test.shape)\n",
        "\n",
        "np.save('./pickles/LDA_similarities_UC_test.npy', LDA_similarities_UC_test)\n",
        "np.save('./pickles/LDA_similarities_CC_test.npy', LDA_similarities_CC_test)\n",
        "\n",
        "# 4) Jensen-Shannon(JS)\n",
        "JS_features_test = featureExtraction.JensenShannon(UC_count_matrix_test, code_count_matrix_test)\n",
        "print('JS', JS_features_test.shape)\n",
        "\n",
        "JS_UC_test = rankdata(-JS_features_test, method='dense', axis=1)\n",
        "print('JS_UC_test', JS_UC_test.shape)\n",
        "JS_CC_test = rankdata(-JS_features_test, method='dense', axis=0)\n",
        "print('JS_CC_test', JS_CC_test.shape)\n",
        "\n",
        "np.save('./pickles/JS_UC_test.npy', JS_UC_test)\n",
        "np.save('./pickles/JS_CC_test.npy', JS_CC_test)\n",
        "\n",
        "# 5)  Okapi BM25\n",
        "# UC means query is UC and document is code\n",
        "BM25_UC_test = featureExtraction.BM25(UC_documents_test, code_documents_test, idf_code_dict_test, code_count_matrix_test)\n",
        "BM25_CC_test = featureExtraction.BM25(code_documents_test, UC_documents_test, idf_uc_dict_test, UC_count_matrix_test)\n",
        "\n",
        "BM25_UC_test = rankdata(-BM25_UC_test, method='dense', axis=0)\n",
        "print(\"BM25_UC_test\", BM25_UC_test.shape)\n",
        "BM25_CC_test = rankdata(-BM25_CC_test, method='dense', axis=0)\n",
        "print(\"BM25_CC_test\", BM25_CC_test.shape)\n",
        "\n",
        "np.save('./pickles/BM25_UC_test.npy', BM25_UC_test)\n",
        "np.save('./pickles/BM25_CC_test.npy', BM25_CC_test)\n",
        "\n",
        "# 6) Language Model with Dirichlet\n",
        "# UC means UC is query and code is doc\n",
        "JM_UC_test = featureExtraction.SmoothingMethods(UC_documents_test, code_documents_test, code_count_matrix_test, tf_code_dict_test, JM_or_DP=True)\n",
        "JM_CC_test = featureExtraction.SmoothingMethods(code_documents_test, UC_documents_test, UC_count_matrix_test, tf_uc_dict_test, True)\n",
        "\n",
        "DP_UC_test = featureExtraction.SmoothingMethods(UC_documents_test, code_documents_test, code_count_matrix_test, tf_code_dict_test, JM_or_DP=False)\n",
        "DP_CC_test = featureExtraction.SmoothingMethods(code_documents_test, UC_documents_test, UC_count_matrix_test, tf_uc_dict_test, False)\n",
        "\n",
        "JM_UC_test = rankdata(-JM_UC_test, method='dense', axis=0)\n",
        "print(\"JM_UC_test\", JM_UC_test.shape)\n",
        "JM_CC_test = rankdata(-JM_CC_test, method='dense', axis=0)\n",
        "print(\"JM_CC_test\", JM_CC_test.shape)\n",
        "DP_UC_test = rankdata(-DP_UC_test, method='dense', axis=0)\n",
        "print(\"DP_UC_test\", DP_UC_test.shape)\n",
        "DP_CC_test = rankdata(-DP_CC_test, method='dense', axis=0)\n",
        "print(\"DP_CC_test\", DP_CC_test.shape)\n",
        "\n",
        "np.save('./pickles/JM_UC_test.npy', JM_UC_test)\n",
        "np.save('./pickles/JM_CC_test.npy', JM_CC_test)\n",
        "\n",
        "np.save('./pickles/DP_UC_test.npy', DP_UC_test)\n",
        "np.save('./pickles/DP_CC_test.npy', DP_CC_test)\n",
        "\n",
        "\n",
        "#200 MIN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#-----------------------IR Train Features Loading------------------#\n",
        "cosine_similarity_UC_train = np.load('./pickles/cosine_similarity_UC_train.npy')\n",
        "cosine_similarity_UC_train = normalizer.fit_transform(cosine_similarity_UC_train)\n",
        "\n",
        "cosine_similarity_CC_train = np.load('./pickles/cosine_similarity_CC_train.npy')\n",
        "cosine_similarity_CC_train = normalizer.fit_transform(cosine_similarity_CC_train)\n",
        "\n",
        "LSA_similarities_UC_train = np.load('./pickles/LSA_similarities_UC_train.npy')\n",
        "LSA_similarities_UC_train = normalizer.fit_transform(LSA_similarities_UC_train)\n",
        "\n",
        "LSA_similarities_CC_train = np.load('./pickles/LSA_similarities_CC_train.npy')\n",
        "LSA_similarities_CC_train = normalizer.fit_transform(LSA_similarities_CC_train)\n",
        "\n",
        "LDA_similarities_UC_train = np.load('./pickles/LDA_similarities_UC_train.npy')\n",
        "LDA_similarities_UC_train = normalizer.fit_transform(LDA_similarities_UC_train)\n",
        "\n",
        "LDA_similarities_CC_train = np.load('./pickles/LDA_similarities_CC_train.npy')\n",
        "LDA_similarities_CC_train = normalizer.fit_transform(LDA_similarities_CC_train)\n",
        "\n",
        "JS_UC_train = np.load('./pickles/JS_UC_train.npy')\n",
        "JS_UC_train = normalizer.fit_transform(JS_UC_train)\n",
        "\n",
        "JS_CC_train = np.load('./pickles/JS_CC_train.npy')\n",
        "JS_CC_train = normalizer.fit_transform(JS_CC_train)\n",
        "\n",
        "BM25_UC_train = np.load('./pickles/BM25_UC_train.npy')\n",
        "BM25_UC_train = normalizer.fit_transform(BM25_UC_train)\n",
        "\n",
        "BM25_CC_train = np.load('./pickles/BM25_CC_train.npy')\n",
        "BM25_CC_train = normalizer.fit_transform(BM25_CC_train)\n",
        "\n",
        "JM_UC_train = np.load('./pickles/JM_UC_train.npy')\n",
        "JM_UC_train = normalizer.fit_transform(JM_UC_train)\n",
        "\n",
        "JM_CC_train = np.load('./pickles/JM_CC_train.npy')\n",
        "JM_CC_train = normalizer.fit_transform(JM_CC_train)\n",
        "\n",
        "DP_UC_train = np.load('./pickles/DP_UC_train.npy')\n",
        "DP_UC_train = normalizer.fit_transform(DP_UC_train)\n",
        "\n",
        "DP_CC_train = np.load('./pickles/DP_CC_train.npy')\n",
        "DP_CC_train = normalizer.fit_transform(DP_CC_train)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#-----------------------IR Test Features Loading------------------#\n",
        "cosine_similarity_UC_test = np.load('./pickles/cosine_similarity_UC_test.npy')\n",
        "cosine_similarity_UC_test = normalizer.fit_transform(cosine_similarity_UC_test)\n",
        "\n",
        "cosine_similarity_CC_test = np.load('./pickles/cosine_similarity_CC_test.npy')\n",
        "cosine_similarity_CC_test = normalizer.fit_transform(cosine_similarity_CC_test)\n",
        "\n",
        "LSA_similarities_UC_test = np.load('./pickles/LSA_similarities_UC_test.npy')\n",
        "LSA_similarities_UC_test = normalizer.fit_transform(LSA_similarities_UC_test)\n",
        "\n",
        "LSA_similarities_CC_test = np.load('./pickles/LSA_similarities_CC_test.npy')\n",
        "LSA_similarities_CC_test = normalizer.fit_transform(LSA_similarities_CC_test)\n",
        "\n",
        "LDA_similarities_UC_test = np.load('./pickles/LDA_similarities_UC_test.npy')\n",
        "LDA_similarities_UC_test = normalizer.fit_transform(LDA_similarities_UC_test)\n",
        "\n",
        "LDA_similarities_CC_test = np.load('./pickles/LDA_similarities_CC_test.npy')\n",
        "LDA_similarities_CC_test = normalizer.fit_transform(LDA_similarities_CC_test)\n",
        "\n",
        "JS_UC_test = np.load('./pickles/JS_UC_test.npy')\n",
        "JS_UC_test = normalizer.fit_transform(JS_UC_test)\n",
        "\n",
        "JS_CC_test = np.load('./pickles/JS_CC_test.npy')\n",
        "JS_CC_test = normalizer.fit_transform(JS_CC_test)\n",
        "\n",
        "BM25_UC_test = np.load('./pickles/BM25_UC_test.npy')\n",
        "BM25_UC_test = normalizer.fit_transform(BM25_UC_test)\n",
        "\n",
        "BM25_CC_test = np.load('./pickles/BM25_CC_test.npy')\n",
        "BM25_CC_test = normalizer.fit_transform(BM25_CC_test)\n",
        "\n",
        "JM_UC_test = np.load('./pickles/JM_UC_test.npy')\n",
        "JM_UC_test = normalizer.fit_transform(JM_UC_test)\n",
        "\n",
        "JM_CC_test = np.load('./pickles/JM_CC_test.npy')\n",
        "JM_CC_test = normalizer.fit_transform(JM_CC_test)\n",
        "\n",
        "DP_UC_test = np.load('./pickles/DP_UC_test.npy')\n",
        "DP_UC_test = normalizer.fit_transform(DP_UC_test)\n",
        "\n",
        "DP_CC_test = np.load('./pickles/DP_CC_test.npy')\n",
        "DP_CC_test = normalizer.fit_transform(DP_CC_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ------------------------pre-retrieval (21 metrics) Train--------------------------#\n",
        "# 1) IDF Features\n",
        "avg_idf_uc_train = featureExtraction.AvgIDF(idf_uc_train)\n",
        "avg_idf_code_train = featureExtraction.AvgIDF(idf_code_train)\n",
        "\n",
        "print('avg_idf_uc_train_shape', avg_idf_uc_train.shape) \n",
        "print('avg_idf_code_train_shape', avg_idf_code_train.shape) \n",
        "\n",
        "max_idf_uc_train = featureExtraction.MaxIDF(idf_uc_train).reshape(1,-1) \n",
        "max_idf_code_train = featureExtraction.MaxIDF(idf_code_train).reshape(1,-1) \n",
        "\n",
        "print('max_idf_uc_train_shape', max_idf_uc_train.shape) \n",
        "print('max_idf_code_train_shape', max_idf_code_train.shape) \n",
        "\n",
        "dev_idf_uc_train = featureExtraction.DevIDF(idf_uc_train).reshape(1,-1) \n",
        "dev_idf_code_train = featureExtraction.DevIDF(idf_code_train).reshape(1,-1) \n",
        "\n",
        "print('dev_idf_uc_train_shape', dev_idf_uc_train.shape) \n",
        "print('dev_idf_code_train_shape', dev_idf_code_train.shape) \n",
        "\n",
        "# 2) ICTF Features\n",
        "avg_ictf_uc_train = featureExtraction.AvgICTF(ictf_uc_train).reshape(1,-1) \n",
        "avg_ictf_code_train = featureExtraction.AvgICTF(ictf_code_train).reshape(1,-1) \n",
        "\n",
        "print('avg_ictf_uc_train_shape', avg_ictf_uc_train.shape)\n",
        "print('avg_ictf_code_train_shape', avg_ictf_code_train.shape)\n",
        "\n",
        "max_ictf_uc_train = featureExtraction.MaxICTF(ictf_uc_train).reshape(1,-1) \n",
        "max_ictf_code_train = featureExtraction.MaxICTF(ictf_code_train).reshape(1,-1) \n",
        "\n",
        "print('max_ictf_uc_train_shape', max_ictf_uc_train.shape)\n",
        "print('max_ictf_code_train_shape', max_ictf_code_train.shape)\n",
        "\n",
        "dev_ictf_uc_train = featureExtraction.DevICTF(ictf_uc_train).reshape(1,-1) \n",
        "dev_ictf_code_train = featureExtraction.DevICTF(ictf_code_train).reshape(1,-1) \n",
        "\n",
        "print('dev_ictf_uc_train_shape', dev_ictf_uc_train.shape)\n",
        "print('dev_ictf_code_train_shape', dev_ictf_code_train.shape)\n",
        "# 3) Entropy Features\n",
        "\n",
        "avg_entropy_uc_train = featureExtraction.AvgEntropy(entropy_uc_train).reshape(1,-1) \n",
        "avg_entropy_code_train = featureExtraction.AvgEntropy(entropy_code_train).reshape(1,-1) \n",
        "\n",
        "print('avg_entropy_uc_train_shape', avg_entropy_uc_train.shape)\n",
        "print('avg_entropy_code_train_shape', avg_entropy_code_train.shape)\n",
        "\n",
        "max_entropy_uc_train = featureExtraction.MaxEntropy(entropy_uc_train).reshape(1,-1) \n",
        "max_entropy_code_train = featureExtraction.MaxEntropy(entropy_code_train).reshape(1,-1) \n",
        "\n",
        "print('max_entropy_uc_train_shape', max_entropy_uc_train.shape)\n",
        "print('max_entropy_code_train_shape', max_entropy_code_train.shape)\n",
        "\n",
        "med_entropy_uc_train = featureExtraction.MedEntropy(entropy_uc_train).reshape(1,-1) \n",
        "med_entropy_code_train = featureExtraction.MedEntropy(entropy_code_train).reshape(1,-1) \n",
        "\n",
        "print('med_entropy_uc_train_shape', med_entropy_uc_train.shape)\n",
        "print('med_entropy_code_train_shape', med_entropy_code_train.shape)\n",
        "\n",
        "dev_entropy_uc_train = featureExtraction.DevEntropy(entropy_uc_train).reshape(1,-1) \n",
        "dev_entropy_code_train = featureExtraction.DevEntropy(entropy_code_train).reshape(1,-1) \n",
        "\n",
        "print('dev_entropy_uc_train_shape', dev_entropy_uc_train.shape)\n",
        "print('dev_entropy_code_train_shape', dev_entropy_code_train.shape)\n",
        "      \n",
        "\n",
        "# 4) Variance Features\n",
        "\n",
        "avg_variance_uc_train = featureExtraction.AvgVariance(variance_uc_train).reshape(1,-1) \n",
        "avg_variance_code_train = featureExtraction.AvgVariance(variance_code_train).reshape(1,-1) \n",
        "\n",
        "print('avg_variance_uc_train_shape', avg_variance_uc_train.shape)\n",
        "print('avg_variance_code_train_shape', avg_variance_code_train.shape)\n",
        "\n",
        "max_variance_uc_train = featureExtraction.MaxVariance(variance_uc_train).reshape(1,-1) \n",
        "max_variance_code_train = featureExtraction.MaxVariance(variance_code_train).reshape(1,-1) \n",
        "\n",
        "print('max_variance_uc_train_shape', max_variance_uc_train.shape)\n",
        "print('max_variance_code_train_shape', max_variance_code_train.shape)\n",
        "\n",
        "sum_variance_uc_train = featureExtraction.SumVariance(variance_uc_train).reshape(1,-1) \n",
        "sum_variance_code_train = featureExtraction.SumVariance(variance_code_train).reshape(1,-1) \n",
        "\n",
        "print('sum_variance_uc_train_shape', sum_variance_uc_train.shape)\n",
        "print('sum_variance_code_train_shape', sum_variance_code_train.shape)\n",
        "# 5) SCQ Features\n",
        "avg_scq_uc_train = featureExtraction.AvgSCQ(SCQ_uc_train).reshape(1,-1) \n",
        "avg_scq_code_train = featureExtraction.AvgSCQ(SCQ_code_train).reshape(1,-1) \n",
        "\n",
        "print('avg_scq_uc_train_shape', avg_scq_uc_train.shape)\n",
        "print('avg_scq_code_train_shape', avg_scq_code_train.shape)\n",
        "\n",
        "max_scq_uc_train = featureExtraction.MaxSCQ(SCQ_uc_train).reshape(1,-1) \n",
        "max_scq_code_train = featureExtraction.MaxSCQ(SCQ_code_train).reshape(1,-1) \n",
        "\n",
        "print('max_scq_uc_train_shape', max_scq_uc_train.shape)\n",
        "print('max_scq_code_train_shape', max_scq_code_train.shape)\n",
        "\n",
        "sum_sqc_uc_train = featureExtraction.SumSCQ(SCQ_uc_train).reshape(1,-1) \n",
        "sum_sqc_code_train = featureExtraction.SumSCQ(SCQ_code_train).reshape(1,-1) \n",
        "\n",
        "print('sum_sqc_uc_train_shape', sum_sqc_uc_train.shape)\n",
        "print('sum_sqc_code_train_shape', sum_sqc_code_train.shape)\n",
        "\n",
        "# 6) PMI Features\n",
        "\n",
        "avg_pmi_uc_train = featureExtraction.AvgPMI(PMI_uc_train).reshape(1,-1) \n",
        "avg_pmi_code_train = featureExtraction.AvgPMI(PMI_code_train).reshape(1,-1) \n",
        "\n",
        "print('avg_pmi_uc_train_shape', avg_pmi_uc_train.shape)\n",
        "print('avg_pmi_code_train_shape', avg_pmi_code_train.shape)\n",
        "\n",
        "max_pmi_uc_train = featureExtraction.MaxPMI(PMI_uc_train).reshape(1,-1) \n",
        "max_pmi_code_train = featureExtraction.MaxPMI(PMI_code_train).reshape(1,-1) \n",
        "\n",
        "print('max_pmi_uc_train_shape', max_pmi_uc_train.shape)\n",
        "print('max_pmi_code_train_shape', max_pmi_code_train.shape)\n",
        "# 7) QS Features\n",
        "\n",
        "qs_uc_train = featureExtraction.QS(UC_documents_train, code_documents_train).reshape(1,-1) \n",
        "qs_code_train = featureExtraction.QS(code_documents_train, UC_documents_train).reshape(1,-1) \n",
        "\n",
        "print('qs_uc_train_shape', qs_uc_train.shape)\n",
        "print('qs_code_train_shape', qs_code_train.shape)\n",
        "\n",
        "# 8) SCS Features\n",
        "UC_SCS_train = featureExtraction.simplifiedClarityScore(UC_documents_train, UC_count_matrix_train, tf_code_dict_train).reshape(1,-1) \n",
        "CC_SCS_train = featureExtraction.simplifiedClarityScore(code_documents_train, code_count_matrix_train, tf_uc_dict_train).reshape(1,-1) \n",
        "\n",
        "print('UC_SCS_train_shape', UC_SCS_train.shape)\n",
        "print('CC_SCS_train_shape', CC_SCS_train.shape)\n",
        "\n",
        "# 9) Coherence Score Features\n",
        "UC_CoherenceScore_train = featureExtraction.CoherenceScore(UC_documents_train, tfidf_matrix_code_train).reshape(1,-1) \n",
        "CC_CoherenceScore_train = featureExtraction.CoherenceScore(code_documents_train, tfidf_matrix_uc_train).reshape(1,-1) \n",
        "\n",
        "print('UC_CoherenceScore_train_shape', UC_CoherenceScore_train.shape)\n",
        "print('CC_CoherenceScore_train_shape', CC_CoherenceScore_train.shape)\n",
        "#75min"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#----------------saving pre retrival Train------------------#\n",
        "np.save('./pickles/avg_idf_uc_train.npy', avg_idf_uc_train)\n",
        "np.save('./pickles/avg_idf_code_train.npy', avg_idf_code_train)\n",
        "\n",
        "np.save('./pickles/max_idf_uc_train.npy', max_idf_uc_train)\n",
        "np.save('./pickles/max_idf_code_train.npy', max_idf_code_train)\n",
        "\n",
        "np.save('./pickles/dev_idf_uc_train.npy', dev_idf_uc_train)\n",
        "np.save('./pickles/dev_idf_code_train.npy', dev_idf_code_train)\n",
        "\n",
        "np.save('./pickles/avg_ictf_uc_train.npy', avg_ictf_uc_train)\n",
        "np.save('./pickles/avg_ictf_code_train.npy', avg_ictf_code_train)\n",
        "\n",
        "np.save('./pickles/max_ictf_uc_train.npy', max_ictf_uc_train)\n",
        "np.save('./pickles/max_ictf_code_train.npy', max_ictf_code_train)\n",
        "\n",
        "np.save('./pickles/dev_ictf_uc_train.npy', dev_ictf_uc_train)\n",
        "np.save('./pickles/dev_ictf_code_train.npy', dev_ictf_code_train)\n",
        "\n",
        "np.save('./pickles/avg_entropy_uc_train.npy', avg_entropy_uc_train)\n",
        "np.save('./pickles/avg_entropy_code_train.npy', avg_entropy_code_train)\n",
        "\n",
        "np.save('./pickles/max_entropy_uc_train.npy', max_entropy_uc_train)\n",
        "np.save('./pickles/max_entropy_code_train.npy', max_entropy_code_train)\n",
        "\n",
        "np.save('./pickles/max_entropy_uc_train.npy', max_entropy_uc_train)\n",
        "np.save('./pickles/max_entropy_code_train.npy', max_entropy_code_train)\n",
        "\n",
        "np.save('./pickles/med_entropy_uc_train.npy', med_entropy_uc_train)\n",
        "np.save('./pickles/med_entropy_code_train.npy', med_entropy_code_train)\n",
        "\n",
        "np.save('./pickles/dev_entropy_uc_train.npy', dev_entropy_uc_train)\n",
        "np.save('./pickles/dev_entropy_code_train.npy', dev_entropy_code_train)\n",
        "\n",
        "np.save('./pickles/avg_variance_uc_train.npy', avg_variance_uc_train)\n",
        "np.save('./pickles/avg_variance_code_train.npy', avg_variance_code_train)\n",
        "\n",
        "np.save('./pickles/max_variance_uc_train.npy', max_variance_uc_train)\n",
        "np.save('./pickles/max_variance_code_train.npy', max_variance_code_train)\n",
        "\n",
        "np.save('./pickles/sum_variance_uc_train.npy', sum_variance_uc_train)\n",
        "np.save('./pickles/sum_variance_code_train.npy', sum_variance_code_train)\n",
        "\n",
        "np.save('./pickles/avg_scq_uc_train.npy', avg_scq_uc_train)\n",
        "np.save('./pickles/avg_scq_code_train.npy', avg_scq_code_train)\n",
        "\n",
        "np.save('./pickles/max_scq_uc_train.npy', max_scq_uc_train)\n",
        "np.save('./pickles/max_scq_code_train.npy', max_scq_code_train)\n",
        "\n",
        "np.save('./pickles/sum_sqc_uc_train.npy', sum_sqc_uc_train)\n",
        "np.save('./pickles/sum_sqc_code_train.npy', sum_sqc_code_train)\n",
        "\n",
        "np.save('./pickles/avg_pmi_uc_train.npy', avg_pmi_uc_train)\n",
        "np.save('./pickles/avg_pmi_code_train.npy', avg_pmi_code_train)\n",
        "\n",
        "np.save('./pickles/max_pmi_uc_train.npy', max_pmi_uc_train)\n",
        "np.save('./pickles/max_pmi_code_train.npy', max_pmi_code_train)\n",
        "\n",
        "np.save('./pickles/qs_uc_train.npy', qs_uc_train)\n",
        "np.save('./pickles/qs_code_train.npy', qs_code_train)\n",
        "\n",
        "np.save('./pickles/UC_SCS_train.npy', UC_SCS_train)\n",
        "np.save('./pickles/CC_SCS_train.npy', CC_SCS_train)\n",
        "\n",
        "np.save('./pickles/UC_CoherenceScore_train.npy', UC_CoherenceScore_train)\n",
        "np.save('./pickles/CC_CoherenceScore_train.npy', CC_CoherenceScore_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ------------------------pre-retrieval (21 metrics) Test--------------------------#\n",
        "# 1) IDF Features\n",
        "avg_idf_uc_test = featureExtraction.AvgIDF(idf_uc_test).reshape(1,-1)\n",
        "avg_idf_code_test = featureExtraction.AvgIDF(idf_code_test).reshape(1,-1)\n",
        "\n",
        "print('avg_idf_uc_test_shape', avg_idf_uc_test.shape)\n",
        "print('avg_idf_code_test_shape', avg_idf_code_test.shape)\n",
        "\n",
        "max_idf_uc_test = featureExtraction.MaxIDF(idf_uc_test).reshape(1,-1)\n",
        "max_idf_code_test = featureExtraction.MaxIDF(idf_code_test).reshape(1,-1)\n",
        "\n",
        "print('max_idf_uc_test_shape', max_idf_uc_test.shape)\n",
        "print('max_idf_code_test_shape', max_idf_code_test.shape)\n",
        "\n",
        "dev_idf_uc_test = featureExtraction.DevIDF(idf_uc_test).reshape(1,-1)\n",
        "dev_idf_code_test = featureExtraction.DevIDF(idf_code_test).reshape(1,-1)\n",
        "\n",
        "print('dev_idf_uc_test_shape', dev_idf_uc_test.shape)\n",
        "print('dev_idf_code_test_shape', dev_idf_code_test.shape)\n",
        "\n",
        "# 2) ICTF Features\n",
        "avg_ictf_uc_test = featureExtraction.AvgICTF(ictf_uc_test).reshape(1,-1)\n",
        "avg_ictf_code_test = featureExtraction.AvgICTF(ictf_code_test).reshape(1,-1)\n",
        "\n",
        "print('avg_ictf_uc_test_shape', avg_ictf_uc_test.shape)\n",
        "print('avg_ictf_code_test_shape', avg_ictf_code_test.shape)\n",
        "\n",
        "max_ictf_uc_test = featureExtraction.MaxICTF(ictf_uc_test).reshape(1,-1)\n",
        "max_ictf_code_test = featureExtraction.MaxICTF(ictf_code_test).reshape(1,-1)\n",
        "\n",
        "print('max_ictf_uc_test_shape', max_ictf_uc_test.shape)\n",
        "print('max_ictf_code_test_shape', max_ictf_code_test.shape)\n",
        "\n",
        "dev_ictf_uc_test = featureExtraction.DevICTF(ictf_uc_test).reshape(1,-1)\n",
        "dev_ictf_code_test = featureExtraction.DevICTF(ictf_code_test).reshape(1,-1)\n",
        "\n",
        "print('dev_ictf_uc_test_shape', dev_ictf_uc_test.shape)\n",
        "print('dev_ictf_code_test_shape', dev_ictf_code_test.shape)\n",
        "\n",
        "# 3) Entropy Features\n",
        "avg_entropy_uc_test = featureExtraction.AvgEntropy(entropy_uc_test).reshape(1,-1)\n",
        "avg_entropy_code_test = featureExtraction.AvgEntropy(entropy_code_test).reshape(1,-1)\n",
        "\n",
        "print('avg_entropy_uc_test_shape', avg_entropy_uc_test.shape)\n",
        "print('avg_entropy_code_test_shape', avg_entropy_code_test.shape)\n",
        "\n",
        "max_entropy_uc_test = featureExtraction.MaxEntropy(entropy_uc_test).reshape(1,-1)\n",
        "max_entropy_code_test = featureExtraction.MaxEntropy(entropy_code_test).reshape(1,-1)\n",
        "\n",
        "print('max_entropy_uc_test_shape', max_entropy_uc_test.shape)\n",
        "print('max_entropy_code_test_shape', max_entropy_code_test.shape)\n",
        "\n",
        "med_entropy_uc_test = featureExtraction.MedEntropy(entropy_uc_test).reshape(1,-1)\n",
        "med_entropy_code_test = featureExtraction.MedEntropy(entropy_code_test).reshape(1,-1)\n",
        "\n",
        "print('med_entropy_uc_test_shape', med_entropy_uc_test.shape)\n",
        "print('med_entropy_code_test_shape', med_entropy_code_test.shape)\n",
        "\n",
        "dev_entropy_uc_test = featureExtraction.DevEntropy(entropy_uc_test).reshape(1,-1)\n",
        "dev_entropy_code_test = featureExtraction.DevEntropy(entropy_code_test).reshape(1,-1)\n",
        "\n",
        "print('dev_entropy_uc_test_shape', dev_entropy_uc_test.shape)\n",
        "print('dev_entropy_code_test_shape', dev_entropy_code_test.shape)\n",
        "\n",
        "# 4) Variance Features\n",
        "\n",
        "avg_variance_uc_test = featureExtraction.AvgVariance(variance_uc_test).reshape(1,-1) \n",
        "avg_variance_code_test = featureExtraction.AvgVariance(variance_code_test).reshape(1,-1) \n",
        "\n",
        "print('avg_variance_uc_test_shape', avg_variance_uc_test.shape)\n",
        "print('avg_variance_code_test_shape', avg_variance_code_test.shape)\n",
        "\n",
        "max_variance_uc_test = featureExtraction.MaxVariance(variance_uc_test).reshape(1,-1) \n",
        "max_variance_code_test = featureExtraction.MaxVariance(variance_code_test).reshape(1,-1) \n",
        "\n",
        "print('max_variance_uc_test_shape', max_variance_uc_test.shape)\n",
        "print('max_variance_code_test_shape', max_variance_code_test.shape)\n",
        "\n",
        "sum_variance_uc_test = featureExtraction.SumVariance(variance_uc_test).reshape(1,-1) \n",
        "sum_variance_code_test = featureExtraction.SumVariance(variance_code_test).reshape(1,-1) \n",
        "\n",
        "print('sum_variance_uc_test_shape', sum_variance_uc_test.shape)\n",
        "print('sum_variance_code_test_shape', sum_variance_code_test.shape)\n",
        "\n",
        "# 5) SCQ Features\n",
        "avg_scq_uc_test = featureExtraction.AvgSCQ(SCQ_uc_test).reshape(1,-1) \n",
        "avg_scq_code_test = featureExtraction.AvgSCQ(SCQ_code_test).reshape(1,-1) \n",
        "\n",
        "print('avg_scq_uc_test_shape', avg_scq_uc_test.shape)\n",
        "print('avg_scq_code_test_shape', avg_scq_code_test.shape)\n",
        "\n",
        "max_scq_uc_test = featureExtraction.MaxSCQ(SCQ_uc_test).reshape(1,-1) \n",
        "max_scq_code_test = featureExtraction.MaxSCQ(SCQ_code_test).reshape(1,-1) \n",
        "\n",
        "print('max_scq_uc_test_shape', max_scq_uc_test.shape)\n",
        "print('max_scq_code_test_shape', max_scq_code_test.shape)\n",
        "\n",
        "sum_sqc_uc_test = featureExtraction.SumSCQ(SCQ_uc_test).reshape(1,-1) \n",
        "sum_sqc_code_test = featureExtraction.SumSCQ(SCQ_code_test).reshape(1,-1) \n",
        "\n",
        "print('sum_sqc_uc_test_shape', sum_sqc_uc_test.shape)\n",
        "print('sum_sqc_code_test_shape', sum_sqc_code_test.shape)\n",
        "\n",
        "# 6) PMI Features\n",
        "\n",
        "avg_pmi_uc_test = featureExtraction.AvgPMI(PMI_uc_test).reshape(1,-1) \n",
        "avg_pmi_code_test = featureExtraction.AvgPMI(PMI_code_test).reshape(1,-1) \n",
        "\n",
        "print('avg_pmi_uc_test_shape', avg_pmi_uc_test.shape)\n",
        "print('avg_pmi_code_test_shape', avg_pmi_code_test.shape)\n",
        "\n",
        "max_pmi_uc_test = featureExtraction.MaxPMI(PMI_uc_test).reshape(1,-1) \n",
        "max_pmi_code_test = featureExtraction.MaxPMI(PMI_code_test).reshape(1,-1) \n",
        "\n",
        "print('max_pmi_uc_test_shape', max_pmi_uc_test.shape)\n",
        "print('max_pmi_code_test_shape', max_pmi_code_test.shape)\n",
        "\n",
        "# 7) QS Features\n",
        "\n",
        "qs_uc_test = featureExtraction.QS(UC_documents_test, code_documents_test).reshape(1,-1) \n",
        "qs_code_test = featureExtraction.QS(code_documents_test, UC_documents_test).reshape(1,-1) \n",
        "\n",
        "print('qs_uc_test_shape', qs_uc_test.shape)\n",
        "print('qs_code_test_shape', qs_code_test.shape)\n",
        "\n",
        "# 8) SCS Features\n",
        "UC_SCS_test = featureExtraction.simplifiedClarityScore(UC_documents_test, UC_count_matrix_test, tf_code_dict_test).reshape(1,-1) \n",
        "CC_SCS_test = featureExtraction.simplifiedClarityScore(code_documents_test, code_count_matrix_test, tf_uc_dict_test).reshape(1,-1) \n",
        "\n",
        "print('UC_SCS_test_shape', UC_SCS_test.shape)\n",
        "print('CC_SCS_test_shape', CC_SCS_test.shape)\n",
        "\n",
        "# 9) Coherence Score Features\n",
        "UC_CoherenceScore_test = featureExtraction.CoherenceScore(UC_documents_test, tfidf_matrix_code_test).reshape(1,-1) \n",
        "CC_CoherenceScore_test = featureExtraction.CoherenceScore(code_documents_test, tfidf_matrix_uc_test).reshape(1,-1) \n",
        "\n",
        "print('UC_CoherenceScore_test_shape', UC_CoherenceScore_test.shape)\n",
        "print('CC_CoherenceScore_test_shape', CC_CoherenceScore_test.shape)\n",
        "\n",
        "#7mins"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#-------------------Saving test Preretival------------------#\n",
        "np.save('./pickles/avg_idf_uc_test.npy', avg_idf_uc_test)\n",
        "np.save('./pickles/avg_idf_code_test.npy', avg_idf_code_test)\n",
        "\n",
        "np.save('./pickles/max_idf_uc_test.npy', max_idf_uc_test)\n",
        "np.save('./pickles/max_idf_code_test.npy', max_idf_code_test)\n",
        "\n",
        "np.save('./pickles/dev_idf_uc_test.npy', dev_idf_uc_test)\n",
        "np.save('./pickles/dev_idf_code_test.npy', dev_idf_code_test)\n",
        "\n",
        "np.save('./pickles/avg_ictf_uc_test.npy', avg_ictf_uc_test)\n",
        "np.save('./pickles/avg_ictf_code_test.npy', avg_ictf_code_test)\n",
        "\n",
        "np.save('./pickles/max_ictf_uc_test.npy', max_ictf_uc_test)\n",
        "np.save('./pickles/max_ictf_code_test.npy', max_ictf_code_test)\n",
        "\n",
        "np.save('./pickles/dev_ictf_uc_test.npy', dev_ictf_uc_test)\n",
        "np.save('./pickles/dev_ictf_code_test.npy', dev_ictf_code_test)\n",
        "\n",
        "np.save('./pickles/avg_entropy_uc_test.npy', avg_entropy_uc_test)\n",
        "np.save('./pickles/avg_entropy_code_test.npy', avg_entropy_code_test)\n",
        "\n",
        "np.save('./pickles/max_entropy_uc_test.npy', max_entropy_uc_test)\n",
        "np.save('./pickles/max_entropy_code_test.npy', max_entropy_code_test)\n",
        "\n",
        "np.save('./pickles/med_entropy_uc_test.npy', med_entropy_uc_test)\n",
        "np.save('./pickles/med_entropy_code_test.npy', med_entropy_code_test)\n",
        "\n",
        "np.save('./pickles/dev_entropy_uc_test.npy', dev_entropy_uc_test)\n",
        "np.save('./pickles/dev_entropy_code_test.npy', dev_entropy_code_test)\n",
        "\n",
        "np.save('./pickles/avg_variance_uc_test.npy', avg_variance_uc_test)\n",
        "np.save('./pickles/avg_variance_code_test.npy', avg_variance_code_test)\n",
        "\n",
        "np.save('./pickles/max_variance_uc_test.npy', max_variance_uc_test)\n",
        "np.save('./pickles/max_variance_code_test.npy', max_variance_code_test)\n",
        "\n",
        "np.save('./pickles/sum_variance_uc_test.npy', sum_variance_uc_test)\n",
        "np.save('./pickles/sum_variance_code_test.npy', sum_variance_code_test)\n",
        "\n",
        "np.save('./pickles/avg_scq_uc_test.npy', avg_scq_uc_test)\n",
        "np.save('./pickles/avg_scq_code_test.npy', avg_scq_code_test)\n",
        "\n",
        "np.save('./pickles/max_scq_uc_test.npy', max_scq_uc_test)\n",
        "np.save('./pickles/max_scq_code_test.npy', max_scq_code_test)\n",
        "\n",
        "np.save('./pickles/sum_sqc_uc_test.npy', sum_sqc_uc_test)\n",
        "np.save('./pickles/sum_sqc_code_test.npy', sum_sqc_code_test)\n",
        "\n",
        "np.save('./pickles/avg_pmi_uc_test.npy', avg_pmi_uc_test)\n",
        "np.save('./pickles/avg_pmi_code_test.npy', avg_pmi_code_test)\n",
        "\n",
        "np.save('./pickles/max_pmi_uc_test.npy', max_pmi_uc_test)\n",
        "np.save('./pickles/max_pmi_code_test.npy', max_pmi_code_test)\n",
        "\n",
        "np.save('./pickles/qs_uc_test.npy', qs_uc_test)\n",
        "np.save('./pickles/qs_code_test.npy', qs_code_test)\n",
        "\n",
        "np.save('./pickles/UC_SCS_test.npy', UC_SCS_test)\n",
        "np.save('./pickles/CC_SCS_test.npy', CC_SCS_test)\n",
        "\n",
        "np.save('./pickles/UC_CoherenceScore_test.npy', UC_CoherenceScore_test)\n",
        "np.save('./pickles/CC_CoherenceScore_test.npy', CC_CoherenceScore_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ------------------------pre-retrieval (21 metrics) Train--------------------------#\n",
        "\n",
        "avg_idf_uc_train = np.load('./pickles/avg_idf_uc_train.npy')\n",
        "\n",
        "avg_idf_uc_train = normalizer.fit_transform(avg_idf_uc_train.reshape(-1,1))\n",
        "\n",
        "avg_idf_code_train = np.load('./pickles/avg_idf_code_train.npy')\n",
        "avg_idf_code_train = normalizer.fit_transform(avg_idf_code_train.reshape(-1,1))\n",
        "\n",
        "max_idf_uc_train = np.load('./pickles/max_idf_uc_train.npy')\n",
        "\n",
        "max_idf_uc_train = normalizer.fit_transform(max_idf_uc_train.reshape(-1,1))\n",
        "\n",
        "max_idf_code_train = np.load('./pickles/max_idf_code_train.npy')\n",
        "max_idf_code_train = normalizer.fit_transform(max_idf_code_train.reshape(-1,1))\n",
        "\n",
        "dev_idf_uc_train = np.load('./pickles/dev_idf_uc_train.npy')\n",
        "dev_idf_uc_train = normalizer.fit_transform(dev_idf_uc_train.reshape(-1,1))\n",
        "\n",
        "dev_idf_code_train = np.load('./pickles/dev_idf_code_train.npy')\n",
        "dev_idf_code_train = normalizer.fit_transform(dev_idf_code_train.reshape(-1,1))\n",
        "\n",
        "avg_ictf_uc_train = np.load('./pickles/avg_ictf_uc_train.npy')\n",
        "avg_ictf_uc_train = normalizer.fit_transform(avg_ictf_uc_train.reshape(-1,1))\n",
        "\n",
        "avg_ictf_code_train = np.load('./pickles/avg_ictf_code_train.npy')\n",
        "avg_ictf_code_train = normalizer.fit_transform(avg_ictf_code_train.reshape(-1,1))\n",
        "\n",
        "max_ictf_uc_train = np.load('./pickles/max_ictf_uc_train.npy')\n",
        "max_ictf_uc_train = normalizer.fit_transform(max_ictf_uc_train.reshape(-1,1))\n",
        "\n",
        "max_ictf_code_train = np.load('./pickles/max_ictf_code_train.npy')\n",
        "max_ictf_code_train = normalizer.fit_transform(max_ictf_code_train.reshape(-1,1))\n",
        "\n",
        "dev_ictf_uc_train = np.load('./pickles/dev_ictf_uc_train.npy')\n",
        "dev_ictf_uc_train = normalizer.fit_transform(dev_ictf_uc_train.reshape(-1,1))\n",
        "\n",
        "dev_ictf_code_train = np.load('./pickles/dev_ictf_code_train.npy')\n",
        "dev_ictf_code_train = normalizer.fit_transform(dev_ictf_code_train.reshape(-1,1))\n",
        "\n",
        "avg_entropy_uc_train = np.load('./pickles/avg_entropy_uc_train.npy')\n",
        "avg_entropy_uc_train = normalizer.fit_transform(avg_entropy_uc_train.reshape(-1,1))\n",
        "\n",
        "avg_entropy_code_train = np.load('./pickles/avg_entropy_code_train.npy')\n",
        "avg_entropy_code_train = normalizer.fit_transform(avg_entropy_code_train.reshape(-1,1))\n",
        "\n",
        "max_entropy_uc_train = np.load('./pickles/max_entropy_uc_train.npy')\n",
        "max_entropy_uc_train = normalizer.fit_transform(max_entropy_uc_train.reshape(-1,1))\n",
        "\n",
        "max_entropy_code_train = np.load('./pickles/max_entropy_code_train.npy')\n",
        "max_entropy_code_train = normalizer.fit_transform(max_entropy_code_train.reshape(-1,1))\n",
        "\n",
        "med_entropy_uc_train = np.load('./pickles/med_entropy_uc_train.npy')\n",
        "med_entropy_uc_train = normalizer.fit_transform(med_entropy_uc_train.reshape(-1,1))\n",
        "med_entropy_code_train = np.load('./pickles/med_entropy_code_train.npy')\n",
        "med_entropy_code_train = normalizer.fit_transform(med_entropy_code_train.reshape(-1,1))\n",
        "\n",
        "dev_entropy_uc_train = np.load('./pickles/dev_entropy_uc_train.npy')\n",
        "dev_entropy_uc_train = normalizer.fit_transform(dev_entropy_uc_train.reshape(-1,1))\n",
        "\n",
        "dev_entropy_code_train = np.load('./pickles/dev_entropy_code_train.npy')\n",
        "dev_entropy_code_train = normalizer.fit_transform(dev_entropy_code_train.reshape(-1,1))\n",
        "\n",
        "avg_variance_uc_train = np.load('./pickles/avg_variance_uc_train.npy')\n",
        "avg_variance_uc_train = normalizer.fit_transform(avg_variance_uc_train.reshape(-1,1))\n",
        "\n",
        "avg_variance_code_train = np.load('./pickles/avg_variance_code_train.npy')\n",
        "avg_variance_code_train = normalizer.fit_transform(avg_variance_code_train.reshape(-1,1))\n",
        "\n",
        "max_variance_uc_train = np.load('./pickles/max_variance_uc_train.npy')\n",
        "max_variance_uc_train = normalizer.fit_transform(max_variance_uc_train.reshape(-1,1))\n",
        "\n",
        "max_variance_code_train = np.load('./pickles/max_variance_code_train.npy')\n",
        "max_variance_code_train = normalizer.fit_transform(max_variance_code_train.reshape(-1,1))\n",
        "sum_variance_uc_train = np.load('./pickles/sum_variance_uc_train.npy')\n",
        "sum_variance_uc_train = normalizer.fit_transform(sum_variance_uc_train.reshape(-1,1))\n",
        "\n",
        "sum_variance_code_train = np.load('./pickles/sum_variance_code_train.npy')\n",
        "sum_variance_code_train = normalizer.fit_transform(sum_variance_code_train.reshape(-1,1))\n",
        "\n",
        "avg_scq_uc_train = np.load('./pickles/avg_scq_uc_train.npy')\n",
        "avg_scq_uc_train = normalizer.fit_transform(avg_scq_uc_train.reshape(-1,1))\n",
        "\n",
        "avg_scq_code_train = np.load('./pickles/avg_scq_code_train.npy')\n",
        "avg_scq_code_train = normalizer.fit_transform(avg_scq_code_train.reshape(-1,1))\n",
        "\n",
        "max_scq_uc_train = np.load('./pickles/max_scq_uc_train.npy')\n",
        "max_scq_uc_train = normalizer.fit_transform(max_scq_uc_train.reshape(-1,1).reshape(-1,1))\n",
        "\n",
        "max_scq_code_train = np.load('./pickles/max_scq_code_train.npy')\n",
        "max_scq_code_train = normalizer.fit_transform(max_scq_code_train.reshape(-1,1))\n",
        "\n",
        "sum_sqc_uc_train = np.load('./pickles/sum_sqc_uc_train.npy')\n",
        "sum_sqc_uc_train = normalizer.fit_transform(sum_sqc_uc_train.reshape(-1,1))\n",
        "\n",
        "sum_sqc_code_train = np.load('./pickles/sum_sqc_code_train.npy')\n",
        "sum_sqc_code_train = normalizer.fit_transform(sum_sqc_code_train.reshape(-1,1))\n",
        "\n",
        "avg_pmi_uc_train = np.load('./pickles/avg_pmi_uc_train.npy')\n",
        "avg_pmi_uc_train = normalizer.fit_transform(avg_pmi_uc_train.reshape(-1,1))\n",
        "\n",
        "avg_pmi_code_train = np.load('./pickles/avg_pmi_code_train.npy')\n",
        "avg_pmi_code_train = normalizer.fit_transform(avg_pmi_code_train.reshape(-1,1))\n",
        "\n",
        "max_pmi_uc_train = np.load('./pickles/max_pmi_uc_train.npy')\n",
        "max_pmi_uc_train = normalizer.fit_transform(max_pmi_uc_train.reshape(-1,1))\n",
        "\n",
        "\n",
        "max_pmi_code_train = np.load('./pickles/max_pmi_code_train.npy')\n",
        "max_pmi_code_train = normalizer.fit_transform(max_pmi_code_train.reshape(-1,1))\n",
        "\n",
        "qs_uc_train = np.load('./pickles/qs_uc_train.npy')\n",
        "qs_uc_train = normalizer.fit_transform(qs_uc_train.reshape(-1,1))\n",
        "\n",
        "qs_code_train = np.load('./pickles/qs_code_train.npy')\n",
        "qs_code_train = normalizer.fit_transform(qs_code_train.reshape(-1,1))\n",
        "\n",
        "UC_SCS_train = np.load('./pickles/UC_SCS_train.npy')\n",
        "UC_SCS_train = normalizer.fit_transform(UC_SCS_train.reshape(-1,1))\n",
        "\n",
        "CC_SCS_train = np.load('./pickles/CC_SCS_train.npy')\n",
        "CC_SCS_train = normalizer.fit_transform(CC_SCS_train.reshape(-1,1))\n",
        "\n",
        "UC_CoherenceScore_train = np.load('./pickles/UC_CoherenceScore_train.npy')\n",
        "UC_CoherenceScore_train = normalizer.fit_transform(UC_CoherenceScore_train.reshape(-1,1))\n",
        "\n",
        "\n",
        "CC_CoherenceScore_train = np.load('./pickles/CC_CoherenceScore_train.npy')\n",
        "CC_CoherenceScore_train = normalizer.fit_transform(CC_CoherenceScore_train.reshape(-1,1))\n",
        "\n",
        "print(\"max_ictf_code_train:\", max_ictf_code_train) #gives ones only\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ------------------------pre-retrieval (21 metrics) Test--------------------------#\n",
        "avg_idf_uc_test = np.load('./pickles/avg_idf_uc_test.npy')\n",
        "avg_idf_uc_test = normalizer.fit_transform(avg_idf_uc_test.reshape(-1,1))\n",
        "\n",
        "avg_idf_code_test = np.load('./pickles/avg_idf_code_test.npy')\n",
        "avg_idf_code_test = normalizer.fit_transform(avg_idf_code_test.reshape(-1,1))\n",
        "\n",
        "max_idf_uc_test = np.load('./pickles/max_idf_uc_test.npy')\n",
        "max_idf_uc_test = normalizer.fit_transform(max_idf_uc_test.reshape(-1,1))\n",
        "\n",
        "max_idf_code_test = np.load('./pickles/max_idf_code_test.npy')\n",
        "max_idf_code_test = normalizer.fit_transform(max_idf_code_test.reshape(-1,1))\n",
        "\n",
        "dev_idf_uc_test = np.load('./pickles/dev_idf_uc_test.npy')\n",
        "dev_idf_uc_test = normalizer.fit_transform(dev_idf_uc_test.reshape(-1,1))\n",
        "\n",
        "dev_idf_code_test = np.load('./pickles/dev_idf_code_test.npy')\n",
        "dev_idf_code_test = normalizer.fit_transform(dev_idf_code_test.reshape(-1,1))\n",
        "\n",
        "avg_ictf_uc_test = np.load('./pickles/avg_ictf_uc_test.npy')\n",
        "avg_ictf_uc_test = normalizer.fit_transform(avg_ictf_uc_test.reshape(-1,1))\n",
        "\n",
        "avg_ictf_code_test = np.load('./pickles/avg_ictf_code_test.npy')\n",
        "avg_ictf_code_test = normalizer.fit_transform(avg_ictf_code_test.reshape(-1,1))\n",
        "\n",
        "max_ictf_uc_test = np.load('./pickles/max_ictf_uc_test.npy')\n",
        "max_ictf_uc_test = normalizer.fit_transform(max_ictf_uc_test.reshape(-1,1))\n",
        "\n",
        "max_ictf_code_test = np.load('./pickles/max_ictf_code_test.npy')\n",
        "max_ictf_code_test = normalizer.fit_transform(max_ictf_code_test.reshape(-1,1))\n",
        "\n",
        "dev_ictf_uc_test = np.load('./pickles/dev_ictf_uc_test.npy')\n",
        "dev_ictf_uc_test = normalizer.fit_transform(dev_ictf_uc_test.reshape(-1,1))\n",
        "\n",
        "dev_ictf_code_test = np.load('./pickles/dev_ictf_code_test.npy')\n",
        "dev_ictf_code_test = normalizer.fit_transform(dev_ictf_code_test.reshape(-1,1))\n",
        "\n",
        "avg_entropy_uc_test = np.load('./pickles/avg_entropy_uc_test.npy')\n",
        "avg_entropy_uc_test = normalizer.fit_transform(avg_entropy_uc_test.reshape(-1,1))\n",
        "\n",
        "avg_entropy_code_test = np.load('./pickles/avg_entropy_code_test.npy')\n",
        "avg_entropy_code_test = normalizer.fit_transform(avg_entropy_code_test.reshape(-1,1))\n",
        "\n",
        "max_entropy_uc_test = np.load('./pickles/max_entropy_uc_test.npy')\n",
        "max_entropy_uc_test = normalizer.fit_transform(max_entropy_uc_test.reshape(-1,1))\n",
        "\n",
        "max_entropy_code_test = np.load('./pickles/max_entropy_code_test.npy')\n",
        "max_entropy_code_test = normalizer.fit_transform(max_entropy_code_test.reshape(-1,1))\n",
        "\n",
        "med_entropy_uc_test = np.load('./pickles/med_entropy_uc_test.npy')\n",
        "med_entropy_uc_test = normalizer.fit_transform(med_entropy_uc_test.reshape(-1,1))\n",
        "\n",
        "med_entropy_code_test = np.load('./pickles/med_entropy_code_test.npy')\n",
        "med_entropy_code_test = normalizer.fit_transform(med_entropy_code_test.reshape(-1,1))\n",
        "\n",
        "dev_entropy_uc_test = np.load('./pickles/dev_entropy_uc_test.npy')\n",
        "dev_entropy_uc_test = normalizer.fit_transform(dev_entropy_uc_test.reshape(-1,1))\n",
        "\n",
        "dev_entropy_code_test = np.load('./pickles/dev_entropy_code_test.npy')\n",
        "dev_entropy_code_test = normalizer.fit_transform(dev_entropy_code_test.reshape(-1,1))\n",
        "\n",
        "avg_variance_uc_test = np.load('./pickles/avg_variance_uc_test.npy')\n",
        "avg_variance_uc_test = normalizer.fit_transform(avg_variance_uc_test.reshape(-1,1))\n",
        "\n",
        "avg_variance_code_test = np.load('./pickles/avg_variance_code_test.npy')\n",
        "avg_variance_code_test = normalizer.fit_transform(avg_variance_code_test.reshape(-1,1))\n",
        "\n",
        "max_variance_uc_test = np.load('./pickles/max_variance_uc_test.npy')\n",
        "max_variance_uc_test = normalizer.fit_transform(max_variance_uc_test.reshape(-1,1))\n",
        "\n",
        "max_variance_code_test = np.load('./pickles/max_variance_code_test.npy')\n",
        "max_variance_code_test = normalizer.fit_transform(max_variance_code_test.reshape(-1,1))\n",
        "\n",
        "sum_variance_uc_test = np.load('./pickles/sum_variance_uc_test.npy')\n",
        "sum_variance_uc_test = normalizer.fit_transform(sum_variance_uc_test.reshape(-1,1))\n",
        "\n",
        "sum_variance_code_test = np.load('./pickles/sum_variance_code_test.npy')\n",
        "sum_variance_code_test = normalizer.fit_transform(sum_variance_code_test.reshape(-1,1))\n",
        "\n",
        "avg_scq_uc_test = np.load('./pickles/avg_scq_uc_test.npy')\n",
        "avg_scq_uc_test = normalizer.fit_transform(avg_scq_uc_test.reshape(-1,1))\n",
        "\n",
        "avg_scq_code_test = np.load('./pickles/avg_scq_code_test.npy')\n",
        "avg_scq_code_test = normalizer.fit_transform(avg_scq_code_test.reshape(-1,1))\n",
        "\n",
        "max_scq_uc_test = np.load('./pickles/max_scq_uc_test.npy')\n",
        "max_scq_uc_test = normalizer.fit_transform(max_scq_uc_test.reshape(-1,1))\n",
        "\n",
        "max_scq_code_test = np.load('./pickles/max_scq_code_test.npy')\n",
        "max_scq_code_test = normalizer.fit_transform(max_scq_code_test.reshape(-1,1))\n",
        "\n",
        "sum_sqc_uc_test = np.load('./pickles/sum_sqc_uc_test.npy')\n",
        "sum_sqc_uc_test = normalizer.fit_transform(sum_sqc_uc_test.reshape(-1,1))\n",
        "\n",
        "sum_sqc_code_test = np.load('./pickles/sum_sqc_code_test.npy')\n",
        "sum_sqc_code_test = normalizer.fit_transform(sum_sqc_code_test.reshape(-1,1))\n",
        "\n",
        "avg_pmi_uc_test = np.load('./pickles/avg_pmi_uc_test.npy')\n",
        "avg_pmi_uc_test = normalizer.fit_transform(avg_pmi_uc_test.reshape(-1,1))\n",
        "\n",
        "avg_pmi_code_test = np.load('./pickles/avg_pmi_code_test.npy')\n",
        "avg_pmi_code_test = normalizer.fit_transform(avg_pmi_code_test.reshape(-1,1))\n",
        "\n",
        "max_pmi_uc_test = np.load('./pickles/max_pmi_uc_test.npy')\n",
        "max_pmi_uc_test = normalizer.fit_transform(max_pmi_uc_test.reshape(-1,1))\n",
        "\n",
        "max_pmi_code_test = np.load('./pickles/max_pmi_code_test.npy')\n",
        "max_pmi_code_test = normalizer.fit_transform(max_pmi_code_test.reshape(-1,1))\n",
        "\n",
        "qs_uc_test = np.load('./pickles/qs_uc_test.npy')\n",
        "qs_uc_test = normalizer.fit_transform(qs_uc_test.reshape(-1,1))\n",
        "\n",
        "qs_code_test = np.load('./pickles/qs_code_test.npy')\n",
        "qs_code_test = normalizer.fit_transform(qs_code_test.reshape(-1,1))\n",
        "\n",
        "UC_SCS_test = np.load('./pickles/UC_SCS_test.npy')\n",
        "UC_SCS_test = normalizer.fit_transform(UC_SCS_test.reshape(-1,1))\n",
        "\n",
        "CC_SCS_test = np.load('./pickles/CC_SCS_test.npy')\n",
        "CC_SCS_test = normalizer.fit_transform(CC_SCS_test.reshape(-1,1))\n",
        "\n",
        "UC_CoherenceScore_test = np.load('./pickles/UC_CoherenceScore_test.npy')\n",
        "UC_CoherenceScore_test = normalizer.fit_transform(UC_CoherenceScore_test.reshape(-1,1))\n",
        "\n",
        "CC_CoherenceScore_test = np.load('./pickles/CC_CoherenceScore_test.npy')\n",
        "CC_CoherenceScore_test = normalizer.fit_transform(CC_CoherenceScore_test.reshape(-1,1))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Post Retrieval features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#BASSANT COMMENTED THIS\n",
        "# #------------------------post-retrieval (7 metrics) Train --------------------------#\n",
        "# # 1.1) Subquery overlap using jensenShannon\n",
        "# code_queries_score_JensenShannon_train = featureExtraction.SubqueryOverlap(code_documents_train, featureExtraction.JensenShannon,\"JS\", UC_count_matrix_train, code_count_matrix_train)\n",
        "# UC_queries_score_JensenShannon_train = featureExtraction.SubqueryOverlap(UC_documents_train, featureExtraction.JensenShannon,\"JS\",code_count_matrix_train, UC_count_matrix_train)\n",
        "\n",
        "# print('code_queries_score_JensenShannon_train', code_queries_score_JensenShannon_train.shape)\n",
        "# print('UC_queries_score_JensenShannon_train', UC_queries_score_JensenShannon_train.shape)\n",
        "\n",
        "# # 1.2) Subquery overlap using VSM\n",
        "# code_queries_score_VSM_train = featureExtraction.SubqueryOverlap(code_documents_train, featureExtraction.VectorSpaceModel,\"VSM\", UC_count_matrix_train, code_count_matrix_train)\n",
        "# UC_queries_score_VSM_train = featureExtraction.SubqueryOverlap(UC_documents_train, featureExtraction.VectorSpaceModel,\"VSM\", code_count_matrix_train, UC_count_matrix_train)\n",
        "\n",
        "# print('code_queries_score_VSM_train', code_queries_score_VSM_train.shape)\n",
        "# print('UC_queries_score_VSM_train', UC_queries_score_VSM_train.shape)\n",
        "\n",
        "# #1.3) Subquery overlap using BM25\n",
        "# code_queries_score_BM25_train = featureExtraction.SubqueryOverlap(code_documents_train, featureExtraction.BM25,\"BM\", UC_documents_train,idf_uc_dict_train,UC_count_matrix_train)\n",
        "# UC_queries_score_BM25_train = featureExtraction.SubqueryOverlap(UC_documents_train, featureExtraction.BM25,\"BM\", code_documents_train,idf_code_dict_train, code_count_matrix_train)\n",
        "\n",
        "# print('code_queries_score_BM25_train', code_queries_score_BM25_train.shape)\n",
        "# print('UC_queries_score_BM25_train', UC_queries_score_BM25_train.shape)\n",
        "\n",
        "# #1.4) Subquery overlap using JM smoothing\n",
        "# code_queries_score_JM_train = featureExtraction.SubqueryOverlap(code_documents_train, featureExtraction.SmoothingMethods,\"SM\", UC_documents_train,UC_count_matrix_train,tf_uc_dict_train,True)\n",
        "# UC_queries_score_JM_train = featureExtraction.SubqueryOverlap(UC_documents_train, featureExtraction.SmoothingMethods,\"SM\", code_documents_train,code_count_matrix_train,tf_code_dict_train,True)\n",
        "\n",
        "# print('code_queries_score_JM_train', code_queries_score_JM_train.shape)\n",
        "# print('UC_queries_score_JM_train', UC_queries_score_JM_train.shape)\n",
        "\n",
        "# # 1.5) Subquery overlap using DP smoothing\n",
        "# code_queries_score_DP_train = featureExtraction.SubqueryOverlap(code_documents_train, featureExtraction.SmoothingMethods,\"SM\", UC_documents_train, UC_count_matrix_train,tf_uc_dict_train,False)\n",
        "# UC_queries_score_DP_train = featureExtraction.SubqueryOverlap(UC_documents_train, featureExtraction.SmoothingMethods,\"SM\", code_documents_train, code_count_matrix_train,tf_code_dict_train,False)\n",
        "\n",
        "# print('code_queries_score_DP_train', code_queries_score_DP_train.shape)\n",
        "# print('UC_queries_score_DP_train', UC_queries_score_DP_train.shape)\n",
        "\n",
        "# #------------------------post-retrieval (7 metrics) Test --------------------------#\n",
        "# # 1.1) Subquery overlap using jensenShannon\n",
        "# code_queries_score_JensenShannon_test = featureExtraction.SubqueryOverlap(code_documents_test, featureExtraction.JensenShannon,\"JS\", UC_count_matrix_test, code_count_matrix_test)\n",
        "# UC_queries_score_JensenShannon_test = featureExtraction.SubqueryOverlap(UC_documents_test, featureExtraction.JensenShannon,\"JS\",code_count_matrix_test, UC_count_matrix_test)\n",
        "\n",
        "# print('code_queries_score_JensenShannon_test', code_queries_score_JensenShannon_test.shape)\n",
        "# print('UC_queries_score_JensenShannon_test', UC_queries_score_JensenShannon_test.shape)\n",
        "\n",
        "# # 1.2) Subquery overlap using VSM\n",
        "# code_queries_score_VSM_test = featureExtraction.SubqueryOverlap(code_documents_test, featureExtraction.VectorSpaceModel,\"VSM\", UC_count_matrix_test, code_count_matrix_test)\n",
        "# UC_queries_score_VSM_test = featureExtraction.SubqueryOverlap(UC_documents_test, featureExtraction.VectorSpaceModel,\"VSM\", code_count_matrix_test, UC_count_matrix_test)\n",
        "\n",
        "# print('code_queries_score_VSM_test', code_queries_score_VSM_test.shape)\n",
        "# print('UC_queries_score_VSM_test', UC_queries_score_VSM_test.shape)\n",
        "\n",
        "# #1.3) Subquery overlap using BM25\n",
        "# code_queries_score_BM25_test = featureExtraction.SubqueryOverlap(code_documents_test, featureExtraction.BM25,\"BM\", UC_documents_test,idf_uc_dict_test,UC_count_matrix_test)\n",
        "# UC_queries_score_BM25_test = featureExtraction.SubqueryOverlap(UC_documents_test, featureExtraction.BM25,\"BM\", code_documents_test,idf_code_dict_test, code_count_matrix_test)\n",
        "\n",
        "# print('code_queries_score_BM25_test', code_queries_score_BM25_test.shape)\n",
        "# print('UC_queries_score_BM25_test', UC_queries_score_BM25_test.shape)\n",
        "\n",
        "# #1.4) Subquery overlap using JM smoothing\n",
        "# code_queries_score_JM_test = featureExtraction.SubqueryOverlap(code_documents_test, featureExtraction.SmoothingMethods,\"SM\", UC_documents_test,UC_count_matrix_test,tf_uc_dict_test,True)\n",
        "# UC_queries_score_JM_test = featureExtraction.SubqueryOverlap(UC_documents_test, featureExtraction.SmoothingMethods,\"SM\", code_documents_test,code_count_matrix_test,tf_code_dict_test,True)\n",
        "\n",
        "# print('code_queries_score_JM_test', code_queries_score_JM_test.shape)\n",
        "# print('UC_queries_score_JM_test', UC_queries_score_JM_test.shape)\n",
        "\n",
        "# # 1.5) Subquery overlap using DP smoothing\n",
        "# code_queries_score_DP_test = featureExtraction.SubqueryOverlap(code_documents_test, featureExtraction.SmoothingMethods,\"SM\", UC_documents_test, UC_count_matrix_test,tf_uc_dict_test,False)\n",
        "# UC_queries_score_DP_test = featureExtraction.SubqueryOverlap(UC_documents_test, featureExtraction.SmoothingMethods,\"SM\", code_documents_test, code_count_matrix_test,tf_code_dict_test,False)\n",
        "\n",
        "# print('code_queries_score_DP_test', code_queries_score_DP_test.shape)\n",
        "# print('UC_queries_score_DP_test', UC_queries_score_DP_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#--------------------------------Robustness Score Train-------------------------------------------------------#\n",
        "\n",
        "# 2.1) Robustness Score using jensenShannon\n",
        "UC_RS_JS_train, UC_FRC_JS_train = featureExtraction.RobustnessScore(UC_documents_train,code_documents_train,\"JS\")\n",
        "code_RS_JS_train, code_FRC_JS_train = featureExtraction.RobustnessScore(code_documents_train,UC_documents_train,\"JS\")\n",
        "\n",
        "print('UC_RS_JS_train', UC_RS_JS_train.shape)\n",
        "print('code_RS_JS_train', code_RS_JS_train.shape)\n",
        "\n",
        "print('UC_FRC_JS_train', UC_FRC_JS_train.shape)\n",
        "print('code_FRC_JS_train', code_FRC_JS_train.shape)\n",
        "\n",
        "np.save('./pickles/UC_RS_JS_train.npy', UC_RS_JS_train)\n",
        "np.save('./pickles/code_RS_JS_train.npy', code_RS_JS_train)\n",
        "\n",
        "np.save('./pickles/UC_FRC_JS_train.npy', UC_FRC_JS_train)\n",
        "np.save('./pickles/code_FRC_JS_train.npy', code_FRC_JS_train)\n",
        "\n",
        "# 2.2) Robustness Score using VSM\n",
        "UC_RS_VSM_train, UC_FRC_VSM_train = featureExtraction.RobustnessScore(UC_documents_train,code_documents_train,\"VSM\")\n",
        "code_RS_VSM_train, code_FRC_VSM_train = featureExtraction.RobustnessScore(code_documents_train,UC_documents_train,\"VSM\")\n",
        "\n",
        "print('UC_RS_VSM_train', UC_RS_VSM_train.shape)\n",
        "print('code_RS_VSM_train', code_RS_VSM_train.shape)\n",
        "\n",
        "print('UC_FRC_VSM_train', UC_FRC_VSM_train.shape)\n",
        "print('code_FRC_VSM_train', code_FRC_VSM_train.shape)\n",
        "\n",
        "np.save('./pickles/UC_RS_VSM_train.npy', UC_RS_VSM_train)\n",
        "np.save('./pickles/code_RS_VSM_train.npy', code_RS_VSM_train)\n",
        "\n",
        "np.save('./pickles/UC_FRC_VSM_train.npy', UC_FRC_VSM_train)\n",
        "np.save('./pickles/code_FRC_VSM_train.npy', code_FRC_VSM_train)\n",
        "\n",
        "# 2.3) Robustness Score using BM25\n",
        "UC_RS_BM25_train, UC_FRC_BM25_train = featureExtraction.RobustnessScore(UC_documents_train,code_documents_train,\"BM\")\n",
        "code_RS_BM25_train, code_FRC_BM25_train = featureExtraction.RobustnessScore(code_documents_train,UC_documents_train,\"BM\")\n",
        "\n",
        "print('UC_RS_BM25_train', UC_RS_BM25_train.shape)\n",
        "print('code_RS_BM25_train', code_RS_BM25_train.shape)\n",
        "\n",
        "print('UC_FRC_BM25_train', UC_FRC_BM25_train.shape)\n",
        "print('code_FRC_BM25_train', code_FRC_BM25_train.shape)\n",
        "\n",
        "np.save('./pickles/UC_RS_BM25_train.npy', UC_RS_BM25_train)\n",
        "np.save('./pickles/code_RS_BM25_train.npy', code_RS_BM25_train)\n",
        "\n",
        "np.save('./pickles/UC_FRC_BM25_train.npy', UC_FRC_BM25_train)\n",
        "np.save('./pickles/code_FRC_BM25_train.npy', code_FRC_BM25_train)\n",
        "\n",
        "# 2.4) Robustness Score using JM smoothing\n",
        "UC_RS_JM_train, UC_FRC_JM_train = featureExtraction.RobustnessScore(UC_documents_train,code_documents_train,\"JM\")\n",
        "code_RS_JM_train, code_FRC_JM_train = featureExtraction.RobustnessScore(code_documents_train,UC_documents_train,\"JM\")\n",
        "\n",
        "print('UC_RS_JM_train', UC_RS_JM_train.shape)\n",
        "print('code_RS_JM_train', code_RS_JM_train.shape)\n",
        "\n",
        "print('UC_FRC_JM_train', UC_FRC_JM_train.shape)\n",
        "print('code_FRC_JM_train', code_FRC_JM_train.shape)\n",
        "\n",
        "np.save('./pickles/UC_RS_JM_train.npy', UC_RS_JM_train)\n",
        "np.save('./pickles/code_RS_JM_train.npy', code_RS_JM_train)\n",
        "\n",
        "np.save('./pickles/UC_FRC_JM_train.npy', UC_FRC_JM_train)\n",
        "np.save('./pickles/code_FRC_JM_train.npy', code_FRC_JM_train)\n",
        "\n",
        "# 2.5) Robustness Score using DP smoothing\n",
        "UC_RS_DP_train, UC_FRC_DP_train = featureExtraction.RobustnessScore(UC_documents_train,code_documents_train,\"DP\")\n",
        "code_RS_DP_train, code_FRC_DP_train = featureExtraction.RobustnessScore(code_documents_train,UC_documents_train,\"DP\")\n",
        "\n",
        "print('UC_RS_DP_train', UC_RS_DP_train.shape)\n",
        "print('code_RS_DP_train', code_RS_DP_train.shape)\n",
        "\n",
        "print('UC_FRC_DP_train', UC_FRC_DP_train.shape)\n",
        "print('code_FRC_DP_train', code_FRC_DP_train.shape)\n",
        "\n",
        "np.save('./pickles/UC_RS_DP_train.npy', UC_RS_DP_train)\n",
        "np.save('./pickles/code_RS_DP_train.npy', code_RS_DP_train)\n",
        "\n",
        "np.save('./pickles/UC_FRC_DP_train.npy', UC_FRC_DP_train)\n",
        "np.save('./pickles/code_FRC_DP_train.npy', code_FRC_DP_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "UC_RS_JS_train = np.load('./pickles/UC_RS_JS_train.npy')\n",
        "UC_RS_JS_train = normalizer.fit_transform(UC_RS_JS_train.reshape(-1, 1))\n",
        "\n",
        "code_RS_JS_train = np.load('./pickles/code_RS_JS_train.npy')\n",
        "code_RS_JS_train = normalizer.fit_transform(code_RS_JS_train.reshape(-1, 1))\n",
        "\n",
        "UC_FRC_JS_train = np.load('./pickles/UC_FRC_JS_train.npy')\n",
        "UC_FRC_JS_train = normalizer.fit_transform(UC_FRC_JS_train.reshape(-1, 1))\n",
        "\n",
        "code_FRC_JS_train = np.load('./pickles/code_FRC_JS_train.npy')\n",
        "code_FRC_JS_train = normalizer.fit_transform(code_FRC_JS_train.reshape(-1, 1))\n",
        "\n",
        "UC_RS_VSM_train = np.load('./pickles/UC_RS_VSM_train.npy')\n",
        "UC_RS_VSM_train = normalizer.fit_transform(UC_RS_VSM_train.reshape(-1, 1))\n",
        "\n",
        "code_RS_VSM_train = np.load('./pickles/code_RS_VSM_train.npy')\n",
        "code_RS_VSM_train = normalizer.fit_transform(code_RS_VSM_train.reshape(-1, 1))\n",
        "\n",
        "UC_FRC_VSM_train = np.load('./pickles/UC_FRC_VSM_train.npy')\n",
        "UC_FRC_VSM_train = normalizer.fit_transform(UC_FRC_VSM_train.reshape(-1, 1))\n",
        "\n",
        "code_FRC_VSM_train = np.load('./pickles/code_FRC_VSM_train.npy')\n",
        "code_FRC_VSM_train = normalizer.fit_transform(code_FRC_VSM_train.reshape(-1, 1))\n",
        "\n",
        "UC_RS_BM25_train = np.load('./pickles/UC_RS_BM25_train.npy')\n",
        "UC_RS_BM25_train = normalizer.fit_transform(UC_RS_BM25_train.reshape(-1, 1))\n",
        "\n",
        "code_RS_BM25_train = np.load('./pickles/code_RS_BM25_train.npy')\n",
        "code_RS_BM25_train = normalizer.fit_transform(code_RS_BM25_train.reshape(-1, 1))\n",
        "\n",
        "UC_FRC_BM25_train = np.load('./pickles/UC_FRC_BM25_train.npy')\n",
        "UC_FRC_BM25_train = normalizer.fit_transform(UC_FRC_BM25_train.reshape(-1, 1))\n",
        "\n",
        "code_FRC_BM25_train = np.load('./pickles/code_FRC_BM25_train.npy')\n",
        "code_FRC_BM25_train = normalizer.fit_transform(code_FRC_BM25_train.reshape(-1, 1))\n",
        "\n",
        "UC_RS_JM_train = np.load('./pickles/UC_RS_JM_train.npy')\n",
        "UC_RS_JM_train = normalizer.fit_transform(UC_RS_JM_train.reshape(-1, 1))\n",
        "\n",
        "code_RS_JM_train = np.load('./pickles/code_RS_JM_train.npy')\n",
        "code_RS_JM_train = normalizer.fit_transform(code_RS_JM_train.reshape(-1, 1))\n",
        "\n",
        "UC_FRC_JM_train = np.load('./pickles/UC_FRC_JM_train.npy')\n",
        "UC_FRC_JM_train = normalizer.fit_transform(UC_FRC_JM_train.reshape(-1, 1))\n",
        "\n",
        "code_FRC_JM_train = np.load('./pickles/code_FRC_JM_train.npy')\n",
        "code_FRC_JM_train = normalizer.fit_transform(code_FRC_JM_train.reshape(-1, 1))\n",
        "\n",
        "UC_RS_DP_train = np.load('./pickles/UC_RS_DP_train.npy')\n",
        "UC_RS_DP_train = normalizer.fit_transform(UC_RS_DP_train.reshape(-1, 1))\n",
        "\n",
        "code_RS_DP_train = np.load('./pickles/code_RS_DP_train.npy')\n",
        "code_RS_DP_train = normalizer.fit_transform(code_RS_DP_train.reshape(-1, 1))\n",
        "\n",
        "UC_FRC_DP_train = np.load('./pickles/UC_FRC_DP_train.npy')\n",
        "UC_FRC_DP_train = normalizer.fit_transform(UC_FRC_DP_train.reshape(-1, 1))\n",
        "\n",
        "code_FRC_DP_train = np.load('./pickles/code_FRC_DP_train.npy')\n",
        "code_FRC_DP_train = normalizer.fit_transform(code_FRC_DP_train.reshape(-1, 1))\n",
        "\n",
        "print(UC_FRC_DP_train,UC_FRC_JM_train,UC_FRC_BM25_train,UC_FRC_JS_train,UC_FRC_VSM_train) # ALERT : el hgat dy bytgeb zeros w ones\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#--------------------------------------------------Robustness Score test------------------------------------------------------------#\n",
        "\n",
        "# 2.1) Robustness Score using jensenShannon\n",
        "UC_RS_JS_test, UC_FRC_JS_test = featureExtraction.RobustnessScore(UC_documents_test,code_documents_test,\"JS\")\n",
        "code_RS_JS_test, code_FRC_JS_test = featureExtraction.RobustnessScore(code_documents_test,UC_documents_test,\"JS\")\n",
        "\n",
        "print('UC_RS_JS_test', UC_RS_JS_test.shape)\n",
        "print('code_RS_JS_test', code_RS_JS_test.shape)\n",
        "\n",
        "print('UC_FRC_JS_test', UC_FRC_JS_test.shape)\n",
        "print('code_FRC_JS_test', code_FRC_JS_test.shape)\n",
        "\n",
        "np.save('./pickles/UC_RS_JS_test.npy', UC_RS_JS_test)\n",
        "np.save('./pickles/code_RS_JS_test.npy', code_RS_JS_test)\n",
        "\n",
        "np.save('./pickles/UC_FRC_JS_test.npy', UC_FRC_JS_test)\n",
        "np.save('./pickles/code_FRC_JS_test.npy', code_FRC_JS_test)\n",
        "\n",
        "# 2.2) Robustness Score using VSM\n",
        "UC_RS_VSM_test, UC_FRC_VSM_test = featureExtraction.RobustnessScore(UC_documents_test,code_documents_test,\"VSM\")\n",
        "code_RS_VSM_test, code_FRC_VSM_test = featureExtraction.RobustnessScore(code_documents_test,UC_documents_test,\"VSM\")\n",
        "\n",
        "print('UC_RS_VSM_test', UC_RS_VSM_test.shape)\n",
        "print('code_RS_VSM_test', code_RS_VSM_test.shape)\n",
        "\n",
        "print('UC_FRC_VSM_test', UC_FRC_VSM_test.shape)\n",
        "print('code_FRC_VSM_test', code_FRC_VSM_test.shape)\n",
        "\n",
        "np.save('./pickles/UC_RS_VSM_test.npy', UC_RS_VSM_test)\n",
        "np.save('./pickles/code_RS_VSM_test.npy', code_RS_VSM_test)\n",
        "\n",
        "np.save('./pickles/UC_FRC_VSM_test.npy', UC_FRC_VSM_test)\n",
        "np.save('./pickles/code_FRC_VSM_test.npy', code_FRC_VSM_test)\n",
        "\n",
        "# 2.3) Robustness Score using BM25\n",
        "UC_RS_BM25_test, UC_FRC_BM25_test = featureExtraction.RobustnessScore(UC_documents_test,code_documents_test,\"BM\")\n",
        "code_RS_BM25_test, code_FRC_BM25_test = featureExtraction.RobustnessScore(code_documents_test,UC_documents_test,\"BM\")\n",
        "\n",
        "print('UC_RS_BM25_test', UC_RS_BM25_test.shape)\n",
        "print('code_RS_BM25_test', code_RS_BM25_test.shape)\n",
        "\n",
        "print('UC_FRC_BM25_test', UC_FRC_BM25_test.shape)\n",
        "print('code_FRC_BM25_test', code_FRC_BM25_test.shape)\n",
        "\n",
        "np.save('./pickles/UC_RS_BM25_test.npy', UC_RS_BM25_test)\n",
        "np.save('./pickles/code_RS_BM25_test.npy', code_RS_BM25_test)\n",
        "\n",
        "np.save('./pickles/UC_FRC_BM25_test.npy', UC_FRC_BM25_test)\n",
        "np.save('./pickles/code_FRC_BM25_test.npy', code_FRC_BM25_test)\n",
        "\n",
        "# 2.4) Robustness Score using JM smoothing\n",
        "UC_RS_JM_test, UC_FRC_JM_test = featureExtraction.RobustnessScore(UC_documents_test,code_documents_test,\"JM\")\n",
        "code_RS_JM_test, code_FRC_JM_test = featureExtraction.RobustnessScore(code_documents_test,UC_documents_test,\"JM\")\n",
        "\n",
        "print('UC_RS_JM_test', UC_RS_JM_test.shape)\n",
        "print('code_RS_JM_test', code_RS_JM_test.shape)\n",
        "\n",
        "print('UC_FRC_JM_test', UC_FRC_JM_test.shape)\n",
        "print('code_FRC_JM_test', code_FRC_JM_test.shape)\n",
        "\n",
        "np.save('./pickles/UC_RS_JM_test.npy', UC_RS_JM_test)\n",
        "np.save('./pickles/code_RS_JM_test.npy', code_RS_JM_test)\n",
        "\n",
        "np.save('./pickles/UC_FRC_JM_test.npy', UC_FRC_JM_test)\n",
        "np.save('./pickles/code_FRC_JM_test.npy', code_FRC_JM_test)\n",
        "\n",
        "# 2.5) Robustness Score using DP smoothing\n",
        "UC_RS_DP_test, UC_FRC_DP_test = featureExtraction.RobustnessScore(UC_documents_test,code_documents_test,\"DP\")\n",
        "code_RS_DP_test, code_FRC_DP_test = featureExtraction.RobustnessScore(code_documents_test,UC_documents_test,\"DP\")\n",
        "\n",
        "print('UC_RS_DP_test', UC_RS_DP_test.shape)\n",
        "print('code_RS_DP_test', code_RS_DP_test.shape)\n",
        "\n",
        "print('UC_FRC_DP_test', UC_FRC_DP_test.shape)\n",
        "print('code_FRC_DP_test', code_FRC_DP_test.shape)\n",
        "\n",
        "np.save('./pickles/UC_RS_DP_test.npy', UC_RS_DP_test)\n",
        "np.save('./pickles/code_RS_DP_test.npy', code_RS_DP_test)\n",
        "\n",
        "np.save('./pickles/UC_FRC_DP_test.npy', UC_FRC_DP_test)\n",
        "np.save('./pickles/code_FRC_DP_test.npy', code_FRC_DP_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#ALERT :FRC BYTL3 1 AND ZEROS M3RFSH LW DY HAGA SAH\n",
        "UC_RS_JS_test = np.load('./pickles/UC_RS_JS_test.npy')\n",
        "UC_RS_JS_test = normalizer.fit_transform(UC_RS_JS_test.reshape(-1, 1))\n",
        "\n",
        "code_RS_JS_test = np.load('./pickles/code_RS_JS_test.npy')\n",
        "code_RS_JS_test = normalizer.fit_transform(code_RS_JS_test.reshape(-1, 1))\n",
        "\n",
        "UC_FRC_JS_test = np.load('./pickles/UC_FRC_JS_test.npy')  #ALERT: bytl3 1 and zeros mfesh decimals\n",
        "UC_FRC_JS_test = normalizer.fit_transform(UC_FRC_JS_test.reshape(-1, 1))\n",
        "\n",
        "code_FRC_JS_test = np.load('./pickles/code_FRC_JS_test.npy')\n",
        "code_FRC_JS_test = normalizer.fit_transform(code_FRC_JS_test.reshape(-1, 1))\n",
        "\n",
        "UC_RS_VSM_test = np.load('./pickles/UC_RS_VSM_test.npy')\n",
        "UC_RS_VSM_test = normalizer.fit_transform(UC_RS_VSM_test.reshape(-1, 1))\n",
        "\n",
        "code_RS_VSM_test = np.load('./pickles/code_RS_VSM_test.npy')\n",
        "code_RS_VSM_test = normalizer.fit_transform(code_RS_VSM_test.reshape(-1, 1))\n",
        "\n",
        "UC_FRC_VSM_test = np.load('./pickles/UC_FRC_VSM_test.npy')\n",
        "UC_FRC_VSM_test = normalizer.fit_transform(UC_FRC_VSM_test.reshape(-1, 1))\n",
        "\n",
        "code_FRC_VSM_test = np.load('./pickles/code_FRC_VSM_test.npy')\n",
        "code_FRC_VSM_test= normalizer.fit_transform(code_FRC_VSM_test.reshape(-1, 1))\n",
        "\n",
        "UC_RS_BM25_test = np.load('./pickles/UC_RS_BM25_test.npy')\n",
        "UC_RS_BM25_test = normalizer.fit_transform(UC_RS_BM25_test.reshape(-1, 1))\n",
        "\n",
        "code_RS_BM25_test = np.load('./pickles/code_RS_BM25_test.npy')\n",
        "code_RS_BM25_test = normalizer.fit_transform(code_RS_BM25_test.reshape(-1, 1))\n",
        "\n",
        "UC_FRC_BM25_test = np.load('./pickles/UC_FRC_BM25_test.npy')\n",
        "UC_FRC_BM25_test = normalizer.fit_transform(UC_FRC_BM25_test.reshape(-1, 1))\n",
        "\n",
        "code_FRC_BM25_test = np.load('./pickles/code_FRC_BM25_test.npy')\n",
        "code_FRC_BM25_test = normalizer.fit_transform(code_FRC_BM25_test.reshape(-1, 1))\n",
        "\n",
        "UC_RS_JM_test = np.load('./pickles/UC_RS_JM_test.npy')\n",
        "UC_RS_JM_test = normalizer.fit_transform(UC_RS_JM_test.reshape(-1, 1))\n",
        "\n",
        "code_RS_JM_test = np.load('./pickles/code_RS_JM_test.npy')\n",
        "code_RS_JM_test = normalizer.fit_transform(code_RS_JM_test.reshape(-1, 1))\n",
        "\n",
        "UC_FRC_JM_test = np.load('./pickles/UC_FRC_JM_test.npy')\n",
        "UC_FRC_JM_test = normalizer.fit_transform(UC_FRC_JM_test.reshape(-1, 1))\n",
        "\n",
        "code_FRC_JM_test = np.load('./pickles/code_FRC_JM_test.npy')\n",
        "code_FRC_JM_test = normalizer.fit_transform(code_FRC_JM_test.reshape(-1, 1))\n",
        "\n",
        "UC_RS_DP_test = np.load('./pickles/UC_RS_DP_test.npy')\n",
        "UC_RS_DP_test = normalizer.fit_transform(UC_RS_DP_test.reshape(-1, 1))\n",
        "\n",
        "code_RS_DP_test = np.load('./pickles/code_RS_DP_test.npy')\n",
        "code_RS_DP_test = normalizer.fit_transform(code_RS_DP_test.reshape(-1, 1))\n",
        "\n",
        "UC_FRC_DP_test = np.load('./pickles/UC_FRC_DP_test.npy')\n",
        "UC_FRC_DP_test = normalizer.fit_transform(UC_FRC_DP_test.reshape(-1, 1))\n",
        "\n",
        "code_FRC_DP_test = np.load('./pickles/code_FRC_DP_test.npy')\n",
        "code_FRC_DP_test = normalizer.fit_transform(code_FRC_DP_test.reshape(-1, 1))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#------------------------------------------------- ClusteringTendency Train---------------------------------------------\n",
        "# 4.1) Clustering Tendency using JensenShannon\n",
        "UC_CT_JensenShannon_train = featureExtraction.ClusteringTendency(JS_UC_train.T,tfidf_matrix_uc_train,tfidf_matrix_code_train)\n",
        "code_CT_JensenShannon_train = featureExtraction.ClusteringTendency(JS_CC_train,tfidf_matrix_code_train,tfidf_matrix_uc_train)\n",
        "\n",
        "print(\"UC_CT_JensenShannon_train\",UC_CT_JensenShannon_train.shape)\n",
        "print(\"code_CT_JensenShannon_train\",code_CT_JensenShannon_train.shape)\n",
        "\n",
        "np.save('./pickles/UC_CT_JensenShannon_train.npy',UC_CT_JensenShannon_train)\n",
        "np.save('./pickles/code_CT_JensenShannon_train.npy',code_CT_JensenShannon_train)\n",
        "\n",
        "# 4.2) Clustering Tendency using VSM\n",
        "UC_CT_VSM_train = featureExtraction.ClusteringTendency(cosine_similarity_UC_train.T,tfidf_matrix_uc_train,tfidf_matrix_code_train)\n",
        "code_CT_VSM_train = featureExtraction.ClusteringTendency(cosine_similarity_CC_train,tfidf_matrix_code_train,tfidf_matrix_uc_train)\n",
        "\n",
        "print(\"UC_CT_VSM_train\",UC_CT_VSM_train.shape)\n",
        "print(\"code_CT_VSM_train\",code_CT_VSM_train.shape)\n",
        "\n",
        "np.save('./pickles/UC_CT_VSM_train.npy',UC_CT_VSM_train)\n",
        "np.save('./pickles/code_CT_VSM_train.npy',code_CT_VSM_train)\n",
        "\n",
        "# 4.3) Clustering Tendency using BM25\n",
        "UC_CT_BM25_train = featureExtraction.ClusteringTendency(BM25_UC_train,tfidf_matrix_uc_train,tfidf_matrix_code_train)\n",
        "code_CT_BM25_train = featureExtraction.ClusteringTendency(BM25_CC_train,tfidf_matrix_code_train,tfidf_matrix_uc_train)\n",
        "\n",
        "print(\"UC_CT_BM25_train\",UC_CT_BM25_train.shape)\n",
        "print(\"code_CT_BM25_train\",code_CT_BM25_train.shape)\n",
        "\n",
        "np.save('./pickles/UC_CT_BM25_train.npy',UC_CT_BM25_train)\n",
        "np.save('./pickles/code_CT_BM25_train.npy',code_CT_BM25_train)\n",
        "\n",
        "# 4.4) Clustering Tendency using JM\n",
        "UC_CT_JM_train = featureExtraction.ClusteringTendency(JM_UC_train,tfidf_matrix_uc_train,tfidf_matrix_code_train)\n",
        "code_CT_JM_train = featureExtraction.ClusteringTendency(JM_CC_train,tfidf_matrix_code_train,tfidf_matrix_uc_train)\n",
        "\n",
        "print(\"UC_CT_JM_train\",UC_CT_JM_train.shape)\n",
        "print(\"code_CT_JM_train\",code_CT_JM_train.shape)\n",
        "\n",
        "\n",
        "np.save('./pickles/UC_CT_JM_train.npy',UC_CT_JM_train)\n",
        "np.save('./pickles/code_CT_JM_train.npy',code_CT_JM_train) \n",
        "\n",
        "# 4.5) Clustering Tendency using DP\n",
        "UC_CT_DP_train = featureExtraction.ClusteringTendency(DP_UC_train,tfidf_matrix_uc_train,tfidf_matrix_code_train)\n",
        "code_CT_DP_train = featureExtraction.ClusteringTendency(DP_CC_train,tfidf_matrix_code_train,tfidf_matrix_uc_train)\n",
        "\n",
        "print(\"UC_CT_DP_train\",UC_CT_DP_train.shape)\n",
        "print(\"code_CT_DP_train\",code_CT_DP_train.shape)\n",
        "\n",
        "np.save('./pickles/UC_CT_DP_train.npy',UC_CT_DP_train)\n",
        "np.save('./pickles/code_CT_DP_train.npy',code_CT_DP_train) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#----------------------------------ClusteringTendency test-------------------------------------------------\n",
        "# 4.1) Clustering Tendency using JensenShannon\n",
        "UC_CT_JensenShannon_test = featureExtraction.ClusteringTendency(JS_UC_test.T,tfidf_matrix_uc_test,tfidf_matrix_code_test)\n",
        "code_CT_JensenShannon_test = featureExtraction.ClusteringTendency(JS_CC_test,tfidf_matrix_code_test,tfidf_matrix_uc_test)\n",
        "\n",
        "print(\"UC_CT_JensenShannon_test\",UC_CT_JensenShannon_test.shape)\n",
        "print(\"code_CT_JensenShannon_test\",code_CT_JensenShannon_test.shape)\n",
        "\n",
        "np.save('./pickles/UC_CT_JensenShannon_test.npy',UC_CT_JensenShannon_test)\n",
        "np.save('./pickles/code_CT_JensenShannon_test.npy',code_CT_JensenShannon_test) \n",
        "\n",
        "# 4.2) Clustering Tendency using VSM\n",
        "UC_CT_VSM_test = featureExtraction.ClusteringTendency(cosine_similarity_UC_test.T,tfidf_matrix_uc_test,tfidf_matrix_code_test)\n",
        "code_CT_VSM_test = featureExtraction.ClusteringTendency(cosine_similarity_CC_test,tfidf_matrix_code_test,tfidf_matrix_uc_test)\n",
        "\n",
        "print(\"UC_CT_VSM_test\",UC_CT_VSM_test.shape)\n",
        "print(\"code_CT_VSM_test\",code_CT_VSM_test.shape)\n",
        "\n",
        "np.save('./pickles/UC_CT_VSM_test.npy',UC_CT_VSM_test)\n",
        "np.save('./pickles/code_CT_VSM_test.npy',code_CT_VSM_test)\n",
        "\n",
        "# 4.3) Clustering Tendency using BM25\n",
        "UC_CT_BM25_test = featureExtraction.ClusteringTendency(BM25_UC_test,tfidf_matrix_uc_test,tfidf_matrix_code_test)\n",
        "code_CT_BM25_test = featureExtraction.ClusteringTendency(BM25_CC_test,tfidf_matrix_code_test,tfidf_matrix_uc_test)\n",
        "\n",
        "print(\"UC_CT_BM25_test\",UC_CT_BM25_test.shape)\n",
        "print(\"code_CT_BM25_test\",code_CT_BM25_test.shape)\n",
        "\n",
        "np.save('./pickles/UC_CT_BM25_test.npy', UC_CT_BM25_test)\n",
        "np.save('./pickles/code_CT_BM25_test.npy', code_CT_BM25_test)\n",
        "\n",
        "# 4.4) Clustering Tendency using JM\n",
        "UC_CT_JM_test = featureExtraction.ClusteringTendency(JM_UC_test,tfidf_matrix_uc_test,tfidf_matrix_code_test)\n",
        "code_CT_JM_test = featureExtraction.ClusteringTendency(JM_CC_test,tfidf_matrix_code_test,tfidf_matrix_uc_test)\n",
        "\n",
        "print(\"UC_CT_JM_test\",UC_CT_JM_test.shape)\n",
        "print(\"code_CT_JM_test\",code_CT_JM_test.shape)\n",
        "\n",
        "np.save('./pickles/UC_CT_JM_test.npy', UC_CT_JM_test)\n",
        "np.save('./pickles/code_CT_JM_test.npy', code_CT_JM_test)\n",
        "\n",
        "# 4.5) Clustering Tendency using DP\n",
        "UC_CT_DP_test = featureExtraction.ClusteringTendency(DP_UC_test,tfidf_matrix_uc_test,tfidf_matrix_code_test)\n",
        "code_CT_DP_test = featureExtraction.ClusteringTendency(DP_CC_test,tfidf_matrix_code_test,tfidf_matrix_uc_test)\n",
        "\n",
        "print(\"UC_CT_DP_test\",UC_CT_DP_test.shape)\n",
        "print(\"code_CT_DP_test\",code_CT_DP_test.shape)\n",
        "\n",
        "np.save('./pickles/UC_CT_DP_test.npy', UC_CT_DP_test)\n",
        "np.save('./pickles/code_CT_DP_test.npy', code_CT_DP_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "UC_CT_JensenShannon_train = np.load('./pickles/UC_CT_JensenShannon_train.npy')\n",
        "UC_CT_JensenShannon_train = normalizer.fit_transform(UC_CT_JensenShannon_train)\n",
        "\n",
        "code_CT_JensenShannon_train = np.load('./pickles/code_CT_JensenShannon_train.npy')\n",
        "code_CT_JensenShannon_train = normalizer.fit_transform(code_CT_JensenShannon_train)\n",
        "\n",
        "UC_CT_VSM_train = np.load('./pickles/UC_CT_VSM_train.npy')\n",
        "UC_CT_VSM_train = normalizer.fit_transform(UC_CT_VSM_train)\n",
        "\n",
        "code_CT_VSM_train = np.load('./pickles/code_CT_VSM_train.npy')\n",
        "code_CT_VSM_train = normalizer.fit_transform(code_CT_VSM_train)\n",
        "\n",
        "UC_CT_BM25_train = np.load('./pickles/UC_CT_BM25_train.npy')\n",
        "UC_CT_BM25_train = normalizer.fit_transform(UC_CT_BM25_train)\n",
        "\n",
        "code_CT_BM25_train = np.load('./pickles/code_CT_BM25_train.npy')\n",
        "code_CT_BM25_train = normalizer.fit_transform(code_CT_BM25_train)\n",
        "\n",
        "UC_CT_JM_train = np.load('./pickles/UC_CT_JM_train.npy')\n",
        "UC_CT_JM_train = normalizer.fit_transform(UC_CT_JM_train)\n",
        "\n",
        "code_CT_JM_train = np.load('./pickles/code_CT_JM_train.npy')\n",
        "code_CT_JM_train = normalizer.fit_transform(code_CT_JM_train)\n",
        "\n",
        "UC_CT_DP_train = np.load('./pickles/UC_CT_DP_train.npy')\n",
        "UC_CT_DP_train = normalizer.fit_transform(UC_CT_DP_train)\n",
        "\n",
        "code_CT_DP_train = np.load('./pickles/code_CT_DP_train.npy')\n",
        "code_CT_DP_train = normalizer.fit_transform(code_CT_DP_train)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "UC_CT_JensenShannon_test = np.load('./pickles/UC_CT_JensenShannon_test.npy')\n",
        "UC_CT_JensenShannon_test = normalizer.fit_transform(UC_CT_JensenShannon_test)\n",
        "\n",
        "code_CT_JensenShannon_test = np.load('./pickles/code_CT_JensenShannon_test.npy')\n",
        "code_CT_JensenShannon_test = normalizer.fit_transform(code_CT_JensenShannon_test)\n",
        "\n",
        "UC_CT_VSM_test = np.load('./pickles/UC_CT_VSM_test.npy')\n",
        "UC_CT_VSM_test = normalizer.fit_transform(UC_CT_VSM_test)\n",
        "\n",
        "code_CT_VSM_test = np.load('./pickles/code_CT_VSM_test.npy')\n",
        "code_CT_VSM_test = normalizer.fit_transform(code_CT_VSM_test)\n",
        "\n",
        "UC_CT_BM25_test = np.load('./pickles/UC_CT_BM25_test.npy')\n",
        "UC_CT_BM25_test = normalizer.fit_transform(UC_CT_BM25_test)\n",
        "\n",
        "code_CT_BM25_test = np.load('./pickles/code_CT_BM25_test.npy')\n",
        "code_CT_BM25_test = normalizer.fit_transform(code_CT_BM25_test)\n",
        "\n",
        "UC_CT_JM_test = np.load('./pickles/UC_CT_JM_test.npy')\n",
        "UC_CT_JM_test = normalizer.fit_transform(UC_CT_JM_test)\n",
        "\n",
        "code_CT_JM_test = np.load('./pickles/code_CT_JM_test.npy')\n",
        "code_CT_JM_test = normalizer.fit_transform(code_CT_JM_test)\n",
        "\n",
        "UC_CT_DP_test = np.load('./pickles/UC_CT_DP_test.npy')\n",
        "UC_CT_DP_test = normalizer.fit_transform(UC_CT_DP_test)\n",
        "\n",
        "code_CT_DP_test = np.load('./pickles/code_CT_DP_test.npy')\n",
        "code_CT_DP_test = normalizer.fit_transform(code_CT_DP_test)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "#------------------------------Spatial AutoCorrelation  Train-------------------------------------------#\n",
        "# 5.1) Spatial AutoCorrelation using JensenShannon\n",
        "UC_SAC_JS_train = featureExtraction.SpatialAutoCorrelation(JS_UC_train.T,tfidf_matrix_code_train)\n",
        "code_SAC_JS_train = featureExtraction.SpatialAutoCorrelation(JS_CC_train,tfidf_matrix_uc_train)\n",
        "\n",
        "print(\"UC_SAC_JS_train\",UC_SAC_JS_train.shape)\n",
        "print(\"code_SAC_JS_train\",code_SAC_JS_train.shape)\n",
        "\n",
        "np.save('./pickles/UC_SAC_JensenShannon_train.npy',UC_SAC_JS_train)\n",
        "np.save('./pickles/code_SAC_JensenShannon_train.npy',code_SAC_JS_train)\n",
        "\n",
        "# 5.2) Spatial AutoCorrelation using VSM\n",
        "UC_SAC_VSM_train = featureExtraction.SpatialAutoCorrelation(cosine_similarity_UC_train.T,tfidf_matrix_code_train)\n",
        "code_SAC_VSM_train= featureExtraction.SpatialAutoCorrelation(cosine_similarity_CC_train,tfidf_matrix_uc_train)\n",
        "\n",
        "print(\"UC_SAC_VSM_train\",UC_SAC_VSM_train.shape)\n",
        "print(\"code_SAC_VSM_train\",code_SAC_VSM_train.shape)\n",
        "\n",
        "np.save('./pickles/UC_SAC_VSM_train.npy',UC_SAC_VSM_train)\n",
        "np.save('./pickles/code_SAC_VSM_train.npy',code_SAC_VSM_train)\n",
        "# 5.3) Spatial AutoCorrelation using BM25\n",
        "UC_SAC_BM25_train = featureExtraction.SpatialAutoCorrelation(BM25_UC_train,tfidf_matrix_code_train)\n",
        "code_SAC_BM25_train = featureExtraction.SpatialAutoCorrelation(BM25_CC_train,tfidf_matrix_uc_train)\n",
        "\n",
        "print(\"UC_SAC_BM25_train\",UC_SAC_BM25_train.shape)\n",
        "print(\"code_SAC_BM25_train\",code_SAC_BM25_train.shape)\n",
        "\n",
        "np.save('./pickles/UC_SAC_BM25_train.npy',UC_SAC_BM25_train)\n",
        "np.save('./pickles/code_SAC_BM25_train.npy',code_SAC_BM25_train)\n",
        "\n",
        "# 5.4) Spatial AutoCorrelation using JM\n",
        "UC_SAC_JM_train = featureExtraction.SpatialAutoCorrelation(JM_UC_train,tfidf_matrix_code_train)\n",
        "code_SAC_JM_train= featureExtraction.SpatialAutoCorrelation(JM_CC_train,tfidf_matrix_uc_train)\n",
        "\n",
        "print(\"UC_SAC_JM_train\",UC_SAC_JM_train.shape)\n",
        "print(\"code_SAC_JM_train\",code_SAC_JM_train.shape)\n",
        "\n",
        "np.save('./pickles/UC_SAC_JM_train.npy',UC_SAC_JM_train)\n",
        "np.save('./pickles/code_SAC_JM_train.npy',code_SAC_JM_train)\n",
        "# 5.5) Spatial AutoCorrelation using DP\n",
        "UC_SAC_DP_train = featureExtraction.SpatialAutoCorrelation(DP_UC_train,tfidf_matrix_code_train)\n",
        "code_SAC_DP_train= featureExtraction.SpatialAutoCorrelation(DP_CC_train,tfidf_matrix_uc_train)\n",
        "\n",
        "print(\"UC_SAC_DP_train\",UC_SAC_DP_train.shape)\n",
        "print(\"code_SAC_DP_train\",code_SAC_DP_train.shape)\n",
        "\n",
        "np.save('./pickles/UC_SAC_DP_train.npy',UC_SAC_DP_train)\n",
        "np.save('./pickles/code_SAC_DP_train.npy',code_SAC_DP_train)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#------------------------------ Spatial AutoCorrelation  Test-------------------------------------------#\n",
        "# 5.1) Spatial AutoCorrelation using JensenShannon\n",
        "UC_SAC_JS_test = featureExtraction.SpatialAutoCorrelation(JS_UC_test.T,tfidf_matrix_code_test)\n",
        "code_SAC_JS_test = featureExtraction.SpatialAutoCorrelation(JS_CC_test,tfidf_matrix_uc_test)\n",
        "\n",
        "print(\"UC_SAC_JS_test\",UC_SAC_JS_test.shape)\n",
        "print(\"code_SAC_JS_test\",code_SAC_JS_test.shape)\n",
        "\n",
        "np.save('./pickles/UC_SAC_JensenShannon_test.npy',UC_SAC_JS_test)\n",
        "np.save('./pickles/code_SAC_JensenShannon_test.npy',code_SAC_JS_test)\n",
        "# 5.2) Spatial AutoCorrelation using VSM\n",
        "UC_SAC_VSM_test = featureExtraction.SpatialAutoCorrelation(cosine_similarity_UC_test.T,tfidf_matrix_code_test)\n",
        "code_SAC_VSM_test= featureExtraction.SpatialAutoCorrelation(cosine_similarity_CC_test,tfidf_matrix_uc_test)\n",
        "\n",
        "print(\"UC_SAC_VSM_test\",UC_SAC_VSM_test.shape)\n",
        "print(\"code_SAC_VSM_test\",code_SAC_VSM_test.shape)\n",
        "\n",
        "np.save('./pickles/UC_SAC_VSM_test.npy',UC_SAC_VSM_test)\n",
        "np.save('./pickles/code_SAC_VSM_test.npy',code_SAC_VSM_test)\n",
        "\n",
        "# 5.3) Spatial AutoCorrelation using BM25\n",
        "UC_SAC_BM25_test = featureExtraction.SpatialAutoCorrelation(BM25_UC_test,tfidf_matrix_code_test)\n",
        "code_SAC_BM25_test = featureExtraction.SpatialAutoCorrelation(BM25_CC_test,tfidf_matrix_uc_test)\n",
        "\n",
        "print(\"UC_SAC_BM25_test\",UC_SAC_BM25_test.shape)\n",
        "print(\"code_SAC_BM25_test\",code_SAC_BM25_test.shape)\n",
        "\n",
        "np.save('./pickles/UC_SAC_BM25_test.npy',UC_SAC_BM25_test)\n",
        "np.save('./pickles/code_SAC_BM25_test.npy',code_SAC_BM25_test)\n",
        "\n",
        "# 5.4) Spatial AutoCorrelation using JM\n",
        "UC_SAC_JM_test = featureExtraction.SpatialAutoCorrelation(JM_UC_test,tfidf_matrix_code_test)\n",
        "code_SAC_JM_test= featureExtraction.SpatialAutoCorrelation(JM_CC_test,tfidf_matrix_uc_test)\n",
        "\n",
        "print(\"UC_SAC_JM_test\",UC_SAC_JM_test.shape)\n",
        "print(\"code_SAC_JM_test\",code_SAC_JM_test.shape)\n",
        "\n",
        "np.save('./pickles/UC_SAC_JM_test.npy',UC_SAC_JM_test)\n",
        "np.save('./pickles/code_SAC_JM_test.npy',code_SAC_JM_test)\n",
        "\n",
        "# 5.5) Spatial AutoCorrelation using DP\n",
        "UC_SAC_DP_test = featureExtraction.SpatialAutoCorrelation(DP_UC_test,tfidf_matrix_code_test)\n",
        "code_SAC_DP_test= featureExtraction.SpatialAutoCorrelation(DP_CC_test,tfidf_matrix_uc_test)\n",
        "\n",
        "print(\"UC_SAC_DP_test\",UC_SAC_DP_test.shape)\n",
        "print(\"code_SAC_DP_test\",code_SAC_DP_test.shape)\n",
        "\n",
        "np.save('./pickles/UC_SAC_DP_test.npy',UC_SAC_DP_test)\n",
        "np.save('./pickles/code_SAC_DP_test.npy',code_SAC_DP_test)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#------------------------------ Spatial AutoCorrelation Train Loading-------------------------------------------#\n",
        "\n",
        "UC_SAC_JS_train = np.load('./pickles/UC_SAC_JensenShannon_train.npy')\n",
        "UC_SAC_JS_train = normalizer.fit_transform(UC_SAC_JS_train)\n",
        "\n",
        "code_SAC_JS_train = np.load('./pickles/code_SAC_JensenShannon_train.npy')\n",
        "code_SAC_JS_train = normalizer.fit_transform(code_SAC_JS_train)\n",
        "\n",
        "UC_SAC_VSM_train = np.load('./pickles/UC_SAC_VSM_train.npy')\n",
        "UC_SAC_VSM_train = normalizer.fit_transform(UC_SAC_VSM_train)\n",
        "\n",
        "code_SAC_VSM_train = np.load('./pickles/code_SAC_VSM_train.npy')\n",
        "code_SAC_VSM_train = normalizer.fit_transform(code_SAC_VSM_train)\n",
        "\n",
        "UC_SAC_BM25_train = np.load('./pickles/UC_SAC_BM25_train.npy')\n",
        "UC_SAC_BM25_train = normalizer.fit_transform(UC_SAC_BM25_train)\n",
        "\n",
        "code_SAC_BM25_train = np.load('./pickles/code_SAC_BM25_train.npy')\n",
        "code_SAC_BM25_train = normalizer.fit_transform(code_SAC_BM25_train)\n",
        "\n",
        "UC_SAC_JM_train = np.load('./pickles/UC_SAC_JM_train.npy')\n",
        "UC_SAC_JM_train = normalizer.fit_transform(UC_SAC_JM_train)\n",
        "\n",
        "code_SAC_JM_train = np.load('./pickles/code_SAC_JM_train.npy')\n",
        "code_SAC_JM_train = normalizer.fit_transform(code_SAC_JM_train)\n",
        "\n",
        "UC_SAC_DP_train = np.load('./pickles/UC_SAC_DP_train.npy')\n",
        "UC_SAC_DP_train = normalizer.fit_transform(UC_SAC_DP_train)  #ALERT : bytl3 ones ktyera awy , ones w zero\n",
        "\n",
        "code_SAC_DP_train = np.load('./pickles/code_SAC_DP_train.npy')\n",
        "code_SAC_DP_train = normalizer.fit_transform(code_SAC_DP_train)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#------------------------------ Spatial AutoCorrelation Test Loading-------------------------------------------#\n",
        "UC_SAC_JS_test = np.load('./pickles/UC_SAC_JensenShannon_test.npy')\n",
        "UC_SAC_JS_test = normalizer.fit_transform(UC_SAC_JS_test)\n",
        "\n",
        "code_SAC_JS_test = np.load('./pickles/code_SAC_JensenShannon_test.npy')\n",
        "code_SAC_JS_test = normalizer.fit_transform(code_SAC_JS_test)\n",
        "\n",
        "UC_SAC_VSM_test = np.load('./pickles/UC_SAC_VSM_test.npy')\n",
        "UC_SAC_VSM_test = normalizer.fit_transform(UC_SAC_VSM_test)\n",
        "\n",
        "code_SAC_VSM_test = np.load('./pickles/code_SAC_VSM_test.npy')\n",
        "code_SAC_VSM_test = normalizer.fit_transform(code_SAC_VSM_test)\n",
        "\n",
        "UC_SAC_BM25_test = np.load('./pickles/UC_SAC_BM25_test.npy')\n",
        "UC_SAC_BM25_test = normalizer.fit_transform(UC_SAC_BM25_test)\n",
        "\n",
        "code_SAC_BM25_test = np.load('./pickles/code_SAC_BM25_test.npy')\n",
        "code_SAC_BM25_test = normalizer.fit_transform(code_SAC_BM25_test)\n",
        "\n",
        "UC_SAC_JM_test = np.load('./pickles/UC_SAC_JM_test.npy')\n",
        "UC_SAC_JM_test = normalizer.fit_transform(UC_SAC_JM_test)\n",
        "\n",
        "code_SAC_JM_test = np.load('./pickles/code_SAC_JM_test.npy')\n",
        "code_SAC_JM_test = normalizer.fit_transform(code_SAC_JM_test)\n",
        "\n",
        "UC_SAC_DP_test = np.load('./pickles/UC_SAC_DP_test.npy')\n",
        "UC_SAC_DP_test = normalizer.fit_transform(UC_SAC_DP_test)\n",
        "\n",
        "code_SAC_DP_test = np.load('./pickles/code_SAC_DP_test.npy')\n",
        "code_SAC_DP_test = normalizer.fit_transform(code_SAC_DP_test)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#----------------------WeightedInformationGain Train and Test-----------------#\n",
        "# 6.1) WIG using JensenShannon\n",
        "\n",
        "UC_WIG_score_JensenShannon_train = featureExtraction.WeightedInformationGain(UC_documents_train,code_documents_train,JS_UC_train.T,tf_code_dict_train,np.sum(list(tf_code_dict_train.values())))\n",
        "code_WIG_score_JensenShannon_train = featureExtraction.WeightedInformationGain(code_documents_train,UC_documents_train,JS_CC_train,tf_uc_dict_train,np.sum(list(tf_uc_dict_train.values())))\n",
        "\n",
        "np.save('./pickles/UC_WIG_score_JensenShannon_train.npy',UC_WIG_score_JensenShannon_train)\n",
        "np.save('./pickles/code_WIG_score_JensenShannon_train.npy',code_WIG_score_JensenShannon_train)\n",
        "\n",
        "UC_WIG_score_JensenShannon_test = featureExtraction.WeightedInformationGain(UC_documents_test,code_documents_test,JS_UC_test.T,tf_code_dict_test,np.sum(list(tf_code_dict_test.values())))\n",
        "code_WIG_score_JensenShannon_test = featureExtraction.WeightedInformationGain(code_documents_test,UC_documents_test,JS_CC_test,tf_uc_dict_test,np.sum(list(tf_uc_dict_test.values())))\n",
        "\n",
        "np.save('./pickles/UC_WIG_score_JensenShannon_test.npy',UC_WIG_score_JensenShannon_test)\n",
        "np.save('./pickles/code_WIG_score_JensenShannon_test.npy',code_WIG_score_JensenShannon_test)\n",
        "\n",
        "# 6.2) WIG Score using VSM\n",
        "\n",
        "UC_WIG_score_VSM_train = featureExtraction.WeightedInformationGain(UC_documents_train,code_documents_train,cosine_similarity_UC_train.T,tf_code_dict_train,np.sum(list(tf_code_dict_train.values())))\n",
        "code_WIG_score_VSM_train = featureExtraction.WeightedInformationGain(code_documents_train,UC_documents_train,cosine_similarity_CC_train,tf_uc_dict_train,np.sum(list(tf_uc_dict_train.values())))\n",
        "\n",
        "np.save('./pickles/UC_WIG_score_VSM_train.npy',UC_WIG_score_VSM_train)\n",
        "np.save('./pickles/code_WIG_score_VSM_train.npy',code_WIG_score_VSM_train)\n",
        "\n",
        "UC_WIG_score_VSM_test = featureExtraction.WeightedInformationGain(UC_documents_test,code_documents_test,cosine_similarity_UC_test.T,tf_code_dict_test,np.sum(list(tf_code_dict_test.values())))\n",
        "code_WIG_score_VSM_test = featureExtraction.WeightedInformationGain(code_documents_test,UC_documents_test,cosine_similarity_CC_test,tf_uc_dict_test,np.sum(list(tf_uc_dict_test.values())))\n",
        "\n",
        "np.save('./pickles/UC_WIG_score_VSM_test.npy',UC_WIG_score_VSM_test)\n",
        "np.save('./pickles/code_WIG_score_VSM_test.npy',code_WIG_score_VSM_test)\n",
        "\n",
        "#6.3) WIG Score using BM25\n",
        "\n",
        "UC_WIG_score_BM25_train = featureExtraction.WeightedInformationGain(UC_documents_train,code_documents_train,BM25_UC_train,tf_code_dict_train,np.sum(list(tf_code_dict_train.values())))\n",
        "code_WIG_score_BM25_train = featureExtraction.WeightedInformationGain(code_documents_train,UC_documents_train,BM25_CC_train,tf_uc_dict_train,np.sum(list(tf_uc_dict_train.values())))\n",
        "\n",
        "np.save('./pickles/UC_WIG_score_BM25_train.npy',UC_WIG_score_BM25_train)\n",
        "np.save('./pickles/code_WIG_score_BM25_train.npy',code_WIG_score_BM25_train)\n",
        "\n",
        "\n",
        "UC_WIG_score_BM25_test = featureExtraction.WeightedInformationGain(UC_documents_test,code_documents_test,BM25_UC_test,tf_code_dict_test,np.sum(list(tf_code_dict_test.values())))\n",
        "code_WIG_score_BM25_test = featureExtraction.WeightedInformationGain(code_documents_test,UC_documents_test,BM25_CC_test,tf_uc_dict_test,np.sum(list(tf_uc_dict_test.values())))\n",
        "\n",
        "np.save('./pickles/UC_WIG_score_BM25_test.npy',UC_WIG_score_BM25_test)\n",
        "np.save('./pickles/code_WIG_score_BM25_test.npy',code_WIG_score_BM25_test)\n",
        "\n",
        "#6.4) WIG Score using JM\n",
        "\n",
        "UC_WIG_score_JM_train = featureExtraction.WeightedInformationGain(UC_documents_train,code_documents_train,JM_UC_train,tf_code_dict_train,np.sum(list(tf_code_dict_train.values())))\n",
        "code_WIG_score_JM_train = featureExtraction.WeightedInformationGain(code_documents_train,UC_documents_train,JM_CC_train,tf_uc_dict_train,np.sum(list(tf_uc_dict_train.values())))\n",
        "\n",
        "np.save('./pickles/UC_WIG_score_JM_train.npy',UC_WIG_score_JM_train)\n",
        "np.save('./pickles/code_WIG_score_JM_train.npy',code_WIG_score_JM_train)\n",
        "\n",
        "UC_WIG_score_JM_test = featureExtraction.WeightedInformationGain(UC_documents_test,code_documents_test,JM_UC_test,tf_code_dict_test,np.sum(list(tf_code_dict_test.values())))\n",
        "code_WIG_score_JM_test = featureExtraction.WeightedInformationGain(code_documents_test,UC_documents_test,JM_CC_test,tf_uc_dict_test,np.sum(list(tf_uc_dict_test.values())))\n",
        "\n",
        "np.save('./pickles/UC_WIG_score_JM_test.npy',UC_WIG_score_JM_test)\n",
        "np.save('./pickles/code_WIG_score_JM_test.npy',code_WIG_score_JM_test)\n",
        "\n",
        "#6.5) WIG Score using DP\n",
        "\n",
        "UC_WIG_score_DP_train = featureExtraction.WeightedInformationGain(UC_documents_train,code_documents_train,DP_UC_train,tf_code_dict_train,np.sum(list(tf_code_dict_train.values())))\n",
        "code_WIG_score_DP_train = featureExtraction.WeightedInformationGain(code_documents_train,UC_documents_train,DP_CC_train,tf_uc_dict_train,np.sum(list(tf_uc_dict_train.values())))\n",
        "\n",
        "np.save('./pickles/UC_WIG_score_DP_train.npy',UC_WIG_score_DP_train)\n",
        "np.save('./pickles/code_WIG_score_DP_train.npy',code_WIG_score_DP_train)\n",
        "\n",
        "UC_WIG_score_DP_test = featureExtraction.WeightedInformationGain(UC_documents_test,code_documents_test,DP_UC_test,tf_code_dict_test,np.sum(list(tf_code_dict_test.values())))\n",
        "code_WIG_score_DP_test = featureExtraction.WeightedInformationGain(code_documents_test,UC_documents_test,DP_CC_test,tf_uc_dict_test,np.sum(list(tf_uc_dict_test.values())))\n",
        "\n",
        "np.save('./pickles/UC_WIG_score_DP_test.npy',UC_WIG_score_DP_test)\n",
        "np.save('./pickles/code_WIG_score_DP_test.npy',code_WIG_score_DP_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "UC_WIG_score_JensenShannon_train = np.load('./pickles/UC_WIG_score_JensenShannon_train.npy')\n",
        "UC_WIG_score_JensenShannon_train = normalizer.fit_transform(UC_WIG_score_JensenShannon_train)\n",
        "\n",
        "code_WIG_score_JensenShannon_train = np.load('./pickles/code_WIG_score_JensenShannon_train.npy') #ALERT : el majority rakam whed\n",
        "code_WIG_score_JensenShannon_train = normalizer.fit_transform(code_WIG_score_JensenShannon_train)\n",
        "\n",
        "UC_WIG_score_JensenShannon_test = np.load('./pickles/UC_WIG_score_JensenShannon_test.npy')\n",
        "UC_WIG_score_JensenShannon_test = normalizer.fit_transform(UC_WIG_score_JensenShannon_test)\n",
        "\n",
        "code_WIG_score_JensenShannon_test = np.load('./pickles/code_WIG_score_JensenShannon_test.npy') #ALERT : el majority rakam whed\n",
        "code_WIG_score_JensenShannon_test = normalizer.fit_transform(code_WIG_score_JensenShannon_test)\n",
        "\n",
        "UC_WIG_score_VSM_train = np.load('./pickles/UC_WIG_score_VSM_train.npy')\n",
        "UC_WIG_score_VSM_train = normalizer.fit_transform(UC_WIG_score_VSM_train)\n",
        "\n",
        "code_WIG_score_VSM_train = np.load('./pickles/code_WIG_score_VSM_train.npy')\n",
        "code_WIG_score_VSM_train = normalizer.fit_transform(code_WIG_score_VSM_train)  # ALERT : zeros kytyera awy\n",
        "\n",
        "UC_WIG_score_VSM_test = np.load('./pickles/UC_WIG_score_VSM_test.npy')\n",
        "UC_WIG_score_VSM_test = normalizer.fit_transform(UC_WIG_score_VSM_test)\n",
        "\n",
        "code_WIG_score_VSM_test = np.load('./pickles/code_WIG_score_VSM_test.npy')\n",
        "code_WIG_score_VSM_test = normalizer.fit_transform(code_WIG_score_VSM_test) # ALERT : zeros kytyera awy\n",
        "\n",
        "UC_WIG_score_BM25_train = np.load('./pickles/UC_WIG_score_BM25_train.npy')\n",
        "UC_WIG_score_BM25_train = normalizer.fit_transform(UC_WIG_score_BM25_train)\n",
        "\n",
        "code_WIG_score_BM25_train = np.load('./pickles/code_WIG_score_BM25_train.npy')\n",
        "code_WIG_score_BM25_train = normalizer.fit_transform(code_WIG_score_BM25_train) # ALERT : zeros kytyera awy\n",
        " \n",
        "UC_WIG_score_BM25_test = np.load('./pickles/UC_WIG_score_BM25_test.npy')\n",
        "UC_WIG_score_BM25_test = normalizer.fit_transform(UC_WIG_score_BM25_test)\n",
        "\n",
        "code_WIG_score_BM25_test = np.load('./pickles/code_WIG_score_BM25_test.npy')\n",
        "code_WIG_score_BM25_test = normalizer.fit_transform(code_WIG_score_BM25_test)#ALERT : el majority rakam whed\n",
        "\n",
        "UC_WIG_score_JM_train = np.load('./pickles/UC_WIG_score_JM_train.npy')\n",
        "UC_WIG_score_JM_train = normalizer.fit_transform(UC_WIG_score_JM_train)\n",
        "\n",
        "code_WIG_score_JM_train = np.load('./pickles/code_WIG_score_JM_train.npy')\n",
        "code_WIG_score_JM_train = normalizer.fit_transform(code_WIG_score_JM_train) # ALERT : zeros kytyera awy\n",
        "\n",
        "UC_WIG_score_JM_test = np.load('./pickles/UC_WIG_score_JM_test.npy')\n",
        "UC_WIG_score_JM_test = normalizer.fit_transform(UC_WIG_score_JM_test)\n",
        "\n",
        "code_WIG_score_JM_test = np.load('./pickles/code_WIG_score_JM_test.npy')\n",
        "code_WIG_score_JM_test = normalizer.fit_transform(code_WIG_score_JM_test) # ALERT : zeros kytyera awy\n",
        "\n",
        "UC_WIG_score_DP_train = np.load('./pickles/UC_WIG_score_DP_train.npy')\n",
        "UC_WIG_score_DP_train = normalizer.fit_transform(UC_WIG_score_DP_train)\n",
        "\n",
        "code_WIG_score_DP_train = np.load('./pickles/code_WIG_score_DP_train.npy')#ALERT : el majority rakam whed\n",
        "code_WIG_score_DP_train = normalizer.fit_transform(code_WIG_score_DP_train)\n",
        "\n",
        "UC_WIG_score_DP_test = np.load('./pickles/UC_WIG_score_DP_test.npy')\n",
        "UC_WIG_score_DP_test = normalizer.fit_transform(UC_WIG_score_DP_test)\n",
        "\n",
        "code_WIG_score_DP_test = np.load('./pickles/code_WIG_score_DP_test.npy')#ALERT : el majority rakam whed\n",
        "code_WIG_score_DP_test = normalizer.fit_transform(code_WIG_score_DP_test)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#--------------------NormalizedQueryCommitment Train and Test -----------#\n",
        "# 7.1) NQC using JensenShannon\n",
        "UC_NQC_JensenShannon_train = featureExtraction.NormalizedQueryCommitment(JS_UC_train.T)\n",
        "code_NQC_JensenShannon_train = featureExtraction.NormalizedQueryCommitment(JS_CC_train)\n",
        "\n",
        "np.save('./pickles/UC_NQC_JensenShannon_train.npy',UC_NQC_JensenShannon_train)\n",
        "np.save('./pickles/code_NQC_JensenShannon_train.npy',code_NQC_JensenShannon_train)\n",
        "\n",
        "UC_NQC_JensenShannon_test = featureExtraction.NormalizedQueryCommitment(JS_UC_test.T)\n",
        "code_NQC_JensenShannon_test = featureExtraction.NormalizedQueryCommitment(JS_CC_test)\n",
        "\n",
        "np.save('./pickles/UC_NQC_JensenShannon_test.npy',UC_NQC_JensenShannon_test)\n",
        "np.save('./pickles/code_NQC_JensenShannon_test.npy',code_NQC_JensenShannon_test)\n",
        "\n",
        "# 7.2) NQC using VSM\n",
        "UC_NQC_VSM_train = featureExtraction.NormalizedQueryCommitment(cosine_similarity_UC_train.T)\n",
        "code_NQC_VSM_train = featureExtraction.NormalizedQueryCommitment(cosine_similarity_CC_train)\n",
        "\n",
        "np.save('./pickles/UC_NQC_VSM_train.npy',UC_NQC_VSM_train)\n",
        "np.save('./pickles/code_NQC_VSM_train.npy',code_NQC_VSM_train)\n",
        "\n",
        "UC_NQC_VSM_test = featureExtraction.NormalizedQueryCommitment(cosine_similarity_UC_test.T)\n",
        "code_NQC_VSM_test = featureExtraction.NormalizedQueryCommitment(cosine_similarity_CC_test)\n",
        "\n",
        "np.save('./pickles/UC_NQC_VSM_test.npy',UC_NQC_VSM_test)\n",
        "np.save('./pickles/code_NQC_VSM_test.npy',code_NQC_VSM_test)\n",
        "\n",
        "# 7.3) NQC using BM25\n",
        "UC_NQC_BM25_train = featureExtraction.NormalizedQueryCommitment(BM25_UC_train)\n",
        "code_NQC_BM25_train = featureExtraction.NormalizedQueryCommitment(BM25_CC_train)\n",
        "\n",
        "np.save('./pickles/UC_NQC_BM25_train.npy',UC_NQC_BM25_train)\n",
        "np.save('./pickles/code_NQC_BM25_train.npy',code_NQC_BM25_train)\n",
        "\n",
        "UC_NQC_BM25_test = featureExtraction.NormalizedQueryCommitment(BM25_UC_test)\n",
        "code_NQC_BM25_test = featureExtraction.NormalizedQueryCommitment(BM25_CC_test)\n",
        "\n",
        "np.save('./pickles/UC_NQC_BM25_test.npy',UC_NQC_BM25_test)\n",
        "np.save('./pickles/code_NQC_BM25_test.npy',code_NQC_BM25_test)\n",
        "\n",
        "# 7.4) NQC using JM\n",
        "UC_NQC_JM_train = featureExtraction.NormalizedQueryCommitment(JM_UC_train)\n",
        "code_NQC_JM_train = featureExtraction.NormalizedQueryCommitment(JM_CC_train)\n",
        "\n",
        "np.save('./pickles/UC_NQC_JM_train.npy',UC_NQC_JM_train)\n",
        "np.save('./pickles/code_NQC_JM_train.npy',code_NQC_JM_train)\n",
        "\n",
        "UC_NQC_JM_test = featureExtraction.NormalizedQueryCommitment(JM_UC_test)\n",
        "code_NQC_JM_test = featureExtraction.NormalizedQueryCommitment(JM_CC_test)\n",
        "\n",
        "np.save('./pickles/UC_NQC_JM_test.npy',UC_NQC_JM_test)\n",
        "np.save('./pickles/code_NQC_JM_test.npy',code_NQC_JM_test)\n",
        "\n",
        "# 7.5) NQC using DP\n",
        "UC_NQC_DP_train = featureExtraction.NormalizedQueryCommitment(DP_UC_train)\n",
        "code_NQC_DP_train = featureExtraction.NormalizedQueryCommitment(DP_CC_train)\n",
        "\n",
        "np.save('./pickles/UC_NQC_DP_train.npy',UC_NQC_DP_train)\n",
        "np.save('./pickles/code_NQC_DP_train.npy',code_NQC_DP_train)\n",
        "\n",
        "UC_NQC_DP_test = featureExtraction.NormalizedQueryCommitment(DP_UC_test)\n",
        "code_NQC_DP_test = featureExtraction.NormalizedQueryCommitment(DP_CC_test)\n",
        "\n",
        "np.save('./pickles/UC_NQC_DP_test.npy',UC_NQC_DP_test)\n",
        "np.save('./pickles/code_NQC_DP_test.npy',code_NQC_DP_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "UC_NQC_JensenShannon_train = np.load('./pickles/UC_NQC_JensenShannon_train.npy')\n",
        "UC_NQC_JensenShannon_train = normalizer.fit_transform(UC_NQC_JensenShannon_train)\n",
        "\n",
        "code_NQC_JensenShannon_train = np.load('./pickles/code_NQC_JensenShannon_train.npy')\n",
        "code_NQC_JensenShannon_train = normalizer.fit_transform(code_NQC_JensenShannon_train)\n",
        "\n",
        "UC_NQC_JensenShannon_test = np.load('./pickles/UC_NQC_JensenShannon_test.npy')\n",
        "UC_NQC_JensenShannon_test = normalizer.fit_transform(UC_NQC_JensenShannon_test)\n",
        "\n",
        "code_NQC_JensenShannon_test = np.load('./pickles/code_NQC_JensenShannon_test.npy')\n",
        "code_NQC_JensenShannon_test = normalizer.fit_transform(code_NQC_JensenShannon_test)\n",
        "\n",
        "UC_NQC_VSM_train = np.load('./pickles/UC_NQC_VSM_train.npy')\n",
        "UC_NQC_VSM_train = normalizer.fit_transform(UC_NQC_VSM_train)\n",
        "\n",
        "code_NQC_VSM_train = np.load('./pickles/code_NQC_VSM_train.npy')\n",
        "code_NQC_VSM_train = normalizer.fit_transform(code_NQC_VSM_train)\n",
        "\n",
        "UC_NQC_VSM_test = np.load('./pickles/UC_NQC_VSM_test.npy')\n",
        "UC_NQC_VSM_test = normalizer.fit_transform(UC_NQC_VSM_test)\n",
        "\n",
        "code_NQC_VSM_test = np.load('./pickles/code_NQC_VSM_test.npy')\n",
        "code_NQC_VSM_test = normalizer.fit_transform(code_NQC_VSM_test)\n",
        "\n",
        "UC_NQC_BM25_train = np.load('./pickles/UC_NQC_BM25_train.npy')\n",
        "UC_NQC_BM25_train = normalizer.fit_transform(UC_NQC_BM25_train)\n",
        "\n",
        "code_NQC_BM25_train = np.load('./pickles/code_NQC_BM25_train.npy')\n",
        "code_NQC_BM25_train = normalizer.fit_transform(code_NQC_BM25_train)\n",
        "\n",
        "UC_NQC_BM25_test = np.load('./pickles/UC_NQC_BM25_test.npy')\n",
        "UC_NQC_BM25_test = normalizer.fit_transform(UC_NQC_BM25_test)\n",
        "\n",
        "code_NQC_BM25_test = np.load('./pickles/code_NQC_BM25_test.npy')\n",
        "code_NQC_BM25_test = normalizer.fit_transform(code_NQC_BM25_test)\n",
        "\n",
        "UC_NQC_JM_train = np.load('./pickles/UC_NQC_JM_train.npy')\n",
        "UC_NQC_JM_train = normalizer.fit_transform(UC_NQC_JM_train)\n",
        "\n",
        "code_NQC_JM_train = np.load('./pickles/code_NQC_JM_train.npy')\n",
        "code_NQC_JM_train = normalizer.fit_transform(code_NQC_JM_train)\n",
        "\n",
        "UC_NQC_JM_test = np.load('./pickles/UC_NQC_JM_test.npy')\n",
        "UC_NQC_JM_test = normalizer.fit_transform(UC_NQC_JM_test)\n",
        "\n",
        "code_NQC_JM_test = np.load('./pickles/code_NQC_JM_test.npy')\n",
        "code_NQC_JM_test = normalizer.fit_transform(code_NQC_JM_test)\n",
        "\n",
        "UC_NQC_DP_train = np.load('./pickles/UC_NQC_DP_train.npy')\n",
        "UC_NQC_DP_train = normalizer.fit_transform(UC_NQC_DP_train)\n",
        "\n",
        "code_NQC_DP_train = np.load('./pickles/code_NQC_DP_train.npy')\n",
        "code_NQC_DP_train = normalizer.fit_transform(code_NQC_DP_train)\n",
        "\n",
        "UC_NQC_DP_test = np.load('./pickles/UC_NQC_DP_test.npy')\n",
        "UC_NQC_DP_test = normalizer.fit_transform(UC_NQC_DP_test)\n",
        "\n",
        "code_NQC_DP_test = np.load('./pickles/code_NQC_DP_test.npy')\n",
        "code_NQC_DP_test = normalizer.fit_transform(code_NQC_DP_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Document Statistics Features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from FeatureExtraction import *\n",
        "featureExtraction = FeatureExtraction(Vocab_UC_train)\n",
        "num_terms_code_train, num_terms_UC_train, num_unique_terms_code_train, num_unique_terms_UC_train, num_overlapping_terms_train = featureExtraction.DocumentStatistics(UC_documents_train, code_documents_train)\n",
        "#18min"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "featureExtraction = FeatureExtraction(Vocab_UC_train)\n",
        "num_terms_code_test, num_terms_UC_test, num_unique_terms_code_test, num_unique_terms_UC_test, num_overlapping_terms_test = featureExtraction.DocumentStatistics(UC_documents_test, code_documents_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "np.save('./pickles/num_terms_code_train.npy',num_terms_code_train)\n",
        "np.save('./pickles/num_terms_UC_train.npy',num_terms_UC_train)\n",
        "np.save('./pickles/num_unique_terms_code_train.npy',num_unique_terms_code_train)\n",
        "np.save('./pickles/num_unique_terms_UC_train.npy',num_unique_terms_UC_train)\n",
        "np.save('./pickles/num_overlapping_terms_train.npy',num_overlapping_terms_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "np.save('./pickles/num_terms_code_test.npy',num_terms_code_test)\n",
        "np.save('./pickles/num_terms_UC_test.npy',num_terms_UC_test)\n",
        "np.save('./pickles/num_unique_terms_code_test.npy',num_unique_terms_code_test)\n",
        "np.save('./pickles/num_unique_terms_UC_test.npy',num_unique_terms_UC_test)\n",
        "np.save('./pickles/num_overlapping_terms_test.npy',num_overlapping_terms_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "num_terms_code_train = np.load('./pickles/num_terms_code_train.npy')\n",
        "num_terms_UC_train = np.load('./pickles/num_terms_UC_train.npy')\n",
        "num_unique_terms_code_train = np.load('./pickles/num_unique_terms_code_train.npy')\n",
        "num_unique_terms_UC_train =np.load('./pickles/num_unique_terms_UC_train.npy')\n",
        "num_overlapping_terms_train = np.load('./pickles/num_overlapping_terms_train.npy')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "num_terms_code_test = np.load('./pickles/num_terms_code_test.npy')\n",
        "num_terms_UC_test= np.load('./pickles/num_terms_UC_test.npy')\n",
        "num_unique_terms_code_test = np.load('./pickles/num_unique_terms_code_test.npy')\n",
        "num_unique_terms_UC_test =np.load('./pickles/num_unique_terms_UC_test.npy')\n",
        "num_overlapping_terms_test = np.load('./pickles/num_overlapping_terms_test.npy')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Tiling and stacking the 126 feature"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "avg_idf_uc_train = np.array(avg_idf_uc_train)\n",
        "avg_idf_code_train = np.array(avg_idf_code_train)\n",
        "max_idf_uc_train = np.array(max_idf_uc_train)\n",
        "max_idf_code_train = np.array(max_idf_code_train)\n",
        "dev_idf_uc_train = np.array(dev_idf_uc_train)\n",
        "dev_idf_code_train = np.array(dev_idf_code_train)\n",
        "avg_ictf_uc_train = np.array(avg_ictf_uc_train)\n",
        "avg_ictf_code_train = np.array(avg_ictf_code_train)\n",
        "max_ictf_uc_train = np.array(max_ictf_uc_train)\n",
        "max_ictf_code_train = np.array(max_ictf_code_train)\n",
        "dev_ictf_uc_train = np.array(dev_ictf_uc_train)\n",
        "dev_ictf_code_train = np.array(dev_ictf_code_train)\n",
        "avg_entropy_uc_train = np.array(avg_entropy_uc_train)\n",
        "avg_entropy_code_train = np.array(avg_entropy_code_train)\n",
        "max_entropy_uc_train = np.array(max_entropy_uc_train)\n",
        "max_entropy_code_train = np.array(max_entropy_code_train)\n",
        "med_entropy_uc_train = np.array(med_entropy_uc_train)\n",
        "med_entropy_code_train = np.array(med_entropy_code_train)\n",
        "dev_entropy_uc_train = np.array(dev_entropy_uc_train)\n",
        "dev_entropy_code_train = np.array(dev_entropy_code_train)\n",
        "avg_variance_uc_train = np.array(avg_variance_uc_train)\n",
        "avg_variance_code_train = np.array(avg_variance_code_train)\n",
        "max_variance_uc_train = np.array(max_variance_uc_train)\n",
        "max_variance_code_train = np.array(max_variance_code_train)\n",
        "sum_variance_uc_train = np.array(sum_variance_uc_train)\n",
        "sum_variance_code_train = np.array(sum_variance_code_train)\n",
        "avg_scq_uc_train = np.array(avg_scq_uc_train)\n",
        "avg_scq_code_train = np.array(avg_scq_code_train)\n",
        "max_scq_uc_train = np.array(max_scq_uc_train)\n",
        "max_scq_code_train = np.array(max_scq_code_train)\n",
        "sum_sqc_uc_train = np.array(sum_sqc_uc_train)\n",
        "sum_sqc_code_train = np.array(sum_sqc_code_train)\n",
        "avg_pmi_uc_train = np.array(avg_pmi_uc_train)\n",
        "avg_pmi_code_train = np.array(avg_pmi_code_train)\n",
        "max_pmi_uc_train = np.array(max_pmi_uc_train)\n",
        "max_pmi_code_train = np.array(max_pmi_code_train)\n",
        "qs_uc_train = np.array(qs_uc_train)\n",
        "qs_code_train = np.array(qs_code_train)\n",
        "UC_SCS_train = np.array(UC_SCS_train)\n",
        "CC_SCS_train = np.array(CC_SCS_train)\n",
        "UC_CoherenceScore_train = np.array(UC_CoherenceScore_train)\n",
        "CC_CoherenceScore_train = np.array(CC_CoherenceScore_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "avg_idf_uc_train_reshaped = np.tile(avg_idf_uc_train, (1, avg_idf_code_train.shape[0]))\n",
        "avg_idf_code_train_reshaped = np.tile(avg_idf_code_train, (1, avg_idf_uc_train.shape[0]))\n",
        "\n",
        "max_idf_uc_train_reshaped = np.tile(max_idf_uc_train, (1, max_idf_code_train.shape[0]))\n",
        "max_idf_code_train_reshaped = np.tile(max_idf_code_train, (1, max_idf_uc_train.shape[0]))\n",
        "\n",
        "dev_idf_uc_train_reshaped = np.tile(dev_idf_uc_train, (1, dev_idf_code_train.shape[0]))\n",
        "dev_idf_code_train_reshaped = np.tile(dev_idf_code_train, (1, dev_idf_uc_train.shape[0]))\n",
        "\n",
        "avg_ictf_uc_train_reshaped = np.tile(avg_ictf_uc_train, (1, avg_ictf_code_train.shape[0]))\n",
        "avg_ictf_code_train_reshaped = np.tile(avg_ictf_code_train, (1, avg_ictf_uc_train.shape[0]))\n",
        "\n",
        "max_ictf_uc_train_reshaped = np.tile(max_ictf_uc_train, (1, max_ictf_code_train.shape[0]))\n",
        "max_ictf_code_train_reshaped = np.tile(max_ictf_code_train, (1, max_ictf_uc_train.shape[0]))\n",
        "\n",
        "dev_ictf_uc_train_reshaped = np.tile(dev_ictf_uc_train, (1, dev_ictf_code_train.shape[0]))\n",
        "dev_ictf_code_train_reshaped = np.tile(dev_ictf_code_train, (1, dev_ictf_uc_train.shape[0]))\n",
        "\n",
        "avg_entropy_uc_train_reshaped = np.tile(avg_entropy_uc_train, (1, avg_entropy_code_train.shape[0]))\n",
        "avg_entropy_code_train_reshaped = np.tile(avg_entropy_code_train, (1, avg_entropy_uc_train.shape[0]))\n",
        "\n",
        "max_entropy_uc_train_reshaped = np.tile(max_entropy_uc_train, (1, max_entropy_code_train.shape[0]))\n",
        "max_entropy_code_train_reshaped = np.tile(max_entropy_code_train, (1, max_entropy_uc_train.shape[0]))\n",
        "\n",
        "med_entropy_uc_train_reshaped = np.tile(med_entropy_uc_train, (1, med_entropy_code_train.shape[0]))\n",
        "med_entropy_code_train_reshaped = np.tile(med_entropy_code_train, (1, med_entropy_uc_train.shape[0]))\n",
        "\n",
        "dev_entropy_uc_train_reshaped = np.tile(dev_entropy_uc_train, (1, dev_entropy_code_train.shape[0]))\n",
        "dev_entropy_code_train_reshaped = np.tile(dev_entropy_code_train, (1, dev_entropy_uc_train.shape[0]))\n",
        "\n",
        "avg_variance_uc_train_reshaped = np.tile(avg_variance_uc_train, (1, avg_variance_code_train.shape[0]))\n",
        "avg_variance_code_train_reshaped = np.tile(avg_variance_code_train, (1, avg_variance_uc_train.shape[0]))\n",
        "\n",
        "max_variance_uc_train_reshaped = np.tile(max_variance_uc_train, (1, max_variance_code_train.shape[0]))\n",
        "max_variance_code_train_reshaped = np.tile(max_variance_code_train, (1, max_variance_uc_train.shape[0]))\n",
        "\n",
        "sum_variance_uc_train_reshaped = np.tile(sum_variance_uc_train, (1, sum_variance_code_train.shape[0]))\n",
        "sum_variance_code_train_reshaped = np.tile(sum_variance_code_train, (1, sum_variance_uc_train.shape[0]))\n",
        "\n",
        "avg_scq_uc_train_reshaped = np.tile(avg_scq_uc_train, (1, avg_scq_code_train.shape[0]))\n",
        "avg_scq_code_train_reshaped = np.tile(avg_scq_code_train, (1, avg_scq_uc_train.shape[0]))\n",
        "\n",
        "max_scq_uc_train_reshaped = np.tile(max_scq_uc_train, (1, max_scq_code_train.shape[0]))\n",
        "max_scq_code_train_reshaped = np.tile(max_scq_code_train, (1, max_scq_uc_train.shape[0]))\n",
        "\n",
        "sum_sqc_uc_train_reshaped = np.tile(sum_sqc_uc_train, (1, sum_sqc_code_train.shape[0]))\n",
        "sum_sqc_code_train_reshaped = np.tile(sum_sqc_code_train, (1, sum_sqc_uc_train.shape[0]))\n",
        "\n",
        "avg_pmi_uc_train_reshaped = np.tile(avg_pmi_uc_train, (1, avg_pmi_code_train.shape[0]))\n",
        "avg_pmi_code_train_reshaped = np.tile(avg_pmi_code_train, (1, avg_pmi_uc_train.shape[0]))\n",
        "\n",
        "max_pmi_uc_train_reshaped = np.tile(max_pmi_uc_train, (1, max_pmi_code_train.shape[0]))\n",
        "max_pmi_code_train_reshaped = np.tile(max_pmi_code_train, (1, max_pmi_uc_train.shape[0]))\n",
        "\n",
        "qs_uc_train_reshaped = np.tile(qs_uc_train, (1, qs_code_train.shape[0]))\n",
        "qs_code_train_reshaped = np.tile(qs_code_train, (1, qs_uc_train.shape[0]))\n",
        "\n",
        "UC_SCS_train_reshaped = np.tile(UC_SCS_train, (1, CC_SCS_train.shape[0]))\n",
        "CC_SCS_train_reshaped = np.tile(CC_SCS_train, (1, UC_SCS_train.shape[0]))\n",
        "\n",
        "UC_CoherenceScore_train_reshaped = np.tile(UC_CoherenceScore_train, (1, CC_CoherenceScore_train.shape[0]))\n",
        "CC_CoherenceScore_train_reshaped = np.tile(CC_CoherenceScore_train, (1, UC_CoherenceScore_train.shape[0]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "UC_RS_JS_train_reshaped = np.tile(UC_RS_JS_train, (1, code_RS_JS_train.shape[0]))\n",
        "code_RS_JS_train_reshaped = np.tile(code_RS_JS_train, (1, UC_RS_JS_train.shape[0]))\n",
        "\n",
        "UC_FRC_JS_train_reshaped = np.tile(UC_FRC_JS_train, (1, code_FRC_JS_train.shape[0]))\n",
        "code_FRC_JS_train_reshaped = np.tile(code_FRC_JS_train, (1, UC_FRC_JS_train.shape[0]))\n",
        "\n",
        "UC_RS_VSM_train_reshaped = np.tile(UC_RS_VSM_train, (1, code_RS_VSM_train.shape[0]))\n",
        "code_RS_VSM_train_reshaped = np.tile(code_RS_VSM_train, (1, UC_RS_VSM_train.shape[0]))\n",
        "\n",
        "UC_FRC_VSM_train_reshaped = np.tile(UC_FRC_VSM_train, (1, code_FRC_VSM_train.shape[0]))\n",
        "code_FRC_VSM_train_reshaped = np.tile(code_FRC_VSM_train, (1, UC_FRC_VSM_train.shape[0]))\n",
        "\n",
        "UC_RS_BM25_train_reshaped = np.tile(UC_RS_BM25_train, (1, code_RS_BM25_train.shape[0]))\n",
        "code_RS_BM25_train_reshaped = np.tile(code_RS_BM25_train, (1, UC_RS_BM25_train.shape[0]))\n",
        "\n",
        "UC_FRC_BM25_train_reshaped = np.tile(UC_FRC_BM25_train, (1, code_FRC_BM25_train.shape[0]))\n",
        "code_FRC_BM25_train_reshaped = np.tile(code_FRC_BM25_train, (1, UC_FRC_BM25_train.shape[0]))\n",
        "\n",
        "UC_RS_JM_train_reshaped = np.tile(UC_RS_JM_train, (1, code_RS_JM_train.shape[0]))\n",
        "code_RS_JM_train_reshaped = np.tile(code_RS_JM_train, (1, UC_RS_JM_train.shape[0]))\n",
        "\n",
        "UC_FRC_JM_train_reshaped = np.tile(UC_FRC_JM_train, (1, code_FRC_JM_train.shape[0]))\n",
        "code_FRC_JM_train_reshaped = np.tile(code_FRC_JM_train, (1, UC_FRC_JM_train.shape[0]))\n",
        "\n",
        "UC_RS_DP_train_reshaped = np.tile(UC_RS_DP_train, (1, code_RS_DP_train.shape[0]))\n",
        "code_RS_DP_train_reshaped = np.tile(code_RS_DP_train, (1, UC_RS_DP_train.shape[0]))\n",
        "\n",
        "UC_FRC_DP_train_reshaped = np.tile(UC_FRC_DP_train, (1, code_FRC_DP_train.shape[0]))\n",
        "code_FRC_DP_train_reshaped = np.tile(code_FRC_DP_train, (1, UC_FRC_DP_train.shape[0]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "UC_CT_JensenShannon_train_reshaped = np.tile(UC_CT_JensenShannon_train, (1, code_CT_JensenShannon_train.shape[0]))\n",
        "code_CT_JensenShannon_train_reshaped = np.tile(code_CT_JensenShannon_train, (1, UC_CT_JensenShannon_train.shape[0]))\n",
        "\n",
        "UC_CT_VSM_train_reshaped = np.tile(UC_CT_VSM_train, (1, code_CT_VSM_train.shape[0]))\n",
        "code_CT_VSM_train_reshaped = np.tile(code_CT_VSM_train, (1, UC_CT_VSM_train.shape[0]))\n",
        "\n",
        "UC_CT_BM25_train_reshaped = np.tile(UC_CT_BM25_train, (1, code_CT_BM25_train.shape[0]))\n",
        "code_CT_BM25_train_reshaped = np.tile(code_CT_BM25_train, (1, UC_CT_BM25_train.shape[0]))\n",
        "\n",
        "UC_CT_JM_train_reshaped = np.tile(UC_CT_JM_train, (1, code_CT_JM_train.shape[0]))\n",
        "code_CT_JM_train_reshaped = np.tile(code_CT_JM_train, (1, UC_CT_JM_train.shape[0]))\n",
        "\n",
        "UC_CT_DP_train_reshaped = np.tile(UC_CT_DP_train, (1, code_CT_DP_train.shape[0]))\n",
        "code_CT_DP_train_reshaped = np.tile(code_CT_DP_train, (1, UC_CT_DP_train.shape[0]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "UC_SAC_JS_train_reshaped = np.tile(UC_SAC_JS_train, (1, code_SAC_JS_train.shape[0]))\n",
        "code_SAC_JS_train_reshaped = np.tile(code_SAC_JS_train, (1, UC_SAC_JS_train.shape[0]))\n",
        "\n",
        "UC_SAC_VSM_train_reshaped = np.tile(UC_SAC_VSM_train, (1, code_SAC_VSM_train.shape[0]))\n",
        "code_SAC_VSM_train_reshaped = np.tile(code_SAC_VSM_train, (1, UC_SAC_VSM_train.shape[0]))\n",
        "\n",
        "UC_SAC_BM25_train_reshaped = np.tile(UC_SAC_BM25_train, (1, code_SAC_BM25_train.shape[0]))\n",
        "code_SAC_BM25_train_reshaped = np.tile(code_SAC_BM25_train, (1, UC_SAC_BM25_train.shape[0]))\n",
        "\n",
        "UC_SAC_JM_train_reshaped = np.tile(UC_SAC_JM_train, (1, code_SAC_JM_train.shape[0]))\n",
        "code_SAC_JM_train_reshaped = np.tile(code_SAC_JM_train, (1, UC_SAC_JM_train.shape[0]))\n",
        "\n",
        "UC_SAC_DP_train_reshaped = np.tile(UC_SAC_DP_train, (1, code_SAC_DP_train.shape[0]))\n",
        "code_SAC_DP_train_reshaped = np.tile(code_SAC_DP_train, (1, UC_SAC_DP_train.shape[0]))\n",
        "\n",
        "print(code_SAC_DP_train.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "UC_WIG_score_JensenShannon_train_reshaped = np.tile(UC_WIG_score_JensenShannon_train, (1, code_WIG_score_JensenShannon_train.shape[0]))\n",
        "code_WIG_score_JensenShannon_train_reshaped = np.tile(code_WIG_score_JensenShannon_train, (1, UC_WIG_score_JensenShannon_train.shape[0]))\n",
        "\n",
        "UC_WIG_score_VSM_train_reshaped = np.tile(UC_WIG_score_VSM_train, (1, code_WIG_score_VSM_train.shape[0]))\n",
        "code_WIG_score_VSM_train_reshaped = np.tile(code_WIG_score_VSM_train, (1, UC_WIG_score_VSM_train.shape[0]))\n",
        "\n",
        "UC_WIG_score_BM25_train_reshaped = np.tile(UC_WIG_score_BM25_train, (1, code_WIG_score_BM25_train.shape[0]))\n",
        "code_WIG_score_BM25_train_reshaped = np.tile(code_WIG_score_BM25_train, (1, UC_WIG_score_BM25_train.shape[0]))\n",
        "\n",
        "UC_WIG_score_JM_train_reshaped = np.tile(UC_WIG_score_JM_train, (1, code_WIG_score_JM_train.shape[0]))\n",
        "code_WIG_score_JM_train_reshaped = np.tile(code_WIG_score_JM_train, (1, UC_WIG_score_JM_train.shape[0]))\n",
        "\n",
        "UC_WIG_score_DP_train_reshaped = np.tile(UC_WIG_score_DP_train, (1, code_WIG_score_DP_train.shape[0]))\n",
        "code_WIG_score_DP_train_reshaped = np.tile(code_WIG_score_DP_train, (1, UC_WIG_score_DP_train.shape[0]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "UC_NQC_JensenShannon_train_reshaped = np.tile(UC_NQC_JensenShannon_train, (1, code_NQC_JensenShannon_train.shape[0]))\n",
        "code_NQC_JensenShannon_train_reshaped = np.tile(code_NQC_JensenShannon_train, (1, UC_NQC_JensenShannon_train.shape[0]))\n",
        "\n",
        "\n",
        "UC_NQC_VSM_train_reshaped = np.tile(UC_NQC_VSM_train, (1, code_NQC_VSM_train.shape[0]))\n",
        "code_NQC_VSM_train_reshaped = np.tile(code_NQC_VSM_train, (1, UC_NQC_VSM_train.shape[0]))\n",
        "\n",
        "UC_NQC_BM25_train_reshaped = np.tile(UC_NQC_BM25_train, (1, code_NQC_BM25_train.shape[0]))\n",
        "code_NQC_BM25_train_reshaped = np.tile(code_NQC_BM25_train, (1, UC_NQC_BM25_train.shape[0]))\n",
        "\n",
        "UC_NQC_JM_train_reshaped = np.tile(UC_NQC_JM_train, (1, code_NQC_JM_train.shape[0]))\n",
        "code_NQC_JM_train_reshaped = np.tile(code_NQC_JM_train, (1, UC_NQC_JM_train.shape[0]))\n",
        "\n",
        "UC_NQC_DP_train_reshaped = np.tile(UC_NQC_DP_train, (1, code_NQC_DP_train.shape[0]))\n",
        "code_NQC_DP_train_reshaped = np.tile(code_NQC_DP_train, (1, UC_NQC_DP_train.shape[0]))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "num_terms_code_train_reshaped = np.tile(num_terms_code_train, (num_terms_UC_train.shape[0],1))\n",
        "num_terms_UC_train_reshaped = np.tile(num_terms_UC_train, (num_terms_code_train.shape[0],1))\n",
        "\n",
        "num_unique_terms_UC_train_reshaped = np.tile(num_unique_terms_UC_train, (num_unique_terms_code_train.shape[0],1))\n",
        "num_unique_terms_code_train_reshaped = np.tile(num_unique_terms_code_train, (num_unique_terms_UC_train.shape[0],1))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "feature_matrix_train = np.stack(( cosine_similarity_UC_train, cosine_similarity_CC_train,LSA_similarities_UC_train,LSA_similarities_CC_train,LDA_similarities_UC_train,LDA_similarities_CC_train,JS_UC_train,JS_CC_train,BM25_UC_train.T,BM25_CC_train,JM_UC_train.T,JM_CC_train,DP_UC_train.T,DP_CC_train,\n",
        "                           \n",
        "   avg_idf_uc_train_reshaped,avg_idf_code_train_reshaped.T,max_idf_uc_train_reshaped,max_idf_code_train_reshaped.T,\n",
        "    dev_idf_uc_train_reshaped,dev_idf_code_train_reshaped.T,avg_ictf_uc_train_reshaped,avg_ictf_code_train_reshaped.T,max_ictf_uc_train_reshaped,max_ictf_code_train_reshaped.T,dev_ictf_uc_train_reshaped,dev_ictf_code_train_reshaped.T,avg_entropy_uc_train_reshaped,avg_entropy_code_train_reshaped.T,max_entropy_uc_train_reshaped,max_entropy_code_train_reshaped.T,med_entropy_uc_train_reshaped,med_entropy_code_train_reshaped.T,dev_entropy_uc_train_reshaped,dev_entropy_code_train_reshaped.T,avg_variance_uc_train_reshaped,avg_variance_code_train_reshaped.T,max_variance_uc_train_reshaped,max_variance_code_train_reshaped.T,sum_variance_uc_train_reshaped,sum_variance_code_train_reshaped.T,avg_scq_uc_train_reshaped,avg_scq_code_train_reshaped.T,max_scq_uc_train_reshaped,max_scq_code_train_reshaped.T,sum_sqc_uc_train_reshaped,sum_sqc_code_train_reshaped.T,avg_pmi_uc_train_reshaped,avg_pmi_code_train_reshaped.T,max_pmi_uc_train_reshaped,max_pmi_code_train_reshaped.T,qs_uc_train_reshaped,qs_code_train_reshaped.T,UC_SCS_train_reshaped,CC_SCS_train_reshaped.T,UC_CoherenceScore_train_reshaped,CC_CoherenceScore_train_reshaped.T,\n",
        "\n",
        "    UC_FRC_DP_train_reshaped,code_FRC_DP_train_reshaped.T,UC_FRC_JM_train_reshaped,code_FRC_JM_train_reshaped.T,UC_FRC_BM25_train_reshaped,code_FRC_BM25_train_reshaped.T,UC_FRC_JS_train_reshaped,code_FRC_JS_train_reshaped.T,UC_FRC_VSM_train_reshaped,code_FRC_VSM_train_reshaped.T\n",
        "\n",
        "    ,UC_RS_DP_train_reshaped,code_RS_DP_train_reshaped.T,UC_RS_JM_train_reshaped,code_RS_JM_train_reshaped.T,UC_RS_BM25_train_reshaped,code_RS_BM25_train_reshaped.T,UC_RS_JS_train_reshaped,code_RS_JS_train_reshaped.T,UC_RS_VSM_train_reshaped,code_RS_VSM_train_reshaped.T,\n",
        "\n",
        "    UC_CT_DP_train_reshaped,code_CT_DP_train_reshaped.T,UC_CT_JM_train_reshaped,\n",
        "    code_CT_JM_train_reshaped.T,UC_CT_BM25_train_reshaped,code_CT_BM25_train_reshaped.T,UC_CT_JensenShannon_train_reshaped,code_CT_JensenShannon_train_reshaped.T,UC_CT_VSM_train_reshaped,code_CT_VSM_train_reshaped.T,\n",
        "\n",
        "    UC_SAC_JM_train_reshaped,code_SAC_JM_train_reshaped.T,\n",
        "    UC_SAC_BM25_train_reshaped,code_SAC_BM25_train_reshaped.T,UC_SAC_JS_train_reshaped,code_SAC_JS_train_reshaped.T,\n",
        "    UC_SAC_VSM_train_reshaped,code_SAC_VSM_train_reshaped.T,UC_SAC_DP_train_reshaped,code_SAC_JS_train_reshaped.T,\n",
        "\n",
        "    UC_WIG_score_DP_train_reshaped,code_WIG_score_DP_train_reshaped.T,UC_WIG_score_JM_train_reshaped,\n",
        "    code_WIG_score_JM_train_reshaped.T,UC_WIG_score_BM25_train_reshaped,code_WIG_score_BM25_train_reshaped.T,UC_WIG_score_JensenShannon_train_reshaped,\n",
        "    code_WIG_score_JensenShannon_train_reshaped.T,UC_WIG_score_VSM_train_reshaped,\n",
        "    code_WIG_score_VSM_train_reshaped.T,\n",
        "\n",
        "    UC_NQC_DP_train_reshaped,code_NQC_DP_train_reshaped.T,UC_NQC_JM_train_reshaped,code_NQC_JM_train_reshaped.T,UC_NQC_BM25_train_reshaped,code_NQC_BM25_train_reshaped.T,UC_NQC_VSM_train_reshaped,code_NQC_VSM_train_reshaped.T,UC_NQC_JensenShannon_train_reshaped,code_NQC_JensenShannon_train_reshaped.T,\n",
        "\n",
        "    num_terms_UC_train_reshaped.T,num_terms_code_train_reshaped,num_unique_terms_UC_train_reshaped.T,num_unique_terms_code_train_reshaped,num_overlapping_terms_train),axis=2)\n",
        "\n",
        "print(feature_matrix_train.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "avg_idf_uc_test = np.array(avg_idf_uc_test)\n",
        "avg_idf_code_test = np.array(avg_idf_code_test)\n",
        "max_idf_uc_test = np.array(max_idf_uc_test)\n",
        "max_idf_code_test = np.array(max_idf_code_test)\n",
        "dev_idf_uc_test = np.array(dev_idf_uc_test)\n",
        "dev_idf_code_test = np.array(dev_idf_code_test)\n",
        "avg_ictf_uc_test = np.array(avg_ictf_uc_test)\n",
        "avg_ictf_code_test = np.array(avg_ictf_code_test)\n",
        "max_ictf_uc_test = np.array(max_ictf_uc_test)\n",
        "max_ictf_code_test = np.array(max_ictf_code_test)\n",
        "dev_ictf_uc_test = np.array(dev_ictf_uc_test)\n",
        "dev_ictf_code_test = np.array(dev_ictf_code_test)\n",
        "avg_entropy_uc_test = np.array(avg_entropy_uc_test)\n",
        "avg_entropy_code_test = np.array(avg_entropy_code_test)\n",
        "max_entropy_uc_test = np.array(max_entropy_uc_test)\n",
        "max_entropy_code_test = np.array(max_entropy_code_test)\n",
        "med_entropy_uc_test = np.array(med_entropy_uc_test)\n",
        "med_entropy_code_test = np.array(med_entropy_code_test)\n",
        "dev_entropy_uc_test = np.array(dev_entropy_uc_test)\n",
        "dev_entropy_code_test = np.array(dev_entropy_code_test)\n",
        "avg_variance_uc_test = np.array(avg_variance_uc_test)\n",
        "avg_variance_code_test = np.array(avg_variance_code_test)\n",
        "max_variance_uc_test = np.array(max_variance_uc_test)\n",
        "max_variance_code_test = np.array(max_variance_code_test)\n",
        "sum_variance_uc_test = np.array(sum_variance_uc_test)\n",
        "sum_variance_code_test = np.array(sum_variance_code_test)\n",
        "avg_scq_uc_test = np.array(avg_scq_uc_test)\n",
        "avg_scq_code_test = np.array(avg_scq_code_test)\n",
        "max_scq_uc_test = np.array(max_scq_uc_test)\n",
        "max_scq_code_test = np.array(max_scq_code_test)\n",
        "sum_sqc_uc_test = np.array(sum_sqc_uc_test)\n",
        "sum_sqc_code_test = np.array(sum_sqc_code_test)\n",
        "avg_pmi_uc_test = np.array(avg_pmi_uc_test)\n",
        "avg_pmi_code_test = np.array(avg_pmi_code_test)\n",
        "max_pmi_uc_test = np.array(max_pmi_uc_test)\n",
        "max_pmi_code_test = np.array(max_pmi_code_test)\n",
        "qs_uc_test = np.array(qs_uc_test)\n",
        "qs_code_test = np.array(qs_code_test)\n",
        "UC_SCS_test = np.array(UC_SCS_test)\n",
        "CC_SCS_test = np.array(CC_SCS_test)\n",
        "UC_CoherenceScore_test = np.array(UC_CoherenceScore_test)\n",
        "CC_CoherenceScore_test = np.array(CC_CoherenceScore_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "avg_idf_uc_test_reshaped = np.tile(avg_idf_uc_test, (1, avg_idf_code_test.shape[0]))\n",
        "avg_idf_code_test_reshaped = np.tile(avg_idf_code_test, (1, avg_idf_uc_test.shape[0]))\n",
        "\n",
        "max_idf_uc_test_reshaped = np.tile(max_idf_uc_test, (1, max_idf_code_test.shape[0]))\n",
        "max_idf_code_test_reshaped = np.tile(max_idf_code_test, (1, max_idf_uc_test.shape[0]))\n",
        "\n",
        "dev_idf_uc_test_reshaped = np.tile(dev_idf_uc_test, (1, dev_idf_code_test.shape[0]))\n",
        "dev_idf_code_test_reshaped = np.tile(dev_idf_code_test, (1, dev_idf_uc_test.shape[0]))\n",
        "\n",
        "avg_ictf_uc_test_reshaped = np.tile(avg_ictf_uc_test, (1, avg_ictf_code_test.shape[0]))\n",
        "avg_ictf_code_test_reshaped = np.tile(avg_ictf_code_test, (1, avg_ictf_uc_test.shape[0]))\n",
        "\n",
        "max_ictf_uc_test_reshaped = np.tile(max_ictf_uc_test, (1, max_ictf_code_test.shape[0]))\n",
        "max_ictf_code_test_reshaped = np.tile(max_ictf_code_test, (1, max_ictf_uc_test.shape[0]))\n",
        "\n",
        "dev_ictf_uc_test_reshaped = np.tile(dev_ictf_uc_test, (1, dev_ictf_code_test.shape[0]))\n",
        "dev_ictf_code_test_reshaped = np.tile(dev_ictf_code_test, (1, dev_ictf_uc_test.shape[0]))\n",
        "\n",
        "avg_entropy_uc_test_reshaped = np.tile(avg_entropy_uc_test, (1, avg_entropy_code_test.shape[0]))\n",
        "avg_entropy_code_test_reshaped = np.tile(avg_entropy_code_test, (1, avg_entropy_uc_test.shape[0]))\n",
        "\n",
        "max_entropy_uc_test_reshaped = np.tile(max_entropy_uc_test, (1, max_entropy_code_test.shape[0]))\n",
        "max_entropy_code_test_reshaped = np.tile(max_entropy_code_test, (1, max_entropy_uc_test.shape[0]))\n",
        "\n",
        "med_entropy_uc_test_reshaped = np.tile(med_entropy_uc_test, (1, med_entropy_code_test.shape[0]))\n",
        "med_entropy_code_test_reshaped = np.tile(med_entropy_code_test, (1, med_entropy_uc_test.shape[0]))\n",
        "\n",
        "dev_entropy_uc_test_reshaped = np.tile(dev_entropy_uc_test, (1, dev_entropy_code_test.shape[0]))\n",
        "dev_entropy_code_test_reshaped = np.tile(dev_entropy_code_test, (1, dev_entropy_uc_test.shape[0]))\n",
        "\n",
        "avg_variance_uc_test_reshaped = np.tile(avg_variance_uc_test, (1, avg_variance_code_test.shape[0]))\n",
        "avg_variance_code_test_reshaped = np.tile(avg_variance_code_test, (1, avg_variance_uc_test.shape[0]))\n",
        "\n",
        "max_variance_uc_test_reshaped = np.tile(max_variance_uc_test, (1, max_variance_code_test.shape[0]))\n",
        "max_variance_code_test_reshaped = np.tile(max_variance_code_test, (1, max_variance_uc_test.shape[0]))\n",
        "\n",
        "sum_variance_uc_test_reshaped = np.tile(sum_variance_uc_test, (1, sum_variance_code_test.shape[0]))\n",
        "sum_variance_code_test_reshaped = np.tile(sum_variance_code_test, (1, sum_variance_uc_test.shape[0]))\n",
        "\n",
        "avg_scq_uc_test_reshaped = np.tile(avg_scq_uc_test, (1, avg_scq_code_test.shape[0]))\n",
        "avg_scq_code_test_reshaped = np.tile(avg_scq_code_test, (1, avg_scq_uc_test.shape[0]))\n",
        "\n",
        "max_scq_uc_test_reshaped = np.tile(max_scq_uc_test, (1, max_scq_code_test.shape[0]))\n",
        "max_scq_code_test_reshaped = np.tile(max_scq_code_test, (1, max_scq_uc_test.shape[0]))\n",
        "\n",
        "sum_sqc_uc_test_reshaped = np.tile(sum_sqc_uc_test, (1, sum_sqc_code_test.shape[0]))\n",
        "sum_sqc_code_test_reshaped = np.tile(sum_sqc_code_test, (1, sum_sqc_uc_test.shape[0]))\n",
        "\n",
        "avg_pmi_uc_test_reshaped = np.tile(avg_pmi_uc_test, (1, avg_pmi_code_test.shape[0]))\n",
        "avg_pmi_code_test_reshaped = np.tile(avg_pmi_code_test, (1, avg_pmi_uc_test.shape[0]))\n",
        "\n",
        "max_pmi_uc_test_reshaped = np.tile(max_pmi_uc_test, (1, max_pmi_code_test.shape[0]))\n",
        "max_pmi_code_test_reshaped = np.tile(max_pmi_code_test, (1, max_pmi_uc_test.shape[0]))\n",
        "\n",
        "qs_uc_test_reshaped = np.tile(qs_uc_test, (1, qs_code_test.shape[0]))\n",
        "qs_code_test_reshaped = np.tile(qs_code_test, (1, qs_uc_test.shape[0]))\n",
        "\n",
        "UC_SCS_test_reshaped = np.tile(UC_SCS_test, (1, CC_SCS_test.shape[0]))\n",
        "CC_SCS_test_reshaped = np.tile(CC_SCS_test, (1, UC_SCS_test.shape[0]))\n",
        "\n",
        "UC_CoherenceScore_test_reshaped = np.tile(UC_CoherenceScore_test, (1, CC_CoherenceScore_test.shape[0]))\n",
        "CC_CoherenceScore_test_reshaped = np.tile(CC_CoherenceScore_test, (1, UC_CoherenceScore_test.shape[0]))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "UC_RS_JS_test_reshaped = np.tile(UC_RS_JS_test, (1, code_RS_JS_test.shape[0]))\n",
        "code_RS_JS_test_reshaped = np.tile(code_RS_JS_test, (1, UC_RS_JS_test.shape[0]))\n",
        "\n",
        "UC_FRC_JS_test_reshaped = np.tile(UC_FRC_JS_test, (1, code_FRC_JS_test.shape[0]))\n",
        "code_FRC_JS_test_reshaped = np.tile(code_FRC_JS_test, (1, UC_FRC_JS_test.shape[0]))\n",
        "\n",
        "UC_RS_VSM_test_reshaped = np.tile(UC_RS_VSM_test, (1, code_RS_VSM_test.shape[0]))\n",
        "code_RS_VSM_test_reshaped = np.tile(code_RS_VSM_test, (1, UC_RS_VSM_test.shape[0]))\n",
        "\n",
        "UC_FRC_VSM_test_reshaped = np.tile(UC_FRC_VSM_test, (1, code_FRC_VSM_test.shape[0]))\n",
        "code_FRC_VSM_test_reshaped = np.tile(code_FRC_VSM_test, (1, UC_FRC_VSM_test.shape[0]))\n",
        "\n",
        "UC_RS_BM25_test_reshaped = np.tile(UC_RS_BM25_test, (1, code_RS_BM25_test.shape[0]))\n",
        "code_RS_BM25_test_reshaped = np.tile(code_RS_BM25_test, (1, UC_RS_BM25_test.shape[0]))\n",
        "\n",
        "UC_FRC_BM25_test_reshaped = np.tile(UC_FRC_BM25_test, (1, code_FRC_BM25_test.shape[0]))\n",
        "code_FRC_BM25_test_reshaped = np.tile(code_FRC_BM25_test, (1, UC_FRC_BM25_test.shape[0]))\n",
        "\n",
        "UC_RS_JM_test_reshaped = np.tile(UC_RS_JM_test, (1, code_RS_JM_test.shape[0]))\n",
        "code_RS_JM_test_reshaped = np.tile(code_RS_JM_test, (1, UC_RS_JM_test.shape[0]))\n",
        "\n",
        "UC_FRC_JM_test_reshaped = np.tile(UC_FRC_JM_test, (1, code_FRC_JM_test.shape[0]))\n",
        "code_FRC_JM_test_reshaped = np.tile(code_FRC_JM_test, (1, UC_FRC_JM_test.shape[0]))\n",
        "\n",
        "UC_RS_DP_test_reshaped = np.tile(UC_RS_DP_test, (1, code_RS_DP_test.shape[0]))\n",
        "code_RS_DP_test_reshaped = np.tile(code_RS_DP_test, (1, UC_RS_DP_test.shape[0]))\n",
        "\n",
        "UC_FRC_DP_test_reshaped = np.tile(UC_FRC_DP_test, (1, code_FRC_DP_test.shape[0]))\n",
        "code_FRC_DP_test_reshaped = np.tile(code_FRC_DP_test, (1, UC_FRC_DP_test.shape[0]))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "UC_CT_JensenShannon_test_reshaped = np.tile(UC_CT_JensenShannon_test, (1, code_CT_JensenShannon_test.shape[0]))\n",
        "code_CT_JensenShannon_test_reshaped = np.tile(code_CT_JensenShannon_test, (1, UC_CT_JensenShannon_test.shape[0]))\n",
        "\n",
        "UC_CT_VSM_test_reshaped = np.tile(UC_CT_VSM_test, (1, code_CT_VSM_test.shape[0]))\n",
        "code_CT_VSM_test_reshaped = np.tile(code_CT_VSM_test, (1, UC_CT_VSM_test.shape[0]))\n",
        "\n",
        "UC_CT_BM25_test_reshaped = np.tile(UC_CT_BM25_test, (1, code_CT_BM25_test.shape[0]))\n",
        "code_CT_BM25_test_reshaped = np.tile(code_CT_BM25_test, (1, UC_CT_BM25_test.shape[0]))\n",
        "\n",
        "UC_CT_JM_test_reshaped = np.tile(UC_CT_JM_test, (1, code_CT_JM_test.shape[0]))\n",
        "code_CT_JM_test_reshaped = np.tile(code_CT_JM_test, (1, UC_CT_JM_test.shape[0]))\n",
        "\n",
        "UC_CT_DP_test_reshaped = np.tile(UC_CT_DP_test, (1, code_CT_DP_test.shape[0]))\n",
        "code_CT_DP_test_reshaped = np.tile(code_CT_DP_test, (1, UC_CT_DP_test.shape[0]))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "UC_SAC_JS_test_reshaped = np.tile(UC_SAC_JS_test, (1, code_SAC_JS_test.shape[0]))\n",
        "code_SAC_JS_test_reshaped = np.tile(code_SAC_JS_test, (1, UC_SAC_JS_test.shape[0]))\n",
        "\n",
        "UC_SAC_VSM_test_reshaped = np.tile(UC_SAC_VSM_test, (1, code_SAC_VSM_test.shape[0]))\n",
        "code_SAC_VSM_test_reshaped = np.tile(code_SAC_VSM_test, (1, UC_SAC_VSM_test.shape[0]))\n",
        "\n",
        "UC_SAC_BM25_test_reshaped = np.tile(UC_SAC_BM25_test, (1, code_SAC_BM25_test.shape[0]))\n",
        "code_SAC_BM25_test_reshaped = np.tile(code_SAC_BM25_test, (1, UC_SAC_BM25_test.shape[0]))\n",
        "\n",
        "UC_SAC_JM_test_reshaped = np.tile(UC_SAC_JM_test, (1, code_SAC_JM_test.shape[0]))\n",
        "code_SAC_JM_test_reshaped = np.tile(code_SAC_JM_test, (1, UC_SAC_JM_test.shape[0]))\n",
        "\n",
        "UC_SAC_DP_test_reshaped = np.tile(UC_SAC_DP_test, (1, code_SAC_DP_test.shape[0]))\n",
        "code_SAC_DP_test_reshaped = np.tile(code_SAC_DP_test, (1, UC_SAC_DP_test.shape[0]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "UC_WIG_score_JensenShannon_test_reshaped = np.tile(UC_WIG_score_JensenShannon_test, (1, code_WIG_score_JensenShannon_test.shape[0]))\n",
        "code_WIG_score_JensenShannon_test_reshaped = np.tile(code_WIG_score_JensenShannon_test, (1, UC_WIG_score_JensenShannon_test.shape[0]))\n",
        "\n",
        "UC_WIG_score_VSM_test_reshaped = np.tile(UC_WIG_score_VSM_test, (1, code_WIG_score_VSM_test.shape[0]))\n",
        "code_WIG_score_VSM_test_reshaped = np.tile(code_WIG_score_VSM_test, (1, UC_WIG_score_VSM_test.shape[0]))\n",
        "\n",
        "UC_WIG_score_BM25_test_reshaped = np.tile(UC_WIG_score_BM25_test, (1, code_WIG_score_BM25_test.shape[0]))\n",
        "code_WIG_score_BM25_test_reshaped = np.tile(code_WIG_score_BM25_test, (1, UC_WIG_score_BM25_test.shape[0]))\n",
        "\n",
        "UC_WIG_score_JM_test_reshaped = np.tile(UC_WIG_score_JM_test, (1, code_WIG_score_JM_test.shape[0]))\n",
        "code_WIG_score_JM_test_reshaped = np.tile(code_WIG_score_JM_test, (1, UC_WIG_score_JM_test.shape[0]))\n",
        "\n",
        "UC_WIG_score_DP_test_reshaped = np.tile(UC_WIG_score_DP_test, (1, code_WIG_score_DP_test.shape[0]))\n",
        "code_WIG_score_DP_test_reshaped = np.tile(code_WIG_score_DP_test, (1, UC_WIG_score_DP_test.shape[0]))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "UC_NQC_JensenShannon_test_reshaped = np.tile(UC_NQC_JensenShannon_test, (1, code_NQC_JensenShannon_test.shape[0]))\n",
        "code_NQC_JensenShannon_test_reshaped = np.tile(code_NQC_JensenShannon_test, (1, UC_NQC_JensenShannon_test.shape[0]))\n",
        "\n",
        "UC_NQC_VSM_test_reshaped = np.tile(UC_NQC_VSM_test, (1, code_NQC_VSM_test.shape[0]))\n",
        "code_NQC_VSM_test_reshaped = np.tile(code_NQC_VSM_test, (1, UC_NQC_VSM_test.shape[0]))\n",
        "\n",
        "UC_NQC_BM25_test_reshaped = np.tile(UC_NQC_BM25_test, (1, code_NQC_BM25_test.shape[0]))\n",
        "code_NQC_BM25_test_reshaped = np.tile(code_NQC_BM25_test, (1, UC_NQC_BM25_test.shape[0]))\n",
        "\n",
        "UC_NQC_JM_test_reshaped = np.tile(UC_NQC_JM_test, (1, code_NQC_JM_test.shape[0]))\n",
        "code_NQC_JM_test_reshaped = np.tile(code_NQC_JM_test, (1, UC_NQC_JM_test.shape[0]))\n",
        "\n",
        "UC_NQC_DP_test_reshaped = np.tile(UC_NQC_DP_test, (1, code_NQC_DP_test.shape[0]))\n",
        "code_NQC_DP_test_reshaped = np.tile(code_NQC_DP_test, (1, UC_NQC_DP_test.shape[0]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "num_terms_code_test_reshaped = np.tile(num_terms_code_test, (num_terms_UC_test.shape[0], 1))\n",
        "num_terms_UC_test_reshaped = np.tile(num_terms_UC_test, (num_terms_code_test.shape[0], 1))\n",
        "\n",
        "num_unique_terms_UC_test_reshaped = np.tile(num_unique_terms_UC_test, (num_unique_terms_code_test.shape[0], 1))\n",
        "num_unique_terms_code_test_reshaped = np.tile(num_unique_terms_code_test, (num_unique_terms_UC_test.shape[0], 1))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "feature_matrix_test = np.stack([\n",
        "    cosine_similarity_UC_test,cosine_similarity_CC_test,LSA_similarities_UC_test,LSA_similarities_CC_test,\n",
        "    LDA_similarities_UC_test,LDA_similarities_CC_test,JS_UC_test,JS_CC_test,BM25_UC_test.T, BM25_CC_test, JM_UC_test.T, JM_CC_test, DP_UC_test.T, DP_CC_test, \n",
        "\n",
        "    avg_idf_uc_test_reshaped, avg_idf_code_test_reshaped.T, max_idf_uc_test_reshaped, max_idf_code_test_reshaped.T,dev_idf_uc_test_reshaped, dev_idf_code_test_reshaped.T, avg_ictf_uc_test_reshaped, avg_ictf_code_test_reshaped.T, max_ictf_uc_test_reshaped, max_ictf_code_test_reshaped.T, dev_ictf_uc_test_reshaped, dev_ictf_code_test_reshaped.T, avg_entropy_uc_test_reshaped, avg_entropy_code_test_reshaped.T, max_entropy_uc_test_reshaped, max_entropy_code_test_reshaped.T, med_entropy_uc_test_reshaped, med_entropy_code_test_reshaped.T, dev_entropy_uc_test_reshaped, dev_entropy_code_test_reshaped.T, avg_variance_uc_test_reshaped,avg_variance_code_test_reshaped.T,max_variance_uc_test_reshaped,max_variance_code_test_reshaped.T,sum_variance_uc_test_reshaped, sum_variance_code_test_reshaped.T, avg_scq_uc_test_reshaped, avg_scq_code_test_reshaped.T,  max_scq_uc_test_reshaped,  max_scq_code_test_reshaped.T,  sum_sqc_uc_test_reshaped,  sum_sqc_code_test_reshaped.T,avg_pmi_uc_test_reshaped, avg_pmi_code_test_reshaped.T,max_pmi_uc_test_reshaped,max_pmi_code_test_reshaped.T,qs_uc_test_reshaped,qs_code_test_reshaped.T,UC_SCS_test_reshaped,CC_SCS_test_reshaped.T,UC_CoherenceScore_test_reshaped,CC_CoherenceScore_test_reshaped.T,\n",
        "    \n",
        "    UC_FRC_DP_test_reshaped,code_FRC_DP_test_reshaped.T,UC_FRC_JM_test_reshaped,code_FRC_JM_test_reshaped.T,UC_FRC_BM25_test_reshaped,code_FRC_BM25_test_reshaped.T,UC_FRC_JS_test_reshaped,code_FRC_JS_test_reshaped.T,UC_FRC_VSM_test_reshaped,code_FRC_VSM_test_reshaped.T,\n",
        "    \n",
        "    UC_RS_DP_test_reshaped,code_RS_DP_test_reshaped.T,UC_RS_JM_test_reshaped,code_RS_JM_test_reshaped.T,UC_RS_BM25_test_reshaped,code_RS_BM25_test_reshaped.T,UC_RS_JS_test_reshaped,code_RS_JS_test_reshaped.T,UC_RS_VSM_test_reshaped,code_RS_VSM_test_reshaped.T,\n",
        "    \n",
        "    UC_CT_DP_test_reshaped,code_CT_DP_test_reshaped.T,UC_CT_JM_test_reshaped,code_CT_JM_test_reshaped.T,UC_CT_BM25_test_reshaped,code_CT_BM25_test_reshaped.T,UC_CT_JensenShannon_test_reshaped,code_CT_JensenShannon_test_reshaped.T,UC_CT_VSM_test_reshaped,code_CT_VSM_test_reshaped.T,\n",
        "    \n",
        "    UC_SAC_JM_test_reshaped,code_SAC_JM_test_reshaped.T,UC_SAC_BM25_test_reshaped,code_SAC_BM25_test_reshaped.T,UC_SAC_JS_test_reshaped,code_SAC_JS_test_reshaped.T,UC_SAC_VSM_test_reshaped,code_SAC_VSM_test_reshaped.T,UC_SAC_DP_test_reshaped,code_SAC_DP_test_reshaped.T\n",
        "    \n",
        "    ,UC_WIG_score_DP_test_reshaped,code_WIG_score_DP_test_reshaped.T,UC_WIG_score_JM_test_reshaped,code_WIG_score_JM_test_reshaped.T,UC_WIG_score_BM25_test_reshaped,code_WIG_score_BM25_test_reshaped.T,UC_WIG_score_JensenShannon_test_reshaped,code_WIG_score_JensenShannon_test_reshaped.T,UC_WIG_score_VSM_test_reshaped,code_WIG_score_VSM_test_reshaped.T,\n",
        "    \n",
        "    UC_NQC_DP_test_reshaped,code_NQC_DP_test_reshaped.T,UC_NQC_JM_test_reshaped,code_NQC_JM_test_reshaped.T,UC_NQC_BM25_test_reshaped,code_NQC_BM25_test_reshaped.T,UC_NQC_VSM_test_reshaped,code_NQC_VSM_test_reshaped.T,UC_NQC_JensenShannon_test_reshaped,code_NQC_JensenShannon_test_reshaped.T,\n",
        "    \n",
        "    num_terms_UC_test_reshaped.T,num_terms_code_test_reshaped,num_unique_terms_UC_test_reshaped.T,num_unique_terms_code_test_reshaped,num_overlapping_terms_test\n",
        "], axis=2)\n",
        "\n",
        "# Print the shape of the feature matrix\n",
        "print(feature_matrix_test.shape)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Feature Selection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# matrix shape = links * features \n",
        "# ----features------\n",
        "#|\n",
        "#links\n",
        "#|\n",
        "feature_matrix_train_reshaped = feature_matrix_train.reshape(feature_matrix_train.shape[0]*feature_matrix_train.shape[1], -1)\n",
        "print(feature_matrix_train_reshaped.shape)\n",
        "correlation_features_train=np.corrcoef(feature_matrix_train_reshaped,rowvar=False)\n",
        "print(correlation_features_train.shape)\n",
        "features_excluded_train=set()\n",
        "\n",
        "for i in range(correlation_features_train.shape[1]):\n",
        "    for j in range(i+1,correlation_features_train.shape[0]):\n",
        "        if (correlation_features_train[j][i] >= 0.9 ):\n",
        "            features_excluded_train.add(j)\n",
        "\n",
        "features_links_selected_train=np.delete(feature_matrix_train_reshaped, list(features_excluded_train), axis=1) \n",
        "print(feature_matrix_train_reshaped)\n",
        "print(features_links_selected_train.shape)\n",
        "features_links_selected_reshaped_train = features_links_selected_train.reshape(feature_matrix_train.shape[0], feature_matrix_train.shape[1], -1)\n",
        "print(features_links_selected_reshaped_train.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# matrix shape = links * features \n",
        "# ----features------\n",
        "#|\n",
        "#links\n",
        "#|\n",
        "feature_matrix_test_reshaped = feature_matrix_test.reshape(feature_matrix_test.shape[0]*feature_matrix_test.shape[1], -1)\n",
        "print(feature_matrix_test_reshaped.shape)\n",
        "correlation_features_test=np.corrcoef(feature_matrix_test_reshaped,rowvar=False)\n",
        "print(correlation_features_test.shape)\n",
        "features_excluded_test=set()\n",
        "\n",
        "for i in range(correlation_features_test.shape[1]):\n",
        "    for j in range(i+1,correlation_features_test.shape[0]):\n",
        "        if (correlation_features_test[j][i] >= 0.9 ):\n",
        "            features_excluded_test.add(j)\n",
        "\n",
        "features_links_selected_test=np.delete(feature_matrix_test_reshaped, list(features_excluded_train), axis=1) \n",
        "print(feature_matrix_test_reshaped)\n",
        "print(features_links_selected_test.shape)\n",
        "features_links_selected_reshaped_test = features_links_selected_test.reshape(feature_matrix_test.shape[0], feature_matrix_test.shape[1], -1)\n",
        "print(features_links_selected_reshaped_test.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Mapping Features to Labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "Features_train = list()\n",
        "DataSet_train = pd.read_csv('Dataset/teiid_dataset/train_modified.csv')\n",
        "for row in DataSet_train.index:\n",
        "    index_code = int(DataSet_train.loc[row, 'CC'])\n",
        "    index_UC = int(DataSet_train.loc[row, 'UC'])\n",
        "    Features_train.append(features_links_selected_reshaped_train[index_UC][index_code])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "Features_test = list()\n",
        "DataSet_test = pd.read_csv('Dataset/teiid_dataset/test_modified.csv')\n",
        "for row in DataSet_test.index:\n",
        "    index_code = int(DataSet_test.loc[row, 'CC'])\n",
        "    index_UC = int(DataSet_test.loc[row, 'UC'])\n",
        "    Features_test.append(features_links_selected_reshaped_test[index_UC][index_code])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# print(len(Features[]))\n",
        "# print(len(DataSet['Labels'].to_list()))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Data Imbalancing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from imblearn.over_sampling import BorderlineSMOTE \n",
        "smote = BorderlineSMOTE(random_state=42)\n",
        "Features_SMOTE_train, Labels_SMOTE_train = smote.fit_resample(Features_train, DataSet_train['Labels'].to_list())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "\n",
        "# train_features, train_labels = train_test_split(Features_SMOTE_train, Labels_SMOTE_train, test_size = 0, random_state = 42)\n",
        "print(type(Features_SMOTE_train))\n",
        "model_random_forest = RandomForestRegressor(n_estimators = 10, random_state = 42, verbose=2, n_jobs=4)\n",
        "model_random_forest.fit(Features_SMOTE_train, Labels_SMOTE_train)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import joblib\n",
        "joblib.dump(model_random_forest, 'Dataset/teiid_dataset/teiid_model.pkl')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "test_labels = DataSet_test['Labels'].to_list()\n",
        "predictions = model_random_forest.predict(Features_test)\n",
        "errors = abs(predictions - test_labels)\n",
        "print('mean Absolute Error:', round(np.mean(errors), 2) )\n",
        "\n",
        "acc=(test_labels==predictions).sum()\n",
        "print(acc/len(test_labels))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Loading Model and Testing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from joblib import load\n",
        "\n",
        "# Load the model\n",
        "model = load('pickles_teiid/RandomForst_131Features_2nd_trial_tehiid.joblib')\n",
        "\n",
        "# Assuming you have test data in variables X_test and y_test\n",
        "predictions = model.predict(test_features)\n",
        "\n",
        "# Calculate the accuracy of the model on the test data\n",
        "test_labels = DataSet_test['Labels'].to_list()\n",
        "errors = abs(predictions - test_labels)\n",
        "print('mean Absolute Error:', round(np.mean(errors), 2) )\n",
        "\n",
        "acc=(test_labels==predictions).sum()\n",
        "print('Accuracy:',acc/len(test_labels))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"test labels: \", test_labels)\n",
        "print(\"predictions: \")\n",
        "for prediction in predictions:\n",
        "    print(prediction)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# from joblib import dump\n",
        "\n",
        "# # Assuming you have trained a model named 'model'\n",
        "# # You can save it using dump\n",
        "# dump(model_random_forest, 'RandomForst_121Features_1st_trial.joblib')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import csv\n",
        "with open('./dataset/answerSet.csv', newline='') as csvfile:\n",
        "    reader = csv.reader(csvfile, delimiter=' ', quotechar='|')\n",
        "    valid_links_labels = []\n",
        "    for row in reader:\n",
        "        temp=row[0].split(\",\")\n",
        "        #match = re.search(rprint('UC(\\d+)\\.txt', temp[0])\n",
        "        valid_links_labels.append((temp[0],temp[1]))\n",
        "        # if (valid_links_labels.get(temp[1])==None):\n",
        "        # valid_links_labels[temp[1]]=[int(match.group(1))]\n",
        "        # else:\n",
        "        #     valid_links_labels[temp[1]].append(int(match.group(1)))\n",
        "\n",
        "# file_names = list(valid_links_labels.keys())\n",
        "# file_names.sort()\n",
        "# valid_links_labels_sorted = {i: valid_links_labels[i] for i in file_names}\n",
        "            \n",
        "# valid_links_labels_sorted)\n",
        "# len(valid_links_labels_sorted.keys()))\n",
        "print(valid_links_labels)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
