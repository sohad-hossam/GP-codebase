{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "from imports import *\n",
        "from FeatureExtraction import *\n",
        "from PreProcessor import *\n",
        "_PreProcessor = PreProcessor()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## dataset new - trial"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                                   commit_hash  \\\n",
            "0     f98aada611afa7404ce9f8266101acdbea835176   \n",
            "1     f98aada611afa7404ce9f8266101acdbea835176   \n",
            "2     f98aada611afa7404ce9f8266101acdbea835176   \n",
            "3     f98aada611afa7404ce9f8266101acdbea835176   \n",
            "4     f98aada611afa7404ce9f8266101acdbea835176   \n",
            "...                                        ...   \n",
            "4361  f5831ea44143bb0d87e000ae76b1ffa2b05cf771   \n",
            "4362  f5831ea44143bb0d87e000ae76b1ffa2b05cf771   \n",
            "4363  dd616868bcf08e9af02c32d9c73097dd7e6b44bd   \n",
            "4364  3de768cc21863addab64c789d802b6c827617a57   \n",
            "4365  3de768cc21863addab64c789d802b6c827617a57   \n",
            "\n",
            "                                              file_path             type  \\\n",
            "0     errai-common/src/main/java/org/jboss/errai/com...  Feature Request   \n",
            "1     errai-ui/src/main/java/org/jboss/errai/ui/rebi...  Feature Request   \n",
            "2     errai-ui/src/main/java/org/jboss/errai/ui/rebi...  Feature Request   \n",
            "3     errai-ui/src/test/java/org/jboss/errai/ui/test...  Feature Request   \n",
            "4     errai-ui/src/test/java/org/jboss/errai/ui/test...  Feature Request   \n",
            "...                                                 ...              ...   \n",
            "4361  errai-workspaces/src/main/java/org/jboss/errai...  Feature Request   \n",
            "4362  errai-workspaces/src/main/java/org/jboss/errai...  Feature Request   \n",
            "4363  errai-workspaces/src/main/java/org/jboss/errai...              Bug   \n",
            "4364  errai-bus-demos/serialization/src/main/java/or...              Bug   \n",
            "4365  errai-bus-demos/serialization/src/main/java/or...              Bug   \n",
            "\n",
            "     resolution                                summary  \\\n",
            "0          Done     Add @ClassName annotation support.   \n",
            "1          Done     Add @ClassName annotation support.   \n",
            "2          Done     Add @ClassName annotation support.   \n",
            "3          Done     Add @ClassName annotation support.   \n",
            "4          Done     Add @ClassName annotation support.   \n",
            "...         ...                                    ...   \n",
            "4361       Done             Update to mosaic 0.4.0-rc4   \n",
            "4362       Done             Update to mosaic 0.4.0-rc4   \n",
            "4363       Done  @DefaultBundle should become optional   \n",
            "4364       Done            Serialization example fails   \n",
            "4365       Done            Serialization example fails   \n",
            "\n",
            "                                            description  \n",
            "0     It could be really  handy to add @ClassName an...  \n",
            "1     It could be really  handy to add @ClassName an...  \n",
            "2     It could be really  handy to add @ClassName an...  \n",
            "3     It could be really  handy to add @ClassName an...  \n",
            "4     It could be really  handy to add @ClassName an...  \n",
            "...                                                 ...  \n",
            "4361                                               None  \n",
            "4362                                               None  \n",
            "4363                                               None  \n",
            "4364  org.jboss.errai.bus.client.BadlyFormedMessageE...  \n",
            "4365  org.jboss.errai.bus.client.BadlyFormedMessageE...  \n",
            "\n",
            "[4366 rows x 6 columns]\n",
            "Index(['commit_hash', 'file_path', 'type', 'resolution', 'summary',\n",
            "       'description'],\n",
            "      dtype='object')\n"
          ]
        }
      ],
      "source": [
        "con = sqlite3.connect(\"Dataset/errai_dataset/errai.sqlite3\")\n",
        "cur = con.cursor()\n",
        "\n",
        "issue_df = pd.read_sql_query(\"SELECT issue_id, type, resolution, summary, description FROM issue WHERE resolution='Done'\", con)\n",
        "change_set_link_df = pd.read_sql_query(\"SELECT issue_id, commit_hash FROM change_set_link\", con)\n",
        "change_set_df = pd.read_sql_query(\"SELECT commit_hash, file_path FROM code_change WHERE file_path LIKE '%.java'\", con)\n",
        "\n",
        "merged_df = pd.merge(pd.merge(change_set_link_df, change_set_df, on='commit_hash'), issue_df, on='issue_id')\n",
        "merged_df = merged_df.drop(columns=['issue_id'])\n",
        "print(merged_df)\n",
        "print(merged_df.columns)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "3430\n"
          ]
        }
      ],
      "source": [
        "import requests\n",
        "import json\n",
        "\n",
        "owner = 'errai'\n",
        "repo = 'errai'\n",
        "token = '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'\n",
        "\n",
        "headers = {\n",
        "    'Authorization': f'token {token}'\n",
        "}\n",
        "\n",
        "repo_local = git.Repo(\"errai_repo_clone\")\n",
        "\n",
        "CC_UC_dict_true = dict()\n",
        "UC_to_index = dict()\n",
        "index_to_UC = dict()\n",
        "CC_list = list()\n",
        "\n",
        "\n",
        "counter = 0\n",
        "UC_index = 0\n",
        "CC_index = 0\n",
        "\n",
        "merged_list = list(merged_df.to_records(index=False))\n",
        "for commit_hash, file_path, type, resolution, summary, description in merged_list:\n",
        "\n",
        "    commit_local = repo_local.commit(commit_hash) \n",
        "    commit_parent_hash = commit_local.parents[0].hexsha\n",
        "    commit_parent = repo_local.commit(commit_parent_hash)\n",
        "\n",
        "    try: \n",
        "        UC = summary+' '+description\n",
        "        if UC_to_index.get(UC) == None:\n",
        "            UC_to_index[UC] = UC_index\n",
        "            index_to_UC[UC_index] = UC\n",
        "            UC_index += 1\n",
        "\n",
        "\n",
        "        if type == 'Bug':\n",
        "            old_content = commit_parent.tree[file_path].data_stream.read().decode('utf-8')\n",
        "            CC_list.append(old_content)\n",
        "        else:\n",
        "            new_content = commit_local.tree[file_path].data_stream.read().decode('utf-8')\n",
        "            CC_list.append(new_content)\n",
        "\n",
        "        CC_UC_dict_true[CC_index] = UC_to_index.get(UC)\n",
        "        CC_index += 1\n",
        "        \n",
        "    except:\n",
        "        counter+=1\n",
        "# print(counter)        \n",
        "# print(old_new_files[0])\n",
        "print(len(CC_list))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2289\n",
            "658\n",
            "1340 5520 5520 1340\n"
          ]
        }
      ],
      "source": [
        "UC_train, UC_test = train_test_split(list(UC_to_index.values()), test_size = 0.2, random_state = 42)\n",
        "\n",
        "CC_train_docs = list()\n",
        "UC_train_docs = list()\n",
        "\n",
        "CC_test_docs = list()\n",
        "UC_test_docs = list()\n",
        "\n",
        "UC_to_index_train_new = dict()\n",
        "CC_to_index_train_new = dict()\n",
        "UC_to_index_test_new = dict()\n",
        "CC_to_index_test_new = dict()\n",
        "\n",
        "UC_index_train = 0\n",
        "CC_index_train = 0\n",
        "UC_index_test = 0\n",
        "CC_index_test = 0\n",
        "\n",
        "for CC_index_old, UC_index_old in CC_UC_dict_true.items():\n",
        "\n",
        "    if UC_index_old in UC_train:\n",
        "        UC_to_index_train_new[UC_index_old] = UC_index_train\n",
        "        CC_to_index_train_new[CC_index_old] = CC_index_train\n",
        "        if CC_list[CC_index_old] not in CC_train_docs:\n",
        "            CC_train_docs.append(CC_list[CC_index_old])\n",
        "        if index_to_UC[UC_index_old] not in UC_train_docs:\n",
        "            UC_train_docs.append(index_to_UC[UC_index_old])\n",
        "        UC_index_train += 1\n",
        "        CC_index_train += 1\n",
        "        \n",
        "    elif UC_index_old in UC_test:\n",
        "        UC_to_index_test_new[UC_index_old] = UC_index_test\n",
        "        CC_to_index_test_new[CC_index_old] = CC_index_test\n",
        "        if CC_list[CC_index_old] not in CC_test_docs:\n",
        "            CC_test_docs.append(CC_list[CC_index_old])\n",
        "        if index_to_UC[UC_index_old] not in UC_test_docs:\n",
        "            UC_test_docs.append(index_to_UC[UC_index_old])\n",
        "        UC_index_test += 1\n",
        "        CC_index_test += 1\n",
        "\n",
        "print(len(CC_train_docs))\n",
        "print(len(CC_test_docs))\n",
        "\n",
        "# to be used for the mapping we took the global dictionary and split it into train and test based on \n",
        "# split results to do that we mapped the old UC and CC indices to new ones based on train and test\n",
        "\n",
        "CC_UC_dict_train = list()\n",
        "CC_UC_dict_test = list()\n",
        "\n",
        "for CC_index_old, UC_index_old in CC_UC_dict_true.items():\n",
        "    if UC_index_old in UC_to_index_train_new.keys():\n",
        "        CC_UC_dict_train.append((CC_to_index_train_new[CC_index_old], UC_to_index_train_new[UC_index_old]))\n",
        "    elif CC_index_old in CC_to_index_test_new.keys():\n",
        "        CC_UC_dict_test.append((CC_to_index_test_new[CC_index_old], UC_to_index_test_new[UC_index_old]))\n",
        "\n",
        "true_train_length = len(CC_UC_dict_train)\n",
        "true_test_length = len(CC_UC_dict_test)\n",
        "\n",
        "CC_UC_train_labels = [1] * true_train_length\n",
        "CC_UC_test_labels = [1] * true_test_length\n",
        "\n",
        "for CC_index_new in CC_to_index_train_new.values():\n",
        "    random_UC_index_new = random.choice(list(UC_to_index_train_new.values()))\n",
        "    while (CC_index_new, random_UC_index_new) in CC_UC_dict_train:\n",
        "        random_UC_index_new = random.choice(list(UC_to_index_train_new.values()))\n",
        "    CC_UC_dict_train.append((CC_index_new, random_UC_index_new))\n",
        "\n",
        "for CC_index_new in CC_to_index_test_new.values():\n",
        "    random_UC_index_new = random.choice(list(UC_to_index_test_new.values()))\n",
        "    while (CC_index_new, random_UC_index_new) in CC_UC_dict_train:\n",
        "        random_UC_index_new = random.choice(list(UC_to_index_test_new.values()))\n",
        "    CC_UC_dict_test.append((CC_index_new, random_UC_index_new))\n",
        "\n",
        "CC_UC_train_labels += [0] * (len(CC_UC_dict_train) - true_train_length)\n",
        "CC_UC_test_labels += [0] * (len(CC_UC_dict_test) - true_test_length)\n",
        "\n",
        "print(len(CC_UC_dict_test), len(CC_UC_dict_train), len(CC_UC_train_labels), len(CC_UC_test_labels))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "x_train, x_test, y_train, y_test = train_test_split(CC_UC_true+CC_UC_false, CC_UC_labels, test_size = 0.2, random_state = 42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "CC_train, UC_train = zip(*x_train)\n",
        "print(len(CC_train), len(UC_train), len(y_train))\n",
        "\n",
        "\n",
        "train_csv = {\n",
        "    'CC': CC_train,\n",
        "    'UC': UC_train,\n",
        "    'Labels': y_train\n",
        "}\n",
        "\n",
        "train_df = pd.DataFrame(train_csv)\n",
        "train_df.to_csv('Dataset/errai_dataset/train.csv', index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "CC_test, UC_test = zip(*x_test)\n",
        "print(len(CC_test), len(UC_test), len(y_test))\n",
        "\n",
        "\n",
        "test_csv = {\n",
        "    'CC': CC_test,\n",
        "    'UC': UC_test,\n",
        "    'Labels': y_test\n",
        "}\n",
        "\n",
        "train_df = pd.DataFrame(test_csv)\n",
        "train_df.to_csv('Dataset/errai_dataset/test.csv', index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Preprocessor"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "</h3>Train </h3>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "CC_train_docs = list()\n",
        "for index in CC_train:\n",
        "    CC_train_docs.append(CC_list[index])\n",
        "\n",
        "UC_documents_train, UC_to_index_train,Vocab_UC_train= _PreProcessor.setupUC(list(UC_to_index.keys()), 'train')\n",
        "code_documents_train, CC_to_index_train,Vocab_CC_train = _PreProcessor.setupCC(CC_train, 'train')\n",
        "\n",
        "# CC_train_docs = values = [CC_list[index] for index in CC_train]\n",
        "UC_documents_test, UC_to_index_test,Vocab_UC_test= _PreProcessor.setupUC(\"./Dataset/errai_dataset/test_UC\", 'test')\n",
        "code_documents_test, CC_to_index_test,Vocab_CC_test = _PreProcessor.setupCC(\"./Dataset/errai_dataset/test_CC\", 'test')\n",
        "\n",
        "Vocab_UC_train.update(Vocab_CC_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "with open('./Dataset/errai_dataset/pickles/UC_documents_train.pkl', 'wb') as f:\n",
        "       pickle.dump(UC_documents_train, f)\n",
        "with open('./Dataset/errai_dataset/pickles/code_documents_train.pkl', 'wb') as f:\n",
        "        pickle.dump(code_documents_train, f)\n",
        "with open('./Dataset/errai_dataset/pickles/UCindex_train.pkl', 'wb') as f:\n",
        "        pickle.dump(UC_to_index_train, f)\n",
        "with open('./Dataset/errai_dataset/pickles/CCindex_train.pkl', 'wb') as f:\n",
        "        pickle.dump(CC_to_index_train, f)\n",
        "with open('./Dataset/errai_dataset/pickles/UCTokens_train.pkl', 'wb') as f:\n",
        "        pickle.dump(Vocab_UC_train, f)\n",
        "with open('./Dataset/errai_dataset/pickles/CodeTokens_train.pkl', 'wb') as f:\n",
        "        pickle.dump(Vocab_CC_train, f)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "</h3>Test</h3>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "with open('./Dataset/errai_dataset/pickles/UC_documents_test.pkl', 'wb') as f:\n",
        "       pickle.dump(UC_documents_test, f)\n",
        "with open('./Dataset/errai_dataset/pickles/code_documents_test.pkl', 'wb') as f:\n",
        "        pickle.dump(code_documents_test, f)\n",
        "with open('./Dataset/errai_dataset/pickles/UCindex_test.pkl', 'wb') as f:\n",
        "        pickle.dump(UC_to_index_test, f)\n",
        "with open('./Dataset/errai_dataset/pickles/CCindex_test.pkl', 'wb') as f:\n",
        "        pickle.dump(CC_to_index_test, f)\n",
        "with open('./Dataset/errai_dataset/pickles/UCTokens_test.pkl', 'wb') as f:\n",
        "        pickle.dump(Vocab_UC_test, f)\n",
        "with open('./Dataset/errai_dataset/pickles/CodeTokens_test.pkl', 'wb') as f:\n",
        "        pickle.dump(Vocab_CC_test, f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "UC_documents_train = np.load('./Dataset/errai_dataset/pickles/UC_documents_train.pkl',allow_pickle=True)\n",
        "Vocab_UC_train = np.load('./Dataset/errai_dataset/pickles/UCTokens_train.pkl',allow_pickle=True)\n",
        "code_documents_train = np.load('./Dataset/errai_dataset/pickles/code_documents_train.pkl',allow_pickle=True)\n",
        "Vocab_CC_train = np.load('./Dataset/errai_dataset/pickles/CodeTokens_train.pkl',allow_pickle=True)\n",
        "UC_to_index_train = np.load('./Dataset/errai_dataset/pickles/UCindex_train.pkl',allow_pickle=True)\n",
        "CC_to_index_train = np.load('./Dataset/errai_dataset/pickles/CCindex_train.pkl',allow_pickle=True)\n",
        "\n",
        "\n",
        "UC_documents_test = np.load('./Dataset/errai_dataset/pickles/UC_documents_test.pkl',allow_pickle=True)\n",
        "Vocab_UC_test = np.load('./Dataset/errai_dataset/pickles/UCTokens_test.pkl',allow_pickle=True)\n",
        "code_documents_test = np.load('./Dataset/errai_dataset/pickles/code_documents_test.pkl',allow_pickle=True)\n",
        "Vocab_CC_test = np.load('./Dataset/errai_dataset/pickles/CodeTokens_test.pkl',allow_pickle=True)\n",
        "UC_to_index_test = np.load('./Dataset/errai_dataset/pickles/UCindex_test.pkl',allow_pickle=True)\n",
        "CC_to_index_test = np.load('./Dataset/errai_dataset/pickles/CCindex_test.pkl',allow_pickle=True)\n",
        "\n",
        "\n",
        "\n",
        "Vocab_UC_train.update(Vocab_CC_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(len(UC_documents_test))\n",
        "print(len(code_documents_test))\n",
        "print(len(UC_to_index_test))\n",
        "print(len(CC_to_index_test))\n",
        "\n",
        "print(len(UC_documents_train))\n",
        "print(len(code_documents_train))\n",
        "print(len(UC_to_index_train))\n",
        "print(len(CC_to_index_train))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Initialize Normalizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "normalizer = MinMaxScaler(copy=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Adjuting the csv file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "_PreProcessor.setupCSV(\"./Dataset/errai_dataset/train.csv\", \"Dataset/errai_dataset/train_modified.csv\",UC_to_index_train,CC_to_index_train)\n",
        "_PreProcessor.setupCSV(\"./Dataset/errai_dataset/test.csv\", \"Dataset/errai_dataset/test_modified.csv\",UC_to_index_test,CC_to_index_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Collecting the 131 features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "featureExtraction = FeatureExtraction(Vocab_UC_train)\n",
        "\n",
        "# Feature extraction for training set\n",
        "tfidf_matrix_uc_train, tfidf_matrix_code_train, idf_uc_dict_train, idf_code_dict_train, feature_names_uc_train, feature_names_code_train, df_uc_dict_train, df_code_dict_train = featureExtraction.TFIDFVectorizer(UC_documents_train, code_documents_train,train_or_test='train')\n",
        "UC_count_matrix_train, code_count_matrix_train, tf_uc_dict_train, tf_code_dict_train = featureExtraction.CountVectorizerModel(UC_documents_train, code_documents_train, 'train')\n",
        "idf_uc_train, idf_code_train = featureExtraction.IDFPreProcessing(UC_documents_train, idf_code_dict_train, code_documents_train, idf_uc_dict_train)\n",
        "ictf_uc_train, ictf_code_train = featureExtraction.ICTFPreProcessing(UC_documents_train, tf_code_dict_train, code_documents_train, tf_uc_dict_train)\n",
        "\n",
        "# Feature extraction for testing set\n",
        "tfidf_matrix_uc_test, tfidf_matrix_code_test, idf_uc_dict_test, idf_code_dict_test, feature_names_uc_test, feature_names_code_test, df_uc_dict_test, df_code_dict_test = featureExtraction.TFIDFVectorizer(UC_documents_test, code_documents_test,train_or_test='test')\n",
        "UC_count_matrix_test, code_count_matrix_test, tf_uc_dict_test, tf_code_dict_test = featureExtraction.CountVectorizerModel(UC_documents_test, code_documents_test, 'test')\n",
        "idf_uc_test, idf_code_test = featureExtraction.IDFPreProcessing(UC_documents_test, idf_code_dict_test, code_documents_test, idf_uc_dict_test)\n",
        "ictf_uc_test, ictf_code_test = featureExtraction.ICTFPreProcessing(UC_documents_test, tf_code_dict_test, code_documents_test, tf_uc_dict_test)\n",
        "# # the values of the count matrices are normalized\n",
        "#8.3 sec"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "entropy_uc_train,entropy_code_train,variance_uc_train,variance_code_train=featureExtraction.EntropyPreProcessing(UC_documents_train,code_documents_train,idf_uc_dict_train,idf_code_dict_train,df_uc_dict_train,df_code_dict_train)\n",
        "entropy_uc_test,entropy_code_test,variance_uc_test,variance_code_test=featureExtraction.EntropyPreProcessing(UC_documents_test,code_documents_test,idf_uc_dict_test,idf_code_dict_test,df_uc_dict_test,df_code_dict_test)\n",
        "#224 min"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "with open('./Dataset/errai_dataset/pickles/entropy_uc_train.pkl', 'wb') as f:\n",
        "       pickle.dump(entropy_uc_train, f)\n",
        "with open('./Dataset/errai_dataset/pickles/entropy_code_train.pkl', 'wb') as f:\n",
        "        pickle.dump(entropy_code_train, f)\n",
        "with open('./Dataset/errai_dataset/pickles/variance_uc_train.pkl', 'wb') as f:\n",
        "        pickle.dump(variance_uc_train, f)\n",
        "with open('./Dataset/errai_dataset/pickles/variance_code_train.pkl', 'wb') as f:\n",
        "        pickle.dump(variance_code_train, f)\n",
        "\n",
        "with open('./Dataset/errai_dataset/pickles/entropy_uc_test.pkl', 'wb') as f:\n",
        "       pickle.dump(entropy_uc_test, f)\n",
        "with open('./Dataset/errai_dataset/pickles/entropy_code_test.pkl', 'wb') as f:\n",
        "        pickle.dump(entropy_code_test, f)\n",
        "with open('./Dataset/errai_dataset/pickles/variance_uc_test.pkl', 'wb') as f:\n",
        "        pickle.dump(variance_uc_test, f)\n",
        "with open('./Dataset/errai_dataset/pickles/variance_code_test.pkl', 'wb') as f:\n",
        "        pickle.dump(variance_code_test, f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "entropy_uc_train = np.load('./Dataset/errai_dataset/pickles/entropy_uc_train.pkl',allow_pickle=True)\n",
        "entropy_code_train = np.load('./Dataset/errai_dataset/pickles/entropy_code_train.pkl',allow_pickle=True)\n",
        "variance_uc_train = np.load('./Dataset/errai_dataset/pickles/variance_uc_train.pkl',allow_pickle=True)\n",
        "variance_code_train = np.load('./Dataset/errai_dataset/pickles/variance_code_train.pkl',allow_pickle=True)\n",
        "entropy_uc_test = np.load('./Dataset/errai_dataset/pickles/entropy_uc_test.pkl',allow_pickle=True)\n",
        "entropy_code_test = np.load('./Dataset/errai_dataset/pickles/entropy_code_test.pkl',allow_pickle=True)\n",
        "variance_uc_test = np.load('./Dataset/errai_dataset/pickles/variance_uc_test.pkl',allow_pickle=True)\n",
        "variance_code_test = np.load('./Dataset/errai_dataset/pickles/variance_code_test.pkl',allow_pickle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# variance_uc_train,variance_code_train= featureExtraction.VarPreProcessing(UC_documents_train,code_documents_train,idf_uc_dict_train,idf_code_dict_train)\n",
        "PMI_uc_train,PMI_code_train=featureExtraction.PMIPreProcessing(code_documents_train,UC_documents_train)\n",
        "SCQ_uc_train,SCQ_code_train = featureExtraction.SCQPreProcessing(UC_documents_train,code_documents_train,tf_uc_dict_train,tf_code_dict_train,idf_uc_dict_train,idf_code_dict_train)\n",
        "\n",
        "# variance_uc_test,variance_code_test= featureExtraction.VarPreProcessing(UC_documents_test,code_documents_test,idf_uc_dict_test,idf_code_dict_test)\n",
        "PMI_uc_test,PMI_code_test=featureExtraction.PMIPreProcessing(code_documents_test,UC_documents_test)\n",
        "SCQ_uc_test,SCQ_code_test = featureExtraction.SCQPreProcessing(UC_documents_test,code_documents_test,tf_uc_dict_test,tf_code_dict_test,idf_uc_dict_test,idf_code_dict_test)\n",
        "#6min"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "with open('./Dataset/errai_dataset/pickles/PMI_uc_train.pkl', 'wb') as f:\n",
        "       pickle.dump(PMI_uc_train, f)\n",
        "with open('./Dataset/errai_dataset/pickles/PMI_code_train.pkl', 'wb') as f:\n",
        "        pickle.dump(PMI_code_train, f)\n",
        "\n",
        "with open('./Dataset/errai_dataset/pickles/SCQ_uc_train.pkl', 'wb') as f:\n",
        "         pickle.dump(SCQ_uc_train, f)\n",
        "with open('./Dataset/errai_dataset/pickles/SCQ_code_train.pkl', 'wb') as f:\n",
        "        pickle.dump(SCQ_code_train, f)\n",
        "\n",
        "with open('./Dataset/errai_dataset/pickles/PMI_uc_test.pkl', 'wb') as f:\n",
        "    pickle.dump(PMI_uc_test, f)\n",
        "\n",
        "with open('./Dataset/errai_dataset/pickles/PMI_code_test.pkl', 'wb') as f:\n",
        "    pickle.dump(PMI_code_test, f)\n",
        "\n",
        "with open('./Dataset/errai_dataset/pickles/SCQ_uc_test.pkl', 'wb') as f:\n",
        "    pickle.dump(SCQ_uc_test, f)\n",
        "\n",
        "with open('./Dataset/errai_dataset/pickles/SCQ_code_test.pkl', 'wb') as f:\n",
        "    pickle.dump(SCQ_code_test, f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "PMI_uc_train = np.load('./Dataset/errai_dataset/pickles/PMI_uc_train.pkl',allow_pickle=True)\n",
        "PMI_code_train = np.load('./Dataset/errai_dataset/pickles/PMI_code_train.pkl',allow_pickle=True)\n",
        "SCQ_uc_train = np.load('./Dataset/errai_dataset/pickles/SCQ_uc_train.pkl',allow_pickle=True)\n",
        "SCQ_code_train = np.load('./Dataset/errai_dataset/pickles/SCQ_code_train.pkl',allow_pickle=True)\n",
        "PMI_uc_test = np.load('./Dataset/errai_dataset/pickles/PMI_uc_test.pkl',allow_pickle=True)\n",
        "PMI_code_test = np.load('./Dataset/errai_dataset/pickles/PMI_code_test.pkl',allow_pickle=True)\n",
        "SCQ_uc_test = np.load('./Dataset/errai_dataset/pickles/SCQ_uc_test.pkl',allow_pickle=True)\n",
        "SCQ_code_test = np.load('./Dataset/errai_dataset/pickles/SCQ_code_test.pkl',allow_pickle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#-------------------------14 IR based features Train--------------------------#\n",
        "\n",
        "# # 1) Vector space model\n",
        "cosine_similarities_feature_train = featureExtraction.VectorSpaceModel(tfidf_matrix_uc_train, tfidf_matrix_code_train)\n",
        "print(\"cosine_similarities_feature_train\", cosine_similarities_feature_train.shape)\n",
        "# Our model will classify based on the ranks of the data rather than their actual values.\n",
        "cosine_similarity_UC_train = rankdata(-cosine_similarities_feature_train, method='dense', axis=1)\n",
        "print(\"cosine_similarity_UC_train\", cosine_similarity_UC_train.shape)\n",
        "cosine_similarity_CC_train = rankdata(-cosine_similarities_feature_train, method='dense', axis=0)\n",
        "print(\"cosine_similarity_CC_train\", cosine_similarity_CC_train.shape)\n",
        "\n",
        "np.save('./Dataset/errai_dataset/pickles/cosine_similarity_UC_train.npy', cosine_similarity_UC_train)\n",
        "np.save('./Dataset/errai_dataset/pickles/cosine_similarity_CC_train.npy', cosine_similarity_CC_train)\n",
        "\n",
        "# # 2) Latent semantic analysis\n",
        "LSA_similarities_feature_train = featureExtraction.LSA(tfidf_matrix_uc_train, tfidf_matrix_code_train)\n",
        "print('LSA similarity', LSA_similarities_feature_train.shape)\n",
        "\n",
        "LSA_similarities_UC_train = rankdata(-LSA_similarities_feature_train, method='dense', axis=1)\n",
        "print(\"LSA_similarities_UC_train\", LSA_similarities_UC_train.shape)\n",
        "LSA_similarities_CC_train = rankdata(-LSA_similarities_feature_train, method='dense', axis=0)\n",
        "print(\"LSA_similarities_CC_train\", LSA_similarities_CC_train.shape)\n",
        "\n",
        "\n",
        "np.save('./Dataset/errai_dataset/pickles/LSA_similarities_UC_train.npy', LSA_similarities_UC_train)\n",
        "np.save('./Dataset/errai_dataset/pickles/LSA_similarities_CC_train.npy', LSA_similarities_CC_train)\n",
        "\n",
        "# 3) Latent Dirichlet Allocation\n",
        "DocumentTopicDisUC_dense_train, DocumentTopicDisCode_dense_train, cosine_similarities_LDA_train = featureExtraction.LDA(UC_documents_train, code_documents_train, Vocab_UC_train)\n",
        "print('LDA similarity', cosine_similarities_LDA_train.shape)\n",
        "\n",
        "LDA_similarities_UC_train = rankdata(-cosine_similarities_LDA_train, method='dense', axis=1)\n",
        "print(\"LDA_similarities_UC_train\", LDA_similarities_UC_train.shape)\n",
        "LDA_similarities_CC_train = rankdata(-cosine_similarities_LDA_train, 'dense', axis=0)\n",
        "print(\"LDA_similarities_CC_train\", LDA_similarities_CC_train.shape)\n",
        "\n",
        "np.save('./Dataset/errai_dataset/pickles/LDA_similarities_UC_train.npy', LDA_similarities_UC_train)\n",
        "np.save('./Dataset/errai_dataset/pickles/LDA_similarities_CC_train.npy', LDA_similarities_CC_train)\n",
        "\n",
        "# 4) Jensen-Shannon(JS)\n",
        "JS_features_train = featureExtraction.JensenShannon(UC_count_matrix_train, code_count_matrix_train)\n",
        "print('JS', JS_features_train.shape)\n",
        "\n",
        "JS_UC_train = rankdata(-JS_features_train, method='dense', axis=1)\n",
        "print('JS_UC_train', JS_UC_train.shape)\n",
        "JS_CC_train = rankdata(-JS_features_train, method='dense', axis=0)\n",
        "print('JS_CC_train', JS_CC_train.shape)\n",
        "\n",
        "np.save('./Dataset/errai_dataset/pickles/JS_UC_train.npy', JS_UC_train)\n",
        "np.save('./Dataset/errai_dataset/pickles/JS_CC_train.npy', JS_CC_train)\n",
        "\n",
        "# 5)  Okapi BM25\n",
        "# UC means query is UC and document is code\n",
        "BM25_UC_train = featureExtraction.BM25(UC_documents_train, code_documents_train, idf_code_dict_train, code_count_matrix_train)\n",
        "BM25_CC_train = featureExtraction.BM25(code_documents_train, UC_documents_train, idf_uc_dict_train, UC_count_matrix_train)\n",
        "\n",
        "BM25_UC_train = rankdata(-BM25_UC_train, method='dense', axis=0)\n",
        "print(\"BM25_UC_train\", BM25_UC_train.shape)\n",
        "BM25_CC_train = rankdata(-BM25_CC_train, method='dense', axis=0)\n",
        "print(\"BM25_CC_train\", BM25_CC_train.shape)\n",
        "\n",
        "np.save('./Dataset/errai_dataset/pickles/BM25_UC_train.npy', BM25_UC_train)\n",
        "np.save('./Dataset/errai_dataset/pickles/BM25_CC_train.npy', BM25_CC_train)\n",
        "\n",
        "# 6) Language Model with Dirichlet\n",
        "# UC means UC is query and code is doc\n",
        "JM_UC_train = featureExtraction.SmoothingMethods(UC_documents_train, code_documents_train, code_count_matrix_train, tf_code_dict_train, JM_or_DP=True)\n",
        "JM_CC_train = featureExtraction.SmoothingMethods(code_documents_train, UC_documents_train, UC_count_matrix_train, tf_uc_dict_train, True)\n",
        "\n",
        "JM_UC_train = rankdata(-JM_UC_train, method='dense', axis=0)\n",
        "print(\"JM_UC_train\", JM_UC_train.shape)\n",
        "JM_CC_train = rankdata(-JM_CC_train, method='dense', axis=0)\n",
        "print(\"JM_CC_train\", JM_CC_train.shape)\n",
        "\n",
        "np.save('./Dataset/errai_dataset/pickles/JM_UC_train.npy', JM_UC_train)\n",
        "np.save('./Dataset/errai_dataset/pickles/JM_CC_train.npy', JM_CC_train)\n",
        "\n",
        "DP_UC_train = featureExtraction.SmoothingMethods(UC_documents_train, code_documents_train, code_count_matrix_train, tf_code_dict_train, JM_or_DP=False)\n",
        "DP_CC_train = featureExtraction.SmoothingMethods(code_documents_train, UC_documents_train, UC_count_matrix_train, tf_uc_dict_train, False)\n",
        "DP_UC_train = rankdata(-DP_UC_train, method='dense', axis=0)\n",
        "print(\"DP_UC_train\", DP_UC_train.shape)\n",
        "DP_CC_train = rankdata(-DP_CC_train, method='dense', axis=0)\n",
        "print(\"DP_CC_train\", DP_CC_train.shape)\n",
        "\n",
        "\n",
        "\n",
        "np.save('./Dataset/errai_dataset/pickles/DP_UC_train.npy', DP_UC_train)\n",
        "np.save('./Dataset/errai_dataset/pickles/DP_CC_train.npy', DP_CC_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "#-------------------------14 IR based features Test--------------------------#\n",
        "\n",
        "# 1) Vector space model\n",
        "cosine_similarities_feature_test = featureExtraction.VectorSpaceModel(tfidf_matrix_uc_test, tfidf_matrix_code_test)\n",
        "print(\"cosine_similarities_feature_test\", cosine_similarities_feature_test.shape)\n",
        "\n",
        "# Our model will classify based on the ranks of the data rather than their actual values.\n",
        "cosine_similarity_UC_test = rankdata(-cosine_similarities_feature_test, method='dense', axis=1)\n",
        "print(\"cosine_similarity_UC_test\", cosine_similarity_UC_test.shape)\n",
        "cosine_similarity_CC_test = rankdata(-cosine_similarities_feature_test, method='dense', axis=0)\n",
        "print(\"cosine_similarity_CC_test\", cosine_similarity_CC_test.shape)\n",
        "\n",
        "\n",
        "np.save('./Dataset/errai_dataset/pickles/cosine_similarity_UC_test.npy', cosine_similarity_UC_test)\n",
        "np.save('./Dataset/errai_dataset/pickles/cosine_similarity_CC_test.npy', cosine_similarity_CC_test)\n",
        "\n",
        "# 2) Latent semantic analysis\n",
        "LSA_similarities_feature_test = featureExtraction.LSA(tfidf_matrix_uc_test, tfidf_matrix_code_test)\n",
        "print('LSA similarity', LSA_similarities_feature_test.shape)\n",
        "\n",
        "LSA_similarities_UC_test = rankdata(-LSA_similarities_feature_test, method='dense', axis=1)\n",
        "print(\"LSA_similarities_UC_test\", LSA_similarities_UC_test.shape)\n",
        "LSA_similarities_CC_test = rankdata(-LSA_similarities_feature_test, method='dense', axis=0)\n",
        "print(\"LSA_similarities_CC_test\", LSA_similarities_CC_test.shape)\n",
        "\n",
        "np.save('./Dataset/errai_dataset/pickles/LSA_similarities_UC_test.npy', LSA_similarities_UC_test)\n",
        "np.save('./Dataset/errai_dataset/pickles/LSA_similarities_CC_test.npy', LSA_similarities_CC_test)\n",
        "\n",
        "# 3) Latent Dirichlet Allocation\n",
        "DocumentTopicDisUC_dense_test, DocumentTopicDisCode_dense_test, cosine_similarities_LDA_test = featureExtraction.LDA(UC_documents_test, code_documents_test, Vocab_UC_test)\n",
        "print('LDA similarity', cosine_similarities_LDA_test.shape)\n",
        "\n",
        "LDA_similarities_UC_test = rankdata(-cosine_similarities_LDA_test, method='dense', axis=1)\n",
        "print(\"LDA_similarities_UC_test\", LDA_similarities_UC_test.shape)\n",
        "LDA_similarities_CC_test = rankdata(-cosine_similarities_LDA_test, 'dense', axis=0)\n",
        "print(\"LDA_similarities_CC_test\", LDA_similarities_CC_test.shape)\n",
        "\n",
        "np.save('./Dataset/errai_dataset/pickles/LDA_similarities_UC_test.npy', LDA_similarities_UC_test)\n",
        "np.save('./Dataset/errai_dataset/pickles/LDA_similarities_CC_test.npy', LDA_similarities_CC_test)\n",
        "\n",
        "# 4) Jensen-Shannon(JS)\n",
        "JS_features_test = featureExtraction.JensenShannon(UC_count_matrix_test, code_count_matrix_test)\n",
        "print('JS', JS_features_test.shape)\n",
        "\n",
        "JS_UC_test = rankdata(-JS_features_test, method='dense', axis=1)\n",
        "print('JS_UC_test', JS_UC_test.shape)\n",
        "JS_CC_test = rankdata(-JS_features_test, method='dense', axis=0)\n",
        "print('JS_CC_test', JS_CC_test.shape)\n",
        "\n",
        "np.save('./Dataset/errai_dataset/pickles/JS_UC_test.npy', JS_UC_test)\n",
        "np.save('./Dataset/errai_dataset/pickles/JS_CC_test.npy', JS_CC_test)\n",
        "\n",
        "# 5)  Okapi BM25\n",
        "# UC means query is UC and document is code\n",
        "BM25_UC_test = featureExtraction.BM25(UC_documents_test, code_documents_test, idf_code_dict_test, code_count_matrix_test)\n",
        "BM25_CC_test = featureExtraction.BM25(code_documents_test, UC_documents_test, idf_uc_dict_test, UC_count_matrix_test)\n",
        "\n",
        "BM25_UC_test = rankdata(-BM25_UC_test, method='dense', axis=0)\n",
        "print(\"BM25_UC_test\", BM25_UC_test.shape)\n",
        "BM25_CC_test = rankdata(-BM25_CC_test, method='dense', axis=0)\n",
        "print(\"BM25_CC_test\", BM25_CC_test.shape)\n",
        "\n",
        "np.save('./Dataset/errai_dataset/pickles/BM25_UC_test.npy', BM25_UC_test)\n",
        "np.save('./Dataset/errai_dataset/pickles/BM25_CC_test.npy', BM25_CC_test)\n",
        "\n",
        "# 6) Language Model with Dirichlet\n",
        "# UC means UC is query and code is doc\n",
        "JM_UC_test = featureExtraction.SmoothingMethods(UC_documents_test, code_documents_test, code_count_matrix_test, tf_code_dict_test, JM_or_DP=True)\n",
        "JM_CC_test = featureExtraction.SmoothingMethods(code_documents_test, UC_documents_test, UC_count_matrix_test, tf_uc_dict_test, True)\n",
        "JM_UC_test = rankdata(-JM_UC_test, method='dense', axis=0)\n",
        "print(\"JM_UC_test\", JM_UC_test.shape)\n",
        "JM_CC_test = rankdata(-JM_CC_test, method='dense', axis=0)\n",
        "print(\"JM_CC_test\", JM_CC_test.shape)\n",
        "\n",
        "np.save('./Dataset/errai_dataset/pickles/JM_UC_test.npy', JM_UC_test)\n",
        "np.save('./Dataset/errai_dataset/pickles/JM_CC_test.npy', JM_CC_test)\n",
        "\n",
        "DP_UC_test = featureExtraction.SmoothingMethods(UC_documents_test, code_documents_test, code_count_matrix_test, tf_code_dict_test, JM_or_DP=False)\n",
        "DP_CC_test = featureExtraction.SmoothingMethods(code_documents_test, UC_documents_test, UC_count_matrix_test, tf_uc_dict_test, False)\n",
        "DP_UC_test = rankdata(-DP_UC_test, method='dense', axis=0)\n",
        "print(\"DP_UC_test\", DP_UC_test.shape)\n",
        "DP_CC_test = rankdata(-DP_CC_test, method='dense', axis=0)\n",
        "print(\"DP_CC_test\", DP_CC_test.shape)\n",
        "\n",
        "np.save('./Dataset/errai_dataset/pickles/DP_UC_test.npy', DP_UC_test)\n",
        "np.save('./Dataset/errai_dataset/pickles/DP_CC_test.npy', DP_CC_test)\n",
        "\n",
        "\n",
        "#200 MIN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#-----------------------IR Train Features Loading------------------#\n",
        "cosine_similarity_UC_train = np.load('./Dataset/errai_dataset/pickles/cosine_similarity_UC_train.npy')\n",
        "cosine_similarity_CC_train = np.load('./Dataset/errai_dataset/pickles/cosine_similarity_CC_train.npy')\n",
        "LSA_similarities_UC_train = np.load('./Dataset/errai_dataset/pickles/LSA_similarities_UC_train.npy')\n",
        "LSA_similarities_CC_train = np.load('./Dataset/errai_dataset/pickles/LSA_similarities_CC_train.npy')\n",
        "LDA_similarities_UC_train = np.load('./Dataset/errai_dataset/pickles/LDA_similarities_UC_train.npy')\n",
        "LDA_similarities_CC_train = np.load('./Dataset/errai_dataset/pickles/LDA_similarities_CC_train.npy')\n",
        "JS_UC_train = np.load('./Dataset/errai_dataset/pickles/JS_UC_train.npy')\n",
        "JS_CC_train = np.load('./Dataset/errai_dataset/pickles/JS_CC_train.npy')\n",
        "BM25_UC_train = np.load('./Dataset/errai_dataset/pickles/BM25_UC_train.npy')\n",
        "BM25_CC_train = np.load('./Dataset/errai_dataset/pickles/BM25_CC_train.npy')\n",
        "JM_UC_train = np.load('./Dataset/errai_dataset/pickles/JM_UC_train.npy')\n",
        "JM_CC_train = np.load('./Dataset/errai_dataset/pickles/JM_CC_train.npy')\n",
        "DP_UC_train = np.load('./Dataset/errai_dataset/pickles/DP_UC_train.npy')\n",
        "DP_CC_train = np.load('./Dataset/errai_dataset/pickles/DP_CC_train.npy')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#-----------------------IR Test Features Loading------------------#\n",
        "cosine_similarity_UC_test = np.load('./Dataset/errai_dataset/pickles/cosine_similarity_UC_test.npy')\n",
        "cosine_similarity_CC_test = np.load('./Dataset/errai_dataset/pickles/cosine_similarity_CC_test.npy')\n",
        "LSA_similarities_UC_test = np.load('./Dataset/errai_dataset/pickles/LSA_similarities_UC_test.npy')\n",
        "LSA_similarities_CC_test = np.load('./Dataset/errai_dataset/pickles/LSA_similarities_CC_test.npy')\n",
        "LDA_similarities_UC_test = np.load('./Dataset/errai_dataset/pickles/LDA_similarities_UC_test.npy')\n",
        "LDA_similarities_CC_test = np.load('./Dataset/errai_dataset/pickles/LDA_similarities_CC_test.npy')\n",
        "JS_UC_test = np.load('./Dataset/errai_dataset/pickles/JS_UC_test.npy')\n",
        "JS_CC_test = np.load('./Dataset/errai_dataset/pickles/JS_CC_test.npy')\n",
        "BM25_UC_test = np.load('./Dataset/errai_dataset/pickles/BM25_UC_test.npy')\n",
        "BM25_CC_test = np.load('./Dataset/errai_dataset/pickles/BM25_CC_test.npy')\n",
        "JM_UC_test = np.load('./Dataset/errai_dataset/pickles/JM_UC_test.npy')\n",
        "JM_CC_test = np.load('./Dataset/errai_dataset/pickles/JM_CC_test.npy')\n",
        "DP_UC_test = np.load('./Dataset/errai_dataset/pickles/DP_UC_test.npy')\n",
        "DP_CC_test = np.load('./Dataset/errai_dataset/pickles/DP_CC_test.npy')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "cosine_similarity_UC_train = normalizer.fit_transform(cosine_similarity_UC_train)\n",
        "cosine_similarity_CC_train = normalizer.fit_transform(cosine_similarity_CC_train)\n",
        "LSA_similarities_UC_train = normalizer.fit_transform(LSA_similarities_UC_train)\n",
        "LSA_similarities_CC_train = normalizer.fit_transform(LSA_similarities_CC_train)\n",
        "LDA_similarities_UC_train = normalizer.fit_transform(LDA_similarities_UC_train)\n",
        "LDA_similarities_CC_train = normalizer.fit_transform(LDA_similarities_CC_train)\n",
        "JS_UC_train = normalizer.fit_transform(JS_UC_train)\n",
        "JS_CC_train = normalizer.fit_transform(JS_CC_train)\n",
        "BM25_UC_train = normalizer.fit_transform(BM25_UC_train)\n",
        "BM25_CC_train = normalizer.fit_transform(BM25_CC_train)\n",
        "JM_UC_train = normalizer.fit_transform(JM_UC_train)\n",
        "JM_CC_train = normalizer.fit_transform(JM_CC_train)\n",
        "DP_UC_train = normalizer.fit_transform(DP_UC_train)\n",
        "DP_CC_train = normalizer.fit_transform(DP_CC_train)\n",
        "\n",
        "\n",
        "cosine_similarity_UC_test = normalizer.fit_transform(cosine_similarity_UC_test)\n",
        "cosine_similarity_CC_test = normalizer.fit_transform(cosine_similarity_CC_test)\n",
        "LSA_similarities_UC_test = normalizer.fit_transform(LSA_similarities_UC_test)\n",
        "LSA_similarities_CC_test = normalizer.fit_transform(LSA_similarities_CC_test)\n",
        "LDA_similarities_UC_test = normalizer.fit_transform(LDA_similarities_UC_test)\n",
        "LDA_similarities_CC_test = normalizer.fit_transform(LDA_similarities_CC_test)\n",
        "JS_UC_test = normalizer.fit_transform(JS_UC_test)\n",
        "JS_CC_test = normalizer.fit_transform(JS_CC_test)\n",
        "BM25_UC_test = normalizer.fit_transform(BM25_UC_test)\n",
        "BM25_CC_test = normalizer.fit_transform(BM25_CC_test)\n",
        "JM_UC_test = normalizer.fit_transform(JM_UC_test)\n",
        "JM_CC_test = normalizer.fit_transform(JM_CC_test)\n",
        "DP_UC_test = normalizer.fit_transform(DP_UC_test)\n",
        "DP_CC_test = normalizer.fit_transform(DP_CC_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ------------------------pre-retrieval (21 metrics) Train--------------------------#\n",
        "# 1) IDF Features\n",
        "avg_idf_uc_train = featureExtraction.AvgIDF(idf_uc_train)\n",
        "avg_idf_code_train = featureExtraction.AvgIDF(idf_code_train)\n",
        "\n",
        "print('avg_idf_uc_train_shape', avg_idf_uc_train.shape) \n",
        "print('avg_idf_code_train_shape', avg_idf_code_train.shape) \n",
        "\n",
        "max_idf_uc_train = featureExtraction.MaxIDF(idf_uc_train)\n",
        "max_idf_code_train = featureExtraction.MaxIDF(idf_code_train)\n",
        "\n",
        "print('max_idf_uc_train_shape', max_idf_uc_train.shape) \n",
        "print('max_idf_code_train_shape', max_idf_code_train.shape) \n",
        "\n",
        "dev_idf_uc_train = featureExtraction.DevIDF(idf_uc_train)\n",
        "dev_idf_code_train = featureExtraction.DevIDF(idf_code_train)\n",
        "\n",
        "print('dev_idf_uc_train_shape', dev_idf_uc_train.shape) \n",
        "print('dev_idf_code_train_shape', dev_idf_code_train.shape) \n",
        "\n",
        "# 2) ICTF Features\n",
        "avg_ictf_uc_train = featureExtraction.AvgICTF(ictf_uc_train)\n",
        "avg_ictf_code_train = featureExtraction.AvgICTF(ictf_code_train)\n",
        "\n",
        "print('avg_ictf_uc_train_shape', avg_ictf_uc_train.shape)\n",
        "print('avg_ictf_code_train_shape', avg_ictf_code_train.shape)\n",
        "\n",
        "max_ictf_uc_train = featureExtraction.MaxICTF(ictf_uc_train)\n",
        "max_ictf_code_train = featureExtraction.MaxICTF(ictf_code_train)\n",
        "\n",
        "print('max_ictf_uc_train_shape', max_ictf_uc_train.shape)\n",
        "print('max_ictf_code_train_shape', max_ictf_code_train.shape)\n",
        "\n",
        "dev_ictf_uc_train = featureExtraction.DevICTF(ictf_uc_train)\n",
        "dev_ictf_code_train = featureExtraction.DevICTF(ictf_code_train)\n",
        "\n",
        "print('dev_ictf_uc_train_shape', dev_ictf_uc_train.shape)\n",
        "print('dev_ictf_code_train_shape', dev_ictf_code_train.shape)\n",
        "# 3) Entropy Features\n",
        "\n",
        "avg_entropy_uc_train = featureExtraction.AvgEntropy(entropy_uc_train)\n",
        "avg_entropy_code_train = featureExtraction.AvgEntropy(entropy_code_train)\n",
        "\n",
        "print('avg_entropy_uc_train_shape', avg_entropy_uc_train.shape)\n",
        "print('avg_entropy_code_train_shape', avg_entropy_code_train.shape)\n",
        "\n",
        "max_entropy_uc_train = featureExtraction.MaxEntropy(entropy_uc_train)\n",
        "max_entropy_code_train = featureExtraction.MaxEntropy(entropy_code_train) \n",
        "\n",
        "print('max_entropy_uc_train_shape', max_entropy_uc_train.shape)\n",
        "print('max_entropy_code_train_shape', max_entropy_code_train.shape)\n",
        "\n",
        "med_entropy_uc_train = featureExtraction.MedEntropy(entropy_uc_train)\n",
        "med_entropy_code_train = featureExtraction.MedEntropy(entropy_code_train)\n",
        "\n",
        "print('med_entropy_uc_train_shape', med_entropy_uc_train.shape)\n",
        "print('med_entropy_code_train_shape', med_entropy_code_train.shape)\n",
        "\n",
        "dev_entropy_uc_train = featureExtraction.DevEntropy(entropy_uc_train)\n",
        "dev_entropy_code_train = featureExtraction.DevEntropy(entropy_code_train)\n",
        "\n",
        "print('dev_entropy_uc_train_shape', dev_entropy_uc_train.shape)\n",
        "print('dev_entropy_code_train_shape', dev_entropy_code_train.shape)\n",
        "      \n",
        "\n",
        "# 4) Variance Features\n",
        "\n",
        "avg_variance_uc_train = featureExtraction.AvgVariance(variance_uc_train)\n",
        "avg_variance_code_train = featureExtraction.AvgVariance(variance_code_train)\n",
        "\n",
        "print('avg_variance_uc_train_shape', avg_variance_uc_train.shape)\n",
        "print('avg_variance_code_train_shape', avg_variance_code_train.shape)\n",
        "\n",
        "max_variance_uc_train = featureExtraction.MaxVariance(variance_uc_train)\n",
        "max_variance_code_train = featureExtraction.MaxVariance(variance_code_train) \n",
        "\n",
        "print('max_variance_uc_train_shape', max_variance_uc_train.shape)\n",
        "print('max_variance_code_train_shape', max_variance_code_train.shape)\n",
        "\n",
        "sum_variance_uc_train = featureExtraction.SumVariance(variance_uc_train) \n",
        "sum_variance_code_train = featureExtraction.SumVariance(variance_code_train)\n",
        "\n",
        "print('sum_variance_uc_train_shape', sum_variance_uc_train.shape)\n",
        "print('sum_variance_code_train_shape', sum_variance_code_train.shape)\n",
        "# 5) SCQ Features\n",
        "avg_scq_uc_train = featureExtraction.AvgSCQ(SCQ_uc_train)\n",
        "avg_scq_code_train = featureExtraction.AvgSCQ(SCQ_code_train)\n",
        "\n",
        "print('avg_scq_uc_train_shape', avg_scq_uc_train.shape)\n",
        "print('avg_scq_code_train_shape', avg_scq_code_train.shape)\n",
        "\n",
        "max_scq_uc_train = featureExtraction.MaxSCQ(SCQ_uc_train) \n",
        "max_scq_code_train = featureExtraction.MaxSCQ(SCQ_code_train)\n",
        "\n",
        "print('max_scq_uc_train_shape', max_scq_uc_train.shape)\n",
        "print('max_scq_code_train_shape', max_scq_code_train.shape)\n",
        "\n",
        "sum_sqc_uc_train = featureExtraction.SumSCQ(SCQ_uc_train) \n",
        "sum_sqc_code_train = featureExtraction.SumSCQ(SCQ_code_train)\n",
        "\n",
        "print('sum_sqc_uc_train_shape', sum_sqc_uc_train.shape)\n",
        "print('sum_sqc_code_train_shape', sum_sqc_code_train.shape)\n",
        "\n",
        "# 6) PMI Features\n",
        "\n",
        "avg_pmi_uc_train = featureExtraction.AvgPMI(PMI_uc_train)\n",
        "avg_pmi_code_train = featureExtraction.AvgPMI(PMI_code_train)\n",
        "\n",
        "print('avg_pmi_uc_train_shape', avg_pmi_uc_train.shape)\n",
        "print('avg_pmi_code_train_shape', avg_pmi_code_train.shape)\n",
        "\n",
        "max_pmi_uc_train = featureExtraction.MaxPMI(PMI_uc_train)\n",
        "max_pmi_code_train = featureExtraction.MaxPMI(PMI_code_train) \n",
        "\n",
        "print('max_pmi_uc_train_shape', max_pmi_uc_train.shape)\n",
        "print('max_pmi_code_train_shape', max_pmi_code_train.shape)\n",
        "# 7) QS Features\n",
        "\n",
        "qs_uc_train = featureExtraction.QS(UC_documents_train, code_documents_train)\n",
        "qs_code_train = featureExtraction.QS(code_documents_train, UC_documents_train)\n",
        "\n",
        "print('qs_uc_train_shape', qs_uc_train.shape)\n",
        "print('qs_code_train_shape', qs_code_train.shape)\n",
        "\n",
        "# 8) SCS Features\n",
        "UC_SCS_train = featureExtraction.simplifiedClarityScore(UC_documents_train, UC_count_matrix_train, tf_code_dict_train) \n",
        "CC_SCS_train = featureExtraction.simplifiedClarityScore(code_documents_train, code_count_matrix_train, tf_uc_dict_train) \n",
        "print(tf_code_dict_train)\n",
        "\n",
        "print('UC_SCS_train_shape', UC_SCS_train.shape)\n",
        "print('CC_SCS_train_shape', CC_SCS_train.shape)\n",
        "\n",
        "# 9) Coherence Score Features\n",
        "UC_CoherenceScore_train = featureExtraction.CoherenceScore(UC_documents_train, tfidf_matrix_code_train) \n",
        "CC_CoherenceScore_train = featureExtraction.CoherenceScore(code_documents_train, tfidf_matrix_uc_train) \n",
        "\n",
        "print('UC_CoherenceScore_train_shape', UC_CoherenceScore_train.shape)\n",
        "print('CC_CoherenceScore_train_shape', CC_CoherenceScore_train.shape)\n",
        "\n",
        "#75min"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#----------------saving pre retrival Train------------------#\n",
        "np.save('./Dataset/errai_dataset/pickles/avg_idf_uc_train.npy', avg_idf_uc_train)\n",
        "np.save('./Dataset/errai_dataset/pickles/avg_idf_code_train.npy', avg_idf_code_train)\n",
        "np.save('./Dataset/errai_dataset/pickles/max_idf_uc_train.npy', max_idf_uc_train)\n",
        "np.save('./Dataset/errai_dataset/pickles/max_idf_code_train.npy', max_idf_code_train)\n",
        "np.save('./Dataset/errai_dataset/pickles/dev_idf_uc_train.npy', dev_idf_uc_train)\n",
        "np.save('./Dataset/errai_dataset/pickles/dev_idf_code_train.npy', dev_idf_code_train)\n",
        "np.save('./Dataset/errai_dataset/pickles/avg_ictf_uc_train.npy', avg_ictf_uc_train)\n",
        "np.save('./Dataset/errai_dataset/pickles/avg_ictf_code_train.npy', avg_ictf_code_train)\n",
        "np.save('./Dataset/errai_dataset/pickles/max_ictf_uc_train.npy', max_ictf_uc_train)\n",
        "np.save('./Dataset/errai_dataset/pickles/max_ictf_code_train.npy', max_ictf_code_train)\n",
        "np.save('./Dataset/errai_dataset/pickles/dev_ictf_uc_train.npy', dev_ictf_uc_train)\n",
        "np.save('./Dataset/errai_dataset/pickles/dev_ictf_code_train.npy', dev_ictf_code_train)\n",
        "np.save('./Dataset/errai_dataset/pickles/avg_entropy_uc_train.npy', avg_entropy_uc_train)\n",
        "np.save('./Dataset/errai_dataset/pickles/avg_entropy_code_train.npy', avg_entropy_code_train)\n",
        "np.save('./Dataset/errai_dataset/pickles/max_entropy_uc_train.npy', max_entropy_uc_train)\n",
        "np.save('./Dataset/errai_dataset/pickles/max_entropy_code_train.npy', max_entropy_code_train)\n",
        "np.save('./Dataset/errai_dataset/pickles/max_entropy_uc_train.npy', max_entropy_uc_train)\n",
        "np.save('./Dataset/errai_dataset/pickles/max_entropy_code_train.npy', max_entropy_code_train)\n",
        "np.save('./Dataset/errai_dataset/pickles/med_entropy_uc_train.npy', med_entropy_uc_train)\n",
        "np.save('./Dataset/errai_dataset/pickles/med_entropy_code_train.npy', med_entropy_code_train)\n",
        "np.save('./Dataset/errai_dataset/pickles/dev_entropy_uc_train.npy', dev_entropy_uc_train)\n",
        "np.save('./Dataset/errai_dataset/pickles/dev_entropy_code_train.npy', dev_entropy_code_train)\n",
        "np.save('./Dataset/errai_dataset/pickles/avg_variance_uc_train.npy', avg_variance_uc_train)\n",
        "np.save('./Dataset/errai_dataset/pickles/avg_variance_code_train.npy', avg_variance_code_train)\n",
        "np.save('./Dataset/errai_dataset/pickles/max_variance_uc_train.npy', max_variance_uc_train)\n",
        "np.save('./Dataset/errai_dataset/pickles/max_variance_code_train.npy', max_variance_code_train)\n",
        "np.save('./Dataset/errai_dataset/pickles/sum_variance_uc_train.npy', sum_variance_uc_train)\n",
        "np.save('./Dataset/errai_dataset/pickles/sum_variance_code_train.npy', sum_variance_code_train)\n",
        "np.save('./Dataset/errai_dataset/pickles/avg_scq_uc_train.npy', avg_scq_uc_train)\n",
        "np.save('./Dataset/errai_dataset/pickles/avg_scq_code_train.npy', avg_scq_code_train)\n",
        "np.save('./Dataset/errai_dataset/pickles/max_scq_uc_train.npy', max_scq_uc_train)\n",
        "np.save('./Dataset/errai_dataset/pickles/max_scq_code_train.npy', max_scq_code_train)\n",
        "np.save('./Dataset/errai_dataset/pickles/sum_sqc_uc_train.npy', sum_sqc_uc_train)\n",
        "np.save('./Dataset/errai_dataset/pickles/sum_sqc_code_train.npy', sum_sqc_code_train)\n",
        "np.save('./Dataset/errai_dataset/pickles/avg_pmi_uc_train.npy', avg_pmi_uc_train)\n",
        "np.save('./Dataset/errai_dataset/pickles/avg_pmi_code_train.npy', avg_pmi_code_train)\n",
        "np.save('./Dataset/errai_dataset/pickles/max_pmi_uc_train.npy', max_pmi_uc_train)\n",
        "np.save('./Dataset/errai_dataset/pickles/max_pmi_code_train.npy', max_pmi_code_train)\n",
        "np.save('./Dataset/errai_dataset/pickles/qs_uc_train.npy', qs_uc_train)\n",
        "np.save('./Dataset/errai_dataset/pickles/qs_code_train.npy', qs_code_train)\n",
        "np.save('./Dataset/errai_dataset/pickles/UC_SCS_train.npy', UC_SCS_train)\n",
        "np.save('./Dataset/errai_dataset/pickles/CC_SCS_train.npy', CC_SCS_train)\n",
        "np.save('./Dataset/errai_dataset/pickles/UC_CoherenceScore_train.npy', UC_CoherenceScore_train)\n",
        "np.save('./Dataset/errai_dataset/pickles/CC_CoherenceScore_train.npy', CC_CoherenceScore_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ------------------------pre-retrieval (21 metrics) Test--------------------------#\n",
        "# 1) IDF Features\n",
        "avg_idf_uc_test = featureExtraction.AvgIDF(idf_uc_test)\n",
        "avg_idf_code_test = featureExtraction.AvgIDF(idf_code_test)\n",
        "\n",
        "print('avg_idf_uc_test_shape', avg_idf_uc_test.shape)\n",
        "print('avg_idf_code_test_shape', avg_idf_code_test.shape)\n",
        "\n",
        "max_idf_uc_test = featureExtraction.MaxIDF(idf_uc_test)\n",
        "max_idf_code_test = featureExtraction.MaxIDF(idf_code_test)\n",
        "print('max_idf_uc_test_shape', max_idf_uc_test.shape)\n",
        "print('max_idf_code_test_shape', max_idf_code_test.shape)\n",
        "\n",
        "dev_idf_uc_test = featureExtraction.DevIDF(idf_uc_test)\n",
        "dev_idf_code_test = featureExtraction.DevIDF(idf_code_test)\n",
        "\n",
        "print('dev_idf_uc_test_shape', dev_idf_uc_test.shape)\n",
        "print('dev_idf_code_test_shape', dev_idf_code_test.shape)\n",
        "\n",
        "# 2) ICTF Features\n",
        "avg_ictf_uc_test = featureExtraction.AvgICTF(ictf_uc_test)\n",
        "avg_ictf_code_test = featureExtraction.AvgICTF(ictf_code_test)\n",
        "\n",
        "print('avg_ictf_uc_test_shape', avg_ictf_uc_test.shape)\n",
        "print('avg_ictf_code_test_shape', avg_ictf_code_test.shape)\n",
        "\n",
        "max_ictf_uc_test = featureExtraction.MaxICTF(ictf_uc_test)\n",
        "max_ictf_code_test = featureExtraction.MaxICTF(ictf_code_test)\n",
        "print('max_ictf_uc_test_shape', max_ictf_uc_test.shape)\n",
        "print('max_ictf_code_test_shape', max_ictf_code_test.shape)\n",
        "\n",
        "dev_ictf_uc_test = featureExtraction.DevICTF(ictf_uc_test)\n",
        "dev_ictf_code_test = featureExtraction.DevICTF(ictf_code_test)\n",
        "\n",
        "print('dev_ictf_uc_test_shape', dev_ictf_uc_test.shape)\n",
        "print('dev_ictf_code_test_shape', dev_ictf_code_test.shape)\n",
        "\n",
        "# 3) Entropy Features\n",
        "avg_entropy_uc_test = featureExtraction.AvgEntropy(entropy_uc_test)\n",
        "avg_entropy_code_test = featureExtraction.AvgEntropy(entropy_code_test)\n",
        "\n",
        "print('avg_entropy_uc_test_shape', avg_entropy_uc_test.shape)\n",
        "print('avg_entropy_code_test_shape', avg_entropy_code_test.shape)\n",
        "\n",
        "max_entropy_uc_test = featureExtraction.MaxEntropy(entropy_uc_test)\n",
        "max_entropy_code_test = featureExtraction.MaxEntropy(entropy_code_test)\n",
        "\n",
        "print('max_entropy_uc_test_shape', max_entropy_uc_test.shape)\n",
        "print('max_entropy_code_test_shape', max_entropy_code_test.shape)\n",
        "\n",
        "med_entropy_uc_test = featureExtraction.MedEntropy(entropy_uc_test)\n",
        "med_entropy_code_test = featureExtraction.MedEntropy(entropy_code_test)\n",
        "\n",
        "print('med_entropy_uc_test_shape', med_entropy_uc_test.shape)\n",
        "print('med_entropy_code_test_shape', med_entropy_code_test.shape)\n",
        "\n",
        "dev_entropy_uc_test = featureExtraction.DevEntropy(entropy_uc_test)\n",
        "dev_entropy_code_test = featureExtraction.DevEntropy(entropy_code_test)\n",
        "\n",
        "print('dev_entropy_uc_test_shape', dev_entropy_uc_test.shape)\n",
        "print('dev_entropy_code_test_shape', dev_entropy_code_test.shape)\n",
        "\n",
        "# 4) Variance Features\n",
        "\n",
        "avg_variance_uc_test = featureExtraction.AvgVariance(variance_uc_test)\n",
        "avg_variance_code_test = featureExtraction.AvgVariance(variance_code_test)\n",
        "print('avg_variance_uc_test_shape', avg_variance_uc_test.shape)\n",
        "print('avg_variance_code_test_shape', avg_variance_code_test.shape)\n",
        "\n",
        "max_variance_uc_test = featureExtraction.MaxVariance(variance_uc_test)\n",
        "max_variance_code_test = featureExtraction.MaxVariance(variance_code_test)\n",
        "\n",
        "print('max_variance_uc_test_shape', max_variance_uc_test.shape)\n",
        "print('max_variance_code_test_shape', max_variance_code_test.shape)\n",
        "\n",
        "sum_variance_uc_test = featureExtraction.SumVariance(variance_uc_test)\n",
        "sum_variance_code_test = featureExtraction.SumVariance(variance_code_test)\n",
        "\n",
        "print('sum_variance_uc_test_shape', sum_variance_uc_test.shape)\n",
        "print('sum_variance_code_test_shape', sum_variance_code_test.shape)\n",
        "\n",
        "# 5) SCQ Features\n",
        "avg_scq_uc_test = featureExtraction.AvgSCQ(SCQ_uc_test)\n",
        "avg_scq_code_test = featureExtraction.AvgSCQ(SCQ_code_test) \n",
        "\n",
        "print('avg_scq_uc_test_shape', avg_scq_uc_test.shape)\n",
        "print('avg_scq_code_test_shape', avg_scq_code_test.shape)\n",
        "\n",
        "max_scq_uc_test = featureExtraction.MaxSCQ(SCQ_uc_test)\n",
        "max_scq_code_test = featureExtraction.MaxSCQ(SCQ_code_test)\n",
        "\n",
        "print('max_scq_uc_test_shape', max_scq_uc_test.shape)\n",
        "print('max_scq_code_test_shape', max_scq_code_test.shape)\n",
        "\n",
        "sum_sqc_uc_test = featureExtraction.SumSCQ(SCQ_uc_test) \n",
        "sum_sqc_code_test = featureExtraction.SumSCQ(SCQ_code_test)\n",
        "\n",
        "print('sum_sqc_uc_test_shape', sum_sqc_uc_test.shape)\n",
        "print('sum_sqc_code_test_shape', sum_sqc_code_test.shape)\n",
        "\n",
        "# 6) PMI Features\n",
        "\n",
        "avg_pmi_uc_test = featureExtraction.AvgPMI(PMI_uc_test) \n",
        "avg_pmi_code_test = featureExtraction.AvgPMI(PMI_code_test)\n",
        "\n",
        "print('avg_pmi_uc_test_shape', avg_pmi_uc_test.shape)\n",
        "print('avg_pmi_code_test_shape', avg_pmi_code_test.shape)\n",
        "\n",
        "max_pmi_uc_test = featureExtraction.MaxPMI(PMI_uc_test)\n",
        "max_pmi_code_test = featureExtraction.MaxPMI(PMI_code_test)\n",
        "print('max_pmi_uc_test_shape', max_pmi_uc_test.shape)\n",
        "print('max_pmi_code_test_shape', max_pmi_code_test.shape)\n",
        "\n",
        "# 7) QS Features\n",
        "\n",
        "qs_uc_test = featureExtraction.QS(UC_documents_test, code_documents_test)\n",
        "qs_code_test = featureExtraction.QS(code_documents_test, UC_documents_test)\n",
        "\n",
        "print('qs_uc_test_shape', qs_uc_test.shape)\n",
        "print('qs_code_test_shape', qs_code_test.shape)\n",
        "\n",
        "# 8) SCS Features\n",
        "UC_SCS_test = featureExtraction.simplifiedClarityScore(UC_documents_test, UC_count_matrix_test, tf_code_dict_test) \n",
        "CC_SCS_test = featureExtraction.simplifiedClarityScore(code_documents_test, code_count_matrix_test, tf_uc_dict_test) \n",
        "\n",
        "print('UC_SCS_test_shape', UC_SCS_test.shape)\n",
        "print('CC_SCS_test_shape', CC_SCS_test.shape)\n",
        "\n",
        "# 9) Coherence Score Features\n",
        "UC_CoherenceScore_test = featureExtraction.CoherenceScore(UC_documents_test, tfidf_matrix_code_test)\n",
        "CC_CoherenceScore_test = featureExtraction.CoherenceScore(code_documents_test, tfidf_matrix_uc_test)\n",
        "\n",
        "print('UC_CoherenceScore_test_shape', UC_CoherenceScore_test.shape)\n",
        "print('CC_CoherenceScore_test_shape', CC_CoherenceScore_test.shape)\n",
        "\n",
        "#7mins"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#-------------------Saving test Preretival------------------#\n",
        "np.save('./Dataset/errai_dataset/pickles/avg_idf_uc_test.npy', avg_idf_uc_test)\n",
        "np.save('./Dataset/errai_dataset/pickles/avg_idf_code_test.npy', avg_idf_code_test)\n",
        "np.save('./Dataset/errai_dataset/pickles/max_idf_uc_test.npy', max_idf_uc_test)\n",
        "np.save('./Dataset/errai_dataset/pickles/max_idf_code_test.npy', max_idf_code_test)\n",
        "np.save('./Dataset/errai_dataset/pickles/dev_idf_uc_test.npy', dev_idf_uc_test)\n",
        "np.save('./Dataset/errai_dataset/pickles/dev_idf_code_test.npy', dev_idf_code_test)\n",
        "np.save('./Dataset/errai_dataset/pickles/avg_ictf_uc_test.npy', avg_ictf_uc_test)\n",
        "np.save('./Dataset/errai_dataset/pickles/avg_ictf_code_test.npy', avg_ictf_code_test)\n",
        "np.save('./Dataset/errai_dataset/pickles/max_ictf_uc_test.npy', max_ictf_uc_test)\n",
        "np.save('./Dataset/errai_dataset/pickles/max_ictf_code_test.npy', max_ictf_code_test)\n",
        "np.save('./Dataset/errai_dataset/pickles/dev_ictf_uc_test.npy', dev_ictf_uc_test)\n",
        "np.save('./Dataset/errai_dataset/pickles/dev_ictf_code_test.npy', dev_ictf_code_test)\n",
        "np.save('./Dataset/errai_dataset/pickles/avg_entropy_uc_test.npy', avg_entropy_uc_test)\n",
        "np.save('./Dataset/errai_dataset/pickles/avg_entropy_code_test.npy', avg_entropy_code_test)\n",
        "np.save('./Dataset/errai_dataset/pickles/max_entropy_uc_test.npy', max_entropy_uc_test)\n",
        "np.save('./Dataset/errai_dataset/pickles/max_entropy_code_test.npy', max_entropy_code_test)\n",
        "np.save('./Dataset/errai_dataset/pickles/med_entropy_uc_test.npy', med_entropy_uc_test)\n",
        "np.save('./Dataset/errai_dataset/pickles/med_entropy_code_test.npy', med_entropy_code_test)\n",
        "np.save('./Dataset/errai_dataset/pickles/dev_entropy_uc_test.npy', dev_entropy_uc_test)\n",
        "np.save('./Dataset/errai_dataset/pickles/dev_entropy_code_test.npy', dev_entropy_code_test)\n",
        "np.save('./Dataset/errai_dataset/pickles/avg_variance_uc_test.npy', avg_variance_uc_test)\n",
        "np.save('./Dataset/errai_dataset/pickles/avg_variance_code_test.npy', avg_variance_code_test)\n",
        "np.save('./Dataset/errai_dataset/pickles/max_variance_uc_test.npy', max_variance_uc_test)\n",
        "np.save('./Dataset/errai_dataset/pickles/max_variance_code_test.npy', max_variance_code_test)\n",
        "np.save('./Dataset/errai_dataset/pickles/sum_variance_uc_test.npy', sum_variance_uc_test)\n",
        "np.save('./Dataset/errai_dataset/pickles/sum_variance_code_test.npy', sum_variance_code_test)\n",
        "np.save('./Dataset/errai_dataset/pickles/avg_scq_uc_test.npy', avg_scq_uc_test)\n",
        "np.save('./Dataset/errai_dataset/pickles/avg_scq_code_test.npy', avg_scq_code_test)\n",
        "np.save('./Dataset/errai_dataset/pickles/max_scq_uc_test.npy', max_scq_uc_test)\n",
        "np.save('./Dataset/errai_dataset/pickles/max_scq_code_test.npy', max_scq_code_test)\n",
        "np.save('./Dataset/errai_dataset/pickles/sum_sqc_uc_test.npy', sum_sqc_uc_test)\n",
        "np.save('./Dataset/errai_dataset/pickles/sum_sqc_code_test.npy', sum_sqc_code_test)\n",
        "np.save('./Dataset/errai_dataset/pickles/avg_pmi_uc_test.npy', avg_pmi_uc_test)\n",
        "np.save('./Dataset/errai_dataset/pickles/avg_pmi_code_test.npy', avg_pmi_code_test)\n",
        "np.save('./Dataset/errai_dataset/pickles/max_pmi_uc_test.npy', max_pmi_uc_test)\n",
        "np.save('./Dataset/errai_dataset/pickles/max_pmi_code_test.npy', max_pmi_code_test)\n",
        "np.save('./Dataset/errai_dataset/pickles/qs_uc_test.npy', qs_uc_test)\n",
        "np.save('./Dataset/errai_dataset/pickles/qs_code_test.npy', qs_code_test)\n",
        "np.save('./Dataset/errai_dataset/pickles/UC_SCS_test.npy', UC_SCS_test)\n",
        "np.save('./Dataset/errai_dataset/pickles/CC_SCS_test.npy', CC_SCS_test)\n",
        "np.save('./Dataset/errai_dataset/pickles/UC_CoherenceScore_test.npy', UC_CoherenceScore_test)\n",
        "np.save('./Dataset/errai_dataset/pickles/CC_CoherenceScore_test.npy', CC_CoherenceScore_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ------------------------pre-retrieval (21 metrics) Train--------------------------#\n",
        "\n",
        "avg_idf_uc_train = np.load('./Dataset/errai_dataset/pickles/avg_idf_uc_train.npy')\n",
        "avg_idf_code_train = np.load('./Dataset/errai_dataset/pickles/avg_idf_code_train.npy')\n",
        "max_idf_uc_train = np.load('./Dataset/errai_dataset/pickles/max_idf_uc_train.npy')\n",
        "max_idf_code_train = np.load('./Dataset/errai_dataset/pickles/max_idf_code_train.npy')\n",
        "dev_idf_uc_train = np.load('./Dataset/errai_dataset/pickles/dev_idf_uc_train.npy')\n",
        "dev_idf_code_train = np.load('./Dataset/errai_dataset/pickles/dev_idf_code_train.npy')\n",
        "avg_ictf_uc_train = np.load('./Dataset/errai_dataset/pickles/avg_ictf_uc_train.npy')\n",
        "avg_ictf_code_train = np.load('./Dataset/errai_dataset/pickles/avg_ictf_code_train.npy')\n",
        "max_ictf_uc_train = np.load('./Dataset/errai_dataset/pickles/max_ictf_uc_train.npy')\n",
        "max_ictf_code_train = np.load('./Dataset/errai_dataset/pickles/max_ictf_code_train.npy')\n",
        "dev_ictf_uc_train = np.load('./Dataset/errai_dataset/pickles/dev_ictf_uc_train.npy')\n",
        "dev_ictf_code_train = np.load('./Dataset/errai_dataset/pickles/dev_ictf_code_train.npy')\n",
        "avg_entropy_uc_train = np.load('./Dataset/errai_dataset/pickles/avg_entropy_uc_train.npy')\n",
        "avg_entropy_code_train = np.load('./Dataset/errai_dataset/pickles/avg_entropy_code_train.npy')\n",
        "max_entropy_uc_train = np.load('./Dataset/errai_dataset/pickles/max_entropy_uc_train.npy')\n",
        "max_entropy_code_train = np.load('./Dataset/errai_dataset/pickles/max_entropy_code_train.npy')\n",
        "med_entropy_uc_train = np.load('./Dataset/errai_dataset/pickles/med_entropy_uc_train.npy')\n",
        "med_entropy_code_train = np.load('./Dataset/errai_dataset/pickles/med_entropy_code_train.npy')\n",
        "dev_entropy_uc_train = np.load('./Dataset/errai_dataset/pickles/dev_entropy_uc_train.npy')\n",
        "dev_entropy_code_train = np.load('./Dataset/errai_dataset/pickles/dev_entropy_code_train.npy')\n",
        "avg_variance_uc_train = np.load('./Dataset/errai_dataset/pickles/avg_variance_uc_train.npy')\n",
        "avg_variance_code_train = np.load('./Dataset/errai_dataset/pickles/avg_variance_code_train.npy')\n",
        "max_variance_uc_train = np.load('./Dataset/errai_dataset/pickles/max_variance_uc_train.npy')\n",
        "max_variance_code_train = np.load('./Dataset/errai_dataset/pickles/max_variance_code_train.npy')\n",
        "sum_variance_uc_train = np.load('./Dataset/errai_dataset/pickles/sum_variance_uc_train.npy')\n",
        "sum_variance_code_train = np.load('./Dataset/errai_dataset/pickles/sum_variance_code_train.npy')\n",
        "avg_scq_uc_train = np.load('./Dataset/errai_dataset/pickles/avg_scq_uc_train.npy')\n",
        "avg_scq_code_train = np.load('./Dataset/errai_dataset/pickles/avg_scq_code_train.npy')\n",
        "max_scq_uc_train = np.load('./Dataset/errai_dataset/pickles/max_scq_uc_train.npy')\n",
        "max_scq_code_train = np.load('./Dataset/errai_dataset/pickles/max_scq_code_train.npy')\n",
        "sum_sqc_uc_train = np.load('./Dataset/errai_dataset/pickles/sum_sqc_uc_train.npy')\n",
        "sum_sqc_code_train = np.load('./Dataset/errai_dataset/pickles/sum_sqc_code_train.npy')\n",
        "avg_pmi_uc_train = np.load('./Dataset/errai_dataset/pickles/avg_pmi_uc_train.npy')\n",
        "avg_pmi_code_train = np.load('./Dataset/errai_dataset/pickles/avg_pmi_code_train.npy')\n",
        "max_pmi_uc_train = np.load('./Dataset/errai_dataset/pickles/max_pmi_uc_train.npy')\n",
        "max_pmi_code_train = np.load('./Dataset/errai_dataset/pickles/max_pmi_code_train.npy')\n",
        "qs_uc_train = np.load('./Dataset/errai_dataset/pickles/qs_uc_train.npy')\n",
        "qs_code_train = np.load('./Dataset/errai_dataset/pickles/qs_code_train.npy')\n",
        "UC_SCS_train = np.load('./Dataset/errai_dataset/pickles/UC_SCS_train.npy')\n",
        "CC_SCS_train = np.load('./Dataset/errai_dataset/pickles/CC_SCS_train.npy')\n",
        "UC_CoherenceScore_train = np.load('./Dataset/errai_dataset/pickles/UC_CoherenceScore_train.npy')\n",
        "CC_CoherenceScore_train = np.load('./Dataset/errai_dataset/pickles/CC_CoherenceScore_train.npy')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "avg_idf_uc_train = normalizer.fit_transform(avg_idf_uc_train.reshape(-1,1))\n",
        "avg_idf_code_train = normalizer.fit_transform(avg_idf_code_train.reshape(-1,1))\n",
        "max_idf_uc_train = normalizer.fit_transform(max_idf_uc_train.reshape(-1,1))\n",
        "max_idf_code_train = normalizer.fit_transform(max_idf_code_train.reshape(-1,1))\n",
        "dev_idf_uc_train = normalizer.fit_transform(dev_idf_uc_train.reshape(-1,1))\n",
        "dev_idf_code_train = normalizer.fit_transform(dev_idf_code_train.reshape(-1,1))\n",
        "avg_ictf_uc_train = normalizer.fit_transform(avg_ictf_uc_train.reshape(-1,1))\n",
        "avg_ictf_code_train = normalizer.fit_transform(avg_ictf_code_train.reshape(-1,1))\n",
        "max_ictf_uc_train = normalizer.fit_transform(max_ictf_uc_train.reshape(-1,1))\n",
        "max_ictf_code_train = normalizer.fit_transform(max_ictf_code_train.reshape(-1,1))\n",
        "dev_ictf_uc_train = normalizer.fit_transform(dev_ictf_uc_train.reshape(-1,1))\n",
        "dev_ictf_code_train = normalizer.fit_transform(dev_ictf_code_train.reshape(-1,1))\n",
        "avg_entropy_uc_train = normalizer.fit_transform(avg_entropy_uc_train.reshape(-1,1))\n",
        "avg_entropy_code_train = normalizer.fit_transform(avg_entropy_code_train.reshape(-1,1))\n",
        "max_entropy_uc_train = normalizer.fit_transform(max_entropy_uc_train.reshape(-1,1))\n",
        "max_entropy_code_train = normalizer.fit_transform(max_entropy_code_train.reshape(-1,1))\n",
        "med_entropy_uc_train = normalizer.fit_transform(med_entropy_uc_train.reshape(-1,1))\n",
        "med_entropy_code_train = normalizer.fit_transform(med_entropy_code_train.reshape(-1,1))\n",
        "dev_entropy_uc_train = normalizer.fit_transform(dev_entropy_uc_train.reshape(-1,1))\n",
        "dev_entropy_code_train = normalizer.fit_transform(dev_entropy_code_train.reshape(-1,1))\n",
        "avg_variance_uc_train = normalizer.fit_transform(avg_variance_uc_train.reshape(-1,1))\n",
        "avg_variance_code_train = normalizer.fit_transform(avg_variance_code_train.reshape(-1,1))\n",
        "max_variance_uc_train = normalizer.fit_transform(max_variance_uc_train.reshape(-1,1))\n",
        "max_variance_code_train = normalizer.fit_transform(max_variance_code_train.reshape(-1,1))\n",
        "sum_variance_uc_train = normalizer.fit_transform(sum_variance_uc_train.reshape(-1,1))\n",
        "sum_variance_code_train = normalizer.fit_transform(sum_variance_code_train.reshape(-1,1))\n",
        "avg_scq_uc_train = normalizer.fit_transform(avg_scq_uc_train.reshape(-1,1))\n",
        "avg_scq_code_train = normalizer.fit_transform(avg_scq_code_train.reshape(-1,1))\n",
        "max_scq_uc_train = normalizer.fit_transform(max_scq_uc_train.reshape(-1,1).reshape(-1,1))\n",
        "max_scq_code_train = normalizer.fit_transform(max_scq_code_train.reshape(-1,1))\n",
        "sum_sqc_uc_train = normalizer.fit_transform(sum_sqc_uc_train.reshape(-1,1))\n",
        "sum_sqc_code_train = normalizer.fit_transform(sum_sqc_code_train.reshape(-1,1))\n",
        "avg_pmi_uc_train = normalizer.fit_transform(avg_pmi_uc_train.reshape(-1,1))\n",
        "avg_pmi_code_train = normalizer.fit_transform(avg_pmi_code_train.reshape(-1,1))\n",
        "max_pmi_uc_train = normalizer.fit_transform(max_pmi_uc_train.reshape(-1,1))\n",
        "max_pmi_code_train = normalizer.fit_transform(max_pmi_code_train.reshape(-1,1))\n",
        "qs_uc_train = normalizer.fit_transform(qs_uc_train.reshape(-1,1))\n",
        "qs_code_train = normalizer.fit_transform(qs_code_train.reshape(-1,1))\n",
        "UC_SCS_train = normalizer.fit_transform(UC_SCS_train.reshape(-1,1))\n",
        "CC_SCS_train = normalizer.fit_transform(CC_SCS_train.reshape(-1,1))\n",
        "UC_CoherenceScore_train = normalizer.fit_transform(UC_CoherenceScore_train.reshape(-1,1))\n",
        "CC_CoherenceScore_train = normalizer.fit_transform(CC_CoherenceScore_train.reshape(-1,1))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ------------------------pre-retrieval (21 metrics) Test--------------------------#\n",
        "avg_idf_uc_test = np.load('./Dataset/errai_dataset/pickles/avg_idf_uc_test.npy')\n",
        "avg_idf_code_test = np.load('./Dataset/errai_dataset/pickles/avg_idf_code_test.npy')\n",
        "max_idf_uc_test = np.load('./Dataset/errai_dataset/pickles/max_idf_uc_test.npy')\n",
        "max_idf_code_test = np.load('./Dataset/errai_dataset/pickles/max_idf_code_test.npy')\n",
        "dev_idf_uc_test = np.load('./Dataset/errai_dataset/pickles/dev_idf_uc_test.npy')\n",
        "dev_idf_code_test = np.load('./Dataset/errai_dataset/pickles/dev_idf_code_test.npy')\n",
        "avg_ictf_uc_test = np.load('./Dataset/errai_dataset/pickles/avg_ictf_uc_test.npy')\n",
        "avg_ictf_code_test = np.load('./Dataset/errai_dataset/pickles/avg_ictf_code_test.npy')\n",
        "max_ictf_uc_test = np.load('./Dataset/errai_dataset/pickles/max_ictf_uc_test.npy')\n",
        "max_ictf_code_test = np.load('./Dataset/errai_dataset/pickles/max_ictf_code_test.npy')\n",
        "dev_ictf_uc_test = np.load('./Dataset/errai_dataset/pickles/dev_ictf_uc_test.npy')\n",
        "dev_ictf_code_test = np.load('./Dataset/errai_dataset/pickles/dev_ictf_code_test.npy')\n",
        "avg_entropy_uc_test = np.load('./Dataset/errai_dataset/pickles/avg_entropy_uc_test.npy')\n",
        "avg_entropy_code_test = np.load('./Dataset/errai_dataset/pickles/avg_entropy_code_test.npy')\n",
        "max_entropy_uc_test = np.load('./Dataset/errai_dataset/pickles/max_entropy_uc_test.npy')\n",
        "max_entropy_code_test = np.load('./Dataset/errai_dataset/pickles/max_entropy_code_test.npy')\n",
        "med_entropy_uc_test = np.load('./Dataset/errai_dataset/pickles/med_entropy_uc_test.npy')\n",
        "med_entropy_code_test = np.load('./Dataset/errai_dataset/pickles/med_entropy_code_test.npy')\n",
        "dev_entropy_uc_test = np.load('./Dataset/errai_dataset/pickles/dev_entropy_uc_test.npy')\n",
        "dev_entropy_code_test = np.load('./Dataset/errai_dataset/pickles/dev_entropy_code_test.npy')\n",
        "avg_variance_uc_test = np.load('./Dataset/errai_dataset/pickles/avg_variance_uc_test.npy')\n",
        "avg_variance_code_test = np.load('./Dataset/errai_dataset/pickles/avg_variance_code_test.npy')\n",
        "max_variance_uc_test = np.load('./Dataset/errai_dataset/pickles/max_variance_uc_test.npy')\n",
        "max_variance_code_test = np.load('./Dataset/errai_dataset/pickles/max_variance_code_test.npy')\n",
        "sum_variance_uc_test = np.load('./Dataset/errai_dataset/pickles/sum_variance_uc_test.npy')\n",
        "sum_variance_code_test = np.load('./Dataset/errai_dataset/pickles/sum_variance_code_test.npy')\n",
        "avg_scq_uc_test = np.load('./Dataset/errai_dataset/pickles/avg_scq_uc_test.npy')\n",
        "avg_scq_code_test = np.load('./Dataset/errai_dataset/pickles/avg_scq_code_test.npy')\n",
        "max_scq_uc_test = np.load('./Dataset/errai_dataset/pickles/max_scq_uc_test.npy')\n",
        "max_scq_code_test = np.load('./Dataset/errai_dataset/pickles/max_scq_code_test.npy')\n",
        "sum_sqc_uc_test = np.load('./Dataset/errai_dataset/pickles/sum_sqc_uc_test.npy')\n",
        "sum_sqc_code_test = np.load('./Dataset/errai_dataset/pickles/sum_sqc_code_test.npy')\n",
        "avg_pmi_uc_test = np.load('./Dataset/errai_dataset/pickles/avg_pmi_uc_test.npy')\n",
        "avg_pmi_code_test = np.load('./Dataset/errai_dataset/pickles/avg_pmi_code_test.npy')\n",
        "max_pmi_uc_test = np.load('./Dataset/errai_dataset/pickles/max_pmi_uc_test.npy')\n",
        "max_pmi_code_test = np.load('./Dataset/errai_dataset/pickles/max_pmi_code_test.npy')\n",
        "qs_uc_test = np.load('./Dataset/errai_dataset/pickles/qs_uc_test.npy')\n",
        "qs_code_test = np.load('./Dataset/errai_dataset/pickles/qs_code_test.npy')\n",
        "UC_SCS_test = np.load('./Dataset/errai_dataset/pickles/UC_SCS_test.npy')\n",
        "CC_SCS_test = np.load('./Dataset/errai_dataset/pickles/CC_SCS_test.npy')\n",
        "UC_CoherenceScore_test = np.load('./Dataset/errai_dataset/pickles/UC_CoherenceScore_test.npy')\n",
        "CC_CoherenceScore_test = np.load('./Dataset/errai_dataset/pickles/CC_CoherenceScore_test.npy')\n",
        "print(UC_CoherenceScore_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "avg_idf_uc_test = normalizer.fit_transform(avg_idf_uc_test.reshape(-1,1))\n",
        "avg_idf_code_test = normalizer.fit_transform(avg_idf_code_test.reshape(-1,1))\n",
        "max_idf_uc_test = normalizer.fit_transform(max_idf_uc_test.reshape(-1,1))\n",
        "max_idf_code_test = normalizer.fit_transform(max_idf_code_test.reshape(-1,1))\n",
        "dev_idf_uc_test = normalizer.fit_transform(dev_idf_uc_test.reshape(-1,1))\n",
        "dev_idf_code_test = normalizer.fit_transform(dev_idf_code_test.reshape(-1,1))\n",
        "avg_ictf_uc_test = normalizer.fit_transform(avg_ictf_uc_test.reshape(-1,1))\n",
        "avg_ictf_code_test = normalizer.fit_transform(avg_ictf_code_test.reshape(-1,1))\n",
        "max_ictf_uc_test = normalizer.fit_transform(max_ictf_uc_test.reshape(-1,1))\n",
        "max_ictf_code_test = normalizer.fit_transform(max_ictf_code_test.reshape(-1,1))\n",
        "dev_ictf_uc_test = normalizer.fit_transform(dev_ictf_uc_test.reshape(-1,1))\n",
        "dev_ictf_code_test = normalizer.fit_transform(dev_ictf_code_test.reshape(-1,1))\n",
        "avg_entropy_uc_test = normalizer.fit_transform(avg_entropy_uc_test.reshape(-1,1))\n",
        "avg_entropy_code_test = normalizer.fit_transform(avg_entropy_code_test.reshape(-1,1))\n",
        "max_entropy_uc_test = normalizer.fit_transform(max_entropy_uc_test.reshape(-1,1))\n",
        "max_entropy_code_test = normalizer.fit_transform(max_entropy_code_test.reshape(-1,1))\n",
        "med_entropy_uc_test = normalizer.fit_transform(med_entropy_uc_test.reshape(-1,1))\n",
        "med_entropy_code_test = normalizer.fit_transform(med_entropy_code_test.reshape(-1,1))\n",
        "dev_entropy_uc_test = normalizer.fit_transform(dev_entropy_uc_test.reshape(-1,1))\n",
        "dev_entropy_code_test = normalizer.fit_transform(dev_entropy_code_test.reshape(-1,1))\n",
        "avg_variance_uc_test = normalizer.fit_transform(avg_variance_uc_test.reshape(-1,1))\n",
        "avg_variance_code_test = normalizer.fit_transform(avg_variance_code_test.reshape(-1,1))\n",
        "max_variance_uc_test = normalizer.fit_transform(max_variance_uc_test.reshape(-1,1))\n",
        "max_variance_code_test = normalizer.fit_transform(max_variance_code_test.reshape(-1,1))\n",
        "sum_variance_uc_test = normalizer.fit_transform(sum_variance_uc_test.reshape(-1,1))\n",
        "sum_variance_code_test = normalizer.fit_transform(sum_variance_code_test.reshape(-1,1))\n",
        "avg_scq_uc_test = normalizer.fit_transform(avg_scq_uc_test.reshape(-1,1))\n",
        "avg_scq_code_test = normalizer.fit_transform(avg_scq_code_test.reshape(-1,1))\n",
        "max_scq_uc_test = normalizer.fit_transform(max_scq_uc_test.reshape(-1,1))\n",
        "max_scq_code_test = normalizer.fit_transform(max_scq_code_test.reshape(-1,1))\n",
        "sum_sqc_uc_test = normalizer.fit_transform(sum_sqc_uc_test.reshape(-1,1))\n",
        "sum_sqc_code_test = normalizer.fit_transform(sum_sqc_code_test.reshape(-1,1))\n",
        "avg_pmi_uc_test = normalizer.fit_transform(avg_pmi_uc_test.reshape(-1,1))\n",
        "avg_pmi_code_test = normalizer.fit_transform(avg_pmi_code_test.reshape(-1,1))\n",
        "max_pmi_uc_test = normalizer.fit_transform(max_pmi_uc_test.reshape(-1,1))\n",
        "max_pmi_code_test = normalizer.fit_transform(max_pmi_code_test.reshape(-1,1))\n",
        "qs_uc_test = normalizer.fit_transform(qs_uc_test.reshape(-1,1))\n",
        "qs_code_test = normalizer.fit_transform(qs_code_test.reshape(-1,1))\n",
        "UC_SCS_test = normalizer.fit_transform(UC_SCS_test.reshape(-1,1))\n",
        "CC_SCS_test = normalizer.fit_transform(CC_SCS_test.reshape(-1,1))\n",
        "UC_CoherenceScore_test = normalizer.fit_transform(UC_CoherenceScore_test.reshape(-1,1))\n",
        "CC_CoherenceScore_test = normalizer.fit_transform(CC_CoherenceScore_test.reshape(-1,1))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Post Retrieval features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# # BASSANT COMMENTED THIS\n",
        "# #------------------------post-retrieval (7 metrics) Train --------------------------#\n",
        "# # 1.1) Subquery overlap using jensenShannon\n",
        "# code_queries_score_JensenShannon_train = featureExtraction.SubqueryOverlap(code_documents_train, featureExtraction.JensenShannon,\"JS\", UC_count_matrix_train, code_count_matrix_train)\n",
        "# UC_queries_score_JensenShannon_train = featureExtraction.SubqueryOverlap(UC_documents_train, featureExtraction.JensenShannon,\"JS\",code_count_matrix_train, UC_count_matrix_train)\n",
        "\n",
        "# print('code_queries_score_JensenShannon_train', code_queries_score_JensenShannon_train.shape)\n",
        "# print('UC_queries_score_JensenShannon_train', UC_queries_score_JensenShannon_train.shape)\n",
        "\n",
        "# np.save('./pickles/UC_queries_score_JensenShannon_train.npy', UC_queries_score_JensenShannon_train)\n",
        "# np.save('./pickles/UC_queries_score_JensenShannon_train.npy', UC_queries_score_JensenShannon_train)\n",
        "\n",
        "# # 1.2) Subquery overlap using VSM\n",
        "# code_queries_score_VSM_train = featureExtraction.SubqueryOverlap(code_documents_train, featureExtraction.VectorSpaceModel,\"VSM\", UC_count_matrix_train, code_count_matrix_train)\n",
        "# UC_queries_score_VSM_train = featureExtraction.SubqueryOverlap(UC_documents_train, featureExtraction.VectorSpaceModel,\"VSM\", code_count_matrix_train, UC_count_matrix_train)\n",
        "\n",
        "# print('code_queries_score_VSM_train', code_queries_score_VSM_train.shape)\n",
        "# print('UC_queries_score_VSM_train', UC_queries_score_VSM_train.shape)\n",
        "\n",
        "# np.save('./pickles/code_queries_score_VSM_train.npy', code_queries_score_VSM_train)\n",
        "# np.save('./pickles/UC_queries_score_VSM_train.npy', UC_queries_score_VSM_train)\n",
        "\n",
        "# #1.3) Subquery overlap using BM25\n",
        "# code_queries_score_BM25_train = featureExtraction.SubqueryOverlap(code_documents_train, featureExtraction.BM25,\"BM\", UC_documents_train,idf_uc_dict_train,UC_count_matrix_train)\n",
        "# UC_queries_score_BM25_train = featureExtraction.SubqueryOverlap(UC_documents_train, featureExtraction.BM25,\"BM\", code_documents_train,idf_code_dict_train, code_count_matrix_train)\n",
        "\n",
        "# print('code_queries_score_BM25_train', code_queries_score_BM25_train.shape)\n",
        "# print('UC_queries_score_BM25_train', UC_queries_score_BM25_train.shape)\n",
        "\n",
        "# np.save('./pickles/code_queries_score_BM25_train.npy', code_queries_score_BM25_train)\n",
        "# np.save('./pickles/UC_queries_score_BM25_train.npy', UC_queries_score_BM25_train)\n",
        "\n",
        "# #1.4) Subquery overlap using JM smoothing\n",
        "# code_queries_score_JM_train = featureExtraction.SubqueryOverlap(code_documents_train, featureExtraction.SmoothingMethods,\"SM\", UC_documents_train,UC_count_matrix_train,tf_uc_dict_train,True)\n",
        "# UC_queries_score_JM_train = featureExtraction.SubqueryOverlap(UC_documents_train, featureExtraction.SmoothingMethods,\"SM\", code_documents_train,code_count_matrix_train,tf_code_dict_train,True)\n",
        "\n",
        "# print('code_queries_score_JM_train', code_queries_score_JM_train.shape)\n",
        "# print('UC_queries_score_JM_train', UC_queries_score_JM_train.shape)\n",
        "\n",
        "# np.save('./pickles/code_queries_score_JM_train.npy', code_queries_score_JM_train)\n",
        "# np.save('./pickles/UC_queries_score_JM_train.npy', UC_queries_score_JM_train)\n",
        "\n",
        "# # 1.5) Subquery overlap using DP smoothing\n",
        "# code_queries_score_DP_train = featureExtraction.SubqueryOverlap(code_documents_train, featureExtraction.SmoothingMethods,\"SM\", UC_documents_train, UC_count_matrix_train,tf_uc_dict_train,False)\n",
        "# UC_queries_score_DP_train = featureExtraction.SubqueryOverlap(UC_documents_train, featureExtraction.SmoothingMethods,\"SM\", code_documents_train, code_count_matrix_train,tf_code_dict_train,False)\n",
        "\n",
        "# print('code_queries_score_DP_train', code_queries_score_DP_train.shape)\n",
        "# print('UC_queries_score_DP_train', UC_queries_score_DP_train.shape)\n",
        "\n",
        "# np.save('./pickles/code_queries_score_DP_train.npy', code_queries_score_DP_train)\n",
        "# np.save('./pickles/UC_queries_score_DP_train.npy', UC_queries_score_DP_train)\n",
        "\n",
        "# #------------------------post-retrieval (7 metrics) Test --------------------------#\n",
        "# # 1.1) Subquery overlap using jensenShannon\n",
        "# code_queries_score_JensenShannon_test = featureExtraction.SubqueryOverlap(code_documents_test, featureExtraction.JensenShannon,\"JS\", UC_count_matrix_test, code_count_matrix_test)\n",
        "# UC_queries_score_JensenShannon_test = featureExtraction.SubqueryOverlap(UC_documents_test, featureExtraction.JensenShannon,\"JS\",code_count_matrix_test, UC_count_matrix_test)\n",
        "\n",
        "# print('code_queries_score_JensenShannon_test', code_queries_score_JensenShannon_test.shape)\n",
        "# print('UC_queries_score_JensenShannon_test', UC_queries_score_JensenShannon_test.shape)\n",
        "\n",
        "# np.save('./pickles/code_queries_score_JensenShannon_test.npy', code_queries_score_JensenShannon_test)\n",
        "# np.save('./pickles/UC_queries_score_JensenShannon_test.npy', UC_queries_score_JensenShannon_test)\n",
        "\n",
        "# # 1.2) Subquery overlap using VSM\n",
        "# code_queries_score_VSM_test = featureExtraction.SubqueryOverlap(code_documents_test, featureExtraction.VectorSpaceModel,\"VSM\", UC_count_matrix_test, code_count_matrix_test)\n",
        "# UC_queries_score_VSM_test = featureExtraction.SubqueryOverlap(UC_documents_test, featureExtraction.VectorSpaceModel,\"VSM\", code_count_matrix_test, UC_count_matrix_test)\n",
        "\n",
        "# print('code_queries_score_VSM_test', code_queries_score_VSM_test.shape)\n",
        "# print('UC_queries_score_VSM_test', UC_queries_score_VSM_test.shape)\n",
        "\n",
        "# np.save('./pickles/code_queries_score_VSM_test.npy', code_queries_score_VSM_test)\n",
        "# np.save('./pickles/UC_queries_score_VSM_test.npy', UC_queries_score_VSM_test)\n",
        "\n",
        "# #1.3) Subquery overlap using BM25\n",
        "# code_queries_score_BM25_test = featureExtraction.SubqueryOverlap(code_documents_test, featureExtraction.BM25,\"BM\", UC_documents_test,idf_uc_dict_test,UC_count_matrix_test)\n",
        "# UC_queries_score_BM25_test = featureExtraction.SubqueryOverlap(UC_documents_test, featureExtraction.BM25,\"BM\", code_documents_test,idf_code_dict_test, code_count_matrix_test)\n",
        "\n",
        "# print('code_queries_score_BM25_test', code_queries_score_BM25_test.shape)\n",
        "# print('UC_queries_score_BM25_test', UC_queries_score_BM25_test.shape)\n",
        "\n",
        "# np.save('./pickles/code_queries_score_BM25_test.npy', code_queries_score_BM25_test)\n",
        "# np.save('./pickles/UC_queries_score_BM25_test.npy', UC_queries_score_BM25_test)\n",
        "\n",
        "# #1.4) Subquery overlap using JM smoothing\n",
        "# code_queries_score_JM_test = featureExtraction.SubqueryOverlap(code_documents_test, featureExtraction.SmoothingMethods,\"SM\", UC_documents_test,UC_count_matrix_test,tf_uc_dict_test,True)\n",
        "# UC_queries_score_JM_test = featureExtraction.SubqueryOverlap(UC_documents_test, featureExtraction.SmoothingMethods,\"SM\", code_documents_test,code_count_matrix_test,tf_code_dict_test,True)\n",
        "\n",
        "# print('code_queries_score_JM_test', code_queries_score_JM_test.shape)\n",
        "# print('UC_queries_score_JM_test', UC_queries_score_JM_test.shape)\n",
        "\n",
        "# np.save('./pickles/code_queries_score_JM_test.npy', code_queries_score_JM_test)\n",
        "# np.save('./pickles/UC_queries_score_JM_test.npy', UC_queries_score_JM_test)\n",
        "\n",
        "# # 1.5) Subquery overlap using DP smoothing\n",
        "# code_queries_score_DP_test = featureExtraction.SubqueryOverlap(code_documents_test, featureExtraction.SmoothingMethods,\"SM\", UC_documents_test, UC_count_matrix_test,tf_uc_dict_test,False)\n",
        "# UC_queries_score_DP_test = featureExtraction.SubqueryOverlap(UC_documents_test, featureExtraction.SmoothingMethods,\"SM\", code_documents_test, code_count_matrix_test,tf_code_dict_test,False)\n",
        "\n",
        "# print('code_queries_score_DP_test', code_queries_score_DP_test.shape)\n",
        "# print('UC_queries_score_DP_test', UC_queries_score_DP_test.shape)\n",
        "\n",
        "# np.save('./pickles/code_queries_score_DP_test.npy', code_queries_score_DP_test)\n",
        "# np.save('./pickles/UC_queries_score_DP_test.npy', UC_queries_score_DP_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#--------------------------------Robustness Score Train-------------------------------------------------------#\n",
        "\n",
        "# 2.1) Robustness Score using jensenShannon\n",
        "UC_RS_JS_train, UC_FRC_JS_train = featureExtraction.RobustnessScore(UC_documents_train,code_documents_train,\"JS\")\n",
        "code_RS_JS_train, code_FRC_JS_train = featureExtraction.RobustnessScore(code_documents_train,UC_documents_train,\"JS\")\n",
        "\n",
        "print('UC_RS_JS_train', UC_RS_JS_train.shape)\n",
        "print('code_RS_JS_train', code_RS_JS_train.shape)\n",
        "\n",
        "print('UC_FRC_JS_train', UC_FRC_JS_train.shape)\n",
        "print('code_FRC_JS_train', code_FRC_JS_train.shape)\n",
        "\n",
        "np.save('./Dataset/errai_dataset/pickles/UC_RS_JS_train.npy', UC_RS_JS_train)\n",
        "np.save('./Dataset/errai_dataset/pickles/code_RS_JS_train.npy', code_RS_JS_train)\n",
        "\n",
        "np.save('./Dataset/errai_dataset/pickles/UC_FRC_JS_train.npy', UC_FRC_JS_train)\n",
        "np.save('./Dataset/errai_dataset/pickles/code_FRC_JS_train.npy', code_FRC_JS_train)\n",
        "\n",
        "# 2.2) Robustness Score using VSM\n",
        "UC_RS_VSM_train, UC_FRC_VSM_train = featureExtraction.RobustnessScore(UC_documents_train,code_documents_train,\"VSM\")\n",
        "code_RS_VSM_train, code_FRC_VSM_train = featureExtraction.RobustnessScore(code_documents_train,UC_documents_train,\"VSM\")\n",
        "\n",
        "print('UC_RS_VSM_train', UC_RS_VSM_train.shape)\n",
        "print('code_RS_VSM_train', code_RS_VSM_train.shape)\n",
        "\n",
        "print('UC_FRC_VSM_train', UC_FRC_VSM_train.shape)\n",
        "print('code_FRC_VSM_train', code_FRC_VSM_train.shape)\n",
        "\n",
        "np.save('./Dataset/errai_dataset/pickles/UC_RS_VSM_train.npy', UC_RS_VSM_train)\n",
        "np.save('./Dataset/errai_dataset/pickles/code_RS_VSM_train.npy', code_RS_VSM_train)\n",
        "\n",
        "np.save('./Dataset/errai_dataset/pickles/UC_FRC_VSM_train.npy', UC_FRC_VSM_train)\n",
        "np.save('./Dataset/errai_dataset/pickles/code_FRC_VSM_train.npy', code_FRC_VSM_train)\n",
        "\n",
        "# 2.3) Robustness Score using BM25\n",
        "UC_RS_BM25_train, UC_FRC_BM25_train = featureExtraction.RobustnessScore(UC_documents_train,code_documents_train,\"BM\")\n",
        "code_RS_BM25_train, code_FRC_BM25_train = featureExtraction.RobustnessScore(code_documents_train,UC_documents_train,\"BM\")\n",
        "\n",
        "print('UC_RS_BM25_train', UC_RS_BM25_train.shape)\n",
        "print('code_RS_BM25_train', code_RS_BM25_train.shape)\n",
        "\n",
        "print('UC_FRC_BM25_train', UC_FRC_BM25_train.shape)\n",
        "print('code_FRC_BM25_train', code_FRC_BM25_train.shape)\n",
        "\n",
        "np.save('./Dataset/errai_dataset/pickles/UC_RS_BM25_train.npy', UC_RS_BM25_train)\n",
        "np.save('./Dataset/errai_dataset/pickles/code_RS_BM25_train.npy', code_RS_BM25_train)\n",
        "\n",
        "np.save('./Dataset/errai_dataset/pickles/UC_FRC_BM25_train.npy', UC_FRC_BM25_train)\n",
        "np.save('./Dataset/errai_dataset/pickles/code_FRC_BM25_train.npy', code_FRC_BM25_train)\n",
        "\n",
        "# 2.4) Robustness Score using JM smoothing\n",
        "UC_RS_JM_train, UC_FRC_JM_train = featureExtraction.RobustnessScore(UC_documents_train,code_documents_train,\"JM\")\n",
        "code_RS_JM_train, code_FRC_JM_train = featureExtraction.RobustnessScore(code_documents_train,UC_documents_train,\"JM\")\n",
        "\n",
        "print('UC_RS_JM_train', UC_RS_JM_train.shape)\n",
        "print('code_RS_JM_train', code_RS_JM_train.shape)\n",
        "\n",
        "print('UC_FRC_JM_train', UC_FRC_JM_train.shape)\n",
        "print('code_FRC_JM_train', code_FRC_JM_train.shape)\n",
        "\n",
        "np.save('./Dataset/errai_dataset/pickles/UC_RS_JM_train.npy', UC_RS_JM_train)\n",
        "np.save('./Dataset/errai_dataset/pickles/code_RS_JM_train.npy', code_RS_JM_train)\n",
        "\n",
        "np.save('./Dataset/errai_dataset/pickles/UC_FRC_JM_train.npy', UC_FRC_JM_train)\n",
        "np.save('./Dataset/errai_dataset/pickles/code_FRC_JM_train.npy', code_FRC_JM_train)\n",
        "\n",
        "# 2.5) Robustness Score using DP smoothing\n",
        "UC_RS_DP_train, UC_FRC_DP_train = featureExtraction.RobustnessScore(UC_documents_train,code_documents_train,\"DP\")\n",
        "code_RS_DP_train, code_FRC_DP_train = featureExtraction.RobustnessScore(code_documents_train,UC_documents_train,\"DP\")\n",
        "\n",
        "print('UC_RS_DP_train', UC_RS_DP_train.shape)\n",
        "print('code_RS_DP_train', code_RS_DP_train.shape)\n",
        "\n",
        "print('UC_FRC_DP_train', UC_FRC_DP_train.shape)\n",
        "print('code_FRC_DP_train', code_FRC_DP_train.shape)\n",
        "\n",
        "np.save('./Dataset/errai_dataset/pickles/UC_RS_DP_train.npy', UC_RS_DP_train)\n",
        "np.save('./Dataset/errai_dataset/pickles/code_RS_DP_train.npy', code_RS_DP_train)\n",
        "\n",
        "np.save('./Dataset/errai_dataset/pickles/UC_FRC_DP_train.npy', UC_FRC_DP_train)\n",
        "np.save('./Dataset/errai_dataset/pickles/code_FRC_DP_train.npy', code_FRC_DP_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "UC_RS_JS_train = np.load('./Dataset/errai_dataset/pickles/UC_RS_JS_train.npy')\n",
        "code_RS_JS_train = np.load('./Dataset/errai_dataset/pickles/code_RS_JS_train.npy')\n",
        "UC_FRC_JS_train = np.load('./Dataset/errai_dataset/pickles/UC_FRC_JS_train.npy')\n",
        "code_FRC_JS_train = np.load('./Dataset/errai_dataset/pickles/code_FRC_JS_train.npy')\n",
        "UC_RS_VSM_train = np.load('./Dataset/errai_dataset/pickles/UC_RS_VSM_train.npy')\n",
        "code_RS_VSM_train = np.load('./Dataset/errai_dataset/pickles/code_RS_VSM_train.npy')\n",
        "UC_FRC_VSM_train = np.load('./Dataset/errai_dataset/pickles/UC_FRC_VSM_train.npy')\n",
        "code_FRC_VSM_train = np.load('./Dataset/errai_dataset/pickles/code_FRC_VSM_train.npy')\n",
        "UC_RS_BM25_train = np.load('./Dataset/errai_dataset/pickles/UC_RS_BM25_train.npy')\n",
        "code_RS_BM25_train = np.load('./Dataset/errai_dataset/pickles/code_RS_BM25_train.npy')\n",
        "UC_FRC_BM25_train = np.load('./Dataset/errai_dataset/pickles/UC_FRC_BM25_train.npy')\n",
        "code_FRC_BM25_train = np.load('./Dataset/errai_dataset/pickles/code_FRC_BM25_train.npy')\n",
        "UC_RS_JM_train = np.load('./Dataset/errai_dataset/pickles/UC_RS_JM_train.npy')\n",
        "code_RS_JM_train = np.load('./Dataset/errai_dataset/pickles/code_RS_JM_train.npy')\n",
        "UC_FRC_JM_train = np.load('./Dataset/errai_dataset/pickles/UC_FRC_JM_train.npy')\n",
        "code_FRC_JM_train = np.load('./Dataset/errai_dataset/pickles/code_FRC_JM_train.npy')\n",
        "UC_RS_DP_train = np.load('./Dataset/errai_dataset/pickles/UC_RS_DP_train.npy')\n",
        "code_RS_DP_train = np.load('./Dataset/errai_dataset/pickles/code_RS_DP_train.npy')\n",
        "UC_FRC_DP_train = np.load('./Dataset/errai_dataset/pickles/UC_FRC_DP_train.npy')\n",
        "code_FRC_DP_train = np.load('./Dataset/errai_dataset/pickles/code_FRC_DP_train.npy')\n",
        "# print(UC_FRC_DP_train,UC_FRC_JM_train,UC_FRC_BM25_train,UC_FRC_JS_train,UC_FRC_VSM_train) # ALERT : el hgat dy bytgeb zeros w ones\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "UC_RS_JS_train = normalizer.fit_transform(UC_RS_JS_train.reshape(-1, 1))\n",
        "code_RS_JS_train = normalizer.fit_transform(code_RS_JS_train.reshape(-1, 1))\n",
        "UC_FRC_JS_train = normalizer.fit_transform(UC_FRC_JS_train.reshape(-1, 1))\n",
        "code_FRC_JS_train = normalizer.fit_transform(code_FRC_JS_train.reshape(-1, 1))\n",
        "UC_RS_VSM_train = normalizer.fit_transform(UC_RS_VSM_train.reshape(-1, 1))\n",
        "code_RS_VSM_train = normalizer.fit_transform(code_RS_VSM_train.reshape(-1, 1))\n",
        "UC_FRC_VSM_train = normalizer.fit_transform(UC_FRC_VSM_train.reshape(-1, 1))\n",
        "code_FRC_VSM_train = normalizer.fit_transform(code_FRC_VSM_train.reshape(-1, 1))\n",
        "UC_RS_BM25_train = normalizer.fit_transform(UC_RS_BM25_train.reshape(-1, 1))\n",
        "code_RS_BM25_train = normalizer.fit_transform(code_RS_BM25_train.reshape(-1, 1))\n",
        "UC_FRC_BM25_train = normalizer.fit_transform(UC_FRC_BM25_train.reshape(-1, 1))\n",
        "code_FRC_BM25_train = normalizer.fit_transform(code_FRC_BM25_train.reshape(-1, 1))\n",
        "UC_RS_JM_train = normalizer.fit_transform(UC_RS_JM_train.reshape(-1, 1))\n",
        "code_RS_JM_train = normalizer.fit_transform(code_RS_JM_train.reshape(-1, 1))\n",
        "UC_FRC_JM_train = normalizer.fit_transform(UC_FRC_JM_train.reshape(-1, 1))\n",
        "code_FRC_JM_train = normalizer.fit_transform(code_FRC_JM_train.reshape(-1, 1))\n",
        "UC_RS_DP_train = normalizer.fit_transform(UC_RS_DP_train.reshape(-1, 1))\n",
        "code_RS_DP_train = normalizer.fit_transform(code_RS_DP_train.reshape(-1, 1))\n",
        "UC_FRC_DP_train = normalizer.fit_transform(UC_FRC_DP_train.reshape(-1, 1))\n",
        "code_FRC_DP_train = normalizer.fit_transform(code_FRC_DP_train.reshape(-1, 1))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#--------------------------------------------------Robustness Score test------------------------------------------------------------#\n",
        "\n",
        "# 2.1) Robustness Score using jensenShannon\n",
        "UC_RS_JS_test, UC_FRC_JS_test = featureExtraction.RobustnessScore(UC_documents_test,code_documents_test,\"JS\")\n",
        "code_RS_JS_test, code_FRC_JS_test = featureExtraction.RobustnessScore(code_documents_test,UC_documents_test,\"JS\")\n",
        "\n",
        "print('UC_RS_JS_test', UC_RS_JS_test.shape)\n",
        "print('code_RS_JS_test', code_RS_JS_test.shape)\n",
        "\n",
        "print('UC_FRC_JS_test', UC_FRC_JS_test.shape)\n",
        "print('code_FRC_JS_test', code_FRC_JS_test.shape)\n",
        "\n",
        "np.save('./Dataset/errai_dataset/pickles/UC_RS_JS_test.npy', UC_RS_JS_test)\n",
        "np.save('./Dataset/errai_dataset/pickles/code_RS_JS_test.npy', code_RS_JS_test)\n",
        "\n",
        "np.save('./Dataset/errai_dataset/pickles/UC_FRC_JS_test.npy', UC_FRC_JS_test)\n",
        "np.save('./Dataset/errai_dataset/pickles/code_FRC_JS_test.npy', code_FRC_JS_test)\n",
        "\n",
        "# 2.2) Robustness Score using VSM\n",
        "UC_RS_VSM_test, UC_FRC_VSM_test = featureExtraction.RobustnessScore(UC_documents_test,code_documents_test,\"VSM\")\n",
        "code_RS_VSM_test, code_FRC_VSM_test = featureExtraction.RobustnessScore(code_documents_test,UC_documents_test,\"VSM\")\n",
        "\n",
        "print('UC_RS_VSM_test', UC_RS_VSM_test.shape)\n",
        "print('code_RS_VSM_test', code_RS_VSM_test.shape)\n",
        "\n",
        "print('UC_FRC_VSM_test', UC_FRC_VSM_test.shape)\n",
        "print('code_FRC_VSM_test', code_FRC_VSM_test.shape)\n",
        "\n",
        "np.save('./Dataset/errai_dataset/pickles/UC_RS_VSM_test.npy', UC_RS_VSM_test)\n",
        "np.save('./Dataset/errai_dataset/pickles/code_RS_VSM_test.npy', code_RS_VSM_test)\n",
        "\n",
        "np.save('./Dataset/errai_dataset/pickles/UC_FRC_VSM_test.npy', UC_FRC_VSM_test)\n",
        "np.save('./Dataset/errai_dataset/pickles/code_FRC_VSM_test.npy', code_FRC_VSM_test)\n",
        "\n",
        "# 2.3) Robustness Score using BM25\n",
        "UC_RS_BM25_test, UC_FRC_BM25_test = featureExtraction.RobustnessScore(UC_documents_test,code_documents_test,\"BM\")\n",
        "code_RS_BM25_test, code_FRC_BM25_test = featureExtraction.RobustnessScore(code_documents_test,UC_documents_test,\"BM\")\n",
        "\n",
        "print('UC_RS_BM25_test', UC_RS_BM25_test.shape)\n",
        "print('code_RS_BM25_test', code_RS_BM25_test.shape)\n",
        "\n",
        "print('UC_FRC_BM25_test', UC_FRC_BM25_test.shape)\n",
        "print('code_FRC_BM25_test', code_FRC_BM25_test.shape)\n",
        "\n",
        "np.save('./Dataset/errai_dataset/pickles/UC_RS_BM25_test.npy', UC_RS_BM25_test)\n",
        "np.save('./Dataset/errai_dataset/pickles/code_RS_BM25_test.npy', code_RS_BM25_test)\n",
        "\n",
        "np.save('./Dataset/errai_dataset/pickles/UC_FRC_BM25_test.npy', UC_FRC_BM25_test)\n",
        "np.save('./Dataset/errai_dataset/pickles/code_FRC_BM25_test.npy', code_FRC_BM25_test)\n",
        "\n",
        "# 2.4) Robustness Score using JM smoothing\n",
        "UC_RS_JM_test, UC_FRC_JM_test = featureExtraction.RobustnessScore(UC_documents_test,code_documents_test,\"JM\")\n",
        "code_RS_JM_test, code_FRC_JM_test = featureExtraction.RobustnessScore(code_documents_test,UC_documents_test,\"JM\")\n",
        "\n",
        "print('UC_RS_JM_test', UC_RS_JM_test.shape)\n",
        "print('code_RS_JM_test', code_RS_JM_test.shape)\n",
        "\n",
        "print('UC_FRC_JM_test', UC_FRC_JM_test.shape)\n",
        "print('code_FRC_JM_test', code_FRC_JM_test.shape)\n",
        "\n",
        "np.save('./Dataset/errai_dataset/pickles/UC_RS_JM_test.npy', UC_RS_JM_test)\n",
        "np.save('./Dataset/errai_dataset/pickles/code_RS_JM_test.npy', code_RS_JM_test)\n",
        "\n",
        "np.save('./Dataset/errai_dataset/pickles/UC_FRC_JM_test.npy', UC_FRC_JM_test)\n",
        "np.save('./Dataset/errai_dataset/pickles/code_FRC_JM_test.npy', code_FRC_JM_test)\n",
        "\n",
        "# 2.5) Robustness Score using DP smoothing\n",
        "UC_RS_DP_test, UC_FRC_DP_test = featureExtraction.RobustnessScore(UC_documents_test,code_documents_test,\"DP\")\n",
        "code_RS_DP_test, code_FRC_DP_test = featureExtraction.RobustnessScore(code_documents_test,UC_documents_test,\"DP\")\n",
        "\n",
        "print('UC_RS_DP_test', UC_RS_DP_test.shape)\n",
        "print('code_RS_DP_test', code_RS_DP_test.shape)\n",
        "\n",
        "print('UC_FRC_DP_test', UC_FRC_DP_test.shape)\n",
        "print('code_FRC_DP_test', code_FRC_DP_test.shape)\n",
        "\n",
        "np.save('./Dataset/errai_dataset/pickles/UC_RS_DP_test.npy', UC_RS_DP_test)\n",
        "np.save('./Dataset/errai_dataset/pickles/code_RS_DP_test.npy', code_RS_DP_test)\n",
        "\n",
        "np.save('./Dataset/errai_dataset/pickles/UC_FRC_DP_test.npy', UC_FRC_DP_test)\n",
        "np.save('./Dataset/errai_dataset/pickles/code_FRC_DP_test.npy', code_FRC_DP_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#ALERT :FRC BYTL3 1 AND ZEROS M3RFSH LW DY HAGA SAH\n",
        "UC_RS_JS_test = np.load('./Dataset/errai_dataset/pickles/UC_RS_JS_test.npy')\n",
        "code_RS_JS_test = np.load('./Dataset/errai_dataset/pickles/code_RS_JS_test.npy')\n",
        "UC_FRC_JS_test = np.load('./Dataset/errai_dataset/pickles/UC_FRC_JS_test.npy')  #ALERT: bytl3 1 and zeros mfesh decimals\n",
        "code_FRC_JS_test = np.load('./Dataset/errai_dataset/pickles/code_FRC_JS_test.npy')\n",
        "UC_RS_VSM_test = np.load('./Dataset/errai_dataset/pickles/UC_RS_VSM_test.npy')\n",
        "code_RS_VSM_test = np.load('./Dataset/errai_dataset/pickles/code_RS_VSM_test.npy')\n",
        "UC_FRC_VSM_test = np.load('./Dataset/errai_dataset/pickles/UC_FRC_VSM_test.npy')\n",
        "code_FRC_VSM_test = np.load('./Dataset/errai_dataset/pickles/code_FRC_VSM_test.npy')\n",
        "UC_RS_BM25_test = np.load('./Dataset/errai_dataset/pickles/UC_RS_BM25_test.npy')\n",
        "code_RS_BM25_test = np.load('./Dataset/errai_dataset/pickles/code_RS_BM25_test.npy')\n",
        "UC_FRC_BM25_test = np.load('./Dataset/errai_dataset/pickles/UC_FRC_BM25_test.npy')\n",
        "code_FRC_BM25_test = np.load('./Dataset/errai_dataset/pickles/code_FRC_BM25_test.npy')\n",
        "UC_RS_JM_test = np.load('./Dataset/errai_dataset/pickles/UC_RS_JM_test.npy')\n",
        "code_RS_JM_test = np.load('./Dataset/errai_dataset/pickles/code_RS_JM_test.npy')\n",
        "UC_FRC_JM_test = np.load('./Dataset/errai_dataset/pickles/UC_FRC_JM_test.npy')\n",
        "code_FRC_JM_test = np.load('./Dataset/errai_dataset/pickles/code_FRC_JM_test.npy')\n",
        "UC_RS_DP_test = np.load('./Dataset/errai_dataset/pickles/UC_RS_DP_test.npy')\n",
        "code_RS_DP_test = np.load('./Dataset/errai_dataset/pickles/code_RS_DP_test.npy')\n",
        "UC_FRC_DP_test = np.load('./Dataset/errai_dataset/pickles/UC_FRC_DP_test.npy')\n",
        "code_FRC_DP_test = np.load('./Dataset/errai_dataset/pickles/code_FRC_DP_test.npy')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "UC_RS_JS_test = normalizer.fit_transform(UC_RS_JS_test.reshape(-1, 1))\n",
        "code_RS_JS_test = normalizer.fit_transform(code_RS_JS_test.reshape(-1, 1))\n",
        "UC_FRC_JS_test = normalizer.fit_transform(UC_FRC_JS_test.reshape(-1, 1))\n",
        "code_FRC_JS_test = normalizer.fit_transform(code_FRC_JS_test.reshape(-1, 1))\n",
        "UC_RS_VSM_test = normalizer.fit_transform(UC_RS_VSM_test.reshape(-1, 1))\n",
        "code_RS_VSM_test = normalizer.fit_transform(code_RS_VSM_test.reshape(-1, 1))\n",
        "UC_FRC_VSM_test = normalizer.fit_transform(UC_FRC_VSM_test.reshape(-1, 1))\n",
        "code_FRC_VSM_test= normalizer.fit_transform(code_FRC_VSM_test.reshape(-1, 1))\n",
        "UC_RS_BM25_test = normalizer.fit_transform(UC_RS_BM25_test.reshape(-1, 1))\n",
        "code_RS_BM25_test = normalizer.fit_transform(code_RS_BM25_test.reshape(-1, 1))\n",
        "UC_FRC_BM25_test = normalizer.fit_transform(UC_FRC_BM25_test.reshape(-1, 1))\n",
        "code_FRC_BM25_test = normalizer.fit_transform(code_FRC_BM25_test.reshape(-1, 1))\n",
        "UC_RS_JM_test = normalizer.fit_transform(UC_RS_JM_test.reshape(-1, 1))\n",
        "code_RS_JM_test = normalizer.fit_transform(code_RS_JM_test.reshape(-1, 1))\n",
        "UC_FRC_JM_test = normalizer.fit_transform(UC_FRC_JM_test.reshape(-1, 1))\n",
        "code_FRC_JM_test = normalizer.fit_transform(code_FRC_JM_test.reshape(-1, 1))\n",
        "UC_RS_DP_test = normalizer.fit_transform(UC_RS_DP_test.reshape(-1, 1))\n",
        "code_RS_DP_test = normalizer.fit_transform(code_RS_DP_test.reshape(-1, 1))\n",
        "UC_FRC_DP_test = normalizer.fit_transform(UC_FRC_DP_test.reshape(-1, 1))\n",
        "code_FRC_DP_test = normalizer.fit_transform(code_FRC_DP_test.reshape(-1, 1))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#------------------------------------------------- ClusteringTendency Train---------------------------------------------\n",
        "# 4.1) Clustering Tendency using JensenShannon\n",
        "UC_CT_JensenShannon_train = featureExtraction.ClusteringTendency(JS_UC_train.T,tfidf_matrix_uc_train,tfidf_matrix_code_train)\n",
        "code_CT_JensenShannon_train = featureExtraction.ClusteringTendency(JS_CC_train,tfidf_matrix_code_train,tfidf_matrix_uc_train)\n",
        "\n",
        "print(\"UC_CT_JensenShannon_train\",UC_CT_JensenShannon_train.shape)\n",
        "print(\"code_CT_JensenShannon_train\",code_CT_JensenShannon_train.shape)\n",
        "\n",
        "np.save('./Dataset/errai_dataset/pickles/UC_CT_JensenShannon_train.npy',UC_CT_JensenShannon_train)\n",
        "np.save('./Dataset/errai_dataset/pickles/code_CT_JensenShannon_train.npy',code_CT_JensenShannon_train)\n",
        "\n",
        "# 4.2) Clustering Tendency using VSM\n",
        "UC_CT_VSM_train = featureExtraction.ClusteringTendency(cosine_similarity_UC_train.T,tfidf_matrix_uc_train,tfidf_matrix_code_train)\n",
        "code_CT_VSM_train = featureExtraction.ClusteringTendency(cosine_similarity_CC_train,tfidf_matrix_code_train,tfidf_matrix_uc_train)\n",
        "\n",
        "print(\"UC_CT_VSM_train\",UC_CT_VSM_train.shape)\n",
        "print(\"code_CT_VSM_train\",code_CT_VSM_train.shape)\n",
        "\n",
        "np.save('./Dataset/errai_dataset/pickles/UC_CT_VSM_train.npy',UC_CT_VSM_train)\n",
        "np.save('./Dataset/errai_dataset/pickles/code_CT_VSM_train.npy',code_CT_VSM_train)\n",
        "\n",
        "# 4.3) Clustering Tendency using BM25\n",
        "UC_CT_BM25_train = featureExtraction.ClusteringTendency(BM25_UC_train,tfidf_matrix_uc_train,tfidf_matrix_code_train)\n",
        "code_CT_BM25_train = featureExtraction.ClusteringTendency(BM25_CC_train,tfidf_matrix_code_train,tfidf_matrix_uc_train)\n",
        "\n",
        "print(\"UC_CT_BM25_train\",UC_CT_BM25_train.shape)\n",
        "print(\"code_CT_BM25_train\",code_CT_BM25_train.shape)\n",
        "\n",
        "np.save('./Dataset/errai_dataset/pickles/UC_CT_BM25_train.npy',UC_CT_BM25_train)\n",
        "np.save('./Dataset/errai_dataset/pickles/code_CT_BM25_train.npy',code_CT_BM25_train)\n",
        "\n",
        "# 4.4) Clustering Tendency using JM\n",
        "UC_CT_JM_train = featureExtraction.ClusteringTendency(JM_UC_train,tfidf_matrix_uc_train,tfidf_matrix_code_train)\n",
        "code_CT_JM_train = featureExtraction.ClusteringTendency(JM_CC_train,tfidf_matrix_code_train,tfidf_matrix_uc_train)\n",
        "\n",
        "print(\"UC_CT_JM_train\",UC_CT_JM_train.shape)\n",
        "print(\"code_CT_JM_train\",code_CT_JM_train.shape)\n",
        "\n",
        "\n",
        "np.save('./Dataset/errai_dataset/pickles/UC_CT_JM_train.npy',UC_CT_JM_train)\n",
        "np.save('./Dataset/errai_dataset/pickles/code_CT_JM_train.npy',code_CT_JM_train) \n",
        "\n",
        "# 4.5) Clustering Tendency using DP\n",
        "UC_CT_DP_train = featureExtraction.ClusteringTendency(DP_UC_train,tfidf_matrix_uc_train,tfidf_matrix_code_train)\n",
        "code_CT_DP_train = featureExtraction.ClusteringTendency(DP_CC_train,tfidf_matrix_code_train,tfidf_matrix_uc_train)\n",
        "\n",
        "print(\"UC_CT_DP_train\",UC_CT_DP_train.shape)\n",
        "print(\"code_CT_DP_train\",code_CT_DP_train.shape)\n",
        "\n",
        "np.save('./Dataset/errai_dataset/pickles/UC_CT_DP_train.npy',UC_CT_DP_train)\n",
        "np.save('./Dataset/errai_dataset/pickles/code_CT_DP_train.npy',code_CT_DP_train) \n",
        "#149.17min"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#----------------------------------ClusteringTendency test-------------------------------------------------\n",
        "# 4.1) Clustering Tendency using JensenShannon\n",
        "UC_CT_JensenShannon_test = featureExtraction.ClusteringTendency(JS_UC_test.T,tfidf_matrix_uc_test,tfidf_matrix_code_test)\n",
        "code_CT_JensenShannon_test = featureExtraction.ClusteringTendency(JS_CC_test,tfidf_matrix_code_test,tfidf_matrix_uc_test)\n",
        "\n",
        "print(\"UC_CT_JensenShannon_test\",UC_CT_JensenShannon_test.shape)\n",
        "print(\"code_CT_JensenShannon_test\",code_CT_JensenShannon_test.shape)\n",
        "\n",
        "np.save('./Dataset/errai_dataset/pickles/UC_CT_JensenShannon_test.npy',UC_CT_JensenShannon_test)\n",
        "np.save('./Dataset/errai_dataset/pickles/code_CT_JensenShannon_test.npy',code_CT_JensenShannon_test) \n",
        "\n",
        "# 4.2) Clustering Tendency using VSM\n",
        "UC_CT_VSM_test = featureExtraction.ClusteringTendency(cosine_similarity_UC_test.T,tfidf_matrix_uc_test,tfidf_matrix_code_test)\n",
        "code_CT_VSM_test = featureExtraction.ClusteringTendency(cosine_similarity_CC_test,tfidf_matrix_code_test,tfidf_matrix_uc_test)\n",
        "\n",
        "print(\"UC_CT_VSM_test\",UC_CT_VSM_test.shape)\n",
        "print(\"code_CT_VSM_test\",code_CT_VSM_test.shape)\n",
        "\n",
        "np.save('./Dataset/errai_dataset/pickles/UC_CT_VSM_test.npy',UC_CT_VSM_test)\n",
        "np.save('./Dataset/errai_dataset/pickles/code_CT_VSM_test.npy',code_CT_VSM_test)\n",
        "\n",
        "# 4.3) Clustering Tendency using BM25\n",
        "UC_CT_BM25_test = featureExtraction.ClusteringTendency(BM25_UC_test,tfidf_matrix_uc_test,tfidf_matrix_code_test)\n",
        "code_CT_BM25_test = featureExtraction.ClusteringTendency(BM25_CC_test,tfidf_matrix_code_test,tfidf_matrix_uc_test)\n",
        "\n",
        "print(\"UC_CT_BM25_test\",UC_CT_BM25_test.shape)\n",
        "print(\"code_CT_BM25_test\",code_CT_BM25_test.shape)\n",
        "\n",
        "np.save('./Dataset/errai_dataset/pickles/UC_CT_BM25_test.npy', UC_CT_BM25_test)\n",
        "np.save('./Dataset/errai_dataset/pickles/code_CT_BM25_test.npy', code_CT_BM25_test)\n",
        "\n",
        "# 4.4) Clustering Tendency using JM\n",
        "UC_CT_JM_test = featureExtraction.ClusteringTendency(JM_UC_test,tfidf_matrix_uc_test,tfidf_matrix_code_test)\n",
        "code_CT_JM_test = featureExtraction.ClusteringTendency(JM_CC_test,tfidf_matrix_code_test,tfidf_matrix_uc_test)\n",
        "\n",
        "print(\"UC_CT_JM_test\",UC_CT_JM_test.shape)\n",
        "print(\"code_CT_JM_test\",code_CT_JM_test.shape)\n",
        "\n",
        "np.save('./Dataset/errai_dataset/pickles/UC_CT_JM_test.npy', UC_CT_JM_test)\n",
        "np.save('./Dataset/errai_dataset/pickles/code_CT_JM_test.npy', code_CT_JM_test)\n",
        "\n",
        "# 4.5) Clustering Tendency using DP\n",
        "UC_CT_DP_test = featureExtraction.ClusteringTendency(DP_UC_test,tfidf_matrix_uc_test,tfidf_matrix_code_test)\n",
        "code_CT_DP_test = featureExtraction.ClusteringTendency(DP_CC_test,tfidf_matrix_code_test,tfidf_matrix_uc_test)\n",
        "\n",
        "print(\"UC_CT_DP_test\",UC_CT_DP_test.shape)\n",
        "print(\"code_CT_DP_test\",code_CT_DP_test.shape)\n",
        "\n",
        "np.save('./Dataset/errai_dataset/pickles/UC_CT_DP_test.npy', UC_CT_DP_test)\n",
        "np.save('./Dataset/errai_dataset/pickles/code_CT_DP_test.npy', code_CT_DP_test)\n",
        "#20 min"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "UC_CT_JensenShannon_train = np.load('./Dataset/errai_dataset/pickles/UC_CT_JensenShannon_train.npy')\n",
        "code_CT_JensenShannon_train = np.load('./Dataset/errai_dataset/pickles/code_CT_JensenShannon_train.npy')\n",
        "UC_CT_VSM_train = np.load('./Dataset/errai_dataset/pickles/UC_CT_VSM_train.npy')\n",
        "code_CT_VSM_train = np.load('./Dataset/errai_dataset/pickles/code_CT_VSM_train.npy')\n",
        "UC_CT_BM25_train = np.load('./Dataset/errai_dataset/pickles/UC_CT_BM25_train.npy')\n",
        "code_CT_BM25_train = np.load('./Dataset/errai_dataset/pickles/code_CT_BM25_train.npy')\n",
        "UC_CT_JM_train = np.load('./Dataset/errai_dataset/pickles/UC_CT_JM_train.npy')\n",
        "code_CT_JM_train = np.load('./Dataset/errai_dataset/pickles/code_CT_JM_train.npy')\n",
        "UC_CT_DP_train = np.load('./Dataset/errai_dataset/pickles/UC_CT_DP_train.npy')\n",
        "code_CT_DP_train = np.load('./Dataset/errai_dataset/pickles/code_CT_DP_train.npy')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "UC_CT_JensenShannon_train = normalizer.fit_transform(UC_CT_JensenShannon_train)\n",
        "code_CT_JensenShannon_train = normalizer.fit_transform(code_CT_JensenShannon_train)\n",
        "UC_CT_VSM_train = normalizer.fit_transform(UC_CT_VSM_train)\n",
        "code_CT_VSM_train = normalizer.fit_transform(code_CT_VSM_train)\n",
        "UC_CT_BM25_train = normalizer.fit_transform(UC_CT_BM25_train)\n",
        "code_CT_BM25_train = normalizer.fit_transform(code_CT_BM25_train)\n",
        "UC_CT_JM_train = normalizer.fit_transform(UC_CT_JM_train)\n",
        "code_CT_JM_train = normalizer.fit_transform(code_CT_JM_train)\n",
        "UC_CT_DP_train = normalizer.fit_transform(UC_CT_DP_train)\n",
        "code_CT_DP_train = normalizer.fit_transform(code_CT_DP_train)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "UC_CT_JensenShannon_test = np.load('./Dataset/errai_dataset/pickles/UC_CT_JensenShannon_test.npy')\n",
        "code_CT_JensenShannon_test = np.load('./Dataset/errai_dataset/pickles/code_CT_JensenShannon_test.npy')\n",
        "UC_CT_VSM_test = np.load('./Dataset/errai_dataset/pickles/UC_CT_VSM_test.npy')\n",
        "code_CT_VSM_test = np.load('./Dataset/errai_dataset/pickles/code_CT_VSM_test.npy')\n",
        "UC_CT_BM25_test = np.load('./Dataset/errai_dataset/pickles/UC_CT_BM25_test.npy')\n",
        "code_CT_BM25_test = np.load('./Dataset/errai_dataset/pickles/code_CT_BM25_test.npy')\n",
        "UC_CT_JM_test = np.load('./Dataset/errai_dataset/pickles/UC_CT_JM_test.npy')\n",
        "code_CT_JM_test = np.load('./Dataset/errai_dataset/pickles/code_CT_JM_test.npy')\n",
        "UC_CT_DP_test = np.load('./Dataset/errai_dataset/pickles/UC_CT_DP_test.npy')\n",
        "code_CT_DP_test = np.load('./Dataset/errai_dataset/pickles/code_CT_DP_test.npy')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "UC_CT_JensenShannon_test = normalizer.fit_transform(UC_CT_JensenShannon_test)\n",
        "code_CT_JensenShannon_test = normalizer.fit_transform(code_CT_JensenShannon_test)\n",
        "UC_CT_VSM_test = normalizer.fit_transform(UC_CT_VSM_test)\n",
        "code_CT_VSM_test = normalizer.fit_transform(code_CT_VSM_test)\n",
        "UC_CT_BM25_test = normalizer.fit_transform(UC_CT_BM25_test)\n",
        "code_CT_BM25_test = normalizer.fit_transform(code_CT_BM25_test)\n",
        "UC_CT_JM_test = normalizer.fit_transform(UC_CT_JM_test)\n",
        "code_CT_JM_test = normalizer.fit_transform(code_CT_JM_test)\n",
        "UC_CT_DP_test = normalizer.fit_transform(UC_CT_DP_test)\n",
        "code_CT_DP_test = normalizer.fit_transform(code_CT_DP_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "#------------------------------Spatial AutoCorrelation  Train-------------------------------------------#\n",
        "# 5.1) Spatial AutoCorrelation using JensenShannon\n",
        "UC_SAC_JS_train = featureExtraction.SpatialAutoCorrelation(JS_UC_train.T,tfidf_matrix_code_train)\n",
        "code_SAC_JS_train = featureExtraction.SpatialAutoCorrelation(JS_CC_train,tfidf_matrix_uc_train)\n",
        "\n",
        "print(\"UC_SAC_JS_train\",UC_SAC_JS_train.shape)\n",
        "print(\"code_SAC_JS_train\",code_SAC_JS_train.shape)\n",
        "\n",
        "np.save('./Dataset/errai_dataset/pickles/UC_SAC_JensenShannon_train.npy',UC_SAC_JS_train)\n",
        "np.save('./Dataset/errai_dataset/pickles/code_SAC_JensenShannon_train.npy',code_SAC_JS_train)\n",
        "\n",
        "# 5.2) Spatial AutoCorrelation using VSM\n",
        "UC_SAC_VSM_train = featureExtraction.SpatialAutoCorrelation(cosine_similarity_UC_train.T,tfidf_matrix_code_train)\n",
        "code_SAC_VSM_train= featureExtraction.SpatialAutoCorrelation(cosine_similarity_CC_train,tfidf_matrix_uc_train)\n",
        "\n",
        "print(\"UC_SAC_VSM_train\",UC_SAC_VSM_train.shape)\n",
        "print(\"code_SAC_VSM_train\",code_SAC_VSM_train.shape)\n",
        "\n",
        "np.save('./Dataset/errai_dataset/pickles/UC_SAC_VSM_train.npy',UC_SAC_VSM_train)\n",
        "np.save('./Dataset/errai_dataset/pickles/code_SAC_VSM_train.npy',code_SAC_VSM_train)\n",
        "# 5.3) Spatial AutoCorrelation using BM25\n",
        "UC_SAC_BM25_train = featureExtraction.SpatialAutoCorrelation(BM25_UC_train,tfidf_matrix_code_train)\n",
        "code_SAC_BM25_train = featureExtraction.SpatialAutoCorrelation(BM25_CC_train,tfidf_matrix_uc_train)\n",
        "\n",
        "print(\"UC_SAC_BM25_train\",UC_SAC_BM25_train.shape)\n",
        "print(\"code_SAC_BM25_train\",code_SAC_BM25_train.shape)\n",
        "\n",
        "np.save('./Dataset/errai_dataset/pickles/UC_SAC_BM25_train.npy',UC_SAC_BM25_train)\n",
        "np.save('./Dataset/errai_dataset/pickles/code_SAC_BM25_train.npy',code_SAC_BM25_train)\n",
        "\n",
        "# 5.4) Spatial AutoCorrelation using JM\n",
        "UC_SAC_JM_train = featureExtraction.SpatialAutoCorrelation(JM_UC_train,tfidf_matrix_code_train)\n",
        "code_SAC_JM_train= featureExtraction.SpatialAutoCorrelation(JM_CC_train,tfidf_matrix_uc_train)\n",
        "\n",
        "print(\"UC_SAC_JM_train\",UC_SAC_JM_train.shape)\n",
        "print(\"code_SAC_JM_train\",code_SAC_JM_train.shape)\n",
        "\n",
        "np.save('./Dataset/errai_dataset/pickles/UC_SAC_JM_train.npy',UC_SAC_JM_train)\n",
        "np.save('./Dataset/errai_dataset/pickles/code_SAC_JM_train.npy',code_SAC_JM_train)\n",
        "# 5.5) Spatial AutoCorrelation using DP\n",
        "UC_SAC_DP_train = featureExtraction.SpatialAutoCorrelation(DP_UC_train,tfidf_matrix_code_train)\n",
        "code_SAC_DP_train= featureExtraction.SpatialAutoCorrelation(DP_CC_train,tfidf_matrix_uc_train)\n",
        "\n",
        "print(\"UC_SAC_DP_train\",UC_SAC_DP_train.shape)\n",
        "print(\"code_SAC_DP_train\",code_SAC_DP_train.shape)\n",
        "\n",
        "np.save('./Dataset/errai_dataset/pickles/UC_SAC_DP_train.npy',UC_SAC_DP_train)\n",
        "np.save('./Dataset/errai_dataset/pickles/code_SAC_DP_train.npy',code_SAC_DP_train)\n",
        "#51.4\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#------------------------------ Spatial AutoCorrelation  Test-------------------------------------------#\n",
        "# 5.1) Spatial AutoCorrelation using JensenShannon\n",
        "UC_SAC_JS_test = featureExtraction.SpatialAutoCorrelation(JS_UC_test.T,tfidf_matrix_code_test)\n",
        "code_SAC_JS_test = featureExtraction.SpatialAutoCorrelation(JS_CC_test,tfidf_matrix_uc_test)\n",
        "\n",
        "print(\"UC_SAC_JS_test\",UC_SAC_JS_test.shape)\n",
        "print(\"code_SAC_JS_test\",code_SAC_JS_test.shape)\n",
        "\n",
        "np.save('./Dataset/errai_dataset/pickles/UC_SAC_JensenShannon_test.npy',UC_SAC_JS_test)\n",
        "np.save('./Dataset/errai_dataset/pickles/code_SAC_JensenShannon_test.npy',code_SAC_JS_test)\n",
        "# 5.2) Spatial AutoCorrelation using VSM\n",
        "UC_SAC_VSM_test = featureExtraction.SpatialAutoCorrelation(cosine_similarity_UC_test.T,tfidf_matrix_code_test)\n",
        "code_SAC_VSM_test= featureExtraction.SpatialAutoCorrelation(cosine_similarity_CC_test,tfidf_matrix_uc_test)\n",
        "\n",
        "print(\"UC_SAC_VSM_test\",UC_SAC_VSM_test.shape)\n",
        "print(\"code_SAC_VSM_test\",code_SAC_VSM_test.shape)\n",
        "\n",
        "np.save('./Dataset/errai_dataset/pickles/UC_SAC_VSM_test.npy',UC_SAC_VSM_test)\n",
        "np.save('./Dataset/errai_dataset/pickles/code_SAC_VSM_test.npy',code_SAC_VSM_test)\n",
        "\n",
        "# 5.3) Spatial AutoCorrelation using BM25\n",
        "UC_SAC_BM25_test = featureExtraction.SpatialAutoCorrelation(BM25_UC_test,tfidf_matrix_code_test)\n",
        "code_SAC_BM25_test = featureExtraction.SpatialAutoCorrelation(BM25_CC_test,tfidf_matrix_uc_test)\n",
        "\n",
        "print(\"UC_SAC_BM25_test\",UC_SAC_BM25_test.shape)\n",
        "print(\"code_SAC_BM25_test\",code_SAC_BM25_test.shape)\n",
        "\n",
        "np.save('./Dataset/errai_dataset/pickles/UC_SAC_BM25_test.npy',UC_SAC_BM25_test)\n",
        "np.save('./Dataset/errai_dataset/pickles/code_SAC_BM25_test.npy',code_SAC_BM25_test)\n",
        "\n",
        "# 5.4) Spatial AutoCorrelation using JM\n",
        "UC_SAC_JM_test = featureExtraction.SpatialAutoCorrelation(JM_UC_test,tfidf_matrix_code_test)\n",
        "code_SAC_JM_test= featureExtraction.SpatialAutoCorrelation(JM_CC_test,tfidf_matrix_uc_test)\n",
        "\n",
        "print(\"UC_SAC_JM_test\",UC_SAC_JM_test.shape)\n",
        "print(\"code_SAC_JM_test\",code_SAC_JM_test.shape)\n",
        "\n",
        "np.save('./Dataset/errai_dataset/pickles/UC_SAC_JM_test.npy',UC_SAC_JM_test)\n",
        "np.save('./Dataset/errai_dataset/pickles/code_SAC_JM_test.npy',code_SAC_JM_test)\n",
        "\n",
        "# 5.5) Spatial AutoCorrelation using DP\n",
        "UC_SAC_DP_test = featureExtraction.SpatialAutoCorrelation(DP_UC_test,tfidf_matrix_code_test)\n",
        "code_SAC_DP_test= featureExtraction.SpatialAutoCorrelation(DP_CC_test,tfidf_matrix_uc_test)\n",
        "\n",
        "print(\"UC_SAC_DP_test\",UC_SAC_DP_test.shape)\n",
        "print(\"code_SAC_DP_test\",code_SAC_DP_test.shape)\n",
        "\n",
        "np.save('./Dataset/errai_dataset/pickles/UC_SAC_DP_test.npy',UC_SAC_DP_test)\n",
        "np.save('./Dataset/errai_dataset/pickles/code_SAC_DP_test.npy',code_SAC_DP_test)\n",
        "#7.8sec"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#------------------------------ Spatial AutoCorrelation Train Loading-------------------------------------------#\n",
        "UC_SAC_JS_train = np.load('./Dataset/errai_dataset/pickles/UC_SAC_JensenShannon_train.npy')\n",
        "code_SAC_JS_train = np.load('./Dataset/errai_dataset/pickles/code_SAC_JensenShannon_train.npy')\n",
        "UC_SAC_VSM_train = np.load('./Dataset/errai_dataset/pickles/UC_SAC_VSM_train.npy')\n",
        "code_SAC_VSM_train = np.load('./Dataset/errai_dataset/pickles/code_SAC_VSM_train.npy')\n",
        "UC_SAC_BM25_train = np.load('./Dataset/errai_dataset/pickles/UC_SAC_BM25_train.npy')\n",
        "code_SAC_BM25_train = np.load('./Dataset/errai_dataset/pickles/code_SAC_BM25_train.npy')\n",
        "UC_SAC_JM_train = np.load('./Dataset/errai_dataset/pickles/UC_SAC_JM_train.npy')\n",
        "code_SAC_JM_train = np.load('./Dataset/errai_dataset/pickles/code_SAC_JM_train.npy')\n",
        "UC_SAC_DP_train = np.load('./Dataset/errai_dataset/pickles/UC_SAC_DP_train.npy')\n",
        "code_SAC_DP_train = np.load('./Dataset/errai_dataset/pickles/code_SAC_DP_train.npy')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "UC_SAC_JS_train = normalizer.fit_transform(UC_SAC_JS_train)\n",
        "code_SAC_JS_train = normalizer.fit_transform(code_SAC_JS_train)\n",
        "UC_SAC_VSM_train = normalizer.fit_transform(UC_SAC_VSM_train)\n",
        "code_SAC_VSM_train = normalizer.fit_transform(code_SAC_VSM_train)\n",
        "UC_SAC_BM25_train = normalizer.fit_transform(UC_SAC_BM25_train)\n",
        "code_SAC_BM25_train = normalizer.fit_transform(code_SAC_BM25_train)\n",
        "UC_SAC_JM_train = normalizer.fit_transform(UC_SAC_JM_train)\n",
        "code_SAC_JM_train = normalizer.fit_transform(code_SAC_JM_train)\n",
        "UC_SAC_DP_train = normalizer.fit_transform(UC_SAC_DP_train)  #ALERT : bytl3 ones ktyera awy , ones w zero\n",
        "code_SAC_DP_train = normalizer.fit_transform(code_SAC_DP_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#------------------------------ Spatial AutoCorrelation Test Loading-------------------------------------------#\n",
        "UC_SAC_JS_test = np.load('./Dataset/errai_dataset/pickles/UC_SAC_JensenShannon_test.npy')\n",
        "code_SAC_JS_test = np.load('./Dataset/errai_dataset/pickles/code_SAC_JensenShannon_test.npy')\n",
        "UC_SAC_VSM_test = np.load('./Dataset/errai_dataset/pickles/UC_SAC_VSM_test.npy')\n",
        "code_SAC_VSM_test = np.load('./Dataset/errai_dataset/pickles/code_SAC_VSM_test.npy')\n",
        "UC_SAC_BM25_test = np.load('./Dataset/errai_dataset/pickles/UC_SAC_BM25_test.npy')\n",
        "code_SAC_BM25_test = np.load('./Dataset/errai_dataset/pickles/code_SAC_BM25_test.npy')\n",
        "UC_SAC_JM_test = np.load('./Dataset/errai_dataset/pickles/UC_SAC_JM_test.npy')\n",
        "code_SAC_JM_test = np.load('./Dataset/errai_dataset/pickles/code_SAC_JM_test.npy')\n",
        "UC_SAC_DP_test = np.load('./Dataset/errai_dataset/pickles/UC_SAC_DP_test.npy')\n",
        "code_SAC_DP_test = np.load('./Dataset/errai_dataset/pickles/code_SAC_DP_test.npy')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "UC_SAC_JS_test = normalizer.fit_transform(UC_SAC_JS_test)\n",
        "code_SAC_JS_test = normalizer.fit_transform(code_SAC_JS_test)\n",
        "UC_SAC_VSM_test = normalizer.fit_transform(UC_SAC_VSM_test)\n",
        "code_SAC_VSM_test = normalizer.fit_transform(code_SAC_VSM_test)\n",
        "UC_SAC_BM25_test = normalizer.fit_transform(UC_SAC_BM25_test)\n",
        "code_SAC_BM25_test = normalizer.fit_transform(code_SAC_BM25_test)\n",
        "UC_SAC_JM_test = normalizer.fit_transform(UC_SAC_JM_test)\n",
        "code_SAC_JM_test = normalizer.fit_transform(code_SAC_JM_test)\n",
        "UC_SAC_DP_test = normalizer.fit_transform(UC_SAC_DP_test)\n",
        "code_SAC_DP_test = normalizer.fit_transform(code_SAC_DP_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#----------------------WeightedInformationGain Train and Test-----------------#\n",
        "# 6.1) WIG using JensenShannon\n",
        "\n",
        "UC_WIG_score_JensenShannon_train = featureExtraction.WeightedInformationGain(UC_documents_train,code_documents_train,JS_UC_train.T,tf_code_dict_train,np.sum(list(tf_code_dict_train.values())))\n",
        "code_WIG_score_JensenShannon_train = featureExtraction.WeightedInformationGain(code_documents_train,UC_documents_train,JS_CC_train,tf_uc_dict_train,np.sum(list(tf_uc_dict_train.values())))\n",
        "\n",
        "np.save('./Dataset/errai_dataset/pickles/UC_WIG_score_JensenShannon_train.npy',UC_WIG_score_JensenShannon_train)\n",
        "np.save('./Dataset/errai_dataset/pickles/code_WIG_score_JensenShannon_train.npy',code_WIG_score_JensenShannon_train)\n",
        "\n",
        "UC_WIG_score_JensenShannon_test = featureExtraction.WeightedInformationGain(UC_documents_test,code_documents_test,JS_UC_test.T,tf_code_dict_test,np.sum(list(tf_code_dict_test.values())))\n",
        "code_WIG_score_JensenShannon_test = featureExtraction.WeightedInformationGain(code_documents_test,UC_documents_test,JS_CC_test,tf_uc_dict_test,np.sum(list(tf_uc_dict_test.values())))\n",
        "\n",
        "np.save('./Dataset/errai_dataset/pickles/UC_WIG_score_JensenShannon_test.npy',UC_WIG_score_JensenShannon_test)\n",
        "np.save('./Dataset/errai_dataset/pickles/code_WIG_score_JensenShannon_test.npy',code_WIG_score_JensenShannon_test)\n",
        "\n",
        "# 6.2) WIG Score using VSM\n",
        "\n",
        "UC_WIG_score_VSM_train = featureExtraction.WeightedInformationGain(UC_documents_train,code_documents_train,cosine_similarity_UC_train.T,tf_code_dict_train,np.sum(list(tf_code_dict_train.values())))\n",
        "code_WIG_score_VSM_train = featureExtraction.WeightedInformationGain(code_documents_train,UC_documents_train,cosine_similarity_CC_train,tf_uc_dict_train,np.sum(list(tf_uc_dict_train.values())))\n",
        "\n",
        "np.save('./Dataset/errai_dataset/pickles/UC_WIG_score_VSM_train.npy',UC_WIG_score_VSM_train)\n",
        "np.save('./Dataset/errai_dataset/pickles/code_WIG_score_VSM_train.npy',code_WIG_score_VSM_train)\n",
        "\n",
        "UC_WIG_score_VSM_test = featureExtraction.WeightedInformationGain(UC_documents_test,code_documents_test,cosine_similarity_UC_test.T,tf_code_dict_test,np.sum(list(tf_code_dict_test.values())))\n",
        "code_WIG_score_VSM_test = featureExtraction.WeightedInformationGain(code_documents_test,UC_documents_test,cosine_similarity_CC_test,tf_uc_dict_test,np.sum(list(tf_uc_dict_test.values())))\n",
        "\n",
        "np.save('./Dataset/errai_dataset/pickles/UC_WIG_score_VSM_test.npy',UC_WIG_score_VSM_test)\n",
        "np.save('./Dataset/errai_dataset/pickles/code_WIG_score_VSM_test.npy',code_WIG_score_VSM_test)\n",
        "\n",
        "#6.3) WIG Score using BM25\n",
        "\n",
        "UC_WIG_score_BM25_train = featureExtraction.WeightedInformationGain(UC_documents_train,code_documents_train,BM25_UC_train,tf_code_dict_train,np.sum(list(tf_code_dict_train.values())))\n",
        "code_WIG_score_BM25_train = featureExtraction.WeightedInformationGain(code_documents_train,UC_documents_train,BM25_CC_train,tf_uc_dict_train,np.sum(list(tf_uc_dict_train.values())))\n",
        "\n",
        "np.save('./Dataset/errai_dataset/pickles/UC_WIG_score_BM25_train.npy',UC_WIG_score_BM25_train)\n",
        "np.save('./Dataset/errai_dataset/pickles/code_WIG_score_BM25_train.npy',code_WIG_score_BM25_train)\n",
        "\n",
        "\n",
        "UC_WIG_score_BM25_test = featureExtraction.WeightedInformationGain(UC_documents_test,code_documents_test,BM25_UC_test,tf_code_dict_test,np.sum(list(tf_code_dict_test.values())))\n",
        "code_WIG_score_BM25_test = featureExtraction.WeightedInformationGain(code_documents_test,UC_documents_test,BM25_CC_test,tf_uc_dict_test,np.sum(list(tf_uc_dict_test.values())))\n",
        "\n",
        "np.save('./Dataset/errai_dataset/pickles/UC_WIG_score_BM25_test.npy',UC_WIG_score_BM25_test)\n",
        "np.save('./Dataset/errai_dataset/pickles/code_WIG_score_BM25_test.npy',code_WIG_score_BM25_test)\n",
        "\n",
        "#6.4) WIG Score using JM\n",
        "\n",
        "UC_WIG_score_JM_train = featureExtraction.WeightedInformationGain(UC_documents_train,code_documents_train,JM_UC_train,tf_code_dict_train,np.sum(list(tf_code_dict_train.values())))\n",
        "code_WIG_score_JM_train = featureExtraction.WeightedInformationGain(code_documents_train,UC_documents_train,JM_CC_train,tf_uc_dict_train,np.sum(list(tf_uc_dict_train.values())))\n",
        "\n",
        "np.save('./Dataset/errai_dataset/pickles/UC_WIG_score_JM_train.npy',UC_WIG_score_JM_train)\n",
        "np.save('./Dataset/errai_dataset/pickles/code_WIG_score_JM_train.npy',code_WIG_score_JM_train)\n",
        "\n",
        "UC_WIG_score_JM_test = featureExtraction.WeightedInformationGain(UC_documents_test,code_documents_test,JM_UC_test,tf_code_dict_test,np.sum(list(tf_code_dict_test.values())))\n",
        "code_WIG_score_JM_test = featureExtraction.WeightedInformationGain(code_documents_test,UC_documents_test,JM_CC_test,tf_uc_dict_test,np.sum(list(tf_uc_dict_test.values())))\n",
        "\n",
        "np.save('./Dataset/errai_dataset/pickles/UC_WIG_score_JM_test.npy',UC_WIG_score_JM_test)\n",
        "np.save('./Dataset/errai_dataset/pickles/code_WIG_score_JM_test.npy',code_WIG_score_JM_test)\n",
        "\n",
        "#6.5) WIG Score using DP\n",
        "\n",
        "UC_WIG_score_DP_train = featureExtraction.WeightedInformationGain(UC_documents_train,code_documents_train,DP_UC_train,tf_code_dict_train,np.sum(list(tf_code_dict_train.values())))\n",
        "code_WIG_score_DP_train = featureExtraction.WeightedInformationGain(code_documents_train,UC_documents_train,DP_CC_train,tf_uc_dict_train,np.sum(list(tf_uc_dict_train.values())))\n",
        "\n",
        "np.save('./Dataset/errai_dataset/pickles/UC_WIG_score_DP_train.npy',UC_WIG_score_DP_train)\n",
        "np.save('./Dataset/errai_dataset/pickles/code_WIG_score_DP_train.npy',code_WIG_score_DP_train)\n",
        "\n",
        "UC_WIG_score_DP_test = featureExtraction.WeightedInformationGain(UC_documents_test,code_documents_test,DP_UC_test,tf_code_dict_test,np.sum(list(tf_code_dict_test.values())))\n",
        "code_WIG_score_DP_test = featureExtraction.WeightedInformationGain(code_documents_test,UC_documents_test,DP_CC_test,tf_uc_dict_test,np.sum(list(tf_uc_dict_test.values())))\n",
        "\n",
        "np.save('./Dataset/errai_dataset/pickles/UC_WIG_score_DP_test.npy',UC_WIG_score_DP_test)\n",
        "np.save('./Dataset/errai_dataset/pickles/code_WIG_score_DP_test.npy',code_WIG_score_DP_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "UC_WIG_score_JensenShannon_train = np.load('./Dataset/errai_dataset/pickles/UC_WIG_score_JensenShannon_train.npy')\n",
        "code_WIG_score_JensenShannon_train = np.load('./Dataset/errai_dataset/pickles/code_WIG_score_JensenShannon_train.npy') #ALERT : el majority rakam whed\n",
        "UC_WIG_score_JensenShannon_test = np.load('./Dataset/errai_dataset/pickles/UC_WIG_score_JensenShannon_test.npy')\n",
        "code_WIG_score_JensenShannon_test = np.load('./Dataset/errai_dataset/pickles/code_WIG_score_JensenShannon_test.npy') #ALERT : el majority rakam whed\n",
        "UC_WIG_score_VSM_train = np.load('./Dataset/errai_dataset/pickles/UC_WIG_score_VSM_train.npy')\n",
        "code_WIG_score_VSM_train = np.load('./Dataset/errai_dataset/pickles/code_WIG_score_VSM_train.npy')\n",
        "UC_WIG_score_VSM_test = np.load('./Dataset/errai_dataset/pickles/UC_WIG_score_VSM_test.npy')\n",
        "code_WIG_score_VSM_test = np.load('./Dataset/errai_dataset/pickles/code_WIG_score_VSM_test.npy')\n",
        "UC_WIG_score_BM25_train = np.load('./Dataset/errai_dataset/pickles/UC_WIG_score_BM25_train.npy')\n",
        "code_WIG_score_BM25_train = np.load('./Dataset/errai_dataset/pickles/code_WIG_score_BM25_train.npy')\n",
        "UC_WIG_score_BM25_test = np.load('./Dataset/errai_dataset/pickles/UC_WIG_score_BM25_test.npy')\n",
        "code_WIG_score_BM25_test = np.load('./Dataset/errai_dataset/pickles/code_WIG_score_BM25_test.npy')\n",
        "UC_WIG_score_JM_train = np.load('./Dataset/errai_dataset/pickles/UC_WIG_score_JM_train.npy')\n",
        "code_WIG_score_JM_train = np.load('./Dataset/errai_dataset/pickles/code_WIG_score_JM_train.npy')\n",
        "UC_WIG_score_JM_test = np.load('./Dataset/errai_dataset/pickles/UC_WIG_score_JM_test.npy')\n",
        "code_WIG_score_JM_test = np.load('./Dataset/errai_dataset/pickles/code_WIG_score_JM_test.npy')\n",
        "UC_WIG_score_DP_train = np.load('./Dataset/errai_dataset/pickles/UC_WIG_score_DP_train.npy')\n",
        "code_WIG_score_DP_train = np.load('./Dataset/errai_dataset/pickles/code_WIG_score_DP_train.npy')#ALERT : el majority rakam whed\n",
        "UC_WIG_score_DP_test = np.load('./Dataset/errai_dataset/pickles/UC_WIG_score_DP_test.npy')\n",
        "code_WIG_score_DP_test = np.load('./Dataset/errai_dataset/pickles/code_WIG_score_DP_test.npy')#ALERT : el majority rakam whed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "UC_WIG_score_JensenShannon_train = normalizer.fit_transform(UC_WIG_score_JensenShannon_train)\n",
        "code_WIG_score_JensenShannon_train = normalizer.fit_transform(code_WIG_score_JensenShannon_train)\n",
        "UC_WIG_score_JensenShannon_test = normalizer.fit_transform(UC_WIG_score_JensenShannon_test)\n",
        "code_WIG_score_JensenShannon_test = normalizer.fit_transform(code_WIG_score_JensenShannon_test)\n",
        "UC_WIG_score_VSM_train = normalizer.fit_transform(UC_WIG_score_VSM_train)\n",
        "code_WIG_score_VSM_train = normalizer.fit_transform(code_WIG_score_VSM_train)  # ALERT : zeros kytyera awy\n",
        "UC_WIG_score_VSM_test = normalizer.fit_transform(UC_WIG_score_VSM_test)\n",
        "code_WIG_score_VSM_test = normalizer.fit_transform(code_WIG_score_VSM_test) # ALERT : zeros kytyera awy\n",
        "UC_WIG_score_BM25_train = normalizer.fit_transform(UC_WIG_score_BM25_train)\n",
        "code_WIG_score_BM25_train = normalizer.fit_transform(code_WIG_score_BM25_train) # ALERT : zeros kytyera awy\n",
        "UC_WIG_score_BM25_test = normalizer.fit_transform(UC_WIG_score_BM25_test)\n",
        "code_WIG_score_BM25_test = normalizer.fit_transform(code_WIG_score_BM25_test)#ALERT : el majority rakam whed\n",
        "UC_WIG_score_JM_train = normalizer.fit_transform(UC_WIG_score_JM_train)\n",
        "code_WIG_score_JM_train = normalizer.fit_transform(code_WIG_score_JM_train) # ALERT : zeros kytyera awy\n",
        "UC_WIG_score_JM_test = normalizer.fit_transform(UC_WIG_score_JM_test)\n",
        "code_WIG_score_JM_test = normalizer.fit_transform(code_WIG_score_JM_test) # ALERT : zeros kytyera awy\n",
        "UC_WIG_score_DP_train = normalizer.fit_transform(UC_WIG_score_DP_train)\n",
        "code_WIG_score_DP_train = normalizer.fit_transform(code_WIG_score_DP_train)\n",
        "UC_WIG_score_DP_test = normalizer.fit_transform(UC_WIG_score_DP_test)\n",
        "code_WIG_score_DP_test = normalizer.fit_transform(code_WIG_score_DP_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#--------------------NormalizedQueryCommitment Train and Test -----------#\n",
        "# 7.1) NQC using JensenShannon\n",
        "UC_NQC_JensenShannon_train = featureExtraction.NormalizedQueryCommitment(JS_UC_train.T)\n",
        "code_NQC_JensenShannon_train = featureExtraction.NormalizedQueryCommitment(JS_CC_train)\n",
        "\n",
        "np.save('./Dataset/errai_dataset/pickles/UC_NQC_JensenShannon_train.npy',UC_NQC_JensenShannon_train)\n",
        "np.save('./Dataset/errai_dataset/pickles/code_NQC_JensenShannon_train.npy',code_NQC_JensenShannon_train)\n",
        "\n",
        "UC_NQC_JensenShannon_test = featureExtraction.NormalizedQueryCommitment(JS_UC_test.T)\n",
        "code_NQC_JensenShannon_test = featureExtraction.NormalizedQueryCommitment(JS_CC_test)\n",
        "\n",
        "np.save('./Dataset/errai_dataset/pickles/UC_NQC_JensenShannon_test.npy',UC_NQC_JensenShannon_test)\n",
        "np.save('./Dataset/errai_dataset/pickles/code_NQC_JensenShannon_test.npy',code_NQC_JensenShannon_test)\n",
        "\n",
        "# 7.2) NQC using VSM\n",
        "UC_NQC_VSM_train = featureExtraction.NormalizedQueryCommitment(cosine_similarity_UC_train.T)\n",
        "code_NQC_VSM_train = featureExtraction.NormalizedQueryCommitment(cosine_similarity_CC_train)\n",
        "\n",
        "np.save('./Dataset/errai_dataset/pickles/UC_NQC_VSM_train.npy',UC_NQC_VSM_train)\n",
        "np.save('./Dataset/errai_dataset/pickles/code_NQC_VSM_train.npy',code_NQC_VSM_train)\n",
        "\n",
        "UC_NQC_VSM_test = featureExtraction.NormalizedQueryCommitment(cosine_similarity_UC_test.T)\n",
        "code_NQC_VSM_test = featureExtraction.NormalizedQueryCommitment(cosine_similarity_CC_test)\n",
        "\n",
        "np.save('./Dataset/errai_dataset/pickles/UC_NQC_VSM_test.npy',UC_NQC_VSM_test)\n",
        "np.save('./Dataset/errai_dataset/pickles/code_NQC_VSM_test.npy',code_NQC_VSM_test)\n",
        "\n",
        "# 7.3) NQC using BM25\n",
        "UC_NQC_BM25_train = featureExtraction.NormalizedQueryCommitment(BM25_UC_train)\n",
        "code_NQC_BM25_train = featureExtraction.NormalizedQueryCommitment(BM25_CC_train)\n",
        "\n",
        "np.save('./Dataset/errai_dataset/pickles/UC_NQC_BM25_train.npy',UC_NQC_BM25_train)\n",
        "np.save('./Dataset/errai_dataset/pickles/code_NQC_BM25_train.npy',code_NQC_BM25_train)\n",
        "\n",
        "UC_NQC_BM25_test = featureExtraction.NormalizedQueryCommitment(BM25_UC_test)\n",
        "code_NQC_BM25_test = featureExtraction.NormalizedQueryCommitment(BM25_CC_test)\n",
        "\n",
        "np.save('./Dataset/errai_dataset/pickles/UC_NQC_BM25_test.npy',UC_NQC_BM25_test)\n",
        "np.save('./Dataset/errai_dataset/pickles/code_NQC_BM25_test.npy',code_NQC_BM25_test)\n",
        "\n",
        "# 7.4) NQC using JM\n",
        "UC_NQC_JM_train = featureExtraction.NormalizedQueryCommitment(JM_UC_train)\n",
        "code_NQC_JM_train = featureExtraction.NormalizedQueryCommitment(JM_CC_train)\n",
        "\n",
        "np.save('./Dataset/errai_dataset/pickles/UC_NQC_JM_train.npy',UC_NQC_JM_train)\n",
        "np.save('./Dataset/errai_dataset/pickles/code_NQC_JM_train.npy',code_NQC_JM_train)\n",
        "\n",
        "UC_NQC_JM_test = featureExtraction.NormalizedQueryCommitment(JM_UC_test)\n",
        "code_NQC_JM_test = featureExtraction.NormalizedQueryCommitment(JM_CC_test)\n",
        "\n",
        "np.save('./Dataset/errai_dataset/pickles/UC_NQC_JM_test.npy',UC_NQC_JM_test)\n",
        "np.save('./Dataset/errai_dataset/pickles/code_NQC_JM_test.npy',code_NQC_JM_test)\n",
        "\n",
        "# 7.5) NQC using DP\n",
        "UC_NQC_DP_train = featureExtraction.NormalizedQueryCommitment(DP_UC_train)\n",
        "code_NQC_DP_train = featureExtraction.NormalizedQueryCommitment(DP_CC_train)\n",
        "\n",
        "np.save('./Dataset/errai_dataset/pickles/UC_NQC_DP_train.npy',UC_NQC_DP_train)\n",
        "np.save('./Dataset/errai_dataset/pickles/code_NQC_DP_train.npy',code_NQC_DP_train)\n",
        "\n",
        "UC_NQC_DP_test = featureExtraction.NormalizedQueryCommitment(DP_UC_test)\n",
        "code_NQC_DP_test = featureExtraction.NormalizedQueryCommitment(DP_CC_test)\n",
        "\n",
        "np.save('./Dataset/errai_dataset/pickles/UC_NQC_DP_test.npy',UC_NQC_DP_test)\n",
        "np.save('./Dataset/errai_dataset/pickles/code_NQC_DP_test.npy',code_NQC_DP_test)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "UC_NQC_JensenShannon_train = np.load('./Dataset/errai_dataset/pickles/UC_NQC_JensenShannon_train.npy')\n",
        "code_NQC_JensenShannon_train = np.load('./Dataset/errai_dataset/pickles/code_NQC_JensenShannon_train.npy')\n",
        "UC_NQC_JensenShannon_test = np.load('./Dataset/errai_dataset/pickles/UC_NQC_JensenShannon_test.npy')\n",
        "code_NQC_JensenShannon_test = np.load('./Dataset/errai_dataset/pickles/code_NQC_JensenShannon_test.npy')\n",
        "UC_NQC_VSM_train = np.load('./Dataset/errai_dataset/pickles/UC_NQC_VSM_train.npy')\n",
        "code_NQC_VSM_train = np.load('./Dataset/errai_dataset/pickles/code_NQC_VSM_train.npy')\n",
        "UC_NQC_VSM_test = np.load('./Dataset/errai_dataset/pickles/UC_NQC_VSM_test.npy')\n",
        "code_NQC_VSM_test = np.load('./Dataset/errai_dataset/pickles/code_NQC_VSM_test.npy')\n",
        "UC_NQC_BM25_train = np.load('./Dataset/errai_dataset/pickles/UC_NQC_BM25_train.npy')\n",
        "code_NQC_BM25_train = np.load('./Dataset/errai_dataset/pickles/code_NQC_BM25_train.npy')\n",
        "UC_NQC_BM25_test = np.load('./Dataset/errai_dataset/pickles/UC_NQC_BM25_test.npy')\n",
        "code_NQC_BM25_test = np.load('./Dataset/errai_dataset/pickles/code_NQC_BM25_test.npy')\n",
        "UC_NQC_JM_train = np.load('./Dataset/errai_dataset/pickles/UC_NQC_JM_train.npy')\n",
        "code_NQC_JM_train = np.load('./Dataset/errai_dataset/pickles/code_NQC_JM_train.npy')\n",
        "UC_NQC_JM_test = np.load('./Dataset/errai_dataset/pickles/UC_NQC_JM_test.npy')\n",
        "code_NQC_JM_test = np.load('./Dataset/errai_dataset/pickles/code_NQC_JM_test.npy')\n",
        "UC_NQC_DP_train = np.load('./Dataset/errai_dataset/pickles/UC_NQC_DP_train.npy')\n",
        "code_NQC_DP_train = np.load('./Dataset/errai_dataset/pickles/code_NQC_DP_train.npy')\n",
        "UC_NQC_DP_test = np.load('./Dataset/errai_dataset/pickles/UC_NQC_DP_test.npy')\n",
        "code_NQC_DP_test = np.load('./Dataset/errai_dataset/pickles/code_NQC_DP_test.npy')\n",
        "print(UC_NQC_VSM_train[0:10])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "UC_NQC_JensenShannon_train = normalizer.fit_transform(UC_NQC_JensenShannon_train)\n",
        "code_NQC_JensenShannon_train = normalizer.fit_transform(code_NQC_JensenShannon_train)\n",
        "UC_NQC_JensenShannon_test = normalizer.fit_transform(UC_NQC_JensenShannon_test)\n",
        "code_NQC_JensenShannon_test = normalizer.fit_transform(code_NQC_JensenShannon_test)\n",
        "UC_NQC_VSM_train = normalizer.fit_transform(UC_NQC_VSM_train)\n",
        "code_NQC_VSM_train = normalizer.fit_transform(code_NQC_VSM_train)\n",
        "UC_NQC_VSM_test = normalizer.fit_transform(UC_NQC_VSM_test)\n",
        "code_NQC_VSM_test = normalizer.fit_transform(code_NQC_VSM_test)\n",
        "UC_NQC_BM25_train = normalizer.fit_transform(UC_NQC_BM25_train)\n",
        "code_NQC_BM25_train = normalizer.fit_transform(code_NQC_BM25_train)\n",
        "UC_NQC_BM25_test = normalizer.fit_transform(UC_NQC_BM25_test)\n",
        "code_NQC_BM25_test = normalizer.fit_transform(code_NQC_BM25_test)\n",
        "UC_NQC_JM_train = normalizer.fit_transform(UC_NQC_JM_train)\n",
        "code_NQC_JM_train = normalizer.fit_transform(code_NQC_JM_train)\n",
        "UC_NQC_JM_test = normalizer.fit_transform(UC_NQC_JM_test)\n",
        "code_NQC_JM_test = normalizer.fit_transform(code_NQC_JM_test)\n",
        "UC_NQC_DP_train = normalizer.fit_transform(UC_NQC_DP_train)\n",
        "code_NQC_DP_train = normalizer.fit_transform(code_NQC_DP_train)\n",
        "UC_NQC_DP_test = normalizer.fit_transform(UC_NQC_DP_test)\n",
        "code_NQC_DP_test = normalizer.fit_transform(code_NQC_DP_test)\n",
        "code_NQC_DP_test = normalizer.fit_transform(code_NQC_DP_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Document Statistics Features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from FeatureExtraction import *\n",
        "featureExtraction = FeatureExtraction(Vocab_UC_train)\n",
        "num_terms_code_train, num_terms_UC_train, num_unique_terms_code_train, num_unique_terms_UC_train, num_overlapping_terms_train = featureExtraction.DocumentStatistics(UC_documents_train, code_documents_train)\n",
        "#18min"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "featureExtraction = FeatureExtraction(Vocab_UC_train)\n",
        "num_terms_code_test, num_terms_UC_test, num_unique_terms_code_test, num_unique_terms_UC_test, num_overlapping_terms_test = featureExtraction.DocumentStatistics(UC_documents_test, code_documents_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "np.save('./Dataset/errai_dataset/pickles/num_terms_code_train.npy',num_terms_code_train)\n",
        "np.save('./Dataset/errai_dataset/pickles/num_terms_UC_train.npy',num_terms_UC_train)\n",
        "np.save('./Dataset/errai_dataset/pickles/num_unique_terms_code_train.npy',num_unique_terms_code_train)\n",
        "np.save('./Dataset/errai_dataset/pickles/num_unique_terms_UC_train.npy',num_unique_terms_UC_train)\n",
        "np.save('./Dataset/errai_dataset/pickles/num_overlapping_terms_train.npy',num_overlapping_terms_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "np.save('./Dataset/errai_dataset/pickles/num_terms_code_test.npy',num_terms_code_test)\n",
        "np.save('./Dataset/errai_dataset/pickles/num_terms_UC_test.npy',num_terms_UC_test)\n",
        "np.save('./Dataset/errai_dataset/pickles/num_unique_terms_code_test.npy',num_unique_terms_code_test)\n",
        "np.save('./Dataset/errai_dataset/pickles/num_unique_terms_UC_test.npy',num_unique_terms_UC_test)\n",
        "np.save('./Dataset/errai_dataset/pickles/num_overlapping_terms_test.npy',num_overlapping_terms_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "num_terms_code_train = np.load('./Dataset/errai_dataset/pickles/num_terms_code_train.npy')\n",
        "num_terms_UC_train = np.load('./Dataset/errai_dataset/pickles/num_terms_UC_train.npy')\n",
        "num_unique_terms_code_train = np.load('./Dataset/errai_dataset/pickles/num_unique_terms_code_train.npy')\n",
        "num_unique_terms_UC_train =np.load('./Dataset/errai_dataset/pickles/num_unique_terms_UC_train.npy')\n",
        "num_overlapping_terms_train = np.load('./Dataset/errai_dataset/pickles/num_overlapping_terms_train.npy')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "num_terms_code_test = np.load('./Dataset/errai_dataset/pickles/num_terms_code_test.npy')\n",
        "num_terms_UC_test= np.load('./Dataset/errai_dataset/pickles/num_terms_UC_test.npy')\n",
        "num_unique_terms_code_test = np.load('./Dataset/errai_dataset/pickles/num_unique_terms_code_test.npy')\n",
        "num_unique_terms_UC_test =np.load('./Dataset/errai_dataset/pickles/num_unique_terms_UC_test.npy')\n",
        "num_overlapping_terms_test = np.load('./Dataset/errai_dataset/pickles/num_overlapping_terms_test.npy')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Tiling and stacking the 126 feature"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "avg_idf_uc_train = np.array(avg_idf_uc_train)\n",
        "avg_idf_code_train = np.array(avg_idf_code_train)\n",
        "max_idf_uc_train = np.array(max_idf_uc_train)\n",
        "max_idf_code_train = np.array(max_idf_code_train)\n",
        "dev_idf_uc_train = np.array(dev_idf_uc_train)\n",
        "dev_idf_code_train = np.array(dev_idf_code_train)\n",
        "avg_ictf_uc_train = np.array(avg_ictf_uc_train)\n",
        "avg_ictf_code_train = np.array(avg_ictf_code_train)\n",
        "max_ictf_uc_train = np.array(max_ictf_uc_train)\n",
        "max_ictf_code_train = np.array(max_ictf_code_train)\n",
        "dev_ictf_uc_train = np.array(dev_ictf_uc_train)\n",
        "dev_ictf_code_train = np.array(dev_ictf_code_train)\n",
        "avg_entropy_uc_train = np.array(avg_entropy_uc_train)\n",
        "avg_entropy_code_train = np.array(avg_entropy_code_train)\n",
        "max_entropy_uc_train = np.array(max_entropy_uc_train)\n",
        "max_entropy_code_train = np.array(max_entropy_code_train)\n",
        "med_entropy_uc_train = np.array(med_entropy_uc_train)\n",
        "med_entropy_code_train = np.array(med_entropy_code_train)\n",
        "dev_entropy_uc_train = np.array(dev_entropy_uc_train)\n",
        "dev_entropy_code_train = np.array(dev_entropy_code_train)\n",
        "avg_variance_uc_train = np.array(avg_variance_uc_train)\n",
        "avg_variance_code_train = np.array(avg_variance_code_train)\n",
        "max_variance_uc_train = np.array(max_variance_uc_train)\n",
        "max_variance_code_train = np.array(max_variance_code_train)\n",
        "sum_variance_uc_train = np.array(sum_variance_uc_train)\n",
        "sum_variance_code_train = np.array(sum_variance_code_train)\n",
        "avg_scq_uc_train = np.array(avg_scq_uc_train)\n",
        "avg_scq_code_train = np.array(avg_scq_code_train)\n",
        "max_scq_uc_train = np.array(max_scq_uc_train)\n",
        "max_scq_code_train = np.array(max_scq_code_train)\n",
        "sum_sqc_uc_train = np.array(sum_sqc_uc_train)\n",
        "sum_sqc_code_train = np.array(sum_sqc_code_train)\n",
        "avg_pmi_uc_train = np.array(avg_pmi_uc_train)\n",
        "avg_pmi_code_train = np.array(avg_pmi_code_train)\n",
        "max_pmi_uc_train = np.array(max_pmi_uc_train)\n",
        "max_pmi_code_train = np.array(max_pmi_code_train)\n",
        "qs_uc_train = np.array(qs_uc_train)\n",
        "qs_code_train = np.array(qs_code_train)\n",
        "UC_SCS_train = np.array(UC_SCS_train)\n",
        "CC_SCS_train = np.array(CC_SCS_train)\n",
        "UC_CoherenceScore_train = np.array(UC_CoherenceScore_train)\n",
        "CC_CoherenceScore_train = np.array(CC_CoherenceScore_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "avg_idf_uc_train_reshaped = np.tile(avg_idf_uc_train, (avg_idf_code_train.shape[0], 1))\n",
        "avg_idf_code_train_reshaped = np.tile(avg_idf_code_train, (avg_idf_uc_train.shape[0], 1))\n",
        "\n",
        "max_idf_uc_train_reshaped = np.tile(max_idf_uc_train, (max_idf_code_train.shape[0], 1))\n",
        "max_idf_code_train_reshaped = np.tile(max_idf_code_train, (max_idf_uc_train.shape[0], 1))\n",
        "\n",
        "dev_idf_uc_train_reshaped = np.tile(dev_idf_uc_train, (dev_idf_code_train.shape[0], 1))\n",
        "dev_idf_code_train_reshaped = np.tile(dev_idf_code_train, (dev_idf_uc_train.shape[0], 1))\n",
        "\n",
        "avg_ictf_uc_train_reshaped = np.tile(avg_ictf_uc_train, (avg_ictf_code_train.shape[0], 1))\n",
        "avg_ictf_code_train_reshaped = np.tile(avg_ictf_code_train, (avg_ictf_uc_train.shape[0], 1))\n",
        "\n",
        "max_ictf_uc_train_reshaped = np.tile(max_ictf_uc_train, (max_ictf_code_train.shape[0], 1))\n",
        "max_ictf_code_train_reshaped = np.tile(max_ictf_code_train, (max_ictf_uc_train.shape[0], 1))\n",
        "\n",
        "dev_ictf_uc_train_reshaped = np.tile(dev_ictf_uc_train, (dev_ictf_code_train.shape[0], 1))\n",
        "dev_ictf_code_train_reshaped = np.tile(dev_ictf_code_train, (dev_ictf_uc_train.shape[0], 1))\n",
        "\n",
        "avg_entropy_uc_train_reshaped = np.tile(avg_entropy_uc_train, (avg_entropy_code_train.shape[0], 1))\n",
        "avg_entropy_code_train_reshaped = np.tile(avg_entropy_code_train, (avg_entropy_uc_train.shape[0], 1))\n",
        "\n",
        "max_entropy_uc_train_reshaped = np.tile(max_entropy_uc_train, (max_entropy_code_train.shape[0], 1))\n",
        "max_entropy_code_train_reshaped = np.tile(max_entropy_code_train, (max_entropy_uc_train.shape[0], 1))\n",
        "\n",
        "med_entropy_uc_train_reshaped = np.tile(med_entropy_uc_train, (med_entropy_code_train.shape[0], 1))\n",
        "med_entropy_code_train_reshaped = np.tile(med_entropy_code_train, (med_entropy_uc_train.shape[0], 1))\n",
        "\n",
        "dev_entropy_uc_train_reshaped = np.tile(dev_entropy_uc_train, (dev_entropy_code_train.shape[0], 1))\n",
        "dev_entropy_code_train_reshaped = np.tile(dev_entropy_code_train, (dev_entropy_uc_train.shape[0], 1))\n",
        "\n",
        "avg_variance_uc_train_reshaped = np.tile(avg_variance_uc_train, (avg_variance_code_train.shape[0], 1))\n",
        "avg_variance_code_train_reshaped = np.tile(avg_variance_code_train, (avg_variance_uc_train.shape[0], 1))\n",
        "\n",
        "max_variance_uc_train_reshaped = np.tile(max_variance_uc_train, (max_variance_code_train.shape[0], 1))\n",
        "max_variance_code_train_reshaped = np.tile(max_variance_code_train, (max_variance_uc_train.shape[0], 1))\n",
        "\n",
        "sum_variance_uc_train_reshaped = np.tile(sum_variance_uc_train, (sum_variance_code_train.shape[0], 1))\n",
        "sum_variance_code_train_reshaped = np.tile(sum_variance_code_train, (sum_variance_uc_train.shape[0], 1))\n",
        "\n",
        "avg_scq_uc_train_reshaped = np.tile(avg_scq_uc_train, (avg_scq_code_train.shape[0], 1))\n",
        "avg_scq_code_train_reshaped = np.tile(avg_scq_code_train, (avg_scq_uc_train.shape[0], 1))\n",
        "\n",
        "max_scq_uc_train_reshaped = np.tile(max_scq_uc_train, (max_scq_code_train.shape[0], 1))\n",
        "max_scq_code_train_reshaped = np.tile(max_scq_code_train, (max_scq_uc_train.shape[0], 1))\n",
        "\n",
        "sum_sqc_uc_train_reshaped = np.tile(sum_sqc_uc_train, (sum_sqc_code_train.shape[0], 1))\n",
        "sum_sqc_code_train_reshaped = np.tile(sum_sqc_code_train, (sum_sqc_uc_train.shape[0], 1))\n",
        "\n",
        "avg_pmi_uc_train_reshaped = np.tile(avg_pmi_uc_train, (avg_pmi_code_train.shape[0], 1))\n",
        "avg_pmi_code_train_reshaped = np.tile(avg_pmi_code_train, (avg_pmi_uc_train.shape[0], 1))\n",
        "\n",
        "max_pmi_uc_train_reshaped = np.tile(max_pmi_uc_train, (max_pmi_code_train.shape[0], 1))\n",
        "max_pmi_code_train_reshaped = np.tile(max_pmi_code_train, (max_pmi_uc_train.shape[0], 1))\n",
        "\n",
        "qs_uc_train_reshaped = np.tile(qs_uc_train, (qs_code_train.shape[0], 1))\n",
        "qs_code_train_reshaped = np.tile(qs_code_train, (qs_uc_train.shape[0], 1))\n",
        "\n",
        "UC_SCS_train_reshaped = np.tile(UC_SCS_train, (1,CC_SCS_train.shape[0]))\n",
        "CC_SCS_train_reshaped = np.tile(CC_SCS_train, (1,UC_SCS_train.shape[0]))\n",
        "\n",
        "UC_CoherenceScore_train_reshaped = np.tile(UC_CoherenceScore_train, (1,CC_CoherenceScore_train.shape[0]))\n",
        "CC_CoherenceScore_train_reshaped = np.tile(CC_CoherenceScore_train, (1,UC_CoherenceScore_train.shape[0]))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "UC_RS_JS_train_reshaped = np.tile(UC_RS_JS_train, (code_RS_JS_train.shape[0],1))\n",
        "code_RS_JS_train_reshaped = np.tile(code_RS_JS_train, (UC_RS_JS_train.shape[0],1))\n",
        "UC_FRC_JS_train_reshaped = np.tile(UC_FRC_JS_train, (code_FRC_JS_train.shape[0],1))\n",
        "code_FRC_JS_train_reshaped = np.tile(code_FRC_JS_train, (UC_FRC_JS_train.shape[0],1))\n",
        "\n",
        "UC_RS_VSM_train_reshaped = np.tile(UC_RS_VSM_train, (code_RS_VSM_train.shape[0],1))\n",
        "code_RS_VSM_train_reshaped = np.tile(code_RS_VSM_train, ( UC_RS_VSM_train.shape[0],1))\n",
        "\n",
        "UC_FRC_VSM_train_reshaped = np.tile(UC_FRC_VSM_train, (code_FRC_VSM_train.shape[0],1))\n",
        "code_FRC_VSM_train_reshaped = np.tile(code_FRC_VSM_train, (UC_FRC_VSM_train.shape[0],1))\n",
        "\n",
        "UC_RS_BM25_train_reshaped = np.tile(UC_RS_BM25_train, (code_RS_BM25_train.shape[0],1))\n",
        "code_RS_BM25_train_reshaped = np.tile(code_RS_BM25_train, (UC_RS_BM25_train.shape[0],1))\n",
        "\n",
        "UC_FRC_BM25_train_reshaped = np.tile(UC_FRC_BM25_train, (code_FRC_BM25_train.shape[0],1))\n",
        "code_FRC_BM25_train_reshaped = np.tile(code_FRC_BM25_train, (UC_FRC_BM25_train.shape[0],1))\n",
        "\n",
        "UC_RS_JM_train_reshaped = np.tile(UC_RS_JM_train, (code_RS_JM_train.shape[0],1))\n",
        "code_RS_JM_train_reshaped = np.tile(code_RS_JM_train, (UC_RS_JM_train.shape[0],1))\n",
        "\n",
        "UC_FRC_JM_train_reshaped = np.tile(UC_FRC_JM_train, (code_FRC_JM_train.shape[0],1))\n",
        "code_FRC_JM_train_reshaped = np.tile(code_FRC_JM_train, (UC_FRC_JM_train.shape[0],1))\n",
        "\n",
        "UC_RS_DP_train_reshaped = np.tile(UC_RS_DP_train, (code_RS_DP_train.shape[0],1))\n",
        "code_RS_DP_train_reshaped = np.tile(code_RS_DP_train, (UC_RS_DP_train.shape[0],1))\n",
        "\n",
        "UC_FRC_DP_train_reshaped = np.tile(UC_FRC_DP_train, (code_FRC_DP_train.shape[0],1))\n",
        "code_FRC_DP_train_reshaped = np.tile(code_FRC_DP_train, (UC_FRC_DP_train.shape[0],1))\n",
        "print( code_RS_JS_train_reshaped.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "UC_CT_JensenShannon_train_reshaped = np.tile(UC_CT_JensenShannon_train, (1, code_CT_JensenShannon_train.shape[0]))\n",
        "code_CT_JensenShannon_train_reshaped = np.tile(code_CT_JensenShannon_train, (1, UC_CT_JensenShannon_train.shape[0]))\n",
        "print(UC_CT_JensenShannon_train.shape)\n",
        "UC_CT_VSM_train_reshaped = np.tile(UC_CT_VSM_train, (1, code_CT_VSM_train.shape[0]))\n",
        "code_CT_VSM_train_reshaped = np.tile(code_CT_VSM_train, (1, UC_CT_VSM_train.shape[0]))\n",
        "\n",
        "UC_CT_BM25_train_reshaped = np.tile(UC_CT_BM25_train, (1, code_CT_BM25_train.shape[0]))\n",
        "code_CT_BM25_train_reshaped = np.tile(code_CT_BM25_train, (1, UC_CT_BM25_train.shape[0]))\n",
        "\n",
        "UC_CT_JM_train_reshaped = np.tile(UC_CT_JM_train, (1, code_CT_JM_train.shape[0]))\n",
        "code_CT_JM_train_reshaped = np.tile(code_CT_JM_train, (1, UC_CT_JM_train.shape[0]))\n",
        "\n",
        "UC_CT_DP_train_reshaped = np.tile(UC_CT_DP_train, (1, code_CT_DP_train.shape[0]))\n",
        "code_CT_DP_train_reshaped = np.tile(code_CT_DP_train, (1, UC_CT_DP_train.shape[0]))\n",
        "print(code_CT_BM25_train_reshaped.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "UC_SAC_JS_train_reshaped = np.tile(UC_SAC_JS_train, (1, code_SAC_JS_train.shape[0]))\n",
        "code_SAC_JS_train_reshaped = np.tile(code_SAC_JS_train, (1, UC_SAC_JS_train.shape[0]))\n",
        "\n",
        "UC_SAC_VSM_train_reshaped = np.tile(UC_SAC_VSM_train, (1, code_SAC_VSM_train.shape[0]))\n",
        "code_SAC_VSM_train_reshaped = np.tile(code_SAC_VSM_train, (1, UC_SAC_VSM_train.shape[0]))\n",
        "\n",
        "UC_SAC_BM25_train_reshaped = np.tile(UC_SAC_BM25_train, (1, code_SAC_BM25_train.shape[0]))\n",
        "code_SAC_BM25_train_reshaped = np.tile(code_SAC_BM25_train, (1, UC_SAC_BM25_train.shape[0]))\n",
        "\n",
        "UC_SAC_JM_train_reshaped = np.tile(UC_SAC_JM_train, (1, code_SAC_JM_train.shape[0]))\n",
        "code_SAC_JM_train_reshaped = np.tile(code_SAC_JM_train, (1, UC_SAC_JM_train.shape[0]))\n",
        "\n",
        "UC_SAC_DP_train_reshaped = np.tile(UC_SAC_DP_train, (1, code_SAC_DP_train.shape[0]))\n",
        "code_SAC_DP_train_reshaped = np.tile(code_SAC_DP_train, (1, UC_SAC_DP_train.shape[0]))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "UC_WIG_score_JensenShannon_train_reshaped = np.tile(UC_WIG_score_JensenShannon_train, (1, code_WIG_score_JensenShannon_train.shape[0]))\n",
        "code_WIG_score_JensenShannon_train_reshaped = np.tile(code_WIG_score_JensenShannon_train, (1, UC_WIG_score_JensenShannon_train.shape[0]))\n",
        "\n",
        "UC_WIG_score_VSM_train_reshaped = np.tile(UC_WIG_score_VSM_train, (1, code_WIG_score_VSM_train.shape[0]))\n",
        "code_WIG_score_VSM_train_reshaped = np.tile(code_WIG_score_VSM_train, (1, UC_WIG_score_VSM_train.shape[0]))\n",
        "\n",
        "UC_WIG_score_BM25_train_reshaped = np.tile(UC_WIG_score_BM25_train, (1, code_WIG_score_BM25_train.shape[0]))\n",
        "code_WIG_score_BM25_train_reshaped = np.tile(code_WIG_score_BM25_train, (1, UC_WIG_score_BM25_train.shape[0]))\n",
        "\n",
        "UC_WIG_score_JM_train_reshaped = np.tile(UC_WIG_score_JM_train, (1, code_WIG_score_JM_train.shape[0]))\n",
        "code_WIG_score_JM_train_reshaped = np.tile(code_WIG_score_JM_train, (1, UC_WIG_score_JM_train.shape[0]))\n",
        "\n",
        "UC_WIG_score_DP_train_reshaped = np.tile(UC_WIG_score_DP_train, (1, code_WIG_score_DP_train.shape[0]))\n",
        "code_WIG_score_DP_train_reshaped = np.tile(code_WIG_score_DP_train, (1, UC_WIG_score_DP_train.shape[0]))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "UC_NQC_JensenShannon_train_reshaped = np.tile(UC_NQC_JensenShannon_train, (1, code_NQC_JensenShannon_train.shape[0]))\n",
        "code_NQC_JensenShannon_train_reshaped = np.tile(code_NQC_JensenShannon_train, (1, UC_NQC_JensenShannon_train.shape[0]))\n",
        "\n",
        "\n",
        "UC_NQC_VSM_train_reshaped = np.tile(UC_NQC_VSM_train, (1, code_NQC_VSM_train.shape[0]))\n",
        "code_NQC_VSM_train_reshaped = np.tile(code_NQC_VSM_train, (1, UC_NQC_VSM_train.shape[0]))\n",
        "\n",
        "UC_NQC_BM25_train_reshaped = np.tile(UC_NQC_BM25_train, (1, code_NQC_BM25_train.shape[0]))\n",
        "code_NQC_BM25_train_reshaped = np.tile(code_NQC_BM25_train, (1, UC_NQC_BM25_train.shape[0]))\n",
        "\n",
        "UC_NQC_JM_train_reshaped = np.tile(UC_NQC_JM_train, (1, code_NQC_JM_train.shape[0]))\n",
        "code_NQC_JM_train_reshaped = np.tile(code_NQC_JM_train, (1, UC_NQC_JM_train.shape[0]))\n",
        "\n",
        "UC_NQC_DP_train_reshaped = np.tile(UC_NQC_DP_train, (1, code_NQC_DP_train.shape[0]))\n",
        "code_NQC_DP_train_reshaped = np.tile(code_NQC_DP_train, (1, UC_NQC_DP_train.shape[0]))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "num_terms_code_train_reshaped = np.tile(num_terms_code_train, (num_terms_UC_train.shape[0],1))\n",
        "num_terms_UC_train_reshaped = np.tile(num_terms_UC_train, (num_terms_code_train.shape[0],1))\n",
        "\n",
        "num_unique_terms_UC_train_reshaped = np.tile(num_unique_terms_UC_train, (num_unique_terms_code_train.shape[0],1))\n",
        "num_unique_terms_code_train_reshaped = np.tile(num_unique_terms_code_train, (num_unique_terms_UC_train.shape[0],1))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(max_idf_uc_train_reshaped.shape)\n",
        "\n",
        "\n",
        "feature_matrix_train = np.stack(( cosine_similarity_UC_train, cosine_similarity_CC_train,\n",
        "                                 LSA_similarities_UC_train,LSA_similarities_CC_train,LDA_similarities_UC_train,LDA_similarities_CC_train,JS_UC_train,JS_CC_train,BM25_UC_train.T,BM25_CC_train,JM_UC_train.T,JM_CC_train,DP_UC_train.T,DP_CC_train,\n",
        "                           \n",
        "    avg_idf_uc_train_reshaped.T,avg_idf_code_train_reshaped,max_idf_uc_train_reshaped.T,max_idf_code_train_reshaped,\n",
        "    dev_idf_uc_train_reshaped.T,dev_idf_code_train_reshaped,avg_ictf_uc_train_reshaped.T,avg_ictf_code_train_reshaped,max_ictf_uc_train_reshaped.T,max_ictf_code_train_reshaped,dev_ictf_uc_train_reshaped.T,dev_ictf_code_train_reshaped,avg_entropy_uc_train_reshaped.T,avg_entropy_code_train_reshaped,max_entropy_uc_train_reshaped.T,max_entropy_code_train_reshaped,med_entropy_uc_train_reshaped.T,med_entropy_code_train_reshaped,dev_entropy_uc_train_reshaped.T,dev_entropy_code_train_reshaped,avg_variance_uc_train_reshaped.T,avg_variance_code_train_reshaped,max_variance_uc_train_reshaped.T,max_variance_code_train_reshaped,sum_variance_uc_train_reshaped.T,sum_variance_code_train_reshaped,avg_scq_uc_train_reshaped.T,avg_scq_code_train_reshaped,max_scq_uc_train_reshaped.T,max_scq_code_train_reshaped,sum_sqc_uc_train_reshaped.T,sum_sqc_code_train_reshaped,avg_pmi_uc_train_reshaped.T,avg_pmi_code_train_reshaped,max_pmi_uc_train_reshaped.T,max_pmi_code_train_reshaped,qs_uc_train_reshaped.T,\n",
        "    qs_code_train_reshaped,UC_SCS_train_reshaped,CC_SCS_train_reshaped.T,\n",
        "    UC_CoherenceScore_train_reshaped,CC_CoherenceScore_train_reshaped.T,\n",
        "\n",
        "    UC_FRC_DP_train_reshaped.T,code_FRC_DP_train_reshaped,UC_FRC_JM_train_reshaped.T,code_FRC_JM_train_reshaped,UC_FRC_BM25_train_reshaped.T,code_FRC_BM25_train_reshaped,UC_FRC_JS_train_reshaped.T,code_FRC_JS_train_reshaped,UC_FRC_VSM_train_reshaped.T,code_FRC_VSM_train_reshaped,\n",
        "\n",
        "    UC_RS_DP_train_reshaped.T,code_RS_DP_train_reshaped,\n",
        "    UC_RS_JM_train_reshaped.T,code_RS_JM_train_reshaped,\n",
        "    UC_RS_BM25_train_reshaped.T,code_RS_BM25_train_reshaped,\n",
        "    UC_RS_JS_train_reshaped.T,code_RS_JS_train_reshaped,\n",
        "    UC_RS_VSM_train_reshaped.T,code_RS_VSM_train_reshaped,\n",
        "\n",
        "    UC_CT_DP_train_reshaped,code_CT_DP_train_reshaped.T,UC_CT_JM_train_reshaped,\n",
        "    code_CT_JM_train_reshaped.T,UC_CT_BM25_train_reshaped,code_CT_BM25_train_reshaped.T,UC_CT_JensenShannon_train_reshaped,code_CT_JensenShannon_train_reshaped.T,UC_CT_VSM_train_reshaped,code_CT_VSM_train_reshaped.T,\n",
        "\n",
        "    UC_SAC_JM_train_reshaped,code_SAC_JM_train_reshaped.T,\n",
        "    UC_SAC_BM25_train_reshaped,code_SAC_BM25_train_reshaped.T,UC_SAC_JS_train_reshaped,code_SAC_JS_train_reshaped.T,\n",
        "    UC_SAC_VSM_train_reshaped,code_SAC_VSM_train_reshaped.T,UC_SAC_DP_train_reshaped,code_SAC_JS_train_reshaped.T,\n",
        "\n",
        "    UC_WIG_score_DP_train_reshaped,code_WIG_score_DP_train_reshaped.T,UC_WIG_score_JM_train_reshaped,\n",
        "    code_WIG_score_JM_train_reshaped.T,UC_WIG_score_BM25_train_reshaped,code_WIG_score_BM25_train_reshaped.T,UC_WIG_score_JensenShannon_train_reshaped,\n",
        "    code_WIG_score_JensenShannon_train_reshaped.T,UC_WIG_score_VSM_train_reshaped,\n",
        "    code_WIG_score_VSM_train_reshaped.T,\n",
        "\n",
        "    UC_NQC_DP_train_reshaped,code_NQC_DP_train_reshaped.T,UC_NQC_JM_train_reshaped,code_NQC_JM_train_reshaped.T,UC_NQC_BM25_train_reshaped,code_NQC_BM25_train_reshaped.T,UC_NQC_VSM_train_reshaped,code_NQC_VSM_train_reshaped.T,UC_NQC_JensenShannon_train_reshaped,code_NQC_JensenShannon_train_reshaped.T,\n",
        "\n",
        "    num_terms_UC_train_reshaped.T,num_terms_code_train_reshaped,num_unique_terms_UC_train_reshaped.T,num_unique_terms_code_train_reshaped,num_overlapping_terms_train\n",
        "),axis=2)\n",
        "\n",
        "print(feature_matrix_train.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "avg_idf_uc_test = np.array(avg_idf_uc_test)\n",
        "avg_idf_code_test = np.array(avg_idf_code_test)\n",
        "max_idf_uc_test = np.array(max_idf_uc_test)\n",
        "max_idf_code_test = np.array(max_idf_code_test)\n",
        "dev_idf_uc_test = np.array(dev_idf_uc_test)\n",
        "dev_idf_code_test = np.array(dev_idf_code_test)\n",
        "avg_ictf_uc_test = np.array(avg_ictf_uc_test)\n",
        "avg_ictf_code_test = np.array(avg_ictf_code_test)\n",
        "max_ictf_uc_test = np.array(max_ictf_uc_test)\n",
        "max_ictf_code_test = np.array(max_ictf_code_test)\n",
        "dev_ictf_uc_test = np.array(dev_ictf_uc_test)\n",
        "dev_ictf_code_test = np.array(dev_ictf_code_test)\n",
        "avg_entropy_uc_test = np.array(avg_entropy_uc_test)\n",
        "avg_entropy_code_test = np.array(avg_entropy_code_test)\n",
        "max_entropy_uc_test = np.array(max_entropy_uc_test)\n",
        "max_entropy_code_test = np.array(max_entropy_code_test)\n",
        "med_entropy_uc_test = np.array(med_entropy_uc_test)\n",
        "med_entropy_code_test = np.array(med_entropy_code_test)\n",
        "dev_entropy_uc_test = np.array(dev_entropy_uc_test)\n",
        "dev_entropy_code_test = np.array(dev_entropy_code_test)\n",
        "avg_variance_uc_test = np.array(avg_variance_uc_test)\n",
        "avg_variance_code_test = np.array(avg_variance_code_test)\n",
        "max_variance_uc_test = np.array(max_variance_uc_test)\n",
        "max_variance_code_test = np.array(max_variance_code_test)\n",
        "sum_variance_uc_test = np.array(sum_variance_uc_test)\n",
        "sum_variance_code_test = np.array(sum_variance_code_test)\n",
        "avg_scq_uc_test = np.array(avg_scq_uc_test)\n",
        "avg_scq_code_test = np.array(avg_scq_code_test)\n",
        "max_scq_uc_test = np.array(max_scq_uc_test)\n",
        "max_scq_code_test = np.array(max_scq_code_test)\n",
        "sum_sqc_uc_test = np.array(sum_sqc_uc_test)\n",
        "sum_sqc_code_test = np.array(sum_sqc_code_test)\n",
        "avg_pmi_uc_test = np.array(avg_pmi_uc_test)\n",
        "avg_pmi_code_test = np.array(avg_pmi_code_test)\n",
        "max_pmi_uc_test = np.array(max_pmi_uc_test)\n",
        "max_pmi_code_test = np.array(max_pmi_code_test)\n",
        "qs_uc_test = np.array(qs_uc_test)\n",
        "qs_code_test = np.array(qs_code_test)\n",
        "UC_SCS_test = np.array(UC_SCS_test)\n",
        "CC_SCS_test = np.array(CC_SCS_test)\n",
        "UC_CoherenceScore_test = np.array(UC_CoherenceScore_test)\n",
        "CC_CoherenceScore_test = np.array(CC_CoherenceScore_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "avg_idf_uc_test_reshaped = np.tile(avg_idf_uc_test, (avg_idf_code_test.shape[0], 1))\n",
        "avg_idf_code_test_reshaped = np.tile(avg_idf_code_test, (avg_idf_uc_test.shape[0], 1))\n",
        "\n",
        "max_idf_uc_test_reshaped = np.tile(max_idf_uc_test, (max_idf_code_test.shape[0], 1))\n",
        "max_idf_code_test_reshaped = np.tile(max_idf_code_test, (max_idf_uc_test.shape[0], 1))\n",
        "\n",
        "dev_idf_uc_test_reshaped = np.tile(dev_idf_uc_test, (dev_idf_code_test.shape[0], 1))\n",
        "dev_idf_code_test_reshaped = np.tile(dev_idf_code_test, (dev_idf_uc_test.shape[0], 1))\n",
        "\n",
        "avg_ictf_uc_test_reshaped = np.tile(avg_ictf_uc_test, (avg_ictf_code_test.shape[0], 1))\n",
        "avg_ictf_code_test_reshaped = np.tile(avg_ictf_code_test, (avg_ictf_uc_test.shape[0], 1))\n",
        "\n",
        "max_ictf_uc_test_reshaped = np.tile(max_ictf_uc_test, (max_ictf_code_test.shape[0], 1))\n",
        "max_ictf_code_test_reshaped = np.tile(max_ictf_code_test, (max_ictf_uc_test.shape[0], 1))\n",
        "\n",
        "dev_ictf_uc_test_reshaped = np.tile(dev_ictf_uc_test, (dev_ictf_code_test.shape[0], 1))\n",
        "dev_ictf_code_test_reshaped = np.tile(dev_ictf_code_test, (dev_ictf_uc_test.shape[0], 1))\n",
        "\n",
        "avg_entropy_uc_test_reshaped = np.tile(avg_entropy_uc_test, (avg_entropy_code_test.shape[0], 1))\n",
        "avg_entropy_code_test_reshaped = np.tile(avg_entropy_code_test, (avg_entropy_uc_test.shape[0], 1))\n",
        "\n",
        "max_entropy_uc_test_reshaped = np.tile(max_entropy_uc_test, (max_entropy_code_test.shape[0], 1))\n",
        "max_entropy_code_test_reshaped = np.tile(max_entropy_code_test, (max_entropy_uc_test.shape[0], 1))\n",
        "\n",
        "med_entropy_uc_test_reshaped = np.tile(med_entropy_uc_test, (med_entropy_code_test.shape[0], 1))\n",
        "med_entropy_code_test_reshaped = np.tile(med_entropy_code_test, (med_entropy_uc_test.shape[0], 1))\n",
        "\n",
        "dev_entropy_uc_test_reshaped = np.tile(dev_entropy_uc_test, (dev_entropy_code_test.shape[0], 1))\n",
        "dev_entropy_code_test_reshaped = np.tile(dev_entropy_code_test, (dev_entropy_uc_test.shape[0], 1))\n",
        "\n",
        "avg_variance_uc_test_reshaped = np.tile(avg_variance_uc_test, (avg_variance_code_test.shape[0], 1))\n",
        "avg_variance_code_test_reshaped = np.tile(avg_variance_code_test, (avg_variance_uc_test.shape[0], 1))\n",
        "\n",
        "max_variance_uc_test_reshaped = np.tile(max_variance_uc_test, (max_variance_code_test.shape[0], 1))\n",
        "max_variance_code_test_reshaped = np.tile(max_variance_code_test, (max_variance_uc_test.shape[0], 1))\n",
        "\n",
        "sum_variance_uc_test_reshaped = np.tile(sum_variance_uc_test, (sum_variance_code_test.shape[0], 1))\n",
        "sum_variance_code_test_reshaped = np.tile(sum_variance_code_test, (sum_variance_uc_test.shape[0], 1))\n",
        "\n",
        "avg_scq_uc_test_reshaped = np.tile(avg_scq_uc_test, (avg_scq_code_test.shape[0], 1))\n",
        "avg_scq_code_test_reshaped = np.tile(avg_scq_code_test, (avg_scq_uc_test.shape[0], 1))\n",
        "\n",
        "max_scq_uc_test_reshaped = np.tile(max_scq_uc_test, (max_scq_code_test.shape[0], 1))\n",
        "max_scq_code_test_reshaped = np.tile(max_scq_code_test, (max_scq_uc_test.shape[0], 1))\n",
        "\n",
        "sum_sqc_uc_test_reshaped = np.tile(sum_sqc_uc_test, (sum_sqc_code_test.shape[0], 1))\n",
        "sum_sqc_code_test_reshaped = np.tile(sum_sqc_code_test, (sum_sqc_uc_test.shape[0], 1))\n",
        "\n",
        "avg_pmi_uc_test_reshaped = np.tile(avg_pmi_uc_test, (avg_pmi_code_test.shape[0], 1))\n",
        "avg_pmi_code_test_reshaped = np.tile(avg_pmi_code_test, (avg_pmi_uc_test.shape[0], 1))\n",
        "\n",
        "max_pmi_uc_test_reshaped = np.tile(max_pmi_uc_test, (max_pmi_code_test.shape[0], 1))\n",
        "max_pmi_code_test_reshaped = np.tile(max_pmi_code_test, (max_pmi_uc_test.shape[0], 1))\n",
        "\n",
        "qs_uc_test_reshaped = np.tile(qs_uc_test, (qs_code_test.shape[0], 1))\n",
        "qs_code_test_reshaped = np.tile(qs_code_test, (qs_uc_test.shape[0], 1))\n",
        "\n",
        "UC_SCS_test_reshaped = np.tile(UC_SCS_test, (1, CC_SCS_test.shape[0]))\n",
        "CC_SCS_test_reshaped = np.tile(CC_SCS_test, (1, UC_SCS_test.shape[0]))\n",
        "\n",
        "UC_CoherenceScore_test_reshaped = np.tile(UC_CoherenceScore_test, (1, CC_CoherenceScore_test.shape[0]))\n",
        "CC_CoherenceScore_test_reshaped = np.tile(CC_CoherenceScore_test, (1, UC_CoherenceScore_test.shape[0]))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "UC_RS_JS_test_reshaped = np.tile(UC_RS_JS_test, (code_RS_JS_test.shape[0],1))\n",
        "code_RS_JS_test_reshaped = np.tile(code_RS_JS_test, (UC_RS_JS_test.shape[0],1))\n",
        "\n",
        "UC_FRC_JS_test_reshaped = np.tile(UC_FRC_JS_test, (code_FRC_JS_test.shape[0],1))\n",
        "code_FRC_JS_test_reshaped = np.tile(code_FRC_JS_test, (UC_FRC_JS_test.shape[0],1))\n",
        "\n",
        "UC_RS_VSM_test_reshaped = np.tile(UC_RS_VSM_test, (code_RS_VSM_test.shape[0],1))\n",
        "code_RS_VSM_test_reshaped = np.tile(code_RS_VSM_test, (UC_RS_VSM_test.shape[0],1))\n",
        "\n",
        "UC_FRC_VSM_test_reshaped = np.tile(UC_FRC_VSM_test, (code_FRC_VSM_test.shape[0],1))\n",
        "code_FRC_VSM_test_reshaped = np.tile(code_FRC_VSM_test, (UC_FRC_VSM_test.shape[0],1))\n",
        "\n",
        "UC_RS_BM25_test_reshaped = np.tile(UC_RS_BM25_test, (code_RS_BM25_test.shape[0],1))\n",
        "code_RS_BM25_test_reshaped = np.tile(code_RS_BM25_test, (UC_RS_BM25_test.shape[0],1))\n",
        "\n",
        "UC_FRC_BM25_test_reshaped = np.tile(UC_FRC_BM25_test, ( code_FRC_BM25_test.shape[0],1))\n",
        "code_FRC_BM25_test_reshaped = np.tile(code_FRC_BM25_test, ( UC_FRC_BM25_test.shape[0],1))\n",
        "\n",
        "UC_RS_JM_test_reshaped = np.tile(UC_RS_JM_test, (code_RS_JM_test.shape[0],1))\n",
        "code_RS_JM_test_reshaped = np.tile(code_RS_JM_test, ( UC_RS_JM_test.shape[0],1))\n",
        "\n",
        "UC_FRC_JM_test_reshaped = np.tile(UC_FRC_JM_test, ( code_FRC_JM_test.shape[0],1))\n",
        "code_FRC_JM_test_reshaped = np.tile(code_FRC_JM_test, ( UC_FRC_JM_test.shape[0],1))\n",
        "\n",
        "UC_RS_DP_test_reshaped = np.tile(UC_RS_DP_test, ( code_RS_DP_test.shape[0],1))\n",
        "code_RS_DP_test_reshaped = np.tile(code_RS_DP_test, ( UC_RS_DP_test.shape[0],1))\n",
        "\n",
        "UC_FRC_DP_test_reshaped = np.tile(UC_FRC_DP_test, (code_FRC_DP_test.shape[0],1))\n",
        "code_FRC_DP_test_reshaped = np.tile(code_FRC_DP_test, (UC_FRC_DP_test.shape[0],1))\n",
        "print(UC_FRC_DP_test_reshaped.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "UC_CT_JensenShannon_test_reshaped = np.tile(UC_CT_JensenShannon_test, (1, code_CT_JensenShannon_test.shape[0]))\n",
        "code_CT_JensenShannon_test_reshaped = np.tile(code_CT_JensenShannon_test, (1, UC_CT_JensenShannon_test.shape[0]))\n",
        "\n",
        "UC_CT_VSM_test_reshaped = np.tile(UC_CT_VSM_test, (1, code_CT_VSM_test.shape[0]))\n",
        "code_CT_VSM_test_reshaped = np.tile(code_CT_VSM_test, (1, UC_CT_VSM_test.shape[0]))\n",
        "\n",
        "UC_CT_BM25_test_reshaped = np.tile(UC_CT_BM25_test, (1, code_CT_BM25_test.shape[0]))\n",
        "code_CT_BM25_test_reshaped = np.tile(code_CT_BM25_test, (1, UC_CT_BM25_test.shape[0]))\n",
        "\n",
        "UC_CT_JM_test_reshaped = np.tile(UC_CT_JM_test, (1, code_CT_JM_test.shape[0]))\n",
        "code_CT_JM_test_reshaped = np.tile(code_CT_JM_test, (1, UC_CT_JM_test.shape[0]))\n",
        "\n",
        "UC_CT_DP_test_reshaped = np.tile(UC_CT_DP_test, (1, code_CT_DP_test.shape[0]))\n",
        "code_CT_DP_test_reshaped = np.tile(code_CT_DP_test, (1, UC_CT_DP_test.shape[0]))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "UC_SAC_JS_test_reshaped = np.tile(UC_SAC_JS_test, (1, code_SAC_JS_test.shape[0]))\n",
        "code_SAC_JS_test_reshaped = np.tile(code_SAC_JS_test, (1, UC_SAC_JS_test.shape[0]))\n",
        "\n",
        "UC_SAC_VSM_test_reshaped = np.tile(UC_SAC_VSM_test, (1, code_SAC_VSM_test.shape[0]))\n",
        "code_SAC_VSM_test_reshaped = np.tile(code_SAC_VSM_test, (1, UC_SAC_VSM_test.shape[0]))\n",
        "\n",
        "UC_SAC_BM25_test_reshaped = np.tile(UC_SAC_BM25_test, (1, code_SAC_BM25_test.shape[0]))\n",
        "code_SAC_BM25_test_reshaped = np.tile(code_SAC_BM25_test, (1, UC_SAC_BM25_test.shape[0]))\n",
        "\n",
        "UC_SAC_JM_test_reshaped = np.tile(UC_SAC_JM_test, (1, code_SAC_JM_test.shape[0]))\n",
        "code_SAC_JM_test_reshaped = np.tile(code_SAC_JM_test, (1, UC_SAC_JM_test.shape[0]))\n",
        "\n",
        "UC_SAC_DP_test_reshaped = np.tile(UC_SAC_DP_test, (1, code_SAC_DP_test.shape[0]))\n",
        "code_SAC_DP_test_reshaped = np.tile(code_SAC_DP_test, (1, UC_SAC_DP_test.shape[0]))\n",
        "\n",
        "print(code_SAC_DP_test_reshaped.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "UC_WIG_score_JensenShannon_test_reshaped = np.tile(UC_WIG_score_JensenShannon_test, (1, code_WIG_score_JensenShannon_test.shape[0]))\n",
        "code_WIG_score_JensenShannon_test_reshaped = np.tile(code_WIG_score_JensenShannon_test, (1, UC_WIG_score_JensenShannon_test.shape[0]))\n",
        "\n",
        "UC_WIG_score_VSM_test_reshaped = np.tile(UC_WIG_score_VSM_test, (1, code_WIG_score_VSM_test.shape[0]))\n",
        "code_WIG_score_VSM_test_reshaped = np.tile(code_WIG_score_VSM_test, (1, UC_WIG_score_VSM_test.shape[0]))\n",
        "\n",
        "UC_WIG_score_BM25_test_reshaped = np.tile(UC_WIG_score_BM25_test, (1, code_WIG_score_BM25_test.shape[0]))\n",
        "code_WIG_score_BM25_test_reshaped = np.tile(code_WIG_score_BM25_test, (1, UC_WIG_score_BM25_test.shape[0]))\n",
        "\n",
        "UC_WIG_score_JM_test_reshaped = np.tile(UC_WIG_score_JM_test, (1, code_WIG_score_JM_test.shape[0]))\n",
        "code_WIG_score_JM_test_reshaped = np.tile(code_WIG_score_JM_test, (1, UC_WIG_score_JM_test.shape[0]))\n",
        "\n",
        "UC_WIG_score_DP_test_reshaped = np.tile(UC_WIG_score_DP_test, (1, code_WIG_score_DP_test.shape[0]))\n",
        "code_WIG_score_DP_test_reshaped = np.tile(code_WIG_score_DP_test, (1, UC_WIG_score_DP_test.shape[0]))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "UC_NQC_JensenShannon_test_reshaped = np.tile(UC_NQC_JensenShannon_test, (1, code_NQC_JensenShannon_test.shape[0]))\n",
        "code_NQC_JensenShannon_test_reshaped = np.tile(code_NQC_JensenShannon_test, (1, UC_NQC_JensenShannon_test.shape[0]))\n",
        "\n",
        "UC_NQC_VSM_test_reshaped = np.tile(UC_NQC_VSM_test, (1, code_NQC_VSM_test.shape[0]))\n",
        "code_NQC_VSM_test_reshaped = np.tile(code_NQC_VSM_test, (1, UC_NQC_VSM_test.shape[0]))\n",
        "\n",
        "UC_NQC_BM25_test_reshaped = np.tile(UC_NQC_BM25_test, (1, code_NQC_BM25_test.shape[0]))\n",
        "code_NQC_BM25_test_reshaped = np.tile(code_NQC_BM25_test, (1, UC_NQC_BM25_test.shape[0]))\n",
        "\n",
        "UC_NQC_JM_test_reshaped = np.tile(UC_NQC_JM_test, (1, code_NQC_JM_test.shape[0]))\n",
        "code_NQC_JM_test_reshaped = np.tile(code_NQC_JM_test, (1, UC_NQC_JM_test.shape[0]))\n",
        "\n",
        "UC_NQC_DP_test_reshaped = np.tile(UC_NQC_DP_test, (1, code_NQC_DP_test.shape[0]))\n",
        "code_NQC_DP_test_reshaped = np.tile(code_NQC_DP_test, (1, UC_NQC_DP_test.shape[0]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "num_terms_code_test_reshaped = np.tile(num_terms_code_test, (num_terms_UC_test.shape[0], 1))\n",
        "num_terms_UC_test_reshaped = np.tile(num_terms_UC_test, (num_terms_code_test.shape[0], 1))\n",
        "\n",
        "num_unique_terms_UC_test_reshaped = np.tile(num_unique_terms_UC_test, (num_unique_terms_code_test.shape[0], 1))\n",
        "num_unique_terms_code_test_reshaped = np.tile(num_unique_terms_code_test, (num_unique_terms_UC_test.shape[0], 1))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(UC_FRC_DP_test_reshaped.shape)\n",
        "feature_matrix_test = np.stack(( cosine_similarity_UC_test, cosine_similarity_CC_test,\n",
        "                                 LSA_similarities_UC_test,LSA_similarities_CC_test,LDA_similarities_UC_test,LDA_similarities_CC_test,JS_UC_test,JS_CC_test,BM25_UC_test.T,BM25_CC_test,JM_UC_test.T,JM_CC_test,DP_UC_test.T,DP_CC_test,\n",
        "                           \n",
        "    avg_idf_uc_test_reshaped.T,avg_idf_code_test_reshaped,max_idf_uc_test_reshaped.T,max_idf_code_test_reshaped,\n",
        "    dev_idf_uc_test_reshaped.T,dev_idf_code_test_reshaped,avg_ictf_uc_test_reshaped.T,avg_ictf_code_test_reshaped,max_ictf_uc_test_reshaped.T,max_ictf_code_test_reshaped,dev_ictf_uc_test_reshaped.T,dev_ictf_code_test_reshaped,avg_entropy_uc_test_reshaped.T,avg_entropy_code_test_reshaped,max_entropy_uc_test_reshaped.T,max_entropy_code_test_reshaped,med_entropy_uc_test_reshaped.T,med_entropy_code_test_reshaped,dev_entropy_uc_test_reshaped.T,dev_entropy_code_test_reshaped,avg_variance_uc_test_reshaped.T,avg_variance_code_test_reshaped,max_variance_uc_test_reshaped.T,max_variance_code_test_reshaped,sum_variance_uc_test_reshaped.T,sum_variance_code_test_reshaped,avg_scq_uc_test_reshaped.T,avg_scq_code_test_reshaped,max_scq_uc_test_reshaped.T,max_scq_code_test_reshaped,sum_sqc_uc_test_reshaped.T,sum_sqc_code_test_reshaped,avg_pmi_uc_test_reshaped.T,avg_pmi_code_test_reshaped,max_pmi_uc_test_reshaped.T,max_pmi_code_test_reshaped,qs_uc_test_reshaped.T,\n",
        "    qs_code_test_reshaped,UC_SCS_test_reshaped,CC_SCS_test_reshaped.T,\n",
        "    UC_CoherenceScore_test_reshaped,CC_CoherenceScore_test_reshaped.T,\n",
        "\n",
        "    UC_FRC_DP_test_reshaped.T,code_FRC_DP_test_reshaped,UC_FRC_JM_test_reshaped.T,code_FRC_JM_test_reshaped,UC_FRC_BM25_test_reshaped.T,code_FRC_BM25_test_reshaped,UC_FRC_JS_test_reshaped.T,code_FRC_JS_test_reshaped,UC_FRC_VSM_test_reshaped.T,code_FRC_VSM_test_reshaped,\n",
        "\n",
        "    UC_RS_DP_test_reshaped.T,code_RS_DP_test_reshaped,\n",
        "    UC_RS_JM_test_reshaped.T,code_RS_JM_test_reshaped,\n",
        "    UC_RS_BM25_test_reshaped.T,code_RS_BM25_test_reshaped,\n",
        "    UC_RS_JS_test_reshaped.T,code_RS_JS_test_reshaped,\n",
        "    UC_RS_VSM_test_reshaped.T,code_RS_VSM_test_reshaped,\n",
        "\n",
        "    UC_CT_DP_test_reshaped,code_CT_DP_test_reshaped.T,UC_CT_JM_test_reshaped,\n",
        "    code_CT_JM_test_reshaped.T,UC_CT_BM25_test_reshaped,code_CT_BM25_test_reshaped.T,UC_CT_JensenShannon_test_reshaped,code_CT_JensenShannon_test_reshaped.T,UC_CT_VSM_test_reshaped,code_CT_VSM_test_reshaped.T,\n",
        "\n",
        "    UC_SAC_JM_test_reshaped,code_SAC_JM_test_reshaped.T,\n",
        "    UC_SAC_BM25_test_reshaped,code_SAC_BM25_test_reshaped.T,UC_SAC_JS_test_reshaped,code_SAC_JS_test_reshaped.T,\n",
        "    UC_SAC_VSM_test_reshaped,code_SAC_VSM_test_reshaped.T,UC_SAC_DP_test_reshaped,code_SAC_JS_test_reshaped.T,\n",
        "\n",
        "    UC_WIG_score_DP_test_reshaped,code_WIG_score_DP_test_reshaped.T,UC_WIG_score_JM_test_reshaped,\n",
        "    code_WIG_score_JM_test_reshaped.T,UC_WIG_score_BM25_test_reshaped,code_WIG_score_BM25_test_reshaped.T,UC_WIG_score_JensenShannon_test_reshaped,\n",
        "    code_WIG_score_JensenShannon_test_reshaped.T,UC_WIG_score_VSM_test_reshaped,\n",
        "    code_WIG_score_VSM_test_reshaped.T,\n",
        "\n",
        "    UC_NQC_DP_test_reshaped,code_NQC_DP_test_reshaped.T,UC_NQC_JM_test_reshaped,code_NQC_JM_test_reshaped.T,UC_NQC_BM25_test_reshaped,code_NQC_BM25_test_reshaped.T,UC_NQC_VSM_test_reshaped,code_NQC_VSM_test_reshaped.T,UC_NQC_JensenShannon_test_reshaped,code_NQC_JensenShannon_test_reshaped.T,\n",
        "\n",
        "    num_terms_UC_test_reshaped.T,num_terms_code_test_reshaped,num_unique_terms_UC_test_reshaped.T,num_unique_terms_code_test_reshaped,num_overlapping_terms_test\n",
        "),axis=2)\n",
        "print(feature_matrix_test.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Feature Selection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# matrix shape = links * features \n",
        "# ----features------\n",
        "#|\n",
        "#links\n",
        "#|\n",
        "feature_matrix_train_reshaped = feature_matrix_train.reshape(feature_matrix_train.shape[0]*feature_matrix_train.shape[1], -1)\n",
        "print(feature_matrix_train_reshaped.shape)\n",
        "correlation_features_train=np.corrcoef(feature_matrix_train_reshaped,rowvar=False)\n",
        "print(correlation_features_train.shape)\n",
        "features_excluded_train=set()\n",
        "\n",
        "for i in range(correlation_features_train.shape[1]):\n",
        "    for j in range(i+1,correlation_features_train.shape[0]):\n",
        "        if (correlation_features_train[j][i] >= 0.98 ):\n",
        "            features_excluded_train.add(j)\n",
        "\n",
        "features_links_selected_train=np.delete(feature_matrix_train_reshaped, list(features_excluded_train), axis=1) \n",
        "# print(feature_matrix_train_reshaped)\n",
        "print(features_links_selected_train.shape)\n",
        "features_links_selected_reshaped_train = features_links_selected_train.reshape(feature_matrix_train.shape[0], feature_matrix_train.shape[1], -1)\n",
        "print(features_links_selected_reshaped_train.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# matrix shape = links * features \n",
        "# ----features------\n",
        "#|\n",
        "#links\n",
        "#|\n",
        "feature_matrix_test_reshaped = feature_matrix_test.reshape(feature_matrix_test.shape[0]*feature_matrix_test.shape[1], -1)\n",
        "print(feature_matrix_test_reshaped.shape)\n",
        "correlation_features_test=np.corrcoef(feature_matrix_test_reshaped,rowvar=False)\n",
        "print(correlation_features_test.shape)\n",
        "features_excluded_test=set()\n",
        "\n",
        "features_links_selected_test=np.delete(feature_matrix_test_reshaped, list(features_excluded_train), axis=1) \n",
        "print(feature_matrix_test_reshaped)\n",
        "print(features_links_selected_test.shape)\n",
        "features_links_selected_reshaped_test = features_links_selected_test.reshape(feature_matrix_test.shape[0], feature_matrix_test.shape[1], -1)\n",
        "print(features_links_selected_reshaped_test.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Mapping Features to Labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "Features_train = list()\n",
        "DataSet_train = pd.read_csv('Dataset/errai_dataset/train_modified.csv')\n",
        "for row in DataSet_train.index:\n",
        "    index_code = int(DataSet_train.loc[row, 'CC'])\n",
        "    index_UC = int(DataSet_train.loc[row, 'UC'])\n",
        "    Features_train.append(features_links_selected_reshaped_train[index_UC][index_code])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Features_train = list()\n",
        "# DataSet_train = pd.read_csv('Dataset/errai_dataset/train_modified.csv')\n",
        "# for row in DataSet_train.index:\n",
        "#     index_code = int(DataSet_train.loc[row, 'CC'])\n",
        "#     index_UC = int(DataSet_train.loc[row, 'UC'])\n",
        "#     Features_train.append(feature_matrix_train[index_UC][index_code])\n",
        "\n",
        "# Features_test = list()\n",
        "# DataSet_test = pd.read_csv('Dataset/errai_dataset/test_modified.csv')\n",
        "# for row in DataSet_test.index:\n",
        "#     index_code = int(DataSet_test.loc[row, 'CC'])\n",
        "#     index_UC = int(DataSet_test.loc[row, 'UC'])\n",
        "#     Features_test.append(feature_matrix_test[index_UC][index_code])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "Features_test = list()\n",
        "DataSet_test = pd.read_csv('Dataset/errai_dataset/test_modified.csv')\n",
        "for row in DataSet_test.index:\n",
        "    index_code = int(DataSet_test.loc[row, 'CC'])\n",
        "    index_UC = int(DataSet_test.loc[row, 'UC'])\n",
        "    Features_test.append(features_links_selected_reshaped_test[index_UC][index_code])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(len(Features_train[0]))\n",
        "print(Features_train[1])\n",
        "print(Features_train[2])\n",
        "\n",
        "# print(len(DataSet['Labels'].to_list()))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Data Imbalancing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from imblearn.over_sampling import SMOTE \n",
        "smote = SMOTE(random_state=42)\n",
        "Features_SMOTE_train, Labels_SMOTE_train = smote.fit_resample(Features_train, DataSet_train['Labels'].to_list())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from imblearn.combine import SMOTETomek\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from imblearn.under_sampling import TomekLinks\n",
        "\n",
        "smote = SMOTETomek(smote=SMOTE(), tomek=TomekLinks(),random_state=42)\n",
        "Features_SMOTE_train, Labels_SMOTE_train = smote.fit_resample(Features_train, DataSet_train['Labels'].to_list())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# import joblib\n",
        "# joblib.dump(model_random_forest, 'Dataset/teiid_dataset/teiid_model_200.pkl')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# from sklearn.model_selection import train_test_split\n",
        "# from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "# # train_features, train_labels = train_test_split(Features_SMOTE_train, Labels_SMOTE_train, test_size = 0, random_state = 42)\n",
        "# model_random_forest = RandomForestClassifier(n_estimators = 33 ,random_state = 42, n_jobs=4)\n",
        "# model_random_forest.fit(Features_SMOTE_train, Labels_SMOTE_train)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# from joblib import load\n",
        "\n",
        "# # Load the model\n",
        "# # model = load('Dataset/teiid_dataset/teiid_model_200.pkl')\n",
        "\n",
        "# # Assuming you have test data in variables X_test and y_test\n",
        "# predictions_prob = np.array(model_random_forest.predict(Features_test))\n",
        "# predictions = np.where(predictions_prob > 0.5, 1, 0)\n",
        "# print(predictions)\n",
        "# # Calculate the accuracy of the model on the test data\n",
        "# test_labels = DataSet_test['Labels'].to_list()\n",
        "# errors = abs(predictions - test_labels)\n",
        "# print('mean Absolute Error:', round(np.mean(errors), 2) )\n",
        "\n",
        "# acc=(test_labels==predictions).sum()\n",
        "# print('Accuracy:',acc/len(test_labels))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# import sklearn\n",
        "# print(sklearn.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from joblib import load\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "\n",
        "model_random_forest = RandomForestClassifier(max_depth=9, n_estimators = 210 ,random_state = 42, n_jobs=10)\n",
        "model_random_forest.fit(Features_SMOTE_train, Labels_SMOTE_train)\n",
        "# predictions_prob = np.array(model_random_forest.predict(Features_test))\n",
        "test_labels = DataSet_test['Labels'].to_list()\n",
        "print(test_labels)\n",
        "predictions = model_random_forest.predict(Features_test)\n",
        "\n",
        "errors = abs(predictions - test_labels)\n",
        "print('mean Absolute Error:', round(np.mean(errors), 2) )\n",
        "acc=(test_labels==predictions).sum()\n",
        "print('Accuracy:',acc/len(test_labels))\n",
        "tp=0\n",
        "fp=0\n",
        "tn=0\n",
        "fn=0\n",
        "\n",
        "precision = precision_score(test_labels, predictions)\n",
        "recall = recall_score(test_labels, predictions)\n",
        "for i,prediction in enumerate(predictions):\n",
        "    if (prediction==1 and test_labels[i]==1 ):\n",
        "        tp+=1\n",
        "    elif (prediction==1 and test_labels[i]==0 ):\n",
        "        fp+=1\n",
        "    elif (prediction==0 and test_labels[i]==0 ):\n",
        "        tn+=1\n",
        "    else:\n",
        "        fn+=1\n",
        "\n",
        "print(\"tp = \", tp)\n",
        "print(\"fp = \", fp)\n",
        "print(\"tn = \", tn)\n",
        "print(\"fn = \", fn)\n",
        "print(\"recall = \", recall)\n",
        "print(\"precesion = \", precision)\n",
        "print(\"f1 = \" , f1_score(test_labels, predictions))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import joblib\n",
        "joblib.dump(model_random_forest, 'Dataset/errai_dataset/errai_model_0.4935064935064935.pkl')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from matplotlib.legend_handler import HandlerLine2D\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import roc_curve, auc\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "import joblib\n",
        "\n",
        "n_estimators =  [50,60,70,80,90,100,110,120,130,140,150,160,170,180,190,200]\n",
        "max_depth =  list(range(5,30,3))\n",
        "\n",
        "train_results = []\n",
        "test_results = []\n",
        "test_labels = DataSet_test['Labels'].to_list()\n",
        "precesion_list=[]\n",
        "recall_list=[]\n",
        "combinations = []\n",
        "max_f1 = 0\n",
        "trees = 0\n",
        "depth_max = 0\n",
        "for estimator in n_estimators:\n",
        "   for depth in max_depth:\n",
        "      combinations.append(str(estimator)+\"_\"+str(depth))\n",
        "      rf = RandomForestClassifier(n_estimators=estimator, n_jobs=10, max_depth = depth)\n",
        "      rf.fit(Features_SMOTE_train, Labels_SMOTE_train)\n",
        "\n",
        "      test_pred = rf.predict(Features_test)\n",
        "      precision = precision_score(test_labels, test_pred)\n",
        "      recall = recall_score(test_labels, test_pred)\n",
        "      f1 = f1_score(test_labels, test_pred)\n",
        "      if(f1 > max_f1):\n",
        "         trees = estimator\n",
        "         depth_max =depth\n",
        "         max_f1 = f1\n",
        "         if (f1 >= 0.5 ):\n",
        "            joblib.dump(rf, f'Dataset/teiid_dataset/errai_model{f1}.pkl')\n",
        "      test_results.append(f1)\n",
        "      precesion_list.append(precision)\n",
        "      recall_list.append(recall)\n",
        "\n",
        "plt.figure(figsize=(10, 10))\n",
        "line1, = plt.plot(combinations, train_results, 'b', label='Train f1score')\n",
        "line2, = plt.plot(combinations, test_results, 'r', label='Test f1score')\n",
        "\n",
        "plt.legend(handler_map={line1: HandlerLine2D(numpoints=2)})\n",
        "plt.ylabel('f1 score')\n",
        "plt.xlabel('n_estimators')\n",
        "plt.show()\n",
        "print(precesion_list)\n",
        "print(recall_list)\n",
        "print(test_results)\n",
        "index = test_results.index(max(test_results))\n",
        "print(precesion_list[index])\n",
        "print(recall_list[index])\n",
        "print(trees, depth_max)\n",
        "#52min"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from matplotlib.legend_handler import HandlerLine2D\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import roc_curve, auc\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "\n",
        "n_estimators =  [5,7,10,12,15,18,20,22,25,28,30,34,35,40]\n",
        "max_depth =  list(range(2,15))\n",
        "152\n",
        "\n",
        "train_results = []\n",
        "test_results = []\n",
        "test_labels = DataSet_test['Labels'].to_list()\n",
        "precesion_list=[]\n",
        "recall_list=[]\n",
        "combinations = []\n",
        "max_f1 = 0\n",
        "trees = 0\n",
        "depth_max = 0\n",
        "\n",
        "# combinations.append(str(estimator)+\"_\"+str(depth))\n",
        "rf = RandomForestClassifier(n_estimators=170,max_depth=8, n_jobs=5)\n",
        "rf.fit(Features_SMOTE_train, Labels_SMOTE_train)\n",
        "# train_pred = rf.predict(Features_SMOTE_train)\n",
        "\n",
        "test_pred = rf.predict(Features_test)\n",
        "tp=0\n",
        "fp=0\n",
        "tn=0\n",
        "fn=0\n",
        "for i,prediction in enumerate(test_pred):\n",
        "    if (prediction==1 and test_labels[i]==1 ):\n",
        "        tp+=1\n",
        "    elif (prediction==1 and test_labels[i]==0 ):\n",
        "        fp+=1\n",
        "    elif (prediction==0 and test_labels[i]==0 ):\n",
        "        tn+=1\n",
        "    else:\n",
        "        fn+=1\n",
        "print(\"tp = \", tp)\n",
        "print(\"fp = \", fp)\n",
        "print(\"tn = \", tn)\n",
        "print(\"fn = \", fn)\n",
        "recall = tp/(tp+fn)\n",
        "precision =  tp/(tp+fp)\n",
        "print(\"precesion\", precision)\n",
        "print(recall)\n",
        "print(\"f1 = \", 2*(recall*precision)/(recall + precision))\n",
        "\n",
        "'''\n",
        "precesion 0.16853932584269662\n",
        "0.625\n",
        "\n",
        "tp =  7  90-10\n",
        "fp =  8\n",
        "tn =  124\n",
        "fn =  17\n",
        "precesion 0.4666666666666667\n",
        "0.2916666666666667\n",
        "\n",
        "precesion 0.375 80 - 10\n",
        "0.5\n",
        "\n",
        "mean Absolute Error: 0.24  140-8\n",
        "Accuracy: 0.7628205128205128\n",
        "tp =  17\n",
        "fp =  30\n",
        "tn =  102\n",
        "fn =  7\n",
        "recall =  0.7083333333333334\n",
        "precesion =  0.3617021276595745\n",
        "f1 =  0.4788732394366197\n",
        "\n",
        "tp =  19 190-9\n",
        "fp =  34\n",
        "tn =  98\n",
        "fn =  5\n",
        "recall =  0.7916666666666666\n",
        "precesion =  0.3584905660377358\n",
        "f1 =  0.4935064935064935\n",
        "'''\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "index = test_results.index(max(test_results))\n",
        "print(max(test_results))\n",
        "print(precesion_list[index])\n",
        "print(recall_list[index])\n",
        "print(trees, depth_max)\n",
        "print(test_results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "'''\n",
        "tp =  127 #10-20\n",
        "fp =  1887\n",
        "tn =  6587\n",
        "fn =  80\n",
        "recall =  0.6135265700483091\n",
        "precesion 0.06305858987090368\n",
        "\n",
        "mean Absolute Error: 0.19  10 40\n",
        "Accuracy: 0.8084322082709365\n",
        "tp =  106\n",
        "fp =  1562\n",
        "tn =  6912\n",
        "fn =  101\n",
        "recall =  0.5120772946859904\n",
        "precesion 0.06354916067146282\n",
        "'''\n",
        "\n",
        "\n",
        "\n",
        "# tp =  99  10-50\n",
        "# fp =  1515\n",
        "# tn =  6959\n",
        "# fn =  108\n",
        "# recall =  0.4782608695652174\n",
        "# precesion 0.06133828996282528\n",
        "\n",
        "# tp =  69  #12-50\n",
        "# fp =  964\n",
        "# tn =  7510\n",
        "# fn =  138\n",
        "# recall =  0.3333333333333333\n",
        "# precesion 0.06679574056147145\n",
        "\n",
        "# tp =  46  #14-60\n",
        "# fp =  460\n",
        "# tn =  8014\n",
        "# fn =  161\n",
        "# recall =  0.2222222222222222\n",
        "# precesion 0.09090909090909091\n",
        " \n",
        "# tp =  27  16 - 60\n",
        "# fp =  290\n",
        "# tn =  8184\n",
        "# fn =  180\n",
        "# recall =  0.13043478260869565\n",
        "# precesion 0.08517350157728706\n",
        "\n",
        "# tp =  158 # 3 - 60\n",
        "# fp =  4232\n",
        "# tn =  4242\n",
        "# fn =  49\n",
        "# recall =  0.7632850241545893\n",
        "# precesion 0.03599088838268793\n",
        "\n",
        "# tp =  148  # 5 -60\n",
        "# fp =  3462\n",
        "# tn =  5012\n",
        "# fn =  59\n",
        "# recall =  0.714975845410628\n",
        "# precesion 0.040997229916897505\n",
        "\n",
        "# tp =  135  # 7 - 60\n",
        "# fp =  3033\n",
        "# tn =  5441\n",
        "# fn =  72\n",
        "# recall =  0.6521739130434783\n",
        "# precesion 0.04261363636363636\n",
        "\n",
        "# tp =  133  # 7 - 40\n",
        "# fp =  2911\n",
        "# tn =  5563\n",
        "# fn =  74\n",
        "# recall =  0.642512077294686\n",
        "# precesion 0.04369250985545335\n",
        "\n",
        "# tp =  134  # 7 - 45\n",
        "# fp =  3002\n",
        "# tn =  5472\n",
        "# fn =  73\n",
        "# recall =  0.6473429951690821\n",
        "# precesion 0.04272959183673469\n",
        "\n",
        "# tp =  118 # 9 - 40\n",
        "# fp =  2185\n",
        "# tn =  6289\n",
        "# fn =  89\n",
        "# recall =  0.5700483091787439\n",
        "# precesion 0.05123751628310899\n",
        "\n",
        "# tp =  102  #10 -100\n",
        "# fp =  1599\n",
        "# tn =  6875\n",
        "# fn =  105\n",
        "# recall =  0.4927536231884058\n",
        "# precesion 0.059964726631393295\n",
        "\n",
        "# tp =  72 #12-100\n",
        "# fp =  886\n",
        "# tn =  7588\n",
        "# fn =  135\n",
        "# recall =  0.34782608695652173\n",
        "# precesion 0.07515657620041753\n",
        "\n",
        "# tp =  126 #8 -100\n",
        "# fp =  2420 \n",
        "# tn =  6054\n",
        "# fn =  81\n",
        "# recall =  0.6086956521739131\n",
        "# precesion 0.04948939512961508\n",
        "\n",
        "# tp =  100  #10 - 110\n",
        "# fp =  1655\n",
        "# tn =  6819\n",
        "# fn =  107\n",
        "# recall =  0.4830917874396135\n",
        "# precesion 0.05698005698005698\n",
        "\n",
        "# tp =  102 #10 -140\n",
        "# fp =  1707\n",
        "# tn =  6767\n",
        "# fn =  105\n",
        "# recall =  0.4927536231884058\n",
        "# precesion 0.05638474295190713\n",
        "\n",
        "# tp =  54 #14 -140\n",
        "# fp =  471\n",
        "# tn =  8003\n",
        "# fn =  153\n",
        "# recall =  0.2608695652173913\n",
        "# precesion 0.10285714285714286"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Loading Model and Testing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# from joblib import dump\n",
        "\n",
        "# # Assuming you have trained a model named 'model'\n",
        "# # You can save it using dump\n",
        "# dump(model_random_forest, 'RandomForst_121Features_1st_trial.joblib')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import csv\n",
        "with open('./dataset/answerSet.csv', newline='') as csvfile:\n",
        "    reader = csv.reader(csvfile, delimiter=' ', quotechar='|')\n",
        "    valid_links_labels = []\n",
        "    for row in reader:\n",
        "        temp=row[0].split(\",\")\n",
        "        #match = re.search(rprint('UC(\\d+)\\.txt', temp[0])\n",
        "        valid_links_labels.append((temp[0],temp[1]))\n",
        "        # if (valid_links_labels.get(temp[1])==None):\n",
        "        # valid_links_labels[temp[1]]=[int(match.group(1))]\n",
        "        # else:\n",
        "        #     valid_links_labels[temp[1]].append(int(match.group(1)))\n",
        "\n",
        "# file_names = list(valid_links_labels.keys())\n",
        "# file_names.sort()\n",
        "# valid_links_labels_sorted = {i: valid_links_labels[i] for i in file_names}\n",
        "            \n",
        "# valid_links_labels_sorted)\n",
        "# len(valid_links_labels_sorted.keys()))\n",
        "print(valid_links_labels)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
