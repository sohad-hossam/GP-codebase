{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "from imports import *\n",
        "from FeatureExtraction import *\n",
        "from PreProcessor import *"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Preprocessor"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "</h3>Train </h3>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "_PreProcessor = PreProcessor()\n",
        "UC_documents_train, UC_to_index_train,Vocab_UC_train= _PreProcessor.setupUC(\"./Dataset/teiid_dataset/train_UC\", 'train')\n",
        "code_documents_train, CC_to_index_train,Vocab_CC_train = _PreProcessor.setupCC(\"./Dataset/teiid_dataset/train_CC\", 'train')\n",
        "\n",
        "UC_documents_test, UC_to_index_test,Vocab_UC_test= _PreProcessor.setupUC(\"./Dataset/teiid_dataset/test_UC\", 'test')\n",
        "code_documents_test, CC_to_index_test,Vocab_CC_test = _PreProcessor.setupCC(\"./Dataset/teiid_dataset/test_CC\", 'test')\n",
        "\n",
        "Vocab_UC_train.update(Vocab_CC_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(Vocab_UC_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "with open('./pickles/UC_documents_train.pkl', 'wb') as f:\n",
        "       pickle.dump(UC_documents_train, f)\n",
        "with open('./pickles/code_documents_train.pkl', 'wb') as f:\n",
        "        pickle.dump(code_documents_train, f)\n",
        "with open('./pickles/UCindex_train.pkl', 'wb') as f:\n",
        "        pickle.dump(UC_to_index_train, f)\n",
        "with open('./pickles/CCindex_train.pkl', 'wb') as f:\n",
        "        pickle.dump(CC_to_index_train, f)\n",
        "with open('./pickles/UCTokens_train.pkl', 'wb') as f:\n",
        "        pickle.dump(Vocab_UC_train, f)\n",
        "with open('./pickles/CodeTokens_train.pkl', 'wb') as f:\n",
        "        pickle.dump(Vocab_CC_train, f)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "</h3>Test</h3>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "with open('./pickles/UC_documents_test.pkl', 'wb') as f:\n",
        "       pickle.dump(UC_documents_test, f)\n",
        "with open('./pickles/code_documents_test.pkl', 'wb') as f:\n",
        "        pickle.dump(code_documents_test, f)\n",
        "with open('./pickles/UCindex_test.pkl', 'wb') as f:\n",
        "        pickle.dump(UC_to_index_test, f)\n",
        "with open('./pickles/CCindex_test.pkl', 'wb') as f:\n",
        "        pickle.dump(CC_to_index_test, f)\n",
        "with open('./pickles/UCTokens_test.pkl', 'wb') as f:\n",
        "        pickle.dump(Vocab_UC_test, f)\n",
        "with open('./pickles/CodeTokens_test.pkl', 'wb') as f:\n",
        "        pickle.dump(Vocab_CC_test, f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "UC_documents_train = np.load('./pickles/UC_documents_train.pkl',allow_pickle=True)\n",
        "Vocab_UC_train = np.load('./pickles/UCTokens_train.pkl',allow_pickle=True)\n",
        "code_documents_train = np.load('./pickles/code_documents_train.pkl',allow_pickle=True)\n",
        "Vocab_CC_train = np.load('./pickles/CodeTokens_train.pkl',allow_pickle=True)\n",
        "UC_to_index_train = np.load('./pickles/UCindex_train.pkl',allow_pickle=True)\n",
        "CC_to_index_train = np.load('./pickles/CCindex_train.pkl',allow_pickle=True)\n",
        "\n",
        "\n",
        "UC_documents_test = np.load('./pickles/UC_documents_test.pkl',allow_pickle=True)\n",
        "Vocab_UC_test = np.load('./pickles/UCTokens_test.pkl',allow_pickle=True)\n",
        "code_documents_test = np.load('./pickles/code_documents_test.pkl',allow_pickle=True)\n",
        "Vocab_CC_test = np.load('./pickles/CodeTokens_test.pkl',allow_pickle=True)\n",
        "UC_to_index_test = np.load('./pickles/UCindex_test.pkl',allow_pickle=True)\n",
        "CC_to_index_test = np.load('./pickles/CCindex_test.pkl',allow_pickle=True)\n",
        "\n",
        "\n",
        "\n",
        "Vocab_UC_train.update(Vocab_CC_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Initialize Normalizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "normalizer = MinMaxScaler(copy=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Adjuting the csv file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "_PreProcessor.setupCSV(\"Dataset/teiid_dataset/train.csv\", \"Dataset/teiid_dataset/train_modified.csv\",UC_to_index_train,CC_to_index_train)\n",
        "_PreProcessor.setupCSV(\"Dataset/teiid_dataset/test.csv\", \"Dataset/teiid_dataset/test_modified.csv\",UC_to_index_test,CC_to_index_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Collecting the 131 features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "featureExtraction = FeatureExtraction(Vocab_UC_train)\n",
        "\n",
        "# Feature extraction for training set\n",
        "tfidf_matrix_uc_train, tfidf_matrix_code_train, idf_uc_dict_train, idf_code_dict_train, feature_names_uc_train, feature_names_code_train, df_uc_dict_train, df_code_dict_train = featureExtraction.TFIDFVectorizer(UC_documents_train, code_documents_train,train_or_test='train')\n",
        "UC_count_matrix_train, code_count_matrix_train, tf_uc_dict_train, tf_code_dict_train = featureExtraction.CountVectorizerModel(UC_documents_train, code_documents_train, 'train')\n",
        "idf_uc_train, idf_code_train = featureExtraction.IDFPreProcessing(UC_documents_train, idf_code_dict_train, code_documents_train, idf_uc_dict_train)\n",
        "ictf_uc_train, ictf_code_train = featureExtraction.ICTFPreProcessing(UC_documents_train, tf_code_dict_train, code_documents_train, tf_uc_dict_train)\n",
        "\n",
        "# Feature extraction for testing set\n",
        "tfidf_matrix_uc_test, tfidf_matrix_code_test, idf_uc_dict_test, idf_code_dict_test, feature_names_uc_test, feature_names_code_test, df_uc_dict_test, df_code_dict_test = featureExtraction.TFIDFVectorizer(UC_documents_test, code_documents_test,train_or_test='test')\n",
        "UC_count_matrix_test, code_count_matrix_test, tf_uc_dict_test, tf_code_dict_test = featureExtraction.CountVectorizerModel(UC_documents_test, code_documents_test, 'test')\n",
        "idf_uc_test, idf_code_test = featureExtraction.IDFPreProcessing(UC_documents_test, idf_code_dict_test, code_documents_test, idf_uc_dict_test)\n",
        "ictf_uc_test, ictf_code_test = featureExtraction.ICTFPreProcessing(UC_documents_test, tf_code_dict_test, code_documents_test, tf_uc_dict_test)\n",
        "# # the values of the count matrices are normalized\n",
        "#8.3 sec"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "entropy_uc_train,entropy_code_train,variance_uc_train,variance_code_train=featureExtraction.EntropyPreProcessing(UC_documents_train,code_documents_train,idf_uc_dict_train,idf_code_dict_train,df_uc_dict_train,df_code_dict_train)\n",
        "entropy_uc_test,entropy_code_test,variance_uc_test,variance_code_test=featureExtraction.EntropyPreProcessing(UC_documents_test,code_documents_test,idf_uc_dict_test,idf_code_dict_test,df_uc_dict_test,df_code_dict_test)\n",
        "#347 min"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "with open('./pickles/entropy_uc_train.pkl', 'wb') as f:\n",
        "       pickle.dump(entropy_uc_train, f)\n",
        "with open('./pickles/entropy_code_train.pkl', 'wb') as f:\n",
        "        pickle.dump(entropy_code_train, f)\n",
        "with open('./pickles/variance_uc_train.pkl', 'wb') as f:\n",
        "        pickle.dump(variance_uc_train, f)\n",
        "with open('./pickles/variance_code_train.pkl', 'wb') as f:\n",
        "        pickle.dump(variance_code_train, f)\n",
        "\n",
        "with open('./pickles/entropy_uc_test.pkl', 'wb') as f:\n",
        "       pickle.dump(entropy_uc_test, f)\n",
        "with open('./pickles/entropy_code_test.pkl', 'wb') as f:\n",
        "        pickle.dump(entropy_code_test, f)\n",
        "with open('./pickles/variance_uc_test.pkl', 'wb') as f:\n",
        "        pickle.dump(variance_uc_test, f)\n",
        "with open('./pickles/variance_code_test.pkl', 'wb') as f:\n",
        "        pickle.dump(variance_code_test, f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "entropy_uc_train = np.load('./pickles/entropy_uc_train.pkl',allow_pickle=True)\n",
        "entropy_code_train = np.load('./pickles/entropy_code_train.pkl',allow_pickle=True)\n",
        "variance_uc_train = np.load('./pickles/variance_uc_train.pkl',allow_pickle=True)\n",
        "variance_code_train = np.load('./pickles/variance_code_train.pkl',allow_pickle=True)\n",
        "entropy_uc_test = np.load('./pickles/entropy_uc_test.pkl',allow_pickle=True)\n",
        "entropy_code_test = np.load('./pickles/entropy_code_test.pkl',allow_pickle=True)\n",
        "variance_uc_test = np.load('./pickles/variance_uc_test.pkl',allow_pickle=True)\n",
        "variance_code_test = np.load('./pickles/variance_code_test.pkl',allow_pickle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "# variance_uc_train,variance_code_train= featureExtraction.VarPreProcessing(UC_documents_train,code_documents_train,idf_uc_dict_train,idf_code_dict_train)\n",
        "PMI_uc_train,PMI_code_train=featureExtraction.PMIPreProcessing(code_documents_train,UC_documents_train)\n",
        "SCQ_uc_train,SCQ_code_train = featureExtraction.SCQPreProcessing(UC_documents_train,code_documents_train,tf_uc_dict_train,tf_code_dict_train,idf_uc_dict_train,idf_code_dict_train)\n",
        "\n",
        "# variance_uc_test,variance_code_test= featureExtraction.VarPreProcessing(UC_documents_test,code_documents_test,idf_uc_dict_test,idf_code_dict_test)\n",
        "PMI_uc_test,PMI_code_test=featureExtraction.PMIPreProcessing(code_documents_test,UC_documents_test)\n",
        "SCQ_uc_test,SCQ_code_test = featureExtraction.SCQPreProcessing(UC_documents_test,code_documents_test,tf_uc_dict_test,tf_code_dict_test,idf_uc_dict_test,idf_code_dict_test)\n",
        "#6min"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [],
      "source": [
        "with open('./pickles/PMI_uc_train.pkl', 'wb') as f:\n",
        "       pickle.dump(PMI_uc_train, f)\n",
        "with open('./pickles/PMI_code_train.pkl', 'wb') as f:\n",
        "        pickle.dump(PMI_code_train, f)\n",
        "\n",
        "with open('./pickles/SCQ_uc_train.pkl', 'wb') as f:\n",
        "         pickle.dump(SCQ_uc_train, f)\n",
        "with open('./pickles/SCQ_code_train.pkl', 'wb') as f:\n",
        "        pickle.dump(SCQ_code_train, f)\n",
        "\n",
        "with open('./pickles/PMI_uc_test.pkl', 'wb') as f:\n",
        "    pickle.dump(PMI_uc_test, f)\n",
        "\n",
        "with open('./pickles/PMI_code_test.pkl', 'wb') as f:\n",
        "    pickle.dump(PMI_code_test, f)\n",
        "\n",
        "with open('./pickles/SCQ_uc_test.pkl', 'wb') as f:\n",
        "    pickle.dump(SCQ_uc_test, f)\n",
        "\n",
        "with open('./pickles/SCQ_code_test.pkl', 'wb') as f:\n",
        "    pickle.dump(SCQ_code_test, f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [],
      "source": [
        "PMI_uc_train = np.load('./pickles/PMI_uc_train.pkl',allow_pickle=True)\n",
        "PMI_code_train = np.load('./pickles/PMI_code_train.pkl',allow_pickle=True)\n",
        "SCQ_uc_train = np.load('./pickles/SCQ_uc_train.pkl',allow_pickle=True)\n",
        "SCQ_code_train = np.load('./pickles/SCQ_code_train.pkl',allow_pickle=True)\n",
        "PMI_uc_test = np.load('./pickles/PMI_uc_test.pkl',allow_pickle=True)\n",
        "PMI_code_test = np.load('./pickles/PMI_code_test.pkl',allow_pickle=True)\n",
        "SCQ_uc_test = np.load('./pickles/SCQ_uc_test.pkl',allow_pickle=True)\n",
        "SCQ_code_test = np.load('./pickles/SCQ_code_test.pkl',allow_pickle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#-------------------------14 IR based features Train--------------------------#\n",
        "\n",
        "# 1) Vector space model\n",
        "cosine_similarities_feature_train = featureExtraction.VectorSpaceModel(tfidf_matrix_uc_train, tfidf_matrix_code_train)\n",
        "print(\"cosine_similarities_feature_train\", cosine_similarities_feature_train.shape)\n",
        "\n",
        "# Our model will classify based on the ranks of the data rather than their actual values.\n",
        "cosine_similarity_UC_train = rankdata(-cosine_similarities_feature_train, method='dense', axis=1)\n",
        "print(\"cosine_similarity_UC_train\", cosine_similarity_UC_train.shape)\n",
        "cosine_similarity_CC_train = rankdata(-cosine_similarities_feature_train, method='dense', axis=0)\n",
        "print(\"cosine_similarity_CC_train\", cosine_similarity_CC_train.shape)\n",
        "\n",
        "\n",
        "np.save('./pickles/cosine_similarity_UC_train.npy', cosine_similarity_UC_train)\n",
        "np.save('./pickles/cosine_similarity_CC_train.npy', cosine_similarity_CC_train)\n",
        "\n",
        "# 2) Latent semantic analysis\n",
        "LSA_similarities_feature_train = featureExtraction.LSA(tfidf_matrix_uc_train, tfidf_matrix_code_train)\n",
        "print('LSA similarity', LSA_similarities_feature_train.shape)\n",
        "\n",
        "LSA_similarities_UC_train = rankdata(-LSA_similarities_feature_train, method='dense', axis=1)\n",
        "print(\"LSA_similarities_UC_train\", LSA_similarities_UC_train.shape)\n",
        "LSA_similarities_CC_train = rankdata(-LSA_similarities_feature_train, method='dense', axis=0)\n",
        "print(\"LSA_similarities_CC_train\", LSA_similarities_CC_train.shape)\n",
        "\n",
        "\n",
        "np.save('./pickles/LSA_similarities_UC_train.npy', LSA_similarities_UC_train)\n",
        "np.save('./pickles/LSA_similarities_CC_train.npy', LSA_similarities_CC_train)\n",
        "\n",
        "# 3) Latent Dirichlet Allocation\n",
        "DocumentTopicDisUC_dense_train, DocumentTopicDisCode_dense_train, cosine_similarities_LDA_train = featureExtraction.LDA(UC_documents_train, code_documents_train, Vocab_UC_train)\n",
        "print('LDA similarity', cosine_similarities_LDA_train.shape)\n",
        "\n",
        "LDA_similarities_UC_train = rankdata(-cosine_similarities_LDA_train, method='dense', axis=1)\n",
        "print(\"LDA_similarities_UC_train\", LDA_similarities_UC_train.shape)\n",
        "LDA_similarities_CC_train = rankdata(-cosine_similarities_LDA_train, 'dense', axis=0)\n",
        "print(\"LDA_similarities_CC_train\", LDA_similarities_CC_train.shape)\n",
        "\n",
        "np.save('./pickles/LDA_similarities_UC_train.npy', LDA_similarities_UC_train)\n",
        "np.save('./pickles/LDA_similarities_CC_train.npy', LDA_similarities_CC_train)\n",
        "\n",
        "# 4) Jensen-Shannon(JS)\n",
        "JS_features_train = featureExtraction.JensenShannon(UC_count_matrix_train, code_count_matrix_train)\n",
        "print('JS', JS_features_train.shape)\n",
        "\n",
        "JS_UC_train = rankdata(-JS_features_train, method='dense', axis=1)\n",
        "print('JS_UC_train', JS_UC_train.shape)\n",
        "JS_CC_train = rankdata(-JS_features_train, method='dense', axis=0)\n",
        "print('JS_CC_train', JS_CC_train.shape)\n",
        "\n",
        "np.save('./pickles/JS_UC_train.npy', JS_UC_train)\n",
        "np.save('./pickles/JS_CC_train.npy', JS_CC_train)\n",
        "\n",
        "# 5)  Okapi BM25\n",
        "# UC means query is UC and document is code\n",
        "BM25_UC_train = featureExtraction.BM25(UC_documents_train, code_documents_train, idf_code_dict_train, code_count_matrix_train)\n",
        "BM25_CC_train = featureExtraction.BM25(code_documents_train, UC_documents_train, idf_uc_dict_train, UC_count_matrix_train)\n",
        "\n",
        "BM25_UC_train = rankdata(-BM25_UC_train, method='dense', axis=0)\n",
        "print(\"BM25_UC_train\", BM25_UC_train.shape)\n",
        "BM25_CC_train = rankdata(-BM25_CC_train, method='dense', axis=0)\n",
        "print(\"BM25_CC_train\", BM25_CC_train.shape)\n",
        "\n",
        "np.save('./pickles/BM25_UC_train.npy', BM25_UC_train)\n",
        "np.save('./pickles/BM25_CC_train.npy', BM25_CC_train)\n",
        "\n",
        "# 6) Language Model with Dirichlet\n",
        "# UC means UC is query and code is doc\n",
        "JM_UC_train = featureExtraction.SmoothingMethods(UC_documents_train, code_documents_train, code_count_matrix_train, tf_code_dict_train, JM_or_DP=True)\n",
        "JM_CC_train = featureExtraction.SmoothingMethods(code_documents_train, UC_documents_train, UC_count_matrix_train, tf_uc_dict_train, True)\n",
        "\n",
        "DP_UC_train = featureExtraction.SmoothingMethods(UC_documents_train, code_documents_train, code_count_matrix_train, tf_code_dict_train, JM_or_DP=False)\n",
        "DP_CC_train = featureExtraction.SmoothingMethods(code_documents_train, UC_documents_train, UC_count_matrix_train, tf_uc_dict_train, False)\n",
        "\n",
        "JM_UC_train = rankdata(-JM_UC_train, method='dense', axis=0)\n",
        "print(\"JM_UC_train\", JM_UC_train.shape)\n",
        "JM_CC_train = rankdata(-JM_CC_train, method='dense', axis=0)\n",
        "print(\"JM_CC_train\", JM_CC_train.shape)\n",
        "DP_UC_train = rankdata(-DP_UC_train, method='dense', axis=0)\n",
        "print(\"DP_UC_train\", DP_UC_train.shape)\n",
        "DP_CC_train = rankdata(-DP_CC_train, method='dense', axis=0)\n",
        "print(\"DP_CC_train\", DP_CC_train.shape)\n",
        "\n",
        "\n",
        "np.save('./pickles/JM_UC_train.npy', JM_UC_train)\n",
        "np.save('./pickles/JM_CC_train.npy', JM_CC_train)\n",
        "\n",
        "\n",
        "np.save('./pickles/DP_UC_train.npy', DP_UC_train)\n",
        "np.save('./pickles/DP_CC_train.npy', DP_CC_train)\n",
        "\n",
        "\n",
        "#-------------------------14 IR based features Test--------------------------#\n",
        "\n",
        "# 1) Vector space model\n",
        "cosine_similarities_feature_test = featureExtraction.VectorSpaceModel(tfidf_matrix_uc_test, tfidf_matrix_code_test)\n",
        "print(\"cosine_similarities_feature_test\", cosine_similarities_feature_test.shape)\n",
        "\n",
        "# Our model will classify based on the ranks of the data rather than their actual values.\n",
        "cosine_similarity_UC_test = rankdata(-cosine_similarities_feature_test, method='dense', axis=1)\n",
        "print(\"cosine_similarity_UC_test\", cosine_similarity_UC_test.shape)\n",
        "cosine_similarity_CC_test = rankdata(-cosine_similarities_feature_test, method='dense', axis=0)\n",
        "print(\"cosine_similarity_CC_test\", cosine_similarity_CC_test.shape)\n",
        "\n",
        "\n",
        "np.save('./pickles/cosine_similarity_UC_test.npy', cosine_similarity_UC_test)\n",
        "np.save('./pickles/cosine_similarity_CC_test.npy', cosine_similarity_CC_test)\n",
        "\n",
        "# 2) Latent semantic analysis\n",
        "LSA_similarities_feature_test = featureExtraction.LSA(tfidf_matrix_uc_test, tfidf_matrix_code_test)\n",
        "print('LSA similarity', LSA_similarities_feature_test.shape)\n",
        "\n",
        "LSA_similarities_UC_test = rankdata(-LSA_similarities_feature_test, method='dense', axis=1)\n",
        "print(\"LSA_similarities_UC_test\", LSA_similarities_UC_test.shape)\n",
        "LSA_similarities_CC_test = rankdata(-LSA_similarities_feature_test, method='dense', axis=0)\n",
        "print(\"LSA_similarities_CC_test\", LSA_similarities_CC_test.shape)\n",
        "\n",
        "np.save('./pickles/LSA_similarities_UC_test.npy', LSA_similarities_UC_test)\n",
        "np.save('./pickles/LSA_similarities_CC_test.npy', LSA_similarities_CC_test)\n",
        "\n",
        "# 3) Latent Dirichlet Allocation\n",
        "DocumentTopicDisUC_dense_test, DocumentTopicDisCode_dense_test, cosine_similarities_LDA_test = featureExtraction.LDA(UC_documents_test, code_documents_test, Vocab_UC_test)\n",
        "print('LDA similarity', cosine_similarities_LDA_test.shape)\n",
        "\n",
        "LDA_similarities_UC_test = rankdata(-cosine_similarities_LDA_test, method='dense', axis=1)\n",
        "print(\"LDA_similarities_UC_test\", LDA_similarities_UC_test.shape)\n",
        "LDA_similarities_CC_test = rankdata(-cosine_similarities_LDA_test, 'dense', axis=0)\n",
        "print(\"LDA_similarities_CC_test\", LDA_similarities_CC_test.shape)\n",
        "\n",
        "np.save('./pickles/LDA_similarities_UC_test.npy', LDA_similarities_UC_test)\n",
        "np.save('./pickles/LDA_similarities_CC_test.npy', LDA_similarities_CC_test)\n",
        "\n",
        "# 4) Jensen-Shannon(JS)\n",
        "JS_features_test = featureExtraction.JensenShannon(UC_count_matrix_test, code_count_matrix_test)\n",
        "print('JS', JS_features_test.shape)\n",
        "\n",
        "JS_UC_test = rankdata(-JS_features_test, method='dense', axis=1)\n",
        "print('JS_UC_test', JS_UC_test.shape)\n",
        "JS_CC_test = rankdata(-JS_features_test, method='dense', axis=0)\n",
        "print('JS_CC_test', JS_CC_test.shape)\n",
        "\n",
        "np.save('./pickles/JS_UC_test.npy', JS_UC_test)\n",
        "np.save('./pickles/JS_CC_test.npy', JS_CC_test)\n",
        "\n",
        "# 5)  Okapi BM25\n",
        "# UC means query is UC and document is code\n",
        "BM25_UC_test = featureExtraction.BM25(UC_documents_test, code_documents_test, idf_code_dict_test, code_count_matrix_test)\n",
        "BM25_CC_test = featureExtraction.BM25(code_documents_test, UC_documents_test, idf_uc_dict_test, UC_count_matrix_test)\n",
        "\n",
        "BM25_UC_test = rankdata(-BM25_UC_test, method='dense', axis=0)\n",
        "print(\"BM25_UC_test\", BM25_UC_test.shape)\n",
        "BM25_CC_test = rankdata(-BM25_CC_test, method='dense', axis=0)\n",
        "print(\"BM25_CC_test\", BM25_CC_test.shape)\n",
        "\n",
        "np.save('./pickles/BM25_UC_test.npy', BM25_UC_test)\n",
        "np.save('./pickles/BM25_CC_test.npy', BM25_CC_test)\n",
        "\n",
        "# 6) Language Model with Dirichlet\n",
        "# UC means UC is query and code is doc\n",
        "JM_UC_test = featureExtraction.SmoothingMethods(UC_documents_test, code_documents_test, code_count_matrix_test, tf_code_dict_test, JM_or_DP=True)\n",
        "JM_CC_test = featureExtraction.SmoothingMethods(code_documents_test, UC_documents_test, UC_count_matrix_test, tf_uc_dict_test, True)\n",
        "\n",
        "DP_UC_test = featureExtraction.SmoothingMethods(UC_documents_test, code_documents_test, code_count_matrix_test, tf_code_dict_test, JM_or_DP=False)\n",
        "DP_CC_test = featureExtraction.SmoothingMethods(code_documents_test, UC_documents_test, UC_count_matrix_test, tf_uc_dict_test, False)\n",
        "\n",
        "JM_UC_test = rankdata(-JM_UC_test, method='dense', axis=0)\n",
        "print(\"JM_UC_test\", JM_UC_test.shape)\n",
        "JM_CC_test = rankdata(-JM_CC_test, method='dense', axis=0)\n",
        "print(\"JM_CC_test\", JM_CC_test.shape)\n",
        "DP_UC_test = rankdata(-DP_UC_test, method='dense', axis=0)\n",
        "print(\"DP_UC_test\", DP_UC_test.shape)\n",
        "DP_CC_test = rankdata(-DP_CC_test, method='dense', axis=0)\n",
        "print(\"DP_CC_test\", DP_CC_test.shape)\n",
        "\n",
        "np.save('./pickles/JM_UC_test.npy', JM_UC_test)\n",
        "np.save('./pickles/JM_CC_test.npy', JM_CC_test)\n",
        "\n",
        "np.save('./pickles/DP_UC_test.npy', DP_UC_test)\n",
        "np.save('./pickles/DP_CC_test.npy', DP_CC_test)\n",
        "\n",
        "\n",
        "#200 MIN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#-----------------------IR Train Features Loading------------------#\n",
        "cosine_similarity_UC_train = np.load('./pickles/cosine_similarity_UC_train.npy')\n",
        "cosine_similarity_UC_train = normalizer.fit_transform(cosine_similarity_UC_train)\n",
        "\n",
        "cosine_similarity_CC_train = np.load('./pickles/cosine_similarity_CC_train.npy')\n",
        "cosine_similarity_CC_train = normalizer.fit_transform(cosine_similarity_CC_train)\n",
        "\n",
        "LSA_similarities_UC_train = np.load('./pickles/LSA_similarities_UC_train.npy')\n",
        "LSA_similarities_UC_train = normalizer.fit_transform(LSA_similarities_UC_train)\n",
        "\n",
        "LSA_similarities_CC_train = np.load('./pickles/LSA_similarities_CC_train.npy')\n",
        "LSA_similarities_CC_train = normalizer.fit_transform(LSA_similarities_CC_train)\n",
        "\n",
        "LDA_similarities_UC_train = np.load('./pickles/LDA_similarities_UC_train.npy')\n",
        "LDA_similarities_UC_train = normalizer.fit_transform(LDA_similarities_UC_train)\n",
        "\n",
        "LDA_similarities_CC_train = np.load('./pickles/LDA_similarities_CC_train.npy')\n",
        "LDA_similarities_CC_train = normalizer.fit_transform(LDA_similarities_CC_train)\n",
        "\n",
        "JS_UC_train = np.load('./pickles/JS_UC_train.npy')\n",
        "JS_UC_train = normalizer.fit_transform(JS_UC_train)\n",
        "\n",
        "JS_CC_train = np.load('./pickles/JS_CC_train.npy')\n",
        "JS_CC_train = normalizer.fit_transform(JS_CC_train)\n",
        "\n",
        "BM25_UC_train = np.load('./pickles/BM25_UC_train.npy')\n",
        "BM25_UC_train = normalizer.fit_transform(BM25_UC_train)\n",
        "\n",
        "BM25_CC_train = np.load('./pickles/BM25_CC_train.npy')\n",
        "BM25_CC_train = normalizer.fit_transform(BM25_CC_train)\n",
        "\n",
        "JM_UC_train = np.load('./pickles/JM_UC_train.npy')\n",
        "JM_UC_train = normalizer.fit_transform(JM_UC_train)\n",
        "\n",
        "JM_CC_train = np.load('./pickles/JM_CC_train.npy')\n",
        "JM_CC_train = normalizer.fit_transform(JM_CC_train)\n",
        "\n",
        "DP_UC_train = np.load('./pickles/DP_UC_train.npy')\n",
        "DP_UC_train = normalizer.fit_transform(DP_UC_train)\n",
        "\n",
        "DP_CC_train = np.load('./pickles/DP_CC_train.npy')\n",
        "DP_CC_train = normalizer.fit_transform(DP_CC_train)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#-----------------------IR Test Features Loading------------------#\n",
        "cosine_similarity_UC_test = np.load('./pickles/cosine_similarity_UC_test.npy')\n",
        "cosine_similarity_UC_test = normalizer.fit_transform(cosine_similarity_UC_test)\n",
        "\n",
        "cosine_similarity_CC_test = np.load('./pickles/cosine_similarity_CC_test.npy')\n",
        "cosine_similarity_CC_test = normalizer.fit_transform(cosine_similarity_CC_test)\n",
        "\n",
        "LSA_similarities_UC_test = np.load('./pickles/LSA_similarities_UC_test.npy')\n",
        "LSA_similarities_UC_test = normalizer.fit_transform(LSA_similarities_UC_test)\n",
        "\n",
        "LSA_similarities_CC_test = np.load('./pickles/LSA_similarities_CC_test.npy')\n",
        "LSA_similarities_CC_test = normalizer.fit_transform(LSA_similarities_CC_test)\n",
        "\n",
        "LDA_similarities_UC_test = np.load('./pickles/LDA_similarities_UC_test.npy')\n",
        "LDA_similarities_UC_test = normalizer.fit_transform(LDA_similarities_UC_test)\n",
        "\n",
        "LDA_similarities_CC_test = np.load('./pickles/LDA_similarities_CC_test.npy')\n",
        "LDA_similarities_CC_test = normalizer.fit_transform(LDA_similarities_CC_test)\n",
        "\n",
        "JS_UC_test = np.load('./pickles/JS_UC_test.npy')\n",
        "JS_UC_test = normalizer.fit_transform(JS_UC_test)\n",
        "\n",
        "JS_CC_test = np.load('./pickles/JS_CC_test.npy')\n",
        "JS_CC_test = normalizer.fit_transform(JS_CC_test)\n",
        "\n",
        "BM25_UC_test = np.load('./pickles/BM25_UC_test.npy')\n",
        "BM25_UC_test = normalizer.fit_transform(BM25_UC_test)\n",
        "\n",
        "BM25_CC_test = np.load('./pickles/BM25_CC_test.npy')\n",
        "BM25_CC_test = normalizer.fit_transform(BM25_CC_test)\n",
        "\n",
        "JM_UC_test = np.load('./pickles/JM_UC_test.npy')\n",
        "JM_UC_test = normalizer.fit_transform(JM_UC_test)\n",
        "\n",
        "JM_CC_test = np.load('./pickles/JM_CC_test.npy')\n",
        "JM_CC_test = normalizer.fit_transform(JM_CC_test)\n",
        "\n",
        "DP_UC_test = np.load('./pickles/DP_UC_test.npy')\n",
        "DP_UC_test = normalizer.fit_transform(DP_UC_test)\n",
        "\n",
        "DP_CC_test = np.load('./pickles/DP_CC_test.npy')\n",
        "DP_CC_test = normalizer.fit_transform(DP_CC_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ------------------------pre-retrieval (21 metrics) Train--------------------------#\n",
        "# 1) IDF Features\n",
        "avg_idf_uc_train = featureExtraction.AvgIDF(idf_uc_train)\n",
        "avg_idf_code_train = featureExtraction.AvgIDF(idf_code_train)\n",
        "\n",
        "print('avg_idf_uc_train_shape', avg_idf_uc_train.shape) \n",
        "print('avg_idf_code_train_shape', avg_idf_code_train.shape) \n",
        "\n",
        "max_idf_uc_train = featureExtraction.MaxIDF(idf_uc_train).reshape(1,-1) \n",
        "max_idf_code_train = featureExtraction.MaxIDF(idf_code_train).reshape(1,-1) \n",
        "\n",
        "print('max_idf_uc_train_shape', max_idf_uc_train.shape) \n",
        "print('max_idf_code_train_shape', max_idf_code_train.shape) \n",
        "\n",
        "dev_idf_uc_train = featureExtraction.DevIDF(idf_uc_train).reshape(1,-1) \n",
        "dev_idf_code_train = featureExtraction.DevIDF(idf_code_train).reshape(1,-1) \n",
        "\n",
        "print('dev_idf_uc_train_shape', dev_idf_uc_train.shape) \n",
        "print('dev_idf_code_train_shape', dev_idf_code_train.shape) \n",
        "\n",
        "# 2) ICTF Features\n",
        "avg_ictf_uc_train = featureExtraction.AvgICTF(ictf_uc_train).reshape(1,-1) \n",
        "avg_ictf_code_train = featureExtraction.AvgICTF(ictf_code_train).reshape(1,-1) \n",
        "\n",
        "print('avg_ictf_uc_train_shape', avg_ictf_uc_train.shape)\n",
        "print('avg_ictf_code_train_shape', avg_ictf_code_train.shape)\n",
        "\n",
        "max_ictf_uc_train = featureExtraction.MaxICTF(ictf_uc_train).reshape(1,-1) \n",
        "max_ictf_code_train = featureExtraction.MaxICTF(ictf_code_train).reshape(1,-1) \n",
        "\n",
        "print('max_ictf_uc_train_shape', max_ictf_uc_train.shape)\n",
        "print('max_ictf_code_train_shape', max_ictf_code_train.shape)\n",
        "\n",
        "dev_ictf_uc_train = featureExtraction.DevICTF(ictf_uc_train).reshape(1,-1) \n",
        "dev_ictf_code_train = featureExtraction.DevICTF(ictf_code_train).reshape(1,-1) \n",
        "\n",
        "print('dev_ictf_uc_train_shape', dev_ictf_uc_train.shape)\n",
        "print('dev_ictf_code_train_shape', dev_ictf_code_train.shape)\n",
        "# 3) Entropy Features\n",
        "\n",
        "avg_entropy_uc_train = featureExtraction.AvgEntropy(entropy_uc_train).reshape(1,-1) \n",
        "avg_entropy_code_train = featureExtraction.AvgEntropy(entropy_code_train).reshape(1,-1) \n",
        "\n",
        "print('avg_entropy_uc_train_shape', avg_entropy_uc_train.shape)\n",
        "print('avg_entropy_code_train_shape', avg_entropy_code_train.shape)\n",
        "\n",
        "max_entropy_uc_train = featureExtraction.MaxEntropy(entropy_uc_train).reshape(1,-1) \n",
        "max_entropy_code_train = featureExtraction.MaxEntropy(entropy_code_train).reshape(1,-1) \n",
        "\n",
        "print('max_entropy_uc_train_shape', max_entropy_uc_train.shape)\n",
        "print('max_entropy_code_train_shape', max_entropy_code_train.shape)\n",
        "\n",
        "med_entropy_uc_train = featureExtraction.MedEntropy(entropy_uc_train).reshape(1,-1) \n",
        "med_entropy_code_train = featureExtraction.MedEntropy(entropy_code_train).reshape(1,-1) \n",
        "\n",
        "print('med_entropy_uc_train_shape', med_entropy_uc_train.shape)\n",
        "print('med_entropy_code_train_shape', med_entropy_code_train.shape)\n",
        "\n",
        "dev_entropy_uc_train = featureExtraction.DevEntropy(entropy_uc_train).reshape(1,-1) \n",
        "dev_entropy_code_train = featureExtraction.DevEntropy(entropy_code_train).reshape(1,-1) \n",
        "\n",
        "print('dev_entropy_uc_train_shape', dev_entropy_uc_train.shape)\n",
        "print('dev_entropy_code_train_shape', dev_entropy_code_train.shape)\n",
        "      \n",
        "\n",
        "# 4) Variance Features\n",
        "\n",
        "avg_variance_uc_train = featureExtraction.AvgVariance(variance_uc_train).reshape(1,-1) \n",
        "avg_variance_code_train = featureExtraction.AvgVariance(variance_code_train).reshape(1,-1) \n",
        "\n",
        "print('avg_variance_uc_train_shape', avg_variance_uc_train.shape)\n",
        "print('avg_variance_code_train_shape', avg_variance_code_train.shape)\n",
        "\n",
        "max_variance_uc_train = featureExtraction.MaxVariance(variance_uc_train).reshape(1,-1) \n",
        "max_variance_code_train = featureExtraction.MaxVariance(variance_code_train).reshape(1,-1) \n",
        "\n",
        "print('max_variance_uc_train_shape', max_variance_uc_train.shape)\n",
        "print('max_variance_code_train_shape', max_variance_code_train.shape)\n",
        "\n",
        "sum_variance_uc_train = featureExtraction.SumVariance(variance_uc_train).reshape(1,-1) \n",
        "sum_variance_code_train = featureExtraction.SumVariance(variance_code_train).reshape(1,-1) \n",
        "\n",
        "print('sum_variance_uc_train_shape', sum_variance_uc_train.shape)\n",
        "print('sum_variance_code_train_shape', sum_variance_code_train.shape)\n",
        "# 5) SCQ Features\n",
        "avg_scq_uc_train = featureExtraction.AvgSCQ(SCQ_uc_train).reshape(1,-1) \n",
        "avg_scq_code_train = featureExtraction.AvgSCQ(SCQ_code_train).reshape(1,-1) \n",
        "\n",
        "print('avg_scq_uc_train_shape', avg_scq_uc_train.shape)\n",
        "print('avg_scq_code_train_shape', avg_scq_code_train.shape)\n",
        "\n",
        "max_scq_uc_train = featureExtraction.MaxSCQ(SCQ_uc_train).reshape(1,-1) \n",
        "max_scq_code_train = featureExtraction.MaxSCQ(SCQ_code_train).reshape(1,-1) \n",
        "\n",
        "print('max_scq_uc_train_shape', max_scq_uc_train.shape)\n",
        "print('max_scq_code_train_shape', max_scq_code_train.shape)\n",
        "\n",
        "sum_sqc_uc_train = featureExtraction.SumSCQ(SCQ_uc_train).reshape(1,-1) \n",
        "sum_sqc_code_train = featureExtraction.SumSCQ(SCQ_code_train).reshape(1,-1) \n",
        "\n",
        "print('sum_sqc_uc_train_shape', sum_sqc_uc_train.shape)\n",
        "print('sum_sqc_code_train_shape', sum_sqc_code_train.shape)\n",
        "\n",
        "# 6) PMI Features\n",
        "\n",
        "avg_pmi_uc_train = featureExtraction.AvgPMI(PMI_uc_train).reshape(1,-1) \n",
        "avg_pmi_code_train = featureExtraction.AvgPMI(PMI_code_train).reshape(1,-1) \n",
        "\n",
        "print('avg_pmi_uc_train_shape', avg_pmi_uc_train.shape)\n",
        "print('avg_pmi_code_train_shape', avg_pmi_code_train.shape)\n",
        "\n",
        "max_pmi_uc_train = featureExtraction.MaxPMI(PMI_uc_train).reshape(1,-1) \n",
        "max_pmi_code_train = featureExtraction.MaxPMI(PMI_code_train).reshape(1,-1) \n",
        "\n",
        "print('max_pmi_uc_train_shape', max_pmi_uc_train.shape)\n",
        "print('max_pmi_code_train_shape', max_pmi_code_train.shape)\n",
        "# 7) QS Features\n",
        "\n",
        "qs_uc_train = featureExtraction.QS(UC_documents_train, code_documents_train).reshape(1,-1) \n",
        "qs_code_train = featureExtraction.QS(code_documents_train, UC_documents_train).reshape(1,-1) \n",
        "\n",
        "print('qs_uc_train_shape', qs_uc_train.shape)\n",
        "print('qs_code_train_shape', qs_code_train.shape)\n",
        "\n",
        "# 8) SCS Features\n",
        "UC_SCS_train = featureExtraction.simplifiedClarityScore(UC_documents_train, UC_count_matrix_train, tf_code_dict_train).reshape(1,-1) \n",
        "CC_SCS_train = featureExtraction.simplifiedClarityScore(code_documents_train, code_count_matrix_train, tf_uc_dict_train).reshape(1,-1) \n",
        "\n",
        "print('UC_SCS_train_shape', UC_SCS_train.shape)\n",
        "print('CC_SCS_train_shape', CC_SCS_train.shape)\n",
        "\n",
        "# 9) Coherence Score Features\n",
        "UC_CoherenceScore_train = featureExtraction.CoherenceScore(UC_documents_train, tfidf_matrix_code_train).reshape(1,-1) \n",
        "CC_CoherenceScore_train = featureExtraction.CoherenceScore(code_documents_train, tfidf_matrix_uc_train).reshape(1,-1) \n",
        "\n",
        "print('UC_CoherenceScore_train_shape', UC_CoherenceScore_train.shape)\n",
        "print('CC_CoherenceScore_train_shape', CC_CoherenceScore_train.shape)\n",
        "#75min"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#----------------saving pre retrival Train------------------#\n",
        "np.save('./pickles/avg_idf_uc_train.npy', avg_idf_uc_train)\n",
        "np.save('./pickles/avg_idf_code_train.npy', avg_idf_code_train)\n",
        "\n",
        "np.save('./pickles/max_idf_uc_train.npy', max_idf_uc_train)\n",
        "np.save('./pickles/max_idf_code_train.npy', max_idf_code_train)\n",
        "\n",
        "np.save('./pickles/dev_idf_uc_train.npy', dev_idf_uc_train)\n",
        "np.save('./pickles/dev_idf_code_train.npy', dev_idf_code_train)\n",
        "\n",
        "np.save('./pickles/avg_ictf_uc_train.npy', avg_ictf_uc_train)\n",
        "np.save('./pickles/avg_ictf_code_train.npy', avg_ictf_code_train)\n",
        "\n",
        "np.save('./pickles/max_ictf_uc_train.npy', max_ictf_uc_train)\n",
        "np.save('./pickles/max_ictf_code_train.npy', max_ictf_code_train)\n",
        "\n",
        "np.save('./pickles/dev_ictf_uc_train.npy', dev_ictf_uc_train)\n",
        "np.save('./pickles/dev_ictf_code_train.npy', dev_ictf_code_train)\n",
        "\n",
        "np.save('./pickles/avg_entropy_uc_train.npy', avg_entropy_uc_train)\n",
        "np.save('./pickles/avg_entropy_code_train.npy', avg_entropy_code_train)\n",
        "\n",
        "np.save('./pickles/max_entropy_uc_train.npy', max_entropy_uc_train)\n",
        "np.save('./pickles/max_entropy_code_train.npy', max_entropy_code_train)\n",
        "\n",
        "np.save('./pickles/max_entropy_uc_train.npy', max_entropy_uc_train)\n",
        "np.save('./pickles/max_entropy_code_train.npy', max_entropy_code_train)\n",
        "\n",
        "np.save('./pickles/med_entropy_uc_train.npy', med_entropy_uc_train)\n",
        "np.save('./pickles/med_entropy_code_train.npy', med_entropy_code_train)\n",
        "\n",
        "np.save('./pickles/dev_entropy_uc_train.npy', dev_entropy_uc_train)\n",
        "np.save('./pickles/dev_entropy_code_train.npy', dev_entropy_code_train)\n",
        "\n",
        "np.save('./pickles/avg_variance_uc_train.npy', avg_variance_uc_train)\n",
        "np.save('./pickles/avg_variance_code_train.npy', avg_variance_code_train)\n",
        "\n",
        "np.save('./pickles/max_variance_uc_train.npy', max_variance_uc_train)\n",
        "np.save('./pickles/max_variance_code_train.npy', max_variance_code_train)\n",
        "\n",
        "np.save('./pickles/sum_variance_uc_train.npy', sum_variance_uc_train)\n",
        "np.save('./pickles/sum_variance_code_train.npy', sum_variance_code_train)\n",
        "\n",
        "np.save('./pickles/avg_scq_uc_train.npy', avg_scq_uc_train)\n",
        "np.save('./pickles/avg_scq_code_train.npy', avg_scq_code_train)\n",
        "\n",
        "np.save('./pickles/max_scq_uc_train.npy', max_scq_uc_train)\n",
        "np.save('./pickles/max_scq_code_train.npy', max_scq_code_train)\n",
        "\n",
        "np.save('./pickles/sum_sqc_uc_train.npy', sum_sqc_uc_train)\n",
        "np.save('./pickles/sum_sqc_code_train.npy', sum_sqc_code_train)\n",
        "\n",
        "np.save('./pickles/avg_pmi_uc_train.npy', avg_pmi_uc_train)\n",
        "np.save('./pickles/avg_pmi_code_train.npy', avg_pmi_code_train)\n",
        "\n",
        "np.save('./pickles/max_pmi_uc_train.npy', max_pmi_uc_train)\n",
        "np.save('./pickles/max_pmi_code_train.npy', max_pmi_code_train)\n",
        "\n",
        "np.save('./pickles/qs_uc_train.npy', qs_uc_train)\n",
        "np.save('./pickles/qs_code_train.npy', qs_code_train)\n",
        "\n",
        "np.save('./pickles/UC_SCS_train.npy', UC_SCS_train)\n",
        "np.save('./pickles/CC_SCS_train.npy', CC_SCS_train)\n",
        "\n",
        "np.save('./pickles/UC_CoherenceScore_train.npy', UC_CoherenceScore_train)\n",
        "np.save('./pickles/CC_CoherenceScore_train.npy', CC_CoherenceScore_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ------------------------pre-retrieval (21 metrics) Test--------------------------#\n",
        "# 1) IDF Features\n",
        "avg_idf_uc_test = featureExtraction.AvgIDF(idf_uc_test).reshape(1,-1)\n",
        "avg_idf_code_test = featureExtraction.AvgIDF(idf_code_test).reshape(1,-1)\n",
        "\n",
        "print('avg_idf_uc_test_shape', avg_idf_uc_test.shape)\n",
        "print('avg_idf_code_test_shape', avg_idf_code_test.shape)\n",
        "\n",
        "max_idf_uc_test = featureExtraction.MaxIDF(idf_uc_test).reshape(1,-1)\n",
        "max_idf_code_test = featureExtraction.MaxIDF(idf_code_test).reshape(1,-1)\n",
        "\n",
        "print('max_idf_uc_test_shape', max_idf_uc_test.shape)\n",
        "print('max_idf_code_test_shape', max_idf_code_test.shape)\n",
        "\n",
        "dev_idf_uc_test = featureExtraction.DevIDF(idf_uc_test).reshape(1,-1)\n",
        "dev_idf_code_test = featureExtraction.DevIDF(idf_code_test).reshape(1,-1)\n",
        "\n",
        "print('dev_idf_uc_test_shape', dev_idf_uc_test.shape)\n",
        "print('dev_idf_code_test_shape', dev_idf_code_test.shape)\n",
        "\n",
        "# 2) ICTF Features\n",
        "avg_ictf_uc_test = featureExtraction.AvgICTF(ictf_uc_test).reshape(1,-1)\n",
        "avg_ictf_code_test = featureExtraction.AvgICTF(ictf_code_test).reshape(1,-1)\n",
        "\n",
        "print('avg_ictf_uc_test_shape', avg_ictf_uc_test.shape)\n",
        "print('avg_ictf_code_test_shape', avg_ictf_code_test.shape)\n",
        "\n",
        "max_ictf_uc_test = featureExtraction.MaxICTF(ictf_uc_test).reshape(1,-1)\n",
        "max_ictf_code_test = featureExtraction.MaxICTF(ictf_code_test).reshape(1,-1)\n",
        "\n",
        "print('max_ictf_uc_test_shape', max_ictf_uc_test.shape)\n",
        "print('max_ictf_code_test_shape', max_ictf_code_test.shape)\n",
        "\n",
        "dev_ictf_uc_test = featureExtraction.DevICTF(ictf_uc_test).reshape(1,-1)\n",
        "dev_ictf_code_test = featureExtraction.DevICTF(ictf_code_test).reshape(1,-1)\n",
        "\n",
        "print('dev_ictf_uc_test_shape', dev_ictf_uc_test.shape)\n",
        "print('dev_ictf_code_test_shape', dev_ictf_code_test.shape)\n",
        "\n",
        "# 3) Entropy Features\n",
        "avg_entropy_uc_test = featureExtraction.AvgEntropy(entropy_uc_test).reshape(1,-1)\n",
        "avg_entropy_code_test = featureExtraction.AvgEntropy(entropy_code_test).reshape(1,-1)\n",
        "\n",
        "print('avg_entropy_uc_test_shape', avg_entropy_uc_test.shape)\n",
        "print('avg_entropy_code_test_shape', avg_entropy_code_test.shape)\n",
        "\n",
        "max_entropy_uc_test = featureExtraction.MaxEntropy(entropy_uc_test).reshape(1,-1)\n",
        "max_entropy_code_test = featureExtraction.MaxEntropy(entropy_code_test).reshape(1,-1)\n",
        "\n",
        "print('max_entropy_uc_test_shape', max_entropy_uc_test.shape)\n",
        "print('max_entropy_code_test_shape', max_entropy_code_test.shape)\n",
        "\n",
        "med_entropy_uc_test = featureExtraction.MedEntropy(entropy_uc_test).reshape(1,-1)\n",
        "med_entropy_code_test = featureExtraction.MedEntropy(entropy_code_test).reshape(1,-1)\n",
        "\n",
        "print('med_entropy_uc_test_shape', med_entropy_uc_test.shape)\n",
        "print('med_entropy_code_test_shape', med_entropy_code_test.shape)\n",
        "\n",
        "dev_entropy_uc_test = featureExtraction.DevEntropy(entropy_uc_test).reshape(1,-1)\n",
        "dev_entropy_code_test = featureExtraction.DevEntropy(entropy_code_test).reshape(1,-1)\n",
        "\n",
        "print('dev_entropy_uc_test_shape', dev_entropy_uc_test.shape)\n",
        "print('dev_entropy_code_test_shape', dev_entropy_code_test.shape)\n",
        "\n",
        "# 4) Variance Features\n",
        "\n",
        "avg_variance_uc_test = featureExtraction.AvgVariance(variance_uc_test).reshape(1,-1) \n",
        "avg_variance_code_test = featureExtraction.AvgVariance(variance_code_test).reshape(1,-1) \n",
        "\n",
        "print('avg_variance_uc_test_shape', avg_variance_uc_test.shape)\n",
        "print('avg_variance_code_test_shape', avg_variance_code_test.shape)\n",
        "\n",
        "max_variance_uc_test = featureExtraction.MaxVariance(variance_uc_test).reshape(1,-1) \n",
        "max_variance_code_test = featureExtraction.MaxVariance(variance_code_test).reshape(1,-1) \n",
        "\n",
        "print('max_variance_uc_test_shape', max_variance_uc_test.shape)\n",
        "print('max_variance_code_test_shape', max_variance_code_test.shape)\n",
        "\n",
        "sum_variance_uc_test = featureExtraction.SumVariance(variance_uc_test).reshape(1,-1) \n",
        "sum_variance_code_test = featureExtraction.SumVariance(variance_code_test).reshape(1,-1) \n",
        "\n",
        "print('sum_variance_uc_test_shape', sum_variance_uc_test.shape)\n",
        "print('sum_variance_code_test_shape', sum_variance_code_test.shape)\n",
        "\n",
        "# 5) SCQ Features\n",
        "avg_scq_uc_test = featureExtraction.AvgSCQ(SCQ_uc_test).reshape(1,-1) \n",
        "avg_scq_code_test = featureExtraction.AvgSCQ(SCQ_code_test).reshape(1,-1) \n",
        "\n",
        "print('avg_scq_uc_test_shape', avg_scq_uc_test.shape)\n",
        "print('avg_scq_code_test_shape', avg_scq_code_test.shape)\n",
        "\n",
        "max_scq_uc_test = featureExtraction.MaxSCQ(SCQ_uc_test).reshape(1,-1) \n",
        "max_scq_code_test = featureExtraction.MaxSCQ(SCQ_code_test).reshape(1,-1) \n",
        "\n",
        "print('max_scq_uc_test_shape', max_scq_uc_test.shape)\n",
        "print('max_scq_code_test_shape', max_scq_code_test.shape)\n",
        "\n",
        "sum_sqc_uc_test = featureExtraction.SumSCQ(SCQ_uc_test).reshape(1,-1) \n",
        "sum_sqc_code_test = featureExtraction.SumSCQ(SCQ_code_test).reshape(1,-1) \n",
        "\n",
        "print('sum_sqc_uc_test_shape', sum_sqc_uc_test.shape)\n",
        "print('sum_sqc_code_test_shape', sum_sqc_code_test.shape)\n",
        "\n",
        "# 6) PMI Features\n",
        "\n",
        "avg_pmi_uc_test = featureExtraction.AvgPMI(PMI_uc_test).reshape(1,-1) \n",
        "avg_pmi_code_test = featureExtraction.AvgPMI(PMI_code_test).reshape(1,-1) \n",
        "\n",
        "print('avg_pmi_uc_test_shape', avg_pmi_uc_test.shape)\n",
        "print('avg_pmi_code_test_shape', avg_pmi_code_test.shape)\n",
        "\n",
        "max_pmi_uc_test = featureExtraction.MaxPMI(PMI_uc_test).reshape(1,-1) \n",
        "max_pmi_code_test = featureExtraction.MaxPMI(PMI_code_test).reshape(1,-1) \n",
        "\n",
        "print('max_pmi_uc_test_shape', max_pmi_uc_test.shape)\n",
        "print('max_pmi_code_test_shape', max_pmi_code_test.shape)\n",
        "\n",
        "# 7) QS Features\n",
        "\n",
        "qs_uc_test = featureExtraction.QS(UC_documents_test, code_documents_test).reshape(1,-1) \n",
        "qs_code_test = featureExtraction.QS(code_documents_test, UC_documents_test).reshape(1,-1) \n",
        "\n",
        "print('qs_uc_test_shape', qs_uc_test.shape)\n",
        "print('qs_code_test_shape', qs_code_test.shape)\n",
        "\n",
        "# 8) SCS Features\n",
        "UC_SCS_test = featureExtraction.simplifiedClarityScore(UC_documents_test, UC_count_matrix_test, tf_code_dict_test).reshape(1,-1) \n",
        "CC_SCS_test = featureExtraction.simplifiedClarityScore(code_documents_test, code_count_matrix_test, tf_uc_dict_test).reshape(1,-1) \n",
        "\n",
        "print('UC_SCS_test_shape', UC_SCS_test.shape)\n",
        "print('CC_SCS_test_shape', CC_SCS_test.shape)\n",
        "\n",
        "# 9) Coherence Score Features\n",
        "UC_CoherenceScore_test = featureExtraction.CoherenceScore(UC_documents_test, tfidf_matrix_code_test).reshape(1,-1) \n",
        "CC_CoherenceScore_test = featureExtraction.CoherenceScore(code_documents_test, tfidf_matrix_uc_test).reshape(1,-1) \n",
        "\n",
        "print('UC_CoherenceScore_test_shape', UC_CoherenceScore_test.shape)\n",
        "print('CC_CoherenceScore_test_shape', CC_CoherenceScore_test.shape)\n",
        "\n",
        "#7mins"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#-------------------Saving test Preretival------------------#\n",
        "np.save('./pickles/avg_idf_uc_test.npy', avg_idf_uc_test)\n",
        "np.save('./pickles/avg_idf_code_test.npy', avg_idf_code_test)\n",
        "\n",
        "np.save('./pickles/max_idf_uc_test.npy', max_idf_uc_test)\n",
        "np.save('./pickles/max_idf_code_test.npy', max_idf_code_test)\n",
        "\n",
        "np.save('./pickles/dev_idf_uc_test.npy', dev_idf_uc_test)\n",
        "np.save('./pickles/dev_idf_code_test.npy', dev_idf_code_test)\n",
        "\n",
        "np.save('./pickles/avg_ictf_uc_test.npy', avg_ictf_uc_test)\n",
        "np.save('./pickles/avg_ictf_code_test.npy', avg_ictf_code_test)\n",
        "\n",
        "np.save('./pickles/max_ictf_uc_test.npy', max_ictf_uc_test)\n",
        "np.save('./pickles/max_ictf_code_test.npy', max_ictf_code_test)\n",
        "\n",
        "np.save('./pickles/dev_ictf_uc_test.npy', dev_ictf_uc_test)\n",
        "np.save('./pickles/dev_ictf_code_test.npy', dev_ictf_code_test)\n",
        "\n",
        "np.save('./pickles/avg_entropy_uc_test.npy', avg_entropy_uc_test)\n",
        "np.save('./pickles/avg_entropy_code_test.npy', avg_entropy_code_test)\n",
        "\n",
        "np.save('./pickles/max_entropy_uc_test.npy', max_entropy_uc_test)\n",
        "np.save('./pickles/max_entropy_code_test.npy', max_entropy_code_test)\n",
        "\n",
        "np.save('./pickles/med_entropy_uc_test.npy', med_entropy_uc_test)\n",
        "np.save('./pickles/med_entropy_code_test.npy', med_entropy_code_test)\n",
        "\n",
        "np.save('./pickles/dev_entropy_uc_test.npy', dev_entropy_uc_test)\n",
        "np.save('./pickles/dev_entropy_code_test.npy', dev_entropy_code_test)\n",
        "\n",
        "np.save('./pickles/avg_variance_uc_test.npy', avg_variance_uc_test)\n",
        "np.save('./pickles/avg_variance_code_test.npy', avg_variance_code_test)\n",
        "\n",
        "np.save('./pickles/max_variance_uc_test.npy', max_variance_uc_test)\n",
        "np.save('./pickles/max_variance_code_test.npy', max_variance_code_test)\n",
        "\n",
        "np.save('./pickles/sum_variance_uc_test.npy', sum_variance_uc_test)\n",
        "np.save('./pickles/sum_variance_code_test.npy', sum_variance_code_test)\n",
        "\n",
        "np.save('./pickles/avg_scq_uc_test.npy', avg_scq_uc_test)\n",
        "np.save('./pickles/avg_scq_code_test.npy', avg_scq_code_test)\n",
        "\n",
        "np.save('./pickles/max_scq_uc_test.npy', max_scq_uc_test)\n",
        "np.save('./pickles/max_scq_code_test.npy', max_scq_code_test)\n",
        "\n",
        "np.save('./pickles/sum_sqc_uc_test.npy', sum_sqc_uc_test)\n",
        "np.save('./pickles/sum_sqc_code_test.npy', sum_sqc_code_test)\n",
        "\n",
        "np.save('./pickles/avg_pmi_uc_test.npy', avg_pmi_uc_test)\n",
        "np.save('./pickles/avg_pmi_code_test.npy', avg_pmi_code_test)\n",
        "\n",
        "np.save('./pickles/max_pmi_uc_test.npy', max_pmi_uc_test)\n",
        "np.save('./pickles/max_pmi_code_test.npy', max_pmi_code_test)\n",
        "\n",
        "np.save('./pickles/qs_uc_test.npy', qs_uc_test)\n",
        "np.save('./pickles/qs_code_test.npy', qs_code_test)\n",
        "\n",
        "np.save('./pickles/UC_SCS_test.npy', UC_SCS_test)\n",
        "np.save('./pickles/CC_SCS_test.npy', CC_SCS_test)\n",
        "\n",
        "np.save('./pickles/UC_CoherenceScore_test.npy', UC_CoherenceScore_test)\n",
        "np.save('./pickles/CC_CoherenceScore_test.npy', CC_CoherenceScore_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ------------------------pre-retrieval (21 metrics) Train--------------------------#\n",
        "\n",
        "avg_idf_uc_train = np.load('./pickles/avg_idf_uc_train.npy')\n",
        "\n",
        "avg_idf_uc_train = normalizer.fit_transform(avg_idf_uc_train.reshape(-1,1))\n",
        "\n",
        "avg_idf_code_train = np.load('./pickles/avg_idf_code_train.npy')\n",
        "avg_idf_code_train = normalizer.fit_transform(avg_idf_code_train.reshape(-1,1))\n",
        "\n",
        "max_idf_uc_train = np.load('./pickles/max_idf_uc_train.npy')\n",
        "\n",
        "max_idf_uc_train = normalizer.fit_transform(max_idf_uc_train.reshape(-1,1))\n",
        "\n",
        "max_idf_code_train = np.load('./pickles/max_idf_code_train.npy')\n",
        "max_idf_code_train = normalizer.fit_transform(max_idf_code_train.reshape(-1,1))\n",
        "\n",
        "dev_idf_uc_train = np.load('./pickles/dev_idf_uc_train.npy')\n",
        "dev_idf_uc_train = normalizer.fit_transform(dev_idf_uc_train.reshape(-1,1))\n",
        "\n",
        "dev_idf_code_train = np.load('./pickles/dev_idf_code_train.npy')\n",
        "dev_idf_code_train = normalizer.fit_transform(dev_idf_code_train.reshape(-1,1))\n",
        "\n",
        "avg_ictf_uc_train = np.load('./pickles/avg_ictf_uc_train.npy')\n",
        "avg_ictf_uc_train = normalizer.fit_transform(avg_ictf_uc_train.reshape(-1,1))\n",
        "\n",
        "avg_ictf_code_train = np.load('./pickles/avg_ictf_code_train.npy')\n",
        "avg_ictf_code_train = normalizer.fit_transform(avg_ictf_code_train.reshape(-1,1))\n",
        "\n",
        "max_ictf_uc_train = np.load('./pickles/max_ictf_uc_train.npy')\n",
        "max_ictf_uc_train = normalizer.fit_transform(max_ictf_uc_train.reshape(-1,1))\n",
        "\n",
        "max_ictf_code_train = np.load('./pickles/max_ictf_code_train.npy')\n",
        "max_ictf_code_train = normalizer.fit_transform(max_ictf_code_train.reshape(-1,1))\n",
        "\n",
        "dev_ictf_uc_train = np.load('./pickles/dev_ictf_uc_train.npy')\n",
        "dev_ictf_uc_train = normalizer.fit_transform(dev_ictf_uc_train.reshape(-1,1))\n",
        "\n",
        "dev_ictf_code_train = np.load('./pickles/dev_ictf_code_train.npy')\n",
        "dev_ictf_code_train = normalizer.fit_transform(dev_ictf_code_train.reshape(-1,1))\n",
        "\n",
        "avg_entropy_uc_train = np.load('./pickles/avg_entropy_uc_train.npy')\n",
        "avg_entropy_uc_train = normalizer.fit_transform(avg_entropy_uc_train.reshape(-1,1))\n",
        "\n",
        "avg_entropy_code_train = np.load('./pickles/avg_entropy_code_train.npy')\n",
        "avg_entropy_code_train = normalizer.fit_transform(avg_entropy_code_train.reshape(-1,1))\n",
        "\n",
        "max_entropy_uc_train = np.load('./pickles/max_entropy_uc_train.npy')\n",
        "max_entropy_uc_train = normalizer.fit_transform(max_entropy_uc_train.reshape(-1,1))\n",
        "\n",
        "max_entropy_code_train = np.load('./pickles/max_entropy_code_train.npy')\n",
        "max_entropy_code_train = normalizer.fit_transform(max_entropy_code_train.reshape(-1,1))\n",
        "\n",
        "med_entropy_uc_train = np.load('./pickles/med_entropy_uc_train.npy')\n",
        "med_entropy_uc_train = normalizer.fit_transform(med_entropy_uc_train.reshape(-1,1))\n",
        "med_entropy_code_train = np.load('./pickles/med_entropy_code_train.npy')\n",
        "med_entropy_code_train = normalizer.fit_transform(med_entropy_code_train.reshape(-1,1))\n",
        "\n",
        "dev_entropy_uc_train = np.load('./pickles/dev_entropy_uc_train.npy')\n",
        "dev_entropy_uc_train = normalizer.fit_transform(dev_entropy_uc_train.reshape(-1,1))\n",
        "\n",
        "dev_entropy_code_train = np.load('./pickles/dev_entropy_code_train.npy')\n",
        "dev_entropy_code_train = normalizer.fit_transform(dev_entropy_code_train.reshape(-1,1))\n",
        "\n",
        "avg_variance_uc_train = np.load('./pickles/avg_variance_uc_train.npy')\n",
        "avg_variance_uc_train = normalizer.fit_transform(avg_variance_uc_train.reshape(-1,1))\n",
        "\n",
        "avg_variance_code_train = np.load('./pickles/avg_variance_code_train.npy')\n",
        "avg_variance_code_train = normalizer.fit_transform(avg_variance_code_train.reshape(-1,1))\n",
        "\n",
        "max_variance_uc_train = np.load('./pickles/max_variance_uc_train.npy')\n",
        "max_variance_uc_train = normalizer.fit_transform(max_variance_uc_train.reshape(-1,1))\n",
        "\n",
        "max_variance_code_train = np.load('./pickles/max_variance_code_train.npy')\n",
        "max_variance_code_train = normalizer.fit_transform(max_variance_code_train.reshape(-1,1))\n",
        "sum_variance_uc_train = np.load('./pickles/sum_variance_uc_train.npy')\n",
        "sum_variance_uc_train = normalizer.fit_transform(sum_variance_uc_train.reshape(-1,1))\n",
        "\n",
        "sum_variance_code_train = np.load('./pickles/sum_variance_code_train.npy')\n",
        "sum_variance_code_train = normalizer.fit_transform(sum_variance_code_train.reshape(-1,1))\n",
        "\n",
        "avg_scq_uc_train = np.load('./pickles/avg_scq_uc_train.npy')\n",
        "avg_scq_uc_train = normalizer.fit_transform(avg_scq_uc_train.reshape(-1,1))\n",
        "\n",
        "avg_scq_code_train = np.load('./pickles/avg_scq_code_train.npy')\n",
        "avg_scq_code_train = normalizer.fit_transform(avg_scq_code_train.reshape(-1,1))\n",
        "\n",
        "max_scq_uc_train = np.load('./pickles/max_scq_uc_train.npy')\n",
        "max_scq_uc_train = normalizer.fit_transform(max_scq_uc_train.reshape(-1,1).reshape(-1,1))\n",
        "\n",
        "max_scq_code_train = np.load('./pickles/max_scq_code_train.npy')\n",
        "max_scq_code_train = normalizer.fit_transform(max_scq_code_train.reshape(-1,1))\n",
        "\n",
        "sum_sqc_uc_train = np.load('./pickles/sum_sqc_uc_train.npy')\n",
        "sum_sqc_uc_train = normalizer.fit_transform(sum_sqc_uc_train.reshape(-1,1))\n",
        "\n",
        "sum_sqc_code_train = np.load('./pickles/sum_sqc_code_train.npy')\n",
        "sum_sqc_code_train = normalizer.fit_transform(sum_sqc_code_train.reshape(-1,1))\n",
        "\n",
        "avg_pmi_uc_train = np.load('./pickles/avg_pmi_uc_train.npy')\n",
        "avg_pmi_uc_train = normalizer.fit_transform(avg_pmi_uc_train.reshape(-1,1))\n",
        "\n",
        "avg_pmi_code_train = np.load('./pickles/avg_pmi_code_train.npy')\n",
        "avg_pmi_code_train = normalizer.fit_transform(avg_pmi_code_train.reshape(-1,1))\n",
        "\n",
        "max_pmi_uc_train = np.load('./pickles/max_pmi_uc_train.npy')\n",
        "max_pmi_uc_train = normalizer.fit_transform(max_pmi_uc_train.reshape(-1,1))\n",
        "\n",
        "\n",
        "max_pmi_code_train = np.load('./pickles/max_pmi_code_train.npy')\n",
        "max_pmi_code_train = normalizer.fit_transform(max_pmi_code_train.reshape(-1,1))\n",
        "\n",
        "qs_uc_train = np.load('./pickles/qs_uc_train.npy')\n",
        "qs_uc_train = normalizer.fit_transform(qs_uc_train.reshape(-1,1))\n",
        "\n",
        "qs_code_train = np.load('./pickles/qs_code_train.npy')\n",
        "qs_code_train = normalizer.fit_transform(qs_code_train.reshape(-1,1))\n",
        "\n",
        "UC_SCS_train = np.load('./pickles/UC_SCS_train.npy')\n",
        "UC_SCS_train = normalizer.fit_transform(UC_SCS_train.reshape(-1,1))\n",
        "\n",
        "CC_SCS_train = np.load('./pickles/CC_SCS_train.npy')\n",
        "CC_SCS_train = normalizer.fit_transform(CC_SCS_train.reshape(-1,1))\n",
        "\n",
        "UC_CoherenceScore_train = np.load('./pickles/UC_CoherenceScore_train.npy')\n",
        "UC_CoherenceScore_train = normalizer.fit_transform(UC_CoherenceScore_train.reshape(-1,1))\n",
        "\n",
        "\n",
        "CC_CoherenceScore_train = np.load('./pickles/CC_CoherenceScore_train.npy')\n",
        "CC_CoherenceScore_train = normalizer.fit_transform(CC_CoherenceScore_train.reshape(-1,1))\n",
        "\n",
        "print(\"max_ictf_code_train:\", max_ictf_code_train) #gives ones only\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ------------------------pre-retrieval (21 metrics) Test--------------------------#\n",
        "avg_idf_uc_test = np.load('./pickles/avg_idf_uc_test.npy')\n",
        "avg_idf_uc_test = normalizer.fit_transform(avg_idf_uc_test.reshape(-1,1))\n",
        "\n",
        "avg_idf_code_test = np.load('./pickles/avg_idf_code_test.npy')\n",
        "avg_idf_code_test = normalizer.fit_transform(avg_idf_code_test.reshape(-1,1))\n",
        "\n",
        "max_idf_uc_test = np.load('./pickles/max_idf_uc_test.npy')\n",
        "max_idf_uc_test = normalizer.fit_transform(max_idf_uc_test.reshape(-1,1))\n",
        "\n",
        "max_idf_code_test = np.load('./pickles/max_idf_code_test.npy')\n",
        "max_idf_code_test = normalizer.fit_transform(max_idf_code_test.reshape(-1,1))\n",
        "\n",
        "dev_idf_uc_test = np.load('./pickles/dev_idf_uc_test.npy')\n",
        "dev_idf_uc_test = normalizer.fit_transform(dev_idf_uc_test.reshape(-1,1))\n",
        "\n",
        "dev_idf_code_test = np.load('./pickles/dev_idf_code_test.npy')\n",
        "dev_idf_code_test = normalizer.fit_transform(dev_idf_code_test.reshape(-1,1))\n",
        "\n",
        "avg_ictf_uc_test = np.load('./pickles/avg_ictf_uc_test.npy')\n",
        "avg_ictf_uc_test = normalizer.fit_transform(avg_ictf_uc_test.reshape(-1,1))\n",
        "\n",
        "avg_ictf_code_test = np.load('./pickles/avg_ictf_code_test.npy')\n",
        "avg_ictf_code_test = normalizer.fit_transform(avg_ictf_code_test.reshape(-1,1))\n",
        "\n",
        "max_ictf_uc_test = np.load('./pickles/max_ictf_uc_test.npy')\n",
        "max_ictf_uc_test = normalizer.fit_transform(max_ictf_uc_test.reshape(-1,1))\n",
        "\n",
        "max_ictf_code_test = np.load('./pickles/max_ictf_code_test.npy')\n",
        "max_ictf_code_test = normalizer.fit_transform(max_ictf_code_test.reshape(-1,1))\n",
        "\n",
        "dev_ictf_uc_test = np.load('./pickles/dev_ictf_uc_test.npy')\n",
        "dev_ictf_uc_test = normalizer.fit_transform(dev_ictf_uc_test.reshape(-1,1))\n",
        "\n",
        "dev_ictf_code_test = np.load('./pickles/dev_ictf_code_test.npy')\n",
        "dev_ictf_code_test = normalizer.fit_transform(dev_ictf_code_test.reshape(-1,1))\n",
        "\n",
        "avg_entropy_uc_test = np.load('./pickles/avg_entropy_uc_test.npy')\n",
        "avg_entropy_uc_test = normalizer.fit_transform(avg_entropy_uc_test.reshape(-1,1))\n",
        "\n",
        "avg_entropy_code_test = np.load('./pickles/avg_entropy_code_test.npy')\n",
        "avg_entropy_code_test = normalizer.fit_transform(avg_entropy_code_test.reshape(-1,1))\n",
        "\n",
        "max_entropy_uc_test = np.load('./pickles/max_entropy_uc_test.npy')\n",
        "max_entropy_uc_test = normalizer.fit_transform(max_entropy_uc_test.reshape(-1,1))\n",
        "\n",
        "max_entropy_code_test = np.load('./pickles/max_entropy_code_test.npy')\n",
        "max_entropy_code_test = normalizer.fit_transform(max_entropy_code_test.reshape(-1,1))\n",
        "\n",
        "med_entropy_uc_test = np.load('./pickles/med_entropy_uc_test.npy')\n",
        "med_entropy_uc_test = normalizer.fit_transform(med_entropy_uc_test.reshape(-1,1))\n",
        "\n",
        "med_entropy_code_test = np.load('./pickles/med_entropy_code_test.npy')\n",
        "med_entropy_code_test = normalizer.fit_transform(med_entropy_code_test.reshape(-1,1))\n",
        "\n",
        "dev_entropy_uc_test = np.load('./pickles/dev_entropy_uc_test.npy')\n",
        "dev_entropy_uc_test = normalizer.fit_transform(dev_entropy_uc_test.reshape(-1,1))\n",
        "\n",
        "dev_entropy_code_test = np.load('./pickles/dev_entropy_code_test.npy')\n",
        "dev_entropy_code_test = normalizer.fit_transform(dev_entropy_code_test.reshape(-1,1))\n",
        "\n",
        "avg_variance_uc_test = np.load('./pickles/avg_variance_uc_test.npy')\n",
        "avg_variance_uc_test = normalizer.fit_transform(avg_variance_uc_test.reshape(-1,1))\n",
        "\n",
        "avg_variance_code_test = np.load('./pickles/avg_variance_code_test.npy')\n",
        "avg_variance_code_test = normalizer.fit_transform(avg_variance_code_test.reshape(-1,1))\n",
        "\n",
        "max_variance_uc_test = np.load('./pickles/max_variance_uc_test.npy')\n",
        "max_variance_uc_test = normalizer.fit_transform(max_variance_uc_test.reshape(-1,1))\n",
        "\n",
        "max_variance_code_test = np.load('./pickles/max_variance_code_test.npy')\n",
        "max_variance_code_test = normalizer.fit_transform(max_variance_code_test.reshape(-1,1))\n",
        "\n",
        "sum_variance_uc_test = np.load('./pickles/sum_variance_uc_test.npy')\n",
        "sum_variance_uc_test = normalizer.fit_transform(sum_variance_uc_test.reshape(-1,1))\n",
        "\n",
        "sum_variance_code_test = np.load('./pickles/sum_variance_code_test.npy')\n",
        "sum_variance_code_test = normalizer.fit_transform(sum_variance_code_test.reshape(-1,1))\n",
        "\n",
        "avg_scq_uc_test = np.load('./pickles/avg_scq_uc_test.npy')\n",
        "avg_scq_uc_test = normalizer.fit_transform(avg_scq_uc_test.reshape(-1,1))\n",
        "\n",
        "avg_scq_code_test = np.load('./pickles/avg_scq_code_test.npy')\n",
        "avg_scq_code_test = normalizer.fit_transform(avg_scq_code_test.reshape(-1,1))\n",
        "\n",
        "max_scq_uc_test = np.load('./pickles/max_scq_uc_test.npy')\n",
        "max_scq_uc_test = normalizer.fit_transform(max_scq_uc_test.reshape(-1,1))\n",
        "\n",
        "max_scq_code_test = np.load('./pickles/max_scq_code_test.npy')\n",
        "max_scq_code_test = normalizer.fit_transform(max_scq_code_test.reshape(-1,1))\n",
        "\n",
        "sum_sqc_uc_test = np.load('./pickles/sum_sqc_uc_test.npy')\n",
        "sum_sqc_uc_test = normalizer.fit_transform(sum_sqc_uc_test.reshape(-1,1))\n",
        "\n",
        "sum_sqc_code_test = np.load('./pickles/sum_sqc_code_test.npy')\n",
        "sum_sqc_code_test = normalizer.fit_transform(sum_sqc_code_test.reshape(-1,1))\n",
        "\n",
        "avg_pmi_uc_test = np.load('./pickles/avg_pmi_uc_test.npy')\n",
        "avg_pmi_uc_test = normalizer.fit_transform(avg_pmi_uc_test.reshape(-1,1))\n",
        "\n",
        "avg_pmi_code_test = np.load('./pickles/avg_pmi_code_test.npy')\n",
        "avg_pmi_code_test = normalizer.fit_transform(avg_pmi_code_test.reshape(-1,1))\n",
        "\n",
        "max_pmi_uc_test = np.load('./pickles/max_pmi_uc_test.npy')\n",
        "max_pmi_uc_test = normalizer.fit_transform(max_pmi_uc_test.reshape(-1,1))\n",
        "\n",
        "max_pmi_code_test = np.load('./pickles/max_pmi_code_test.npy')\n",
        "max_pmi_code_test = normalizer.fit_transform(max_pmi_code_test.reshape(-1,1))\n",
        "\n",
        "qs_uc_test = np.load('./pickles/qs_uc_test.npy')\n",
        "qs_uc_test = normalizer.fit_transform(qs_uc_test.reshape(-1,1))\n",
        "\n",
        "qs_code_test = np.load('./pickles/qs_code_test.npy')\n",
        "qs_code_test = normalizer.fit_transform(qs_code_test.reshape(-1,1))\n",
        "\n",
        "UC_SCS_test = np.load('./pickles/UC_SCS_test.npy')\n",
        "UC_SCS_test = normalizer.fit_transform(UC_SCS_test.reshape(-1,1))\n",
        "\n",
        "CC_SCS_test = np.load('./pickles/CC_SCS_test.npy')\n",
        "CC_SCS_test = normalizer.fit_transform(CC_SCS_test.reshape(-1,1))\n",
        "\n",
        "UC_CoherenceScore_test = np.load('./pickles/UC_CoherenceScore_test.npy')\n",
        "UC_CoherenceScore_test = normalizer.fit_transform(UC_CoherenceScore_test.reshape(-1,1))\n",
        "\n",
        "CC_CoherenceScore_test = np.load('./pickles/CC_CoherenceScore_test.npy')\n",
        "CC_CoherenceScore_test = normalizer.fit_transform(CC_CoherenceScore_test.reshape(-1,1))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Post Retrieval features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#BASSANT COMMENTED THIS\n",
        "# #------------------------post-retrieval (7 metrics) Train --------------------------#\n",
        "# # 1.1) Subquery overlap using jensenShannon\n",
        "# code_queries_score_JensenShannon_train = featureExtraction.SubqueryOverlap(code_documents_train, featureExtraction.JensenShannon,\"JS\", UC_count_matrix_train, code_count_matrix_train)\n",
        "# UC_queries_score_JensenShannon_train = featureExtraction.SubqueryOverlap(UC_documents_train, featureExtraction.JensenShannon,\"JS\",code_count_matrix_train, UC_count_matrix_train)\n",
        "\n",
        "# print('code_queries_score_JensenShannon_train', code_queries_score_JensenShannon_train.shape)\n",
        "# print('UC_queries_score_JensenShannon_train', UC_queries_score_JensenShannon_train.shape)\n",
        "\n",
        "# # 1.2) Subquery overlap using VSM\n",
        "# code_queries_score_VSM_train = featureExtraction.SubqueryOverlap(code_documents_train, featureExtraction.VectorSpaceModel,\"VSM\", UC_count_matrix_train, code_count_matrix_train)\n",
        "# UC_queries_score_VSM_train = featureExtraction.SubqueryOverlap(UC_documents_train, featureExtraction.VectorSpaceModel,\"VSM\", code_count_matrix_train, UC_count_matrix_train)\n",
        "\n",
        "# print('code_queries_score_VSM_train', code_queries_score_VSM_train.shape)\n",
        "# print('UC_queries_score_VSM_train', UC_queries_score_VSM_train.shape)\n",
        "\n",
        "# #1.3) Subquery overlap using BM25\n",
        "# code_queries_score_BM25_train = featureExtraction.SubqueryOverlap(code_documents_train, featureExtraction.BM25,\"BM\", UC_documents_train,idf_uc_dict_train,UC_count_matrix_train)\n",
        "# UC_queries_score_BM25_train = featureExtraction.SubqueryOverlap(UC_documents_train, featureExtraction.BM25,\"BM\", code_documents_train,idf_code_dict_train, code_count_matrix_train)\n",
        "\n",
        "# print('code_queries_score_BM25_train', code_queries_score_BM25_train.shape)\n",
        "# print('UC_queries_score_BM25_train', UC_queries_score_BM25_train.shape)\n",
        "\n",
        "# #1.4) Subquery overlap using JM smoothing\n",
        "# code_queries_score_JM_train = featureExtraction.SubqueryOverlap(code_documents_train, featureExtraction.SmoothingMethods,\"SM\", UC_documents_train,UC_count_matrix_train,tf_uc_dict_train,True)\n",
        "# UC_queries_score_JM_train = featureExtraction.SubqueryOverlap(UC_documents_train, featureExtraction.SmoothingMethods,\"SM\", code_documents_train,code_count_matrix_train,tf_code_dict_train,True)\n",
        "\n",
        "# print('code_queries_score_JM_train', code_queries_score_JM_train.shape)\n",
        "# print('UC_queries_score_JM_train', UC_queries_score_JM_train.shape)\n",
        "\n",
        "# # 1.5) Subquery overlap using DP smoothing\n",
        "# code_queries_score_DP_train = featureExtraction.SubqueryOverlap(code_documents_train, featureExtraction.SmoothingMethods,\"SM\", UC_documents_train, UC_count_matrix_train,tf_uc_dict_train,False)\n",
        "# UC_queries_score_DP_train = featureExtraction.SubqueryOverlap(UC_documents_train, featureExtraction.SmoothingMethods,\"SM\", code_documents_train, code_count_matrix_train,tf_code_dict_train,False)\n",
        "\n",
        "# print('code_queries_score_DP_train', code_queries_score_DP_train.shape)\n",
        "# print('UC_queries_score_DP_train', UC_queries_score_DP_train.shape)\n",
        "\n",
        "# #------------------------post-retrieval (7 metrics) Test --------------------------#\n",
        "# # 1.1) Subquery overlap using jensenShannon\n",
        "# code_queries_score_JensenShannon_test = featureExtraction.SubqueryOverlap(code_documents_test, featureExtraction.JensenShannon,\"JS\", UC_count_matrix_test, code_count_matrix_test)\n",
        "# UC_queries_score_JensenShannon_test = featureExtraction.SubqueryOverlap(UC_documents_test, featureExtraction.JensenShannon,\"JS\",code_count_matrix_test, UC_count_matrix_test)\n",
        "\n",
        "# print('code_queries_score_JensenShannon_test', code_queries_score_JensenShannon_test.shape)\n",
        "# print('UC_queries_score_JensenShannon_test', UC_queries_score_JensenShannon_test.shape)\n",
        "\n",
        "# # 1.2) Subquery overlap using VSM\n",
        "# code_queries_score_VSM_test = featureExtraction.SubqueryOverlap(code_documents_test, featureExtraction.VectorSpaceModel,\"VSM\", UC_count_matrix_test, code_count_matrix_test)\n",
        "# UC_queries_score_VSM_test = featureExtraction.SubqueryOverlap(UC_documents_test, featureExtraction.VectorSpaceModel,\"VSM\", code_count_matrix_test, UC_count_matrix_test)\n",
        "\n",
        "# print('code_queries_score_VSM_test', code_queries_score_VSM_test.shape)\n",
        "# print('UC_queries_score_VSM_test', UC_queries_score_VSM_test.shape)\n",
        "\n",
        "# #1.3) Subquery overlap using BM25\n",
        "# code_queries_score_BM25_test = featureExtraction.SubqueryOverlap(code_documents_test, featureExtraction.BM25,\"BM\", UC_documents_test,idf_uc_dict_test,UC_count_matrix_test)\n",
        "# UC_queries_score_BM25_test = featureExtraction.SubqueryOverlap(UC_documents_test, featureExtraction.BM25,\"BM\", code_documents_test,idf_code_dict_test, code_count_matrix_test)\n",
        "\n",
        "# print('code_queries_score_BM25_test', code_queries_score_BM25_test.shape)\n",
        "# print('UC_queries_score_BM25_test', UC_queries_score_BM25_test.shape)\n",
        "\n",
        "# #1.4) Subquery overlap using JM smoothing\n",
        "# code_queries_score_JM_test = featureExtraction.SubqueryOverlap(code_documents_test, featureExtraction.SmoothingMethods,\"SM\", UC_documents_test,UC_count_matrix_test,tf_uc_dict_test,True)\n",
        "# UC_queries_score_JM_test = featureExtraction.SubqueryOverlap(UC_documents_test, featureExtraction.SmoothingMethods,\"SM\", code_documents_test,code_count_matrix_test,tf_code_dict_test,True)\n",
        "\n",
        "# print('code_queries_score_JM_test', code_queries_score_JM_test.shape)\n",
        "# print('UC_queries_score_JM_test', UC_queries_score_JM_test.shape)\n",
        "\n",
        "# # 1.5) Subquery overlap using DP smoothing\n",
        "# code_queries_score_DP_test = featureExtraction.SubqueryOverlap(code_documents_test, featureExtraction.SmoothingMethods,\"SM\", UC_documents_test, UC_count_matrix_test,tf_uc_dict_test,False)\n",
        "# UC_queries_score_DP_test = featureExtraction.SubqueryOverlap(UC_documents_test, featureExtraction.SmoothingMethods,\"SM\", code_documents_test, code_count_matrix_test,tf_code_dict_test,False)\n",
        "\n",
        "# print('code_queries_score_DP_test', code_queries_score_DP_test.shape)\n",
        "# print('UC_queries_score_DP_test', UC_queries_score_DP_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#--------------------------------Robustness Score Train-------------------------------------------------------#\n",
        "\n",
        "# 2.1) Robustness Score using jensenShannon\n",
        "UC_RS_JS_train, UC_FRC_JS_train = featureExtraction.RobustnessScore(UC_documents_train,code_documents_train,\"JS\")\n",
        "code_RS_JS_train, code_FRC_JS_train = featureExtraction.RobustnessScore(code_documents_train,UC_documents_train,\"JS\")\n",
        "\n",
        "print('UC_RS_JS_train', UC_RS_JS_train.shape)\n",
        "print('code_RS_JS_train', code_RS_JS_train.shape)\n",
        "\n",
        "print('UC_FRC_JS_train', UC_FRC_JS_train.shape)\n",
        "print('code_FRC_JS_train', code_FRC_JS_train.shape)\n",
        "\n",
        "np.save('./pickles/UC_RS_JS_train.npy', UC_RS_JS_train)\n",
        "np.save('./pickles/code_RS_JS_train.npy', code_RS_JS_train)\n",
        "\n",
        "np.save('./pickles/UC_FRC_JS_train.npy', UC_FRC_JS_train)\n",
        "np.save('./pickles/code_FRC_JS_train.npy', code_FRC_JS_train)\n",
        "\n",
        "# 2.2) Robustness Score using VSM\n",
        "UC_RS_VSM_train, UC_FRC_VSM_train = featureExtraction.RobustnessScore(UC_documents_train,code_documents_train,\"VSM\")\n",
        "code_RS_VSM_train, code_FRC_VSM_train = featureExtraction.RobustnessScore(code_documents_train,UC_documents_train,\"VSM\")\n",
        "\n",
        "print('UC_RS_VSM_train', UC_RS_VSM_train.shape)\n",
        "print('code_RS_VSM_train', code_RS_VSM_train.shape)\n",
        "\n",
        "print('UC_FRC_VSM_train', UC_FRC_VSM_train.shape)\n",
        "print('code_FRC_VSM_train', code_FRC_VSM_train.shape)\n",
        "\n",
        "np.save('./pickles/UC_RS_VSM_train.npy', UC_RS_VSM_train)\n",
        "np.save('./pickles/code_RS_VSM_train.npy', code_RS_VSM_train)\n",
        "\n",
        "np.save('./pickles/UC_FRC_VSM_train.npy', UC_FRC_VSM_train)\n",
        "np.save('./pickles/code_FRC_VSM_train.npy', code_FRC_VSM_train)\n",
        "\n",
        "# 2.3) Robustness Score using BM25\n",
        "UC_RS_BM25_train, UC_FRC_BM25_train = featureExtraction.RobustnessScore(UC_documents_train,code_documents_train,\"BM\")\n",
        "code_RS_BM25_train, code_FRC_BM25_train = featureExtraction.RobustnessScore(code_documents_train,UC_documents_train,\"BM\")\n",
        "\n",
        "print('UC_RS_BM25_train', UC_RS_BM25_train.shape)\n",
        "print('code_RS_BM25_train', code_RS_BM25_train.shape)\n",
        "\n",
        "print('UC_FRC_BM25_train', UC_FRC_BM25_train.shape)\n",
        "print('code_FRC_BM25_train', code_FRC_BM25_train.shape)\n",
        "\n",
        "np.save('./pickles/UC_RS_BM25_train.npy', UC_RS_BM25_train)\n",
        "np.save('./pickles/code_RS_BM25_train.npy', code_RS_BM25_train)\n",
        "\n",
        "np.save('./pickles/UC_FRC_BM25_train.npy', UC_FRC_BM25_train)\n",
        "np.save('./pickles/code_FRC_BM25_train.npy', code_FRC_BM25_train)\n",
        "\n",
        "# 2.4) Robustness Score using JM smoothing\n",
        "UC_RS_JM_train, UC_FRC_JM_train = featureExtraction.RobustnessScore(UC_documents_train,code_documents_train,\"JM\")\n",
        "code_RS_JM_train, code_FRC_JM_train = featureExtraction.RobustnessScore(code_documents_train,UC_documents_train,\"JM\")\n",
        "\n",
        "print('UC_RS_JM_train', UC_RS_JM_train.shape)\n",
        "print('code_RS_JM_train', code_RS_JM_train.shape)\n",
        "\n",
        "print('UC_FRC_JM_train', UC_FRC_JM_train.shape)\n",
        "print('code_FRC_JM_train', code_FRC_JM_train.shape)\n",
        "\n",
        "np.save('./pickles/UC_RS_JM_train.npy', UC_RS_JM_train)\n",
        "np.save('./pickles/code_RS_JM_train.npy', code_RS_JM_train)\n",
        "\n",
        "np.save('./pickles/UC_FRC_JM_train.npy', UC_FRC_JM_train)\n",
        "np.save('./pickles/code_FRC_JM_train.npy', code_FRC_JM_train)\n",
        "\n",
        "# 2.5) Robustness Score using DP smoothing\n",
        "UC_RS_DP_train, UC_FRC_DP_train = featureExtraction.RobustnessScore(UC_documents_train,code_documents_train,\"DP\")\n",
        "code_RS_DP_train, code_FRC_DP_train = featureExtraction.RobustnessScore(code_documents_train,UC_documents_train,\"DP\")\n",
        "\n",
        "print('UC_RS_DP_train', UC_RS_DP_train.shape)\n",
        "print('code_RS_DP_train', code_RS_DP_train.shape)\n",
        "\n",
        "print('UC_FRC_DP_train', UC_FRC_DP_train.shape)\n",
        "print('code_FRC_DP_train', code_FRC_DP_train.shape)\n",
        "\n",
        "np.save('./pickles/UC_RS_DP_train.npy', UC_RS_DP_train)\n",
        "np.save('./pickles/code_RS_DP_train.npy', code_RS_DP_train)\n",
        "\n",
        "np.save('./pickles/UC_FRC_DP_train.npy', UC_FRC_DP_train)\n",
        "np.save('./pickles/code_FRC_DP_train.npy', code_FRC_DP_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "UC_RS_JS_train = np.load('./pickles/UC_RS_JS_train.npy')\n",
        "UC_RS_JS_train = normalizer.fit_transform(UC_RS_JS_train.reshape(-1, 1))\n",
        "\n",
        "code_RS_JS_train = np.load('./pickles/code_RS_JS_train.npy')\n",
        "code_RS_JS_train = normalizer.fit_transform(code_RS_JS_train.reshape(-1, 1))\n",
        "\n",
        "UC_FRC_JS_train = np.load('./pickles/UC_FRC_JS_train.npy')\n",
        "UC_FRC_JS_train = normalizer.fit_transform(UC_FRC_JS_train.reshape(-1, 1))\n",
        "\n",
        "code_FRC_JS_train = np.load('./pickles/code_FRC_JS_train.npy')\n",
        "code_FRC_JS_train = normalizer.fit_transform(code_FRC_JS_train.reshape(-1, 1))\n",
        "\n",
        "UC_RS_VSM_train = np.load('./pickles/UC_RS_VSM_train.npy')\n",
        "UC_RS_VSM_train = normalizer.fit_transform(UC_RS_VSM_train.reshape(-1, 1))\n",
        "\n",
        "code_RS_VSM_train = np.load('./pickles/code_RS_VSM_train.npy')\n",
        "code_RS_VSM_train = normalizer.fit_transform(code_RS_VSM_train.reshape(-1, 1))\n",
        "\n",
        "UC_FRC_VSM_train = np.load('./pickles/UC_FRC_VSM_train.npy')\n",
        "UC_FRC_VSM_train = normalizer.fit_transform(UC_FRC_VSM_train.reshape(-1, 1))\n",
        "\n",
        "code_FRC_VSM_train = np.load('./pickles/code_FRC_VSM_train.npy')\n",
        "code_FRC_VSM_train = normalizer.fit_transform(code_FRC_VSM_train.reshape(-1, 1))\n",
        "\n",
        "UC_RS_BM25_train = np.load('./pickles/UC_RS_BM25_train.npy')\n",
        "UC_RS_BM25_train = normalizer.fit_transform(UC_RS_BM25_train.reshape(-1, 1))\n",
        "\n",
        "code_RS_BM25_train = np.load('./pickles/code_RS_BM25_train.npy')\n",
        "code_RS_BM25_train = normalizer.fit_transform(code_RS_BM25_train.reshape(-1, 1))\n",
        "\n",
        "UC_FRC_BM25_train = np.load('./pickles/UC_FRC_BM25_train.npy')\n",
        "UC_FRC_BM25_train = normalizer.fit_transform(UC_FRC_BM25_train.reshape(-1, 1))\n",
        "\n",
        "code_FRC_BM25_train = np.load('./pickles/code_FRC_BM25_train.npy')\n",
        "code_FRC_BM25_train = normalizer.fit_transform(code_FRC_BM25_train.reshape(-1, 1))\n",
        "\n",
        "UC_RS_JM_train = np.load('./pickles/UC_RS_JM_train.npy')\n",
        "UC_RS_JM_train = normalizer.fit_transform(UC_RS_JM_train.reshape(-1, 1))\n",
        "\n",
        "code_RS_JM_train = np.load('./pickles/code_RS_JM_train.npy')\n",
        "code_RS_JM_train = normalizer.fit_transform(code_RS_JM_train.reshape(-1, 1))\n",
        "\n",
        "UC_FRC_JM_train = np.load('./pickles/UC_FRC_JM_train.npy')\n",
        "UC_FRC_JM_train = normalizer.fit_transform(UC_FRC_JM_train.reshape(-1, 1))\n",
        "\n",
        "code_FRC_JM_train = np.load('./pickles/code_FRC_JM_train.npy')\n",
        "code_FRC_JM_train = normalizer.fit_transform(code_FRC_JM_train.reshape(-1, 1))\n",
        "\n",
        "UC_RS_DP_train = np.load('./pickles/UC_RS_DP_train.npy')\n",
        "UC_RS_DP_train = normalizer.fit_transform(UC_RS_DP_train.reshape(-1, 1))\n",
        "\n",
        "code_RS_DP_train = np.load('./pickles/code_RS_DP_train.npy')\n",
        "code_RS_DP_train = normalizer.fit_transform(code_RS_DP_train.reshape(-1, 1))\n",
        "\n",
        "UC_FRC_DP_train = np.load('./pickles/UC_FRC_DP_train.npy')\n",
        "UC_FRC_DP_train = normalizer.fit_transform(UC_FRC_DP_train.reshape(-1, 1))\n",
        "\n",
        "code_FRC_DP_train = np.load('./pickles/code_FRC_DP_train.npy')\n",
        "code_FRC_DP_train = normalizer.fit_transform(code_FRC_DP_train.reshape(-1, 1))\n",
        "\n",
        "print(UC_FRC_DP_train,UC_FRC_JM_train,UC_FRC_BM25_train,UC_FRC_JS_train,UC_FRC_VSM_train) # ALERT : el hgat dy bytgeb zeros w ones\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#--------------------------------------------------Robustness Score test------------------------------------------------------------#\n",
        "\n",
        "# 2.1) Robustness Score using jensenShannon\n",
        "UC_RS_JS_test, UC_FRC_JS_test = featureExtraction.RobustnessScore(UC_documents_test,code_documents_test,\"JS\")\n",
        "code_RS_JS_test, code_FRC_JS_test = featureExtraction.RobustnessScore(code_documents_test,UC_documents_test,\"JS\")\n",
        "\n",
        "print('UC_RS_JS_test', UC_RS_JS_test.shape)\n",
        "print('code_RS_JS_test', code_RS_JS_test.shape)\n",
        "\n",
        "print('UC_FRC_JS_test', UC_FRC_JS_test.shape)\n",
        "print('code_FRC_JS_test', code_FRC_JS_test.shape)\n",
        "\n",
        "np.save('./pickles/UC_RS_JS_test.npy', UC_RS_JS_test)\n",
        "np.save('./pickles/code_RS_JS_test.npy', code_RS_JS_test)\n",
        "\n",
        "np.save('./pickles/UC_FRC_JS_test.npy', UC_FRC_JS_test)\n",
        "np.save('./pickles/code_FRC_JS_test.npy', code_FRC_JS_test)\n",
        "\n",
        "# 2.2) Robustness Score using VSM\n",
        "UC_RS_VSM_test, UC_FRC_VSM_test = featureExtraction.RobustnessScore(UC_documents_test,code_documents_test,\"VSM\")\n",
        "code_RS_VSM_test, code_FRC_VSM_test = featureExtraction.RobustnessScore(code_documents_test,UC_documents_test,\"VSM\")\n",
        "\n",
        "print('UC_RS_VSM_test', UC_RS_VSM_test.shape)\n",
        "print('code_RS_VSM_test', code_RS_VSM_test.shape)\n",
        "\n",
        "print('UC_FRC_VSM_test', UC_FRC_VSM_test.shape)\n",
        "print('code_FRC_VSM_test', code_FRC_VSM_test.shape)\n",
        "\n",
        "np.save('./pickles/UC_RS_VSM_test.npy', UC_RS_VSM_test)\n",
        "np.save('./pickles/code_RS_VSM_test.npy', code_RS_VSM_test)\n",
        "\n",
        "np.save('./pickles/UC_FRC_VSM_test.npy', UC_FRC_VSM_test)\n",
        "np.save('./pickles/code_FRC_VSM_test.npy', code_FRC_VSM_test)\n",
        "\n",
        "# 2.3) Robustness Score using BM25\n",
        "UC_RS_BM25_test, UC_FRC_BM25_test = featureExtraction.RobustnessScore(UC_documents_test,code_documents_test,\"BM\")\n",
        "code_RS_BM25_test, code_FRC_BM25_test = featureExtraction.RobustnessScore(code_documents_test,UC_documents_test,\"BM\")\n",
        "\n",
        "print('UC_RS_BM25_test', UC_RS_BM25_test.shape)\n",
        "print('code_RS_BM25_test', code_RS_BM25_test.shape)\n",
        "\n",
        "print('UC_FRC_BM25_test', UC_FRC_BM25_test.shape)\n",
        "print('code_FRC_BM25_test', code_FRC_BM25_test.shape)\n",
        "\n",
        "np.save('./pickles/UC_RS_BM25_test.npy', UC_RS_BM25_test)\n",
        "np.save('./pickles/code_RS_BM25_test.npy', code_RS_BM25_test)\n",
        "\n",
        "np.save('./pickles/UC_FRC_BM25_test.npy', UC_FRC_BM25_test)\n",
        "np.save('./pickles/code_FRC_BM25_test.npy', code_FRC_BM25_test)\n",
        "\n",
        "# 2.4) Robustness Score using JM smoothing\n",
        "UC_RS_JM_test, UC_FRC_JM_test = featureExtraction.RobustnessScore(UC_documents_test,code_documents_test,\"JM\")\n",
        "code_RS_JM_test, code_FRC_JM_test = featureExtraction.RobustnessScore(code_documents_test,UC_documents_test,\"JM\")\n",
        "\n",
        "print('UC_RS_JM_test', UC_RS_JM_test.shape)\n",
        "print('code_RS_JM_test', code_RS_JM_test.shape)\n",
        "\n",
        "print('UC_FRC_JM_test', UC_FRC_JM_test.shape)\n",
        "print('code_FRC_JM_test', code_FRC_JM_test.shape)\n",
        "\n",
        "np.save('./pickles/UC_RS_JM_test.npy', UC_RS_JM_test)\n",
        "np.save('./pickles/code_RS_JM_test.npy', code_RS_JM_test)\n",
        "\n",
        "np.save('./pickles/UC_FRC_JM_test.npy', UC_FRC_JM_test)\n",
        "np.save('./pickles/code_FRC_JM_test.npy', code_FRC_JM_test)\n",
        "\n",
        "# 2.5) Robustness Score using DP smoothing\n",
        "UC_RS_DP_test, UC_FRC_DP_test = featureExtraction.RobustnessScore(UC_documents_test,code_documents_test,\"DP\")\n",
        "code_RS_DP_test, code_FRC_DP_test = featureExtraction.RobustnessScore(code_documents_test,UC_documents_test,\"DP\")\n",
        "\n",
        "print('UC_RS_DP_test', UC_RS_DP_test.shape)\n",
        "print('code_RS_DP_test', code_RS_DP_test.shape)\n",
        "\n",
        "print('UC_FRC_DP_test', UC_FRC_DP_test.shape)\n",
        "print('code_FRC_DP_test', code_FRC_DP_test.shape)\n",
        "\n",
        "np.save('./pickles/UC_RS_DP_test.npy', UC_RS_DP_test)\n",
        "np.save('./pickles/code_RS_DP_test.npy', code_RS_DP_test)\n",
        "\n",
        "np.save('./pickles/UC_FRC_DP_test.npy', UC_FRC_DP_test)\n",
        "np.save('./pickles/code_FRC_DP_test.npy', code_FRC_DP_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#ALERT :FRC BYTL3 1 AND ZEROS M3RFSH LW DY HAGA SAH\n",
        "UC_RS_JS_test = np.load('./pickles/UC_RS_JS_test.npy')\n",
        "UC_RS_JS_test = normalizer.fit_transform(UC_RS_JS_test.reshape(-1, 1))\n",
        "\n",
        "code_RS_JS_test = np.load('./pickles/code_RS_JS_test.npy')\n",
        "code_RS_JS_test = normalizer.fit_transform(code_RS_JS_test.reshape(-1, 1))\n",
        "\n",
        "UC_FRC_JS_test = np.load('./pickles/UC_FRC_JS_test.npy')  #ALERT: bytl3 1 and zeros mfesh decimals\n",
        "UC_FRC_JS_test = normalizer.fit_transform(UC_FRC_JS_test.reshape(-1, 1))\n",
        "\n",
        "code_FRC_JS_test = np.load('./pickles/code_FRC_JS_test.npy')\n",
        "code_FRC_JS_test = normalizer.fit_transform(code_FRC_JS_test.reshape(-1, 1))\n",
        "\n",
        "UC_RS_VSM_test = np.load('./pickles/UC_RS_VSM_test.npy')\n",
        "UC_RS_VSM_test = normalizer.fit_transform(UC_RS_VSM_test.reshape(-1, 1))\n",
        "\n",
        "code_RS_VSM_test = np.load('./pickles/code_RS_VSM_test.npy')\n",
        "code_RS_VSM_test = normalizer.fit_transform(code_RS_VSM_test.reshape(-1, 1))\n",
        "\n",
        "UC_FRC_VSM_test = np.load('./pickles/UC_FRC_VSM_test.npy')\n",
        "UC_FRC_VSM_test = normalizer.fit_transform(UC_FRC_VSM_test.reshape(-1, 1))\n",
        "\n",
        "code_FRC_VSM_test = np.load('./pickles/code_FRC_VSM_test.npy')\n",
        "code_FRC_VSM_test= normalizer.fit_transform(code_FRC_VSM_test.reshape(-1, 1))\n",
        "\n",
        "UC_RS_BM25_test = np.load('./pickles/UC_RS_BM25_test.npy')\n",
        "UC_RS_BM25_test = normalizer.fit_transform(UC_RS_BM25_test.reshape(-1, 1))\n",
        "\n",
        "code_RS_BM25_test = np.load('./pickles/code_RS_BM25_test.npy')\n",
        "code_RS_BM25_test = normalizer.fit_transform(code_RS_BM25_test.reshape(-1, 1))\n",
        "\n",
        "UC_FRC_BM25_test = np.load('./pickles/UC_FRC_BM25_test.npy')\n",
        "UC_FRC_BM25_test = normalizer.fit_transform(UC_FRC_BM25_test.reshape(-1, 1))\n",
        "\n",
        "code_FRC_BM25_test = np.load('./pickles/code_FRC_BM25_test.npy')\n",
        "code_FRC_BM25_test = normalizer.fit_transform(code_FRC_BM25_test.reshape(-1, 1))\n",
        "\n",
        "UC_RS_JM_test = np.load('./pickles/UC_RS_JM_test.npy')\n",
        "UC_RS_JM_test = normalizer.fit_transform(UC_RS_JM_test.reshape(-1, 1))\n",
        "\n",
        "code_RS_JM_test = np.load('./pickles/code_RS_JM_test.npy')\n",
        "code_RS_JM_test = normalizer.fit_transform(code_RS_JM_test.reshape(-1, 1))\n",
        "\n",
        "UC_FRC_JM_test = np.load('./pickles/UC_FRC_JM_test.npy')\n",
        "UC_FRC_JM_test = normalizer.fit_transform(UC_FRC_JM_test.reshape(-1, 1))\n",
        "\n",
        "code_FRC_JM_test = np.load('./pickles/code_FRC_JM_test.npy')\n",
        "code_FRC_JM_test = normalizer.fit_transform(code_FRC_JM_test.reshape(-1, 1))\n",
        "\n",
        "UC_RS_DP_test = np.load('./pickles/UC_RS_DP_test.npy')\n",
        "UC_RS_DP_test = normalizer.fit_transform(UC_RS_DP_test.reshape(-1, 1))\n",
        "\n",
        "code_RS_DP_test = np.load('./pickles/code_RS_DP_test.npy')\n",
        "code_RS_DP_test = normalizer.fit_transform(code_RS_DP_test.reshape(-1, 1))\n",
        "\n",
        "UC_FRC_DP_test = np.load('./pickles/UC_FRC_DP_test.npy')\n",
        "UC_FRC_DP_test = normalizer.fit_transform(UC_FRC_DP_test.reshape(-1, 1))\n",
        "\n",
        "code_FRC_DP_test = np.load('./pickles/code_FRC_DP_test.npy')\n",
        "code_FRC_DP_test = normalizer.fit_transform(code_FRC_DP_test.reshape(-1, 1))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#------------------------------------------------- ClusteringTendency Train---------------------------------------------\n",
        "# 4.1) Clustering Tendency using JensenShannon\n",
        "UC_CT_JensenShannon_train = featureExtraction.ClusteringTendency(JS_UC_train.T,tfidf_matrix_uc_train,tfidf_matrix_code_train)\n",
        "code_CT_JensenShannon_train = featureExtraction.ClusteringTendency(JS_CC_train,tfidf_matrix_code_train,tfidf_matrix_uc_train)\n",
        "\n",
        "print(\"UC_CT_JensenShannon_train\",UC_CT_JensenShannon_train.shape)\n",
        "print(\"code_CT_JensenShannon_train\",code_CT_JensenShannon_train.shape)\n",
        "\n",
        "np.save('./pickles/UC_CT_JensenShannon_train.npy',UC_CT_JensenShannon_train)\n",
        "np.save('./pickles/code_CT_JensenShannon_train.npy',code_CT_JensenShannon_train)\n",
        "\n",
        "# 4.2) Clustering Tendency using VSM\n",
        "UC_CT_VSM_train = featureExtraction.ClusteringTendency(cosine_similarity_UC_train.T,tfidf_matrix_uc_train,tfidf_matrix_code_train)\n",
        "code_CT_VSM_train = featureExtraction.ClusteringTendency(cosine_similarity_CC_train,tfidf_matrix_code_train,tfidf_matrix_uc_train)\n",
        "\n",
        "print(\"UC_CT_VSM_train\",UC_CT_VSM_train.shape)\n",
        "print(\"code_CT_VSM_train\",code_CT_VSM_train.shape)\n",
        "\n",
        "np.save('./pickles/UC_CT_VSM_train.npy',UC_CT_VSM_train)\n",
        "np.save('./pickles/code_CT_VSM_train.npy',code_CT_VSM_train)\n",
        "\n",
        "# 4.3) Clustering Tendency using BM25\n",
        "UC_CT_BM25_train = featureExtraction.ClusteringTendency(BM25_UC_train,tfidf_matrix_uc_train,tfidf_matrix_code_train)\n",
        "code_CT_BM25_train = featureExtraction.ClusteringTendency(BM25_CC_train,tfidf_matrix_code_train,tfidf_matrix_uc_train)\n",
        "\n",
        "print(\"UC_CT_BM25_train\",UC_CT_BM25_train.shape)\n",
        "print(\"code_CT_BM25_train\",code_CT_BM25_train.shape)\n",
        "\n",
        "np.save('./pickles/UC_CT_BM25_train.npy',UC_CT_BM25_train)\n",
        "np.save('./pickles/code_CT_BM25_train.npy',code_CT_BM25_train)\n",
        "\n",
        "# 4.4) Clustering Tendency using JM\n",
        "UC_CT_JM_train = featureExtraction.ClusteringTendency(JM_UC_train,tfidf_matrix_uc_train,tfidf_matrix_code_train)\n",
        "code_CT_JM_train = featureExtraction.ClusteringTendency(JM_CC_train,tfidf_matrix_code_train,tfidf_matrix_uc_train)\n",
        "\n",
        "print(\"UC_CT_JM_train\",UC_CT_JM_train.shape)\n",
        "print(\"code_CT_JM_train\",code_CT_JM_train.shape)\n",
        "\n",
        "\n",
        "np.save('./pickles/UC_CT_JM_train.npy',UC_CT_JM_train)\n",
        "np.save('./pickles/code_CT_JM_train.npy',code_CT_JM_train) \n",
        "\n",
        "# 4.5) Clustering Tendency using DP\n",
        "UC_CT_DP_train = featureExtraction.ClusteringTendency(DP_UC_train,tfidf_matrix_uc_train,tfidf_matrix_code_train)\n",
        "code_CT_DP_train = featureExtraction.ClusteringTendency(DP_CC_train,tfidf_matrix_code_train,tfidf_matrix_uc_train)\n",
        "\n",
        "print(\"UC_CT_DP_train\",UC_CT_DP_train.shape)\n",
        "print(\"code_CT_DP_train\",code_CT_DP_train.shape)\n",
        "\n",
        "np.save('./pickles/UC_CT_DP_train.npy',UC_CT_DP_train)\n",
        "np.save('./pickles/code_CT_DP_train.npy',code_CT_DP_train) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#----------------------------------ClusteringTendency test-------------------------------------------------\n",
        "# 4.1) Clustering Tendency using JensenShannon\n",
        "UC_CT_JensenShannon_test = featureExtraction.ClusteringTendency(JS_UC_test.T,tfidf_matrix_uc_test,tfidf_matrix_code_test)\n",
        "code_CT_JensenShannon_test = featureExtraction.ClusteringTendency(JS_CC_test,tfidf_matrix_code_test,tfidf_matrix_uc_test)\n",
        "\n",
        "print(\"UC_CT_JensenShannon_test\",UC_CT_JensenShannon_test.shape)\n",
        "print(\"code_CT_JensenShannon_test\",code_CT_JensenShannon_test.shape)\n",
        "\n",
        "np.save('./pickles/UC_CT_JensenShannon_test.npy',UC_CT_JensenShannon_test)\n",
        "np.save('./pickles/code_CT_JensenShannon_test.npy',code_CT_JensenShannon_test) \n",
        "\n",
        "# 4.2) Clustering Tendency using VSM\n",
        "UC_CT_VSM_test = featureExtraction.ClusteringTendency(cosine_similarity_UC_test.T,tfidf_matrix_uc_test,tfidf_matrix_code_test)\n",
        "code_CT_VSM_test = featureExtraction.ClusteringTendency(cosine_similarity_CC_test,tfidf_matrix_code_test,tfidf_matrix_uc_test)\n",
        "\n",
        "print(\"UC_CT_VSM_test\",UC_CT_VSM_test.shape)\n",
        "print(\"code_CT_VSM_test\",code_CT_VSM_test.shape)\n",
        "\n",
        "np.save('./pickles/UC_CT_VSM_test.npy',UC_CT_VSM_test)\n",
        "np.save('./pickles/code_CT_VSM_test.npy',code_CT_VSM_test)\n",
        "\n",
        "# 4.3) Clustering Tendency using BM25\n",
        "UC_CT_BM25_test = featureExtraction.ClusteringTendency(BM25_UC_test,tfidf_matrix_uc_test,tfidf_matrix_code_test)\n",
        "code_CT_BM25_test = featureExtraction.ClusteringTendency(BM25_CC_test,tfidf_matrix_code_test,tfidf_matrix_uc_test)\n",
        "\n",
        "print(\"UC_CT_BM25_test\",UC_CT_BM25_test.shape)\n",
        "print(\"code_CT_BM25_test\",code_CT_BM25_test.shape)\n",
        "\n",
        "np.save('./pickles/UC_CT_BM25_test.npy', UC_CT_BM25_test)\n",
        "np.save('./pickles/code_CT_BM25_test.npy', code_CT_BM25_test)\n",
        "\n",
        "# 4.4) Clustering Tendency using JM\n",
        "UC_CT_JM_test = featureExtraction.ClusteringTendency(JM_UC_test,tfidf_matrix_uc_test,tfidf_matrix_code_test)\n",
        "code_CT_JM_test = featureExtraction.ClusteringTendency(JM_CC_test,tfidf_matrix_code_test,tfidf_matrix_uc_test)\n",
        "\n",
        "print(\"UC_CT_JM_test\",UC_CT_JM_test.shape)\n",
        "print(\"code_CT_JM_test\",code_CT_JM_test.shape)\n",
        "\n",
        "np.save('./pickles/UC_CT_JM_test.npy', UC_CT_JM_test)\n",
        "np.save('./pickles/code_CT_JM_test.npy', code_CT_JM_test)\n",
        "\n",
        "# 4.5) Clustering Tendency using DP\n",
        "UC_CT_DP_test = featureExtraction.ClusteringTendency(DP_UC_test,tfidf_matrix_uc_test,tfidf_matrix_code_test)\n",
        "code_CT_DP_test = featureExtraction.ClusteringTendency(DP_CC_test,tfidf_matrix_code_test,tfidf_matrix_uc_test)\n",
        "\n",
        "print(\"UC_CT_DP_test\",UC_CT_DP_test.shape)\n",
        "print(\"code_CT_DP_test\",code_CT_DP_test.shape)\n",
        "\n",
        "np.save('./pickles/UC_CT_DP_test.npy', UC_CT_DP_test)\n",
        "np.save('./pickles/code_CT_DP_test.npy', code_CT_DP_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "UC_CT_JensenShannon_train = np.load('./pickles/UC_CT_JensenShannon_train.npy')\n",
        "UC_CT_JensenShannon_train = normalizer.fit_transform(UC_CT_JensenShannon_train)\n",
        "\n",
        "code_CT_JensenShannon_train = np.load('./pickles/code_CT_JensenShannon_train.npy')\n",
        "code_CT_JensenShannon_train = normalizer.fit_transform(code_CT_JensenShannon_train)\n",
        "\n",
        "UC_CT_VSM_train = np.load('./pickles/UC_CT_VSM_train.npy')\n",
        "UC_CT_VSM_train = normalizer.fit_transform(UC_CT_VSM_train)\n",
        "\n",
        "code_CT_VSM_train = np.load('./pickles/code_CT_VSM_train.npy')\n",
        "code_CT_VSM_train = normalizer.fit_transform(code_CT_VSM_train)\n",
        "\n",
        "UC_CT_BM25_train = np.load('./pickles/UC_CT_BM25_train.npy')\n",
        "UC_CT_BM25_train = normalizer.fit_transform(UC_CT_BM25_train)\n",
        "\n",
        "code_CT_BM25_train = np.load('./pickles/code_CT_BM25_train.npy')\n",
        "code_CT_BM25_train = normalizer.fit_transform(code_CT_BM25_train)\n",
        "\n",
        "UC_CT_JM_train = np.load('./pickles/UC_CT_JM_train.npy')\n",
        "UC_CT_JM_train = normalizer.fit_transform(UC_CT_JM_train)\n",
        "\n",
        "code_CT_JM_train = np.load('./pickles/code_CT_JM_train.npy')\n",
        "code_CT_JM_train = normalizer.fit_transform(code_CT_JM_train)\n",
        "\n",
        "UC_CT_DP_train = np.load('./pickles/UC_CT_DP_train.npy')\n",
        "UC_CT_DP_train = normalizer.fit_transform(UC_CT_DP_train)\n",
        "\n",
        "code_CT_DP_train = np.load('./pickles/code_CT_DP_train.npy')\n",
        "code_CT_DP_train = normalizer.fit_transform(code_CT_DP_train)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "UC_CT_JensenShannon_test = np.load('./pickles/UC_CT_JensenShannon_test.npy')\n",
        "UC_CT_JensenShannon_test = normalizer.fit_transform(UC_CT_JensenShannon_test)\n",
        "\n",
        "code_CT_JensenShannon_test = np.load('./pickles/code_CT_JensenShannon_test.npy')\n",
        "code_CT_JensenShannon_test = normalizer.fit_transform(code_CT_JensenShannon_test)\n",
        "\n",
        "UC_CT_VSM_test = np.load('./pickles/UC_CT_VSM_test.npy')\n",
        "UC_CT_VSM_test = normalizer.fit_transform(UC_CT_VSM_test)\n",
        "\n",
        "code_CT_VSM_test = np.load('./pickles/code_CT_VSM_test.npy')\n",
        "code_CT_VSM_test = normalizer.fit_transform(code_CT_VSM_test)\n",
        "\n",
        "UC_CT_BM25_test = np.load('./pickles/UC_CT_BM25_test.npy')\n",
        "UC_CT_BM25_test = normalizer.fit_transform(UC_CT_BM25_test)\n",
        "\n",
        "code_CT_BM25_test = np.load('./pickles/code_CT_BM25_test.npy')\n",
        "code_CT_BM25_test = normalizer.fit_transform(code_CT_BM25_test)\n",
        "\n",
        "UC_CT_JM_test = np.load('./pickles/UC_CT_JM_test.npy')\n",
        "UC_CT_JM_test = normalizer.fit_transform(UC_CT_JM_test)\n",
        "\n",
        "code_CT_JM_test = np.load('./pickles/code_CT_JM_test.npy')\n",
        "code_CT_JM_test = normalizer.fit_transform(code_CT_JM_test)\n",
        "\n",
        "UC_CT_DP_test = np.load('./pickles/UC_CT_DP_test.npy')\n",
        "UC_CT_DP_test = normalizer.fit_transform(UC_CT_DP_test)\n",
        "\n",
        "code_CT_DP_test = np.load('./pickles/code_CT_DP_test.npy')\n",
        "code_CT_DP_test = normalizer.fit_transform(code_CT_DP_test)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "#------------------------------Spatial AutoCorrelation  Train-------------------------------------------#\n",
        "# 5.1) Spatial AutoCorrelation using JensenShannon\n",
        "UC_SAC_JS_train = featureExtraction.SpatialAutoCorrelation(JS_UC_train.T,tfidf_matrix_code_train)\n",
        "code_SAC_JS_train = featureExtraction.SpatialAutoCorrelation(JS_CC_train,tfidf_matrix_uc_train)\n",
        "\n",
        "print(\"UC_SAC_JS_train\",UC_SAC_JS_train.shape)\n",
        "print(\"code_SAC_JS_train\",code_SAC_JS_train.shape)\n",
        "\n",
        "np.save('./pickles/UC_SAC_JensenShannon_train.npy',UC_SAC_JS_train)\n",
        "np.save('./pickles/code_SAC_JensenShannon_train.npy',code_SAC_JS_train)\n",
        "\n",
        "# 5.2) Spatial AutoCorrelation using VSM\n",
        "UC_SAC_VSM_train = featureExtraction.SpatialAutoCorrelation(cosine_similarity_UC_train.T,tfidf_matrix_code_train)\n",
        "code_SAC_VSM_train= featureExtraction.SpatialAutoCorrelation(cosine_similarity_CC_train,tfidf_matrix_uc_train)\n",
        "\n",
        "print(\"UC_SAC_VSM_train\",UC_SAC_VSM_train.shape)\n",
        "print(\"code_SAC_VSM_train\",code_SAC_VSM_train.shape)\n",
        "\n",
        "np.save('./pickles/UC_SAC_VSM_train.npy',UC_SAC_VSM_train)\n",
        "np.save('./pickles/code_SAC_VSM_train.npy',code_SAC_VSM_train)\n",
        "# 5.3) Spatial AutoCorrelation using BM25\n",
        "UC_SAC_BM25_train = featureExtraction.SpatialAutoCorrelation(BM25_UC_train,tfidf_matrix_code_train)\n",
        "code_SAC_BM25_train = featureExtraction.SpatialAutoCorrelation(BM25_CC_train,tfidf_matrix_uc_train)\n",
        "\n",
        "print(\"UC_SAC_BM25_train\",UC_SAC_BM25_train.shape)\n",
        "print(\"code_SAC_BM25_train\",code_SAC_BM25_train.shape)\n",
        "\n",
        "np.save('./pickles/UC_SAC_BM25_train.npy',UC_SAC_BM25_train)\n",
        "np.save('./pickles/code_SAC_BM25_train.npy',code_SAC_BM25_train)\n",
        "\n",
        "# 5.4) Spatial AutoCorrelation using JM\n",
        "UC_SAC_JM_train = featureExtraction.SpatialAutoCorrelation(JM_UC_train,tfidf_matrix_code_train)\n",
        "code_SAC_JM_train= featureExtraction.SpatialAutoCorrelation(JM_CC_train,tfidf_matrix_uc_train)\n",
        "\n",
        "print(\"UC_SAC_JM_train\",UC_SAC_JM_train.shape)\n",
        "print(\"code_SAC_JM_train\",code_SAC_JM_train.shape)\n",
        "\n",
        "np.save('./pickles/UC_SAC_JM_train.npy',UC_SAC_JM_train)\n",
        "np.save('./pickles/code_SAC_JM_train.npy',code_SAC_JM_train)\n",
        "# 5.5) Spatial AutoCorrelation using DP\n",
        "UC_SAC_DP_train = featureExtraction.SpatialAutoCorrelation(DP_UC_train,tfidf_matrix_code_train)\n",
        "code_SAC_DP_train= featureExtraction.SpatialAutoCorrelation(DP_CC_train,tfidf_matrix_uc_train)\n",
        "\n",
        "print(\"UC_SAC_DP_train\",UC_SAC_DP_train.shape)\n",
        "print(\"code_SAC_DP_train\",code_SAC_DP_train.shape)\n",
        "\n",
        "np.save('./pickles/UC_SAC_DP_train.npy',UC_SAC_DP_train)\n",
        "np.save('./pickles/code_SAC_DP_train.npy',code_SAC_DP_train)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#------------------------------ Spatial AutoCorrelation  Test-------------------------------------------#\n",
        "# 5.1) Spatial AutoCorrelation using JensenShannon\n",
        "UC_SAC_JS_test = featureExtraction.SpatialAutoCorrelation(JS_UC_test.T,tfidf_matrix_code_test)\n",
        "code_SAC_JS_test = featureExtraction.SpatialAutoCorrelation(JS_CC_test,tfidf_matrix_uc_test)\n",
        "\n",
        "print(\"UC_SAC_JS_test\",UC_SAC_JS_test.shape)\n",
        "print(\"code_SAC_JS_test\",code_SAC_JS_test.shape)\n",
        "\n",
        "np.save('./pickles/UC_SAC_JensenShannon_test.npy',UC_SAC_JS_test)\n",
        "np.save('./pickles/code_SAC_JensenShannon_test.npy',code_SAC_JS_test)\n",
        "# 5.2) Spatial AutoCorrelation using VSM\n",
        "UC_SAC_VSM_test = featureExtraction.SpatialAutoCorrelation(cosine_similarity_UC_test.T,tfidf_matrix_code_test)\n",
        "code_SAC_VSM_test= featureExtraction.SpatialAutoCorrelation(cosine_similarity_CC_test,tfidf_matrix_uc_test)\n",
        "\n",
        "print(\"UC_SAC_VSM_test\",UC_SAC_VSM_test.shape)\n",
        "print(\"code_SAC_VSM_test\",code_SAC_VSM_test.shape)\n",
        "\n",
        "np.save('./pickles/UC_SAC_VSM_test.npy',UC_SAC_VSM_test)\n",
        "np.save('./pickles/code_SAC_VSM_test.npy',code_SAC_VSM_test)\n",
        "\n",
        "# 5.3) Spatial AutoCorrelation using BM25\n",
        "UC_SAC_BM25_test = featureExtraction.SpatialAutoCorrelation(BM25_UC_test,tfidf_matrix_code_test)\n",
        "code_SAC_BM25_test = featureExtraction.SpatialAutoCorrelation(BM25_CC_test,tfidf_matrix_uc_test)\n",
        "\n",
        "print(\"UC_SAC_BM25_test\",UC_SAC_BM25_test.shape)\n",
        "print(\"code_SAC_BM25_test\",code_SAC_BM25_test.shape)\n",
        "\n",
        "np.save('./pickles/UC_SAC_BM25_test.npy',UC_SAC_BM25_test)\n",
        "np.save('./pickles/code_SAC_BM25_test.npy',code_SAC_BM25_test)\n",
        "\n",
        "# 5.4) Spatial AutoCorrelation using JM\n",
        "UC_SAC_JM_test = featureExtraction.SpatialAutoCorrelation(JM_UC_test,tfidf_matrix_code_test)\n",
        "code_SAC_JM_test= featureExtraction.SpatialAutoCorrelation(JM_CC_test,tfidf_matrix_uc_test)\n",
        "\n",
        "print(\"UC_SAC_JM_test\",UC_SAC_JM_test.shape)\n",
        "print(\"code_SAC_JM_test\",code_SAC_JM_test.shape)\n",
        "\n",
        "np.save('./pickles/UC_SAC_JM_test.npy',UC_SAC_JM_test)\n",
        "np.save('./pickles/code_SAC_JM_test.npy',code_SAC_JM_test)\n",
        "\n",
        "# 5.5) Spatial AutoCorrelation using DP\n",
        "UC_SAC_DP_test = featureExtraction.SpatialAutoCorrelation(DP_UC_test,tfidf_matrix_code_test)\n",
        "code_SAC_DP_test= featureExtraction.SpatialAutoCorrelation(DP_CC_test,tfidf_matrix_uc_test)\n",
        "\n",
        "print(\"UC_SAC_DP_test\",UC_SAC_DP_test.shape)\n",
        "print(\"code_SAC_DP_test\",code_SAC_DP_test.shape)\n",
        "\n",
        "np.save('./pickles/UC_SAC_DP_test.npy',UC_SAC_DP_test)\n",
        "np.save('./pickles/code_SAC_DP_test.npy',code_SAC_DP_test)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#------------------------------ Spatial AutoCorrelation Train Loading-------------------------------------------#\n",
        "\n",
        "UC_SAC_JS_train = np.load('./pickles/UC_SAC_JensenShannon_train.npy')\n",
        "UC_SAC_JS_train = normalizer.fit_transform(UC_SAC_JS_train)\n",
        "\n",
        "code_SAC_JS_train = np.load('./pickles/code_SAC_JensenShannon_train.npy')\n",
        "code_SAC_JS_train = normalizer.fit_transform(code_SAC_JS_train)\n",
        "\n",
        "UC_SAC_VSM_train = np.load('./pickles/UC_SAC_VSM_train.npy')\n",
        "UC_SAC_VSM_train = normalizer.fit_transform(UC_SAC_VSM_train)\n",
        "\n",
        "code_SAC_VSM_train = np.load('./pickles/code_SAC_VSM_train.npy')\n",
        "code_SAC_VSM_train = normalizer.fit_transform(code_SAC_VSM_train)\n",
        "\n",
        "UC_SAC_BM25_train = np.load('./pickles/UC_SAC_BM25_train.npy')\n",
        "UC_SAC_BM25_train = normalizer.fit_transform(UC_SAC_BM25_train)\n",
        "\n",
        "code_SAC_BM25_train = np.load('./pickles/code_SAC_BM25_train.npy')\n",
        "code_SAC_BM25_train = normalizer.fit_transform(code_SAC_BM25_train)\n",
        "\n",
        "UC_SAC_JM_train = np.load('./pickles/UC_SAC_JM_train.npy')\n",
        "UC_SAC_JM_train = normalizer.fit_transform(UC_SAC_JM_train)\n",
        "\n",
        "code_SAC_JM_train = np.load('./pickles/code_SAC_JM_train.npy')\n",
        "code_SAC_JM_train = normalizer.fit_transform(code_SAC_JM_train)\n",
        "\n",
        "UC_SAC_DP_train = np.load('./pickles/UC_SAC_DP_train.npy')\n",
        "UC_SAC_DP_train = normalizer.fit_transform(UC_SAC_DP_train)  #ALERT : bytl3 ones ktyera awy , ones w zero\n",
        "\n",
        "code_SAC_DP_train = np.load('./pickles/code_SAC_DP_train.npy')\n",
        "code_SAC_DP_train = normalizer.fit_transform(code_SAC_DP_train)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#------------------------------ Spatial AutoCorrelation Test Loading-------------------------------------------#\n",
        "UC_SAC_JS_test = np.load('./pickles/UC_SAC_JensenShannon_test.npy')\n",
        "UC_SAC_JS_test = normalizer.fit_transform(UC_SAC_JS_test)\n",
        "\n",
        "code_SAC_JS_test = np.load('./pickles/code_SAC_JensenShannon_test.npy')\n",
        "code_SAC_JS_test = normalizer.fit_transform(code_SAC_JS_test)\n",
        "\n",
        "UC_SAC_VSM_test = np.load('./pickles/UC_SAC_VSM_test.npy')\n",
        "UC_SAC_VSM_test = normalizer.fit_transform(UC_SAC_VSM_test)\n",
        "\n",
        "code_SAC_VSM_test = np.load('./pickles/code_SAC_VSM_test.npy')\n",
        "code_SAC_VSM_test = normalizer.fit_transform(code_SAC_VSM_test)\n",
        "\n",
        "UC_SAC_BM25_test = np.load('./pickles/UC_SAC_BM25_test.npy')\n",
        "UC_SAC_BM25_test = normalizer.fit_transform(UC_SAC_BM25_test)\n",
        "\n",
        "code_SAC_BM25_test = np.load('./pickles/code_SAC_BM25_test.npy')\n",
        "code_SAC_BM25_test = normalizer.fit_transform(code_SAC_BM25_test)\n",
        "\n",
        "UC_SAC_JM_test = np.load('./pickles/UC_SAC_JM_test.npy')\n",
        "UC_SAC_JM_test = normalizer.fit_transform(UC_SAC_JM_test)\n",
        "\n",
        "code_SAC_JM_test = np.load('./pickles/code_SAC_JM_test.npy')\n",
        "code_SAC_JM_test = normalizer.fit_transform(code_SAC_JM_test)\n",
        "\n",
        "UC_SAC_DP_test = np.load('./pickles/UC_SAC_DP_test.npy')\n",
        "UC_SAC_DP_test = normalizer.fit_transform(UC_SAC_DP_test)\n",
        "\n",
        "code_SAC_DP_test = np.load('./pickles/code_SAC_DP_test.npy')\n",
        "code_SAC_DP_test = normalizer.fit_transform(code_SAC_DP_test)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#----------------------WeightedInformationGain Train and Test-----------------#\n",
        "# 6.1) WIG using JensenShannon\n",
        "\n",
        "UC_WIG_score_JensenShannon_train = featureExtraction.WeightedInformationGain(UC_documents_train,code_documents_train,JS_UC_train.T,tf_code_dict_train,np.sum(list(tf_code_dict_train.values())))\n",
        "code_WIG_score_JensenShannon_train = featureExtraction.WeightedInformationGain(code_documents_train,UC_documents_train,JS_CC_train,tf_uc_dict_train,np.sum(list(tf_uc_dict_train.values())))\n",
        "\n",
        "np.save('./pickles/UC_WIG_score_JensenShannon_train.npy',UC_WIG_score_JensenShannon_train)\n",
        "np.save('./pickles/code_WIG_score_JensenShannon_train.npy',code_WIG_score_JensenShannon_train)\n",
        "\n",
        "UC_WIG_score_JensenShannon_test = featureExtraction.WeightedInformationGain(UC_documents_test,code_documents_test,JS_UC_test.T,tf_code_dict_test,np.sum(list(tf_code_dict_test.values())))\n",
        "code_WIG_score_JensenShannon_test = featureExtraction.WeightedInformationGain(code_documents_test,UC_documents_test,JS_CC_test,tf_uc_dict_test,np.sum(list(tf_uc_dict_test.values())))\n",
        "\n",
        "np.save('./pickles/UC_WIG_score_JensenShannon_test.npy',UC_WIG_score_JensenShannon_test)\n",
        "np.save('./pickles/code_WIG_score_JensenShannon_test.npy',code_WIG_score_JensenShannon_test)\n",
        "\n",
        "# 6.2) WIG Score using VSM\n",
        "\n",
        "UC_WIG_score_VSM_train = featureExtraction.WeightedInformationGain(UC_documents_train,code_documents_train,cosine_similarity_UC_train.T,tf_code_dict_train,np.sum(list(tf_code_dict_train.values())))\n",
        "code_WIG_score_VSM_train = featureExtraction.WeightedInformationGain(code_documents_train,UC_documents_train,cosine_similarity_CC_train,tf_uc_dict_train,np.sum(list(tf_uc_dict_train.values())))\n",
        "\n",
        "np.save('./pickles/UC_WIG_score_VSM_train.npy',UC_WIG_score_VSM_train)\n",
        "np.save('./pickles/code_WIG_score_VSM_train.npy',code_WIG_score_VSM_train)\n",
        "\n",
        "UC_WIG_score_VSM_test = featureExtraction.WeightedInformationGain(UC_documents_test,code_documents_test,cosine_similarity_UC_test.T,tf_code_dict_test,np.sum(list(tf_code_dict_test.values())))\n",
        "code_WIG_score_VSM_test = featureExtraction.WeightedInformationGain(code_documents_test,UC_documents_test,cosine_similarity_CC_test,tf_uc_dict_test,np.sum(list(tf_uc_dict_test.values())))\n",
        "\n",
        "np.save('./pickles/UC_WIG_score_VSM_test.npy',UC_WIG_score_VSM_test)\n",
        "np.save('./pickles/code_WIG_score_VSM_test.npy',code_WIG_score_VSM_test)\n",
        "\n",
        "#6.3) WIG Score using BM25\n",
        "\n",
        "UC_WIG_score_BM25_train = featureExtraction.WeightedInformationGain(UC_documents_train,code_documents_train,BM25_UC_train,tf_code_dict_train,np.sum(list(tf_code_dict_train.values())))\n",
        "code_WIG_score_BM25_train = featureExtraction.WeightedInformationGain(code_documents_train,UC_documents_train,BM25_CC_train,tf_uc_dict_train,np.sum(list(tf_uc_dict_train.values())))\n",
        "\n",
        "np.save('./pickles/UC_WIG_score_BM25_train.npy',UC_WIG_score_BM25_train)\n",
        "np.save('./pickles/code_WIG_score_BM25_train.npy',code_WIG_score_BM25_train)\n",
        "\n",
        "\n",
        "UC_WIG_score_BM25_test = featureExtraction.WeightedInformationGain(UC_documents_test,code_documents_test,BM25_UC_test,tf_code_dict_test,np.sum(list(tf_code_dict_test.values())))\n",
        "code_WIG_score_BM25_test = featureExtraction.WeightedInformationGain(code_documents_test,UC_documents_test,BM25_CC_test,tf_uc_dict_test,np.sum(list(tf_uc_dict_test.values())))\n",
        "\n",
        "np.save('./pickles/UC_WIG_score_BM25_test.npy',UC_WIG_score_BM25_test)\n",
        "np.save('./pickles/code_WIG_score_BM25_test.npy',code_WIG_score_BM25_test)\n",
        "\n",
        "#6.4) WIG Score using JM\n",
        "\n",
        "UC_WIG_score_JM_train = featureExtraction.WeightedInformationGain(UC_documents_train,code_documents_train,JM_UC_train,tf_code_dict_train,np.sum(list(tf_code_dict_train.values())))\n",
        "code_WIG_score_JM_train = featureExtraction.WeightedInformationGain(code_documents_train,UC_documents_train,JM_CC_train,tf_uc_dict_train,np.sum(list(tf_uc_dict_train.values())))\n",
        "\n",
        "np.save('./pickles/UC_WIG_score_JM_train.npy',UC_WIG_score_JM_train)\n",
        "np.save('./pickles/code_WIG_score_JM_train.npy',code_WIG_score_JM_train)\n",
        "\n",
        "UC_WIG_score_JM_test = featureExtraction.WeightedInformationGain(UC_documents_test,code_documents_test,JM_UC_test,tf_code_dict_test,np.sum(list(tf_code_dict_test.values())))\n",
        "code_WIG_score_JM_test = featureExtraction.WeightedInformationGain(code_documents_test,UC_documents_test,JM_CC_test,tf_uc_dict_test,np.sum(list(tf_uc_dict_test.values())))\n",
        "\n",
        "np.save('./pickles/UC_WIG_score_JM_test.npy',UC_WIG_score_JM_test)\n",
        "np.save('./pickles/code_WIG_score_JM_test.npy',code_WIG_score_JM_test)\n",
        "\n",
        "#6.5) WIG Score using DP\n",
        "\n",
        "UC_WIG_score_DP_train = featureExtraction.WeightedInformationGain(UC_documents_train,code_documents_train,DP_UC_train,tf_code_dict_train,np.sum(list(tf_code_dict_train.values())))\n",
        "code_WIG_score_DP_train = featureExtraction.WeightedInformationGain(code_documents_train,UC_documents_train,DP_CC_train,tf_uc_dict_train,np.sum(list(tf_uc_dict_train.values())))\n",
        "\n",
        "np.save('./pickles/UC_WIG_score_DP_train.npy',UC_WIG_score_DP_train)\n",
        "np.save('./pickles/code_WIG_score_DP_train.npy',code_WIG_score_DP_train)\n",
        "\n",
        "UC_WIG_score_DP_test = featureExtraction.WeightedInformationGain(UC_documents_test,code_documents_test,DP_UC_test,tf_code_dict_test,np.sum(list(tf_code_dict_test.values())))\n",
        "code_WIG_score_DP_test = featureExtraction.WeightedInformationGain(code_documents_test,UC_documents_test,DP_CC_test,tf_uc_dict_test,np.sum(list(tf_uc_dict_test.values())))\n",
        "\n",
        "np.save('./pickles/UC_WIG_score_DP_test.npy',UC_WIG_score_DP_test)\n",
        "np.save('./pickles/code_WIG_score_DP_test.npy',code_WIG_score_DP_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "UC_WIG_score_JensenShannon_train = np.load('./pickles/UC_WIG_score_JensenShannon_train.npy')\n",
        "UC_WIG_score_JensenShannon_train = normalizer.fit_transform(UC_WIG_score_JensenShannon_train)\n",
        "\n",
        "code_WIG_score_JensenShannon_train = np.load('./pickles/code_WIG_score_JensenShannon_train.npy') #ALERT : el majority rakam whed\n",
        "code_WIG_score_JensenShannon_train = normalizer.fit_transform(code_WIG_score_JensenShannon_train)\n",
        "\n",
        "UC_WIG_score_JensenShannon_test = np.load('./pickles/UC_WIG_score_JensenShannon_test.npy')\n",
        "UC_WIG_score_JensenShannon_test = normalizer.fit_transform(UC_WIG_score_JensenShannon_test)\n",
        "\n",
        "code_WIG_score_JensenShannon_test = np.load('./pickles/code_WIG_score_JensenShannon_test.npy') #ALERT : el majority rakam whed\n",
        "code_WIG_score_JensenShannon_test = normalizer.fit_transform(code_WIG_score_JensenShannon_test)\n",
        "\n",
        "UC_WIG_score_VSM_train = np.load('./pickles/UC_WIG_score_VSM_train.npy')\n",
        "UC_WIG_score_VSM_train = normalizer.fit_transform(UC_WIG_score_VSM_train)\n",
        "\n",
        "code_WIG_score_VSM_train = np.load('./pickles/code_WIG_score_VSM_train.npy')\n",
        "code_WIG_score_VSM_train = normalizer.fit_transform(code_WIG_score_VSM_train)  # ALERT : zeros kytyera awy\n",
        "\n",
        "UC_WIG_score_VSM_test = np.load('./pickles/UC_WIG_score_VSM_test.npy')\n",
        "UC_WIG_score_VSM_test = normalizer.fit_transform(UC_WIG_score_VSM_test)\n",
        "\n",
        "code_WIG_score_VSM_test = np.load('./pickles/code_WIG_score_VSM_test.npy')\n",
        "code_WIG_score_VSM_test = normalizer.fit_transform(code_WIG_score_VSM_test) # ALERT : zeros kytyera awy\n",
        "\n",
        "UC_WIG_score_BM25_train = np.load('./pickles/UC_WIG_score_BM25_train.npy')\n",
        "UC_WIG_score_BM25_train = normalizer.fit_transform(UC_WIG_score_BM25_train)\n",
        "\n",
        "code_WIG_score_BM25_train = np.load('./pickles/code_WIG_score_BM25_train.npy')\n",
        "code_WIG_score_BM25_train = normalizer.fit_transform(code_WIG_score_BM25_train) # ALERT : zeros kytyera awy\n",
        " \n",
        "UC_WIG_score_BM25_test = np.load('./pickles/UC_WIG_score_BM25_test.npy')\n",
        "UC_WIG_score_BM25_test = normalizer.fit_transform(UC_WIG_score_BM25_test)\n",
        "\n",
        "code_WIG_score_BM25_test = np.load('./pickles/code_WIG_score_BM25_test.npy')\n",
        "code_WIG_score_BM25_test = normalizer.fit_transform(code_WIG_score_BM25_test)#ALERT : el majority rakam whed\n",
        "\n",
        "UC_WIG_score_JM_train = np.load('./pickles/UC_WIG_score_JM_train.npy')\n",
        "UC_WIG_score_JM_train = normalizer.fit_transform(UC_WIG_score_JM_train)\n",
        "\n",
        "code_WIG_score_JM_train = np.load('./pickles/code_WIG_score_JM_train.npy')\n",
        "code_WIG_score_JM_train = normalizer.fit_transform(code_WIG_score_JM_train) # ALERT : zeros kytyera awy\n",
        "\n",
        "UC_WIG_score_JM_test = np.load('./pickles/UC_WIG_score_JM_test.npy')\n",
        "UC_WIG_score_JM_test = normalizer.fit_transform(UC_WIG_score_JM_test)\n",
        "\n",
        "code_WIG_score_JM_test = np.load('./pickles/code_WIG_score_JM_test.npy')\n",
        "code_WIG_score_JM_test = normalizer.fit_transform(code_WIG_score_JM_test) # ALERT : zeros kytyera awy\n",
        "\n",
        "UC_WIG_score_DP_train = np.load('./pickles/UC_WIG_score_DP_train.npy')\n",
        "UC_WIG_score_DP_train = normalizer.fit_transform(UC_WIG_score_DP_train)\n",
        "\n",
        "code_WIG_score_DP_train = np.load('./pickles/code_WIG_score_DP_train.npy')#ALERT : el majority rakam whed\n",
        "code_WIG_score_DP_train = normalizer.fit_transform(code_WIG_score_DP_train)\n",
        "\n",
        "UC_WIG_score_DP_test = np.load('./pickles/UC_WIG_score_DP_test.npy')\n",
        "UC_WIG_score_DP_test = normalizer.fit_transform(UC_WIG_score_DP_test)\n",
        "\n",
        "code_WIG_score_DP_test = np.load('./pickles/code_WIG_score_DP_test.npy')#ALERT : el majority rakam whed\n",
        "code_WIG_score_DP_test = normalizer.fit_transform(code_WIG_score_DP_test)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#--------------------NormalizedQueryCommitment Train and Test -----------#\n",
        "# 7.1) NQC using JensenShannon\n",
        "UC_NQC_JensenShannon_train = featureExtraction.NormalizedQueryCommitment(JS_UC_train.T)\n",
        "code_NQC_JensenShannon_train = featureExtraction.NormalizedQueryCommitment(JS_CC_train)\n",
        "\n",
        "np.save('./pickles/UC_NQC_JensenShannon_train.npy',UC_NQC_JensenShannon_train)\n",
        "np.save('./pickles/code_NQC_JensenShannon_train.npy',code_NQC_JensenShannon_train)\n",
        "\n",
        "UC_NQC_JensenShannon_test = featureExtraction.NormalizedQueryCommitment(JS_UC_test.T)\n",
        "code_NQC_JensenShannon_test = featureExtraction.NormalizedQueryCommitment(JS_CC_test)\n",
        "\n",
        "np.save('./pickles/UC_NQC_JensenShannon_test.npy',UC_NQC_JensenShannon_test)\n",
        "np.save('./pickles/code_NQC_JensenShannon_test.npy',code_NQC_JensenShannon_test)\n",
        "\n",
        "# 7.2) NQC using VSM\n",
        "UC_NQC_VSM_train = featureExtraction.NormalizedQueryCommitment(cosine_similarity_UC_train.T)\n",
        "code_NQC_VSM_train = featureExtraction.NormalizedQueryCommitment(cosine_similarity_CC_train)\n",
        "\n",
        "np.save('./pickles/UC_NQC_VSM_train.npy',UC_NQC_VSM_train)\n",
        "np.save('./pickles/code_NQC_VSM_train.npy',code_NQC_VSM_train)\n",
        "\n",
        "UC_NQC_VSM_test = featureExtraction.NormalizedQueryCommitment(cosine_similarity_UC_test.T)\n",
        "code_NQC_VSM_test = featureExtraction.NormalizedQueryCommitment(cosine_similarity_CC_test)\n",
        "\n",
        "np.save('./pickles/UC_NQC_VSM_test.npy',UC_NQC_VSM_test)\n",
        "np.save('./pickles/code_NQC_VSM_test.npy',code_NQC_VSM_test)\n",
        "\n",
        "# 7.3) NQC using BM25\n",
        "UC_NQC_BM25_train = featureExtraction.NormalizedQueryCommitment(BM25_UC_train)\n",
        "code_NQC_BM25_train = featureExtraction.NormalizedQueryCommitment(BM25_CC_train)\n",
        "\n",
        "np.save('./pickles/UC_NQC_BM25_train.npy',UC_NQC_BM25_train)\n",
        "np.save('./pickles/code_NQC_BM25_train.npy',code_NQC_BM25_train)\n",
        "\n",
        "UC_NQC_BM25_test = featureExtraction.NormalizedQueryCommitment(BM25_UC_test)\n",
        "code_NQC_BM25_test = featureExtraction.NormalizedQueryCommitment(BM25_CC_test)\n",
        "\n",
        "np.save('./pickles/UC_NQC_BM25_test.npy',UC_NQC_BM25_test)\n",
        "np.save('./pickles/code_NQC_BM25_test.npy',code_NQC_BM25_test)\n",
        "\n",
        "# 7.4) NQC using JM\n",
        "UC_NQC_JM_train = featureExtraction.NormalizedQueryCommitment(JM_UC_train)\n",
        "code_NQC_JM_train = featureExtraction.NormalizedQueryCommitment(JM_CC_train)\n",
        "\n",
        "np.save('./pickles/UC_NQC_JM_train.npy',UC_NQC_JM_train)\n",
        "np.save('./pickles/code_NQC_JM_train.npy',code_NQC_JM_train)\n",
        "\n",
        "UC_NQC_JM_test = featureExtraction.NormalizedQueryCommitment(JM_UC_test)\n",
        "code_NQC_JM_test = featureExtraction.NormalizedQueryCommitment(JM_CC_test)\n",
        "\n",
        "np.save('./pickles/UC_NQC_JM_test.npy',UC_NQC_JM_test)\n",
        "np.save('./pickles/code_NQC_JM_test.npy',code_NQC_JM_test)\n",
        "\n",
        "# 7.5) NQC using DP\n",
        "UC_NQC_DP_train = featureExtraction.NormalizedQueryCommitment(DP_UC_train)\n",
        "code_NQC_DP_train = featureExtraction.NormalizedQueryCommitment(DP_CC_train)\n",
        "\n",
        "np.save('./pickles/UC_NQC_DP_train.npy',UC_NQC_DP_train)\n",
        "np.save('./pickles/code_NQC_DP_train.npy',code_NQC_DP_train)\n",
        "\n",
        "UC_NQC_DP_test = featureExtraction.NormalizedQueryCommitment(DP_UC_test)\n",
        "code_NQC_DP_test = featureExtraction.NormalizedQueryCommitment(DP_CC_test)\n",
        "\n",
        "np.save('./pickles/UC_NQC_DP_test.npy',UC_NQC_DP_test)\n",
        "np.save('./pickles/code_NQC_DP_test.npy',code_NQC_DP_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "UC_NQC_JensenShannon_train = np.load('./pickles/UC_NQC_JensenShannon_train.npy')\n",
        "UC_NQC_JensenShannon_train = normalizer.fit_transform(UC_NQC_JensenShannon_train)\n",
        "\n",
        "code_NQC_JensenShannon_train = np.load('./pickles/code_NQC_JensenShannon_train.npy')\n",
        "code_NQC_JensenShannon_train = normalizer.fit_transform(code_NQC_JensenShannon_train)\n",
        "\n",
        "UC_NQC_JensenShannon_test = np.load('./pickles/UC_NQC_JensenShannon_test.npy')\n",
        "UC_NQC_JensenShannon_test = normalizer.fit_transform(UC_NQC_JensenShannon_test)\n",
        "\n",
        "code_NQC_JensenShannon_test = np.load('./pickles/code_NQC_JensenShannon_test.npy')\n",
        "code_NQC_JensenShannon_test = normalizer.fit_transform(code_NQC_JensenShannon_test)\n",
        "\n",
        "UC_NQC_VSM_train = np.load('./pickles/UC_NQC_VSM_train.npy')\n",
        "UC_NQC_VSM_train = normalizer.fit_transform(UC_NQC_VSM_train)\n",
        "\n",
        "code_NQC_VSM_train = np.load('./pickles/code_NQC_VSM_train.npy')\n",
        "code_NQC_VSM_train = normalizer.fit_transform(code_NQC_VSM_train)\n",
        "\n",
        "UC_NQC_VSM_test = np.load('./pickles/UC_NQC_VSM_test.npy')\n",
        "UC_NQC_VSM_test = normalizer.fit_transform(UC_NQC_VSM_test)\n",
        "\n",
        "code_NQC_VSM_test = np.load('./pickles/code_NQC_VSM_test.npy')\n",
        "code_NQC_VSM_test = normalizer.fit_transform(code_NQC_VSM_test)\n",
        "\n",
        "UC_NQC_BM25_train = np.load('./pickles/UC_NQC_BM25_train.npy')\n",
        "UC_NQC_BM25_train = normalizer.fit_transform(UC_NQC_BM25_train)\n",
        "\n",
        "code_NQC_BM25_train = np.load('./pickles/code_NQC_BM25_train.npy')\n",
        "code_NQC_BM25_train = normalizer.fit_transform(code_NQC_BM25_train)\n",
        "\n",
        "UC_NQC_BM25_test = np.load('./pickles/UC_NQC_BM25_test.npy')\n",
        "UC_NQC_BM25_test = normalizer.fit_transform(UC_NQC_BM25_test)\n",
        "\n",
        "code_NQC_BM25_test = np.load('./pickles/code_NQC_BM25_test.npy')\n",
        "code_NQC_BM25_test = normalizer.fit_transform(code_NQC_BM25_test)\n",
        "\n",
        "UC_NQC_JM_train = np.load('./pickles/UC_NQC_JM_train.npy')\n",
        "UC_NQC_JM_train = normalizer.fit_transform(UC_NQC_JM_train)\n",
        "\n",
        "code_NQC_JM_train = np.load('./pickles/code_NQC_JM_train.npy')\n",
        "code_NQC_JM_train = normalizer.fit_transform(code_NQC_JM_train)\n",
        "\n",
        "UC_NQC_JM_test = np.load('./pickles/UC_NQC_JM_test.npy')\n",
        "UC_NQC_JM_test = normalizer.fit_transform(UC_NQC_JM_test)\n",
        "\n",
        "code_NQC_JM_test = np.load('./pickles/code_NQC_JM_test.npy')\n",
        "code_NQC_JM_test = normalizer.fit_transform(code_NQC_JM_test)\n",
        "\n",
        "UC_NQC_DP_train = np.load('./pickles/UC_NQC_DP_train.npy')\n",
        "UC_NQC_DP_train = normalizer.fit_transform(UC_NQC_DP_train)\n",
        "\n",
        "code_NQC_DP_train = np.load('./pickles/code_NQC_DP_train.npy')\n",
        "code_NQC_DP_train = normalizer.fit_transform(code_NQC_DP_train)\n",
        "\n",
        "UC_NQC_DP_test = np.load('./pickles/UC_NQC_DP_test.npy')\n",
        "UC_NQC_DP_test = normalizer.fit_transform(UC_NQC_DP_test)\n",
        "\n",
        "code_NQC_DP_test = np.load('./pickles/code_NQC_DP_test.npy')\n",
        "code_NQC_DP_test = normalizer.fit_transform(code_NQC_DP_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Document Statistics Features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from FeatureExtraction import *\n",
        "featureExtraction = FeatureExtraction(Vocab_UC_train)\n",
        "num_terms_code_train, num_terms_UC_train, num_unique_terms_code_train, num_unique_terms_UC_train, num_overlapping_terms_train = featureExtraction.DocumentStatistics(UC_documents_train, code_documents_train)\n",
        "#18min"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "featureExtraction = FeatureExtraction(Vocab_UC_train)\n",
        "num_terms_code_test, num_terms_UC_test, num_unique_terms_code_test, num_unique_terms_UC_test, num_overlapping_terms_test = featureExtraction.DocumentStatistics(UC_documents_test, code_documents_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "np.save('./pickles/num_terms_code_train.npy',num_terms_code_train)\n",
        "np.save('./pickles/num_terms_UC_train.npy',num_terms_UC_train)\n",
        "np.save('./pickles/num_unique_terms_code_train.npy',num_unique_terms_code_train)\n",
        "np.save('./pickles/num_unique_terms_UC_train.npy',num_unique_terms_UC_train)\n",
        "np.save('./pickles/num_overlapping_terms_train.npy',num_overlapping_terms_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "np.save('./pickles/num_terms_code_test.npy',num_terms_code_test)\n",
        "np.save('./pickles/num_terms_UC_test.npy',num_terms_UC_test)\n",
        "np.save('./pickles/num_unique_terms_code_test.npy',num_unique_terms_code_test)\n",
        "np.save('./pickles/num_unique_terms_UC_test.npy',num_unique_terms_UC_test)\n",
        "np.save('./pickles/num_overlapping_terms_test.npy',num_overlapping_terms_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "num_terms_code_train = np.load('./pickles/num_terms_code_train.npy')\n",
        "num_terms_UC_train = np.load('./pickles/num_terms_UC_train.npy')\n",
        "num_unique_terms_code_train = np.load('./pickles/num_unique_terms_code_train.npy')\n",
        "num_unique_terms_UC_train =np.load('./pickles/num_unique_terms_UC_train.npy')\n",
        "num_overlapping_terms_train = np.load('./pickles/num_overlapping_terms_train.npy')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "num_terms_code_test = np.load('./pickles/num_terms_code_test.npy')\n",
        "num_terms_UC_test= np.load('./pickles/num_terms_UC_test.npy')\n",
        "num_unique_terms_code_test = np.load('./pickles/num_unique_terms_code_test.npy')\n",
        "num_unique_terms_UC_test =np.load('./pickles/num_unique_terms_UC_test.npy')\n",
        "num_overlapping_terms_test = np.load('./pickles/num_overlapping_terms_test.npy')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Tiling and stacking the 126 feature"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "avg_idf_uc_train = np.array(avg_idf_uc_train)\n",
        "avg_idf_code_train = np.array(avg_idf_code_train)\n",
        "max_idf_uc_train = np.array(max_idf_uc_train)\n",
        "max_idf_code_train = np.array(max_idf_code_train)\n",
        "dev_idf_uc_train = np.array(dev_idf_uc_train)\n",
        "dev_idf_code_train = np.array(dev_idf_code_train)\n",
        "avg_ictf_uc_train = np.array(avg_ictf_uc_train)\n",
        "avg_ictf_code_train = np.array(avg_ictf_code_train)\n",
        "max_ictf_uc_train = np.array(max_ictf_uc_train)\n",
        "max_ictf_code_train = np.array(max_ictf_code_train)\n",
        "dev_ictf_uc_train = np.array(dev_ictf_uc_train)\n",
        "dev_ictf_code_train = np.array(dev_ictf_code_train)\n",
        "avg_entropy_uc_train = np.array(avg_entropy_uc_train)\n",
        "avg_entropy_code_train = np.array(avg_entropy_code_train)\n",
        "max_entropy_uc_train = np.array(max_entropy_uc_train)\n",
        "max_entropy_code_train = np.array(max_entropy_code_train)\n",
        "med_entropy_uc_train = np.array(med_entropy_uc_train)\n",
        "med_entropy_code_train = np.array(med_entropy_code_train)\n",
        "dev_entropy_uc_train = np.array(dev_entropy_uc_train)\n",
        "dev_entropy_code_train = np.array(dev_entropy_code_train)\n",
        "avg_variance_uc_train = np.array(avg_variance_uc_train)\n",
        "avg_variance_code_train = np.array(avg_variance_code_train)\n",
        "max_variance_uc_train = np.array(max_variance_uc_train)\n",
        "max_variance_code_train = np.array(max_variance_code_train)\n",
        "sum_variance_uc_train = np.array(sum_variance_uc_train)\n",
        "sum_variance_code_train = np.array(sum_variance_code_train)\n",
        "avg_scq_uc_train = np.array(avg_scq_uc_train)\n",
        "avg_scq_code_train = np.array(avg_scq_code_train)\n",
        "max_scq_uc_train = np.array(max_scq_uc_train)\n",
        "max_scq_code_train = np.array(max_scq_code_train)\n",
        "sum_sqc_uc_train = np.array(sum_sqc_uc_train)\n",
        "sum_sqc_code_train = np.array(sum_sqc_code_train)\n",
        "avg_pmi_uc_train = np.array(avg_pmi_uc_train)\n",
        "avg_pmi_code_train = np.array(avg_pmi_code_train)\n",
        "max_pmi_uc_train = np.array(max_pmi_uc_train)\n",
        "max_pmi_code_train = np.array(max_pmi_code_train)\n",
        "qs_uc_train = np.array(qs_uc_train)\n",
        "qs_code_train = np.array(qs_code_train)\n",
        "UC_SCS_train = np.array(UC_SCS_train)\n",
        "CC_SCS_train = np.array(CC_SCS_train)\n",
        "UC_CoherenceScore_train = np.array(UC_CoherenceScore_train)\n",
        "CC_CoherenceScore_train = np.array(CC_CoherenceScore_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "avg_idf_uc_train_reshaped = np.tile(avg_idf_uc_train, (1, avg_idf_code_train.shape[0]))\n",
        "avg_idf_code_train_reshaped = np.tile(avg_idf_code_train, (1, avg_idf_uc_train.shape[0]))\n",
        "\n",
        "max_idf_uc_train_reshaped = np.tile(max_idf_uc_train, (1, max_idf_code_train.shape[0]))\n",
        "max_idf_code_train_reshaped = np.tile(max_idf_code_train, (1, max_idf_uc_train.shape[0]))\n",
        "\n",
        "dev_idf_uc_train_reshaped = np.tile(dev_idf_uc_train, (1, dev_idf_code_train.shape[0]))\n",
        "dev_idf_code_train_reshaped = np.tile(dev_idf_code_train, (1, dev_idf_uc_train.shape[0]))\n",
        "\n",
        "avg_ictf_uc_train_reshaped = np.tile(avg_ictf_uc_train, (1, avg_ictf_code_train.shape[0]))\n",
        "avg_ictf_code_train_reshaped = np.tile(avg_ictf_code_train, (1, avg_ictf_uc_train.shape[0]))\n",
        "\n",
        "max_ictf_uc_train_reshaped = np.tile(max_ictf_uc_train, (1, max_ictf_code_train.shape[0]))\n",
        "max_ictf_code_train_reshaped = np.tile(max_ictf_code_train, (1, max_ictf_uc_train.shape[0]))\n",
        "\n",
        "dev_ictf_uc_train_reshaped = np.tile(dev_ictf_uc_train, (1, dev_ictf_code_train.shape[0]))\n",
        "dev_ictf_code_train_reshaped = np.tile(dev_ictf_code_train, (1, dev_ictf_uc_train.shape[0]))\n",
        "\n",
        "avg_entropy_uc_train_reshaped = np.tile(avg_entropy_uc_train, (1, avg_entropy_code_train.shape[0]))\n",
        "avg_entropy_code_train_reshaped = np.tile(avg_entropy_code_train, (1, avg_entropy_uc_train.shape[0]))\n",
        "\n",
        "max_entropy_uc_train_reshaped = np.tile(max_entropy_uc_train, (1, max_entropy_code_train.shape[0]))\n",
        "max_entropy_code_train_reshaped = np.tile(max_entropy_code_train, (1, max_entropy_uc_train.shape[0]))\n",
        "\n",
        "med_entropy_uc_train_reshaped = np.tile(med_entropy_uc_train, (1, med_entropy_code_train.shape[0]))\n",
        "med_entropy_code_train_reshaped = np.tile(med_entropy_code_train, (1, med_entropy_uc_train.shape[0]))\n",
        "\n",
        "dev_entropy_uc_train_reshaped = np.tile(dev_entropy_uc_train, (1, dev_entropy_code_train.shape[0]))\n",
        "dev_entropy_code_train_reshaped = np.tile(dev_entropy_code_train, (1, dev_entropy_uc_train.shape[0]))\n",
        "\n",
        "avg_variance_uc_train_reshaped = np.tile(avg_variance_uc_train, (1, avg_variance_code_train.shape[0]))\n",
        "avg_variance_code_train_reshaped = np.tile(avg_variance_code_train, (1, avg_variance_uc_train.shape[0]))\n",
        "\n",
        "max_variance_uc_train_reshaped = np.tile(max_variance_uc_train, (1, max_variance_code_train.shape[0]))\n",
        "max_variance_code_train_reshaped = np.tile(max_variance_code_train, (1, max_variance_uc_train.shape[0]))\n",
        "\n",
        "sum_variance_uc_train_reshaped = np.tile(sum_variance_uc_train, (1, sum_variance_code_train.shape[0]))\n",
        "sum_variance_code_train_reshaped = np.tile(sum_variance_code_train, (1, sum_variance_uc_train.shape[0]))\n",
        "\n",
        "avg_scq_uc_train_reshaped = np.tile(avg_scq_uc_train, (1, avg_scq_code_train.shape[0]))\n",
        "avg_scq_code_train_reshaped = np.tile(avg_scq_code_train, (1, avg_scq_uc_train.shape[0]))\n",
        "\n",
        "max_scq_uc_train_reshaped = np.tile(max_scq_uc_train, (1, max_scq_code_train.shape[0]))\n",
        "max_scq_code_train_reshaped = np.tile(max_scq_code_train, (1, max_scq_uc_train.shape[0]))\n",
        "\n",
        "sum_sqc_uc_train_reshaped = np.tile(sum_sqc_uc_train, (1, sum_sqc_code_train.shape[0]))\n",
        "sum_sqc_code_train_reshaped = np.tile(sum_sqc_code_train, (1, sum_sqc_uc_train.shape[0]))\n",
        "\n",
        "avg_pmi_uc_train_reshaped = np.tile(avg_pmi_uc_train, (1, avg_pmi_code_train.shape[0]))\n",
        "avg_pmi_code_train_reshaped = np.tile(avg_pmi_code_train, (1, avg_pmi_uc_train.shape[0]))\n",
        "\n",
        "max_pmi_uc_train_reshaped = np.tile(max_pmi_uc_train, (1, max_pmi_code_train.shape[0]))\n",
        "max_pmi_code_train_reshaped = np.tile(max_pmi_code_train, (1, max_pmi_uc_train.shape[0]))\n",
        "\n",
        "qs_uc_train_reshaped = np.tile(qs_uc_train, (1, qs_code_train.shape[0]))\n",
        "qs_code_train_reshaped = np.tile(qs_code_train, (1, qs_uc_train.shape[0]))\n",
        "\n",
        "UC_SCS_train_reshaped = np.tile(UC_SCS_train, (1, CC_SCS_train.shape[0]))\n",
        "CC_SCS_train_reshaped = np.tile(CC_SCS_train, (1, UC_SCS_train.shape[0]))\n",
        "\n",
        "UC_CoherenceScore_train_reshaped = np.tile(UC_CoherenceScore_train, (1, CC_CoherenceScore_train.shape[0]))\n",
        "CC_CoherenceScore_train_reshaped = np.tile(CC_CoherenceScore_train, (1, UC_CoherenceScore_train.shape[0]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "UC_RS_JS_train_reshaped = np.tile(UC_RS_JS_train, (1, code_RS_JS_train.shape[0]))\n",
        "code_RS_JS_train_reshaped = np.tile(code_RS_JS_train, (1, UC_RS_JS_train.shape[0]))\n",
        "\n",
        "UC_FRC_JS_train_reshaped = np.tile(UC_FRC_JS_train, (1, code_FRC_JS_train.shape[0]))\n",
        "code_FRC_JS_train_reshaped = np.tile(code_FRC_JS_train, (1, UC_FRC_JS_train.shape[0]))\n",
        "\n",
        "UC_RS_VSM_train_reshaped = np.tile(UC_RS_VSM_train, (1, code_RS_VSM_train.shape[0]))\n",
        "code_RS_VSM_train_reshaped = np.tile(code_RS_VSM_train, (1, UC_RS_VSM_train.shape[0]))\n",
        "\n",
        "UC_FRC_VSM_train_reshaped = np.tile(UC_FRC_VSM_train, (1, code_FRC_VSM_train.shape[0]))\n",
        "code_FRC_VSM_train_reshaped = np.tile(code_FRC_VSM_train, (1, UC_FRC_VSM_train.shape[0]))\n",
        "\n",
        "UC_RS_BM25_train_reshaped = np.tile(UC_RS_BM25_train, (1, code_RS_BM25_train.shape[0]))\n",
        "code_RS_BM25_train_reshaped = np.tile(code_RS_BM25_train, (1, UC_RS_BM25_train.shape[0]))\n",
        "\n",
        "UC_FRC_BM25_train_reshaped = np.tile(UC_FRC_BM25_train, (1, code_FRC_BM25_train.shape[0]))\n",
        "code_FRC_BM25_train_reshaped = np.tile(code_FRC_BM25_train, (1, UC_FRC_BM25_train.shape[0]))\n",
        "\n",
        "UC_RS_JM_train_reshaped = np.tile(UC_RS_JM_train, (1, code_RS_JM_train.shape[0]))\n",
        "code_RS_JM_train_reshaped = np.tile(code_RS_JM_train, (1, UC_RS_JM_train.shape[0]))\n",
        "\n",
        "UC_FRC_JM_train_reshaped = np.tile(UC_FRC_JM_train, (1, code_FRC_JM_train.shape[0]))\n",
        "code_FRC_JM_train_reshaped = np.tile(code_FRC_JM_train, (1, UC_FRC_JM_train.shape[0]))\n",
        "\n",
        "UC_RS_DP_train_reshaped = np.tile(UC_RS_DP_train, (1, code_RS_DP_train.shape[0]))\n",
        "code_RS_DP_train_reshaped = np.tile(code_RS_DP_train, (1, UC_RS_DP_train.shape[0]))\n",
        "\n",
        "UC_FRC_DP_train_reshaped = np.tile(UC_FRC_DP_train, (1, code_FRC_DP_train.shape[0]))\n",
        "code_FRC_DP_train_reshaped = np.tile(code_FRC_DP_train, (1, UC_FRC_DP_train.shape[0]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "UC_CT_JensenShannon_train_reshaped = np.tile(UC_CT_JensenShannon_train, (1, code_CT_JensenShannon_train.shape[0]))\n",
        "code_CT_JensenShannon_train_reshaped = np.tile(code_CT_JensenShannon_train, (1, UC_CT_JensenShannon_train.shape[0]))\n",
        "\n",
        "UC_CT_VSM_train_reshaped = np.tile(UC_CT_VSM_train, (1, code_CT_VSM_train.shape[0]))\n",
        "code_CT_VSM_train_reshaped = np.tile(code_CT_VSM_train, (1, UC_CT_VSM_train.shape[0]))\n",
        "\n",
        "UC_CT_BM25_train_reshaped = np.tile(UC_CT_BM25_train, (1, code_CT_BM25_train.shape[0]))\n",
        "code_CT_BM25_train_reshaped = np.tile(code_CT_BM25_train, (1, UC_CT_BM25_train.shape[0]))\n",
        "\n",
        "UC_CT_JM_train_reshaped = np.tile(UC_CT_JM_train, (1, code_CT_JM_train.shape[0]))\n",
        "code_CT_JM_train_reshaped = np.tile(code_CT_JM_train, (1, UC_CT_JM_train.shape[0]))\n",
        "\n",
        "UC_CT_DP_train_reshaped = np.tile(UC_CT_DP_train, (1, code_CT_DP_train.shape[0]))\n",
        "code_CT_DP_train_reshaped = np.tile(code_CT_DP_train, (1, UC_CT_DP_train.shape[0]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "UC_SAC_JS_train_reshaped = np.tile(UC_SAC_JS_train, (1, code_SAC_JS_train.shape[0]))\n",
        "code_SAC_JS_train_reshaped = np.tile(code_SAC_JS_train, (1, UC_SAC_JS_train.shape[0]))\n",
        "\n",
        "UC_SAC_VSM_train_reshaped = np.tile(UC_SAC_VSM_train, (1, code_SAC_VSM_train.shape[0]))\n",
        "code_SAC_VSM_train_reshaped = np.tile(code_SAC_VSM_train, (1, UC_SAC_VSM_train.shape[0]))\n",
        "\n",
        "UC_SAC_BM25_train_reshaped = np.tile(UC_SAC_BM25_train, (1, code_SAC_BM25_train.shape[0]))\n",
        "code_SAC_BM25_train_reshaped = np.tile(code_SAC_BM25_train, (1, UC_SAC_BM25_train.shape[0]))\n",
        "\n",
        "UC_SAC_JM_train_reshaped = np.tile(UC_SAC_JM_train, (1, code_SAC_JM_train.shape[0]))\n",
        "code_SAC_JM_train_reshaped = np.tile(code_SAC_JM_train, (1, UC_SAC_JM_train.shape[0]))\n",
        "\n",
        "UC_SAC_DP_train_reshaped = np.tile(UC_SAC_DP_train, (1, code_SAC_DP_train.shape[0]))\n",
        "code_SAC_DP_train_reshaped = np.tile(code_SAC_DP_train, (1, UC_SAC_DP_train.shape[0]))\n",
        "\n",
        "print(code_SAC_DP_train.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "UC_WIG_score_JensenShannon_train_reshaped = np.tile(UC_WIG_score_JensenShannon_train, (1, code_WIG_score_JensenShannon_train.shape[0]))\n",
        "code_WIG_score_JensenShannon_train_reshaped = np.tile(code_WIG_score_JensenShannon_train, (1, UC_WIG_score_JensenShannon_train.shape[0]))\n",
        "\n",
        "UC_WIG_score_VSM_train_reshaped = np.tile(UC_WIG_score_VSM_train, (1, code_WIG_score_VSM_train.shape[0]))\n",
        "code_WIG_score_VSM_train_reshaped = np.tile(code_WIG_score_VSM_train, (1, UC_WIG_score_VSM_train.shape[0]))\n",
        "\n",
        "UC_WIG_score_BM25_train_reshaped = np.tile(UC_WIG_score_BM25_train, (1, code_WIG_score_BM25_train.shape[0]))\n",
        "code_WIG_score_BM25_train_reshaped = np.tile(code_WIG_score_BM25_train, (1, UC_WIG_score_BM25_train.shape[0]))\n",
        "\n",
        "UC_WIG_score_JM_train_reshaped = np.tile(UC_WIG_score_JM_train, (1, code_WIG_score_JM_train.shape[0]))\n",
        "code_WIG_score_JM_train_reshaped = np.tile(code_WIG_score_JM_train, (1, UC_WIG_score_JM_train.shape[0]))\n",
        "\n",
        "UC_WIG_score_DP_train_reshaped = np.tile(UC_WIG_score_DP_train, (1, code_WIG_score_DP_train.shape[0]))\n",
        "code_WIG_score_DP_train_reshaped = np.tile(code_WIG_score_DP_train, (1, UC_WIG_score_DP_train.shape[0]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "UC_NQC_JensenShannon_train_reshaped = np.tile(UC_NQC_JensenShannon_train, (1, code_NQC_JensenShannon_train.shape[0]))\n",
        "code_NQC_JensenShannon_train_reshaped = np.tile(code_NQC_JensenShannon_train, (1, UC_NQC_JensenShannon_train.shape[0]))\n",
        "\n",
        "\n",
        "UC_NQC_VSM_train_reshaped = np.tile(UC_NQC_VSM_train, (1, code_NQC_VSM_train.shape[0]))\n",
        "code_NQC_VSM_train_reshaped = np.tile(code_NQC_VSM_train, (1, UC_NQC_VSM_train.shape[0]))\n",
        "\n",
        "UC_NQC_BM25_train_reshaped = np.tile(UC_NQC_BM25_train, (1, code_NQC_BM25_train.shape[0]))\n",
        "code_NQC_BM25_train_reshaped = np.tile(code_NQC_BM25_train, (1, UC_NQC_BM25_train.shape[0]))\n",
        "\n",
        "UC_NQC_JM_train_reshaped = np.tile(UC_NQC_JM_train, (1, code_NQC_JM_train.shape[0]))\n",
        "code_NQC_JM_train_reshaped = np.tile(code_NQC_JM_train, (1, UC_NQC_JM_train.shape[0]))\n",
        "\n",
        "UC_NQC_DP_train_reshaped = np.tile(UC_NQC_DP_train, (1, code_NQC_DP_train.shape[0]))\n",
        "code_NQC_DP_train_reshaped = np.tile(code_NQC_DP_train, (1, UC_NQC_DP_train.shape[0]))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "num_terms_code_train_reshaped = np.tile(num_terms_code_train, (num_terms_UC_train.shape[0],1))\n",
        "num_terms_UC_train_reshaped = np.tile(num_terms_UC_train, (num_terms_code_train.shape[0],1))\n",
        "\n",
        "num_unique_terms_UC_train_reshaped = np.tile(num_unique_terms_UC_train, (num_unique_terms_code_train.shape[0],1))\n",
        "num_unique_terms_code_train_reshaped = np.tile(num_unique_terms_code_train, (num_unique_terms_UC_train.shape[0],1))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "feature_matrix_train = np.stack(( cosine_similarity_UC_train, cosine_similarity_CC_train,LSA_similarities_UC_train,LSA_similarities_CC_train,LDA_similarities_UC_train,LDA_similarities_CC_train,JS_UC_train,JS_CC_train,BM25_UC_train.T,BM25_CC_train,JM_UC_train.T,JM_CC_train,DP_UC_train.T,DP_CC_train,\n",
        "                           \n",
        "   avg_idf_uc_train_reshaped,avg_idf_code_train_reshaped.T,max_idf_uc_train_reshaped,max_idf_code_train_reshaped.T,\n",
        "    dev_idf_uc_train_reshaped,dev_idf_code_train_reshaped.T,avg_ictf_uc_train_reshaped,avg_ictf_code_train_reshaped.T,max_ictf_uc_train_reshaped,max_ictf_code_train_reshaped.T,dev_ictf_uc_train_reshaped,dev_ictf_code_train_reshaped.T,avg_entropy_uc_train_reshaped,avg_entropy_code_train_reshaped.T,max_entropy_uc_train_reshaped,max_entropy_code_train_reshaped.T,med_entropy_uc_train_reshaped,med_entropy_code_train_reshaped.T,dev_entropy_uc_train_reshaped,dev_entropy_code_train_reshaped.T,avg_variance_uc_train_reshaped,avg_variance_code_train_reshaped.T,max_variance_uc_train_reshaped,max_variance_code_train_reshaped.T,sum_variance_uc_train_reshaped,sum_variance_code_train_reshaped.T,avg_scq_uc_train_reshaped,avg_scq_code_train_reshaped.T,max_scq_uc_train_reshaped,max_scq_code_train_reshaped.T,sum_sqc_uc_train_reshaped,sum_sqc_code_train_reshaped.T,avg_pmi_uc_train_reshaped,avg_pmi_code_train_reshaped.T,max_pmi_uc_train_reshaped,max_pmi_code_train_reshaped.T,qs_uc_train_reshaped,qs_code_train_reshaped.T,UC_SCS_train_reshaped,CC_SCS_train_reshaped.T,UC_CoherenceScore_train_reshaped,CC_CoherenceScore_train_reshaped.T,\n",
        "\n",
        "    UC_FRC_DP_train_reshaped,code_FRC_DP_train_reshaped.T,UC_FRC_JM_train_reshaped,code_FRC_JM_train_reshaped.T,UC_FRC_BM25_train_reshaped,code_FRC_BM25_train_reshaped.T,UC_FRC_JS_train_reshaped,code_FRC_JS_train_reshaped.T,UC_FRC_VSM_train_reshaped,code_FRC_VSM_train_reshaped.T\n",
        "\n",
        "    ,UC_RS_DP_train_reshaped,code_RS_DP_train_reshaped.T,UC_RS_JM_train_reshaped,code_RS_JM_train_reshaped.T,UC_RS_BM25_train_reshaped,code_RS_BM25_train_reshaped.T,UC_RS_JS_train_reshaped,code_RS_JS_train_reshaped.T,UC_RS_VSM_train_reshaped,code_RS_VSM_train_reshaped.T,\n",
        "\n",
        "    UC_CT_DP_train_reshaped,code_CT_DP_train_reshaped.T,UC_CT_JM_train_reshaped,\n",
        "    code_CT_JM_train_reshaped.T,UC_CT_BM25_train_reshaped,code_CT_BM25_train_reshaped.T,UC_CT_JensenShannon_train_reshaped,code_CT_JensenShannon_train_reshaped.T,UC_CT_VSM_train_reshaped,code_CT_VSM_train_reshaped.T,\n",
        "\n",
        "    UC_SAC_JM_train_reshaped,code_SAC_JM_train_reshaped.T,\n",
        "    UC_SAC_BM25_train_reshaped,code_SAC_BM25_train_reshaped.T,UC_SAC_JS_train_reshaped,code_SAC_JS_train_reshaped.T,\n",
        "    UC_SAC_VSM_train_reshaped,code_SAC_VSM_train_reshaped.T,UC_SAC_DP_train_reshaped,code_SAC_JS_train_reshaped.T,\n",
        "\n",
        "    UC_WIG_score_DP_train_reshaped,code_WIG_score_DP_train_reshaped.T,UC_WIG_score_JM_train_reshaped,\n",
        "    code_WIG_score_JM_train_reshaped.T,UC_WIG_score_BM25_train_reshaped,code_WIG_score_BM25_train_reshaped.T,UC_WIG_score_JensenShannon_train_reshaped,\n",
        "    code_WIG_score_JensenShannon_train_reshaped.T,UC_WIG_score_VSM_train_reshaped,\n",
        "    code_WIG_score_VSM_train_reshaped.T,\n",
        "\n",
        "    UC_NQC_DP_train_reshaped,code_NQC_DP_train_reshaped.T,UC_NQC_JM_train_reshaped,code_NQC_JM_train_reshaped.T,UC_NQC_BM25_train_reshaped,code_NQC_BM25_train_reshaped.T,UC_NQC_VSM_train_reshaped,code_NQC_VSM_train_reshaped.T,UC_NQC_JensenShannon_train_reshaped,code_NQC_JensenShannon_train_reshaped.T,\n",
        "\n",
        "    num_terms_UC_train_reshaped.T,num_terms_code_train_reshaped,num_unique_terms_UC_train_reshaped.T,num_unique_terms_code_train_reshaped,num_overlapping_terms_train),axis=2)\n",
        "\n",
        "print(feature_matrix_train.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "avg_idf_uc_test = np.array(avg_idf_uc_test)\n",
        "avg_idf_code_test = np.array(avg_idf_code_test)\n",
        "max_idf_uc_test = np.array(max_idf_uc_test)\n",
        "max_idf_code_test = np.array(max_idf_code_test)\n",
        "dev_idf_uc_test = np.array(dev_idf_uc_test)\n",
        "dev_idf_code_test = np.array(dev_idf_code_test)\n",
        "avg_ictf_uc_test = np.array(avg_ictf_uc_test)\n",
        "avg_ictf_code_test = np.array(avg_ictf_code_test)\n",
        "max_ictf_uc_test = np.array(max_ictf_uc_test)\n",
        "max_ictf_code_test = np.array(max_ictf_code_test)\n",
        "dev_ictf_uc_test = np.array(dev_ictf_uc_test)\n",
        "dev_ictf_code_test = np.array(dev_ictf_code_test)\n",
        "avg_entropy_uc_test = np.array(avg_entropy_uc_test)\n",
        "avg_entropy_code_test = np.array(avg_entropy_code_test)\n",
        "max_entropy_uc_test = np.array(max_entropy_uc_test)\n",
        "max_entropy_code_test = np.array(max_entropy_code_test)\n",
        "med_entropy_uc_test = np.array(med_entropy_uc_test)\n",
        "med_entropy_code_test = np.array(med_entropy_code_test)\n",
        "dev_entropy_uc_test = np.array(dev_entropy_uc_test)\n",
        "dev_entropy_code_test = np.array(dev_entropy_code_test)\n",
        "avg_variance_uc_test = np.array(avg_variance_uc_test)\n",
        "avg_variance_code_test = np.array(avg_variance_code_test)\n",
        "max_variance_uc_test = np.array(max_variance_uc_test)\n",
        "max_variance_code_test = np.array(max_variance_code_test)\n",
        "sum_variance_uc_test = np.array(sum_variance_uc_test)\n",
        "sum_variance_code_test = np.array(sum_variance_code_test)\n",
        "avg_scq_uc_test = np.array(avg_scq_uc_test)\n",
        "avg_scq_code_test = np.array(avg_scq_code_test)\n",
        "max_scq_uc_test = np.array(max_scq_uc_test)\n",
        "max_scq_code_test = np.array(max_scq_code_test)\n",
        "sum_sqc_uc_test = np.array(sum_sqc_uc_test)\n",
        "sum_sqc_code_test = np.array(sum_sqc_code_test)\n",
        "avg_pmi_uc_test = np.array(avg_pmi_uc_test)\n",
        "avg_pmi_code_test = np.array(avg_pmi_code_test)\n",
        "max_pmi_uc_test = np.array(max_pmi_uc_test)\n",
        "max_pmi_code_test = np.array(max_pmi_code_test)\n",
        "qs_uc_test = np.array(qs_uc_test)\n",
        "qs_code_test = np.array(qs_code_test)\n",
        "UC_SCS_test = np.array(UC_SCS_test)\n",
        "CC_SCS_test = np.array(CC_SCS_test)\n",
        "UC_CoherenceScore_test = np.array(UC_CoherenceScore_test)\n",
        "CC_CoherenceScore_test = np.array(CC_CoherenceScore_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "avg_idf_uc_test_reshaped = np.tile(avg_idf_uc_test, (1, avg_idf_code_test.shape[0]))\n",
        "avg_idf_code_test_reshaped = np.tile(avg_idf_code_test, (1, avg_idf_uc_test.shape[0]))\n",
        "\n",
        "max_idf_uc_test_reshaped = np.tile(max_idf_uc_test, (1, max_idf_code_test.shape[0]))\n",
        "max_idf_code_test_reshaped = np.tile(max_idf_code_test, (1, max_idf_uc_test.shape[0]))\n",
        "\n",
        "dev_idf_uc_test_reshaped = np.tile(dev_idf_uc_test, (1, dev_idf_code_test.shape[0]))\n",
        "dev_idf_code_test_reshaped = np.tile(dev_idf_code_test, (1, dev_idf_uc_test.shape[0]))\n",
        "\n",
        "avg_ictf_uc_test_reshaped = np.tile(avg_ictf_uc_test, (1, avg_ictf_code_test.shape[0]))\n",
        "avg_ictf_code_test_reshaped = np.tile(avg_ictf_code_test, (1, avg_ictf_uc_test.shape[0]))\n",
        "\n",
        "max_ictf_uc_test_reshaped = np.tile(max_ictf_uc_test, (1, max_ictf_code_test.shape[0]))\n",
        "max_ictf_code_test_reshaped = np.tile(max_ictf_code_test, (1, max_ictf_uc_test.shape[0]))\n",
        "\n",
        "dev_ictf_uc_test_reshaped = np.tile(dev_ictf_uc_test, (1, dev_ictf_code_test.shape[0]))\n",
        "dev_ictf_code_test_reshaped = np.tile(dev_ictf_code_test, (1, dev_ictf_uc_test.shape[0]))\n",
        "\n",
        "avg_entropy_uc_test_reshaped = np.tile(avg_entropy_uc_test, (1, avg_entropy_code_test.shape[0]))\n",
        "avg_entropy_code_test_reshaped = np.tile(avg_entropy_code_test, (1, avg_entropy_uc_test.shape[0]))\n",
        "\n",
        "max_entropy_uc_test_reshaped = np.tile(max_entropy_uc_test, (1, max_entropy_code_test.shape[0]))\n",
        "max_entropy_code_test_reshaped = np.tile(max_entropy_code_test, (1, max_entropy_uc_test.shape[0]))\n",
        "\n",
        "med_entropy_uc_test_reshaped = np.tile(med_entropy_uc_test, (1, med_entropy_code_test.shape[0]))\n",
        "med_entropy_code_test_reshaped = np.tile(med_entropy_code_test, (1, med_entropy_uc_test.shape[0]))\n",
        "\n",
        "dev_entropy_uc_test_reshaped = np.tile(dev_entropy_uc_test, (1, dev_entropy_code_test.shape[0]))\n",
        "dev_entropy_code_test_reshaped = np.tile(dev_entropy_code_test, (1, dev_entropy_uc_test.shape[0]))\n",
        "\n",
        "avg_variance_uc_test_reshaped = np.tile(avg_variance_uc_test, (1, avg_variance_code_test.shape[0]))\n",
        "avg_variance_code_test_reshaped = np.tile(avg_variance_code_test, (1, avg_variance_uc_test.shape[0]))\n",
        "\n",
        "max_variance_uc_test_reshaped = np.tile(max_variance_uc_test, (1, max_variance_code_test.shape[0]))\n",
        "max_variance_code_test_reshaped = np.tile(max_variance_code_test, (1, max_variance_uc_test.shape[0]))\n",
        "\n",
        "sum_variance_uc_test_reshaped = np.tile(sum_variance_uc_test, (1, sum_variance_code_test.shape[0]))\n",
        "sum_variance_code_test_reshaped = np.tile(sum_variance_code_test, (1, sum_variance_uc_test.shape[0]))\n",
        "\n",
        "avg_scq_uc_test_reshaped = np.tile(avg_scq_uc_test, (1, avg_scq_code_test.shape[0]))\n",
        "avg_scq_code_test_reshaped = np.tile(avg_scq_code_test, (1, avg_scq_uc_test.shape[0]))\n",
        "\n",
        "max_scq_uc_test_reshaped = np.tile(max_scq_uc_test, (1, max_scq_code_test.shape[0]))\n",
        "max_scq_code_test_reshaped = np.tile(max_scq_code_test, (1, max_scq_uc_test.shape[0]))\n",
        "\n",
        "sum_sqc_uc_test_reshaped = np.tile(sum_sqc_uc_test, (1, sum_sqc_code_test.shape[0]))\n",
        "sum_sqc_code_test_reshaped = np.tile(sum_sqc_code_test, (1, sum_sqc_uc_test.shape[0]))\n",
        "\n",
        "avg_pmi_uc_test_reshaped = np.tile(avg_pmi_uc_test, (1, avg_pmi_code_test.shape[0]))\n",
        "avg_pmi_code_test_reshaped = np.tile(avg_pmi_code_test, (1, avg_pmi_uc_test.shape[0]))\n",
        "\n",
        "max_pmi_uc_test_reshaped = np.tile(max_pmi_uc_test, (1, max_pmi_code_test.shape[0]))\n",
        "max_pmi_code_test_reshaped = np.tile(max_pmi_code_test, (1, max_pmi_uc_test.shape[0]))\n",
        "\n",
        "qs_uc_test_reshaped = np.tile(qs_uc_test, (1, qs_code_test.shape[0]))\n",
        "qs_code_test_reshaped = np.tile(qs_code_test, (1, qs_uc_test.shape[0]))\n",
        "\n",
        "UC_SCS_test_reshaped = np.tile(UC_SCS_test, (1, CC_SCS_test.shape[0]))\n",
        "CC_SCS_test_reshaped = np.tile(CC_SCS_test, (1, UC_SCS_test.shape[0]))\n",
        "\n",
        "UC_CoherenceScore_test_reshaped = np.tile(UC_CoherenceScore_test, (1, CC_CoherenceScore_test.shape[0]))\n",
        "CC_CoherenceScore_test_reshaped = np.tile(CC_CoherenceScore_test, (1, UC_CoherenceScore_test.shape[0]))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "UC_RS_JS_test_reshaped = np.tile(UC_RS_JS_test, (1, code_RS_JS_test.shape[0]))\n",
        "code_RS_JS_test_reshaped = np.tile(code_RS_JS_test, (1, UC_RS_JS_test.shape[0]))\n",
        "\n",
        "UC_FRC_JS_test_reshaped = np.tile(UC_FRC_JS_test, (1, code_FRC_JS_test.shape[0]))\n",
        "code_FRC_JS_test_reshaped = np.tile(code_FRC_JS_test, (1, UC_FRC_JS_test.shape[0]))\n",
        "\n",
        "UC_RS_VSM_test_reshaped = np.tile(UC_RS_VSM_test, (1, code_RS_VSM_test.shape[0]))\n",
        "code_RS_VSM_test_reshaped = np.tile(code_RS_VSM_test, (1, UC_RS_VSM_test.shape[0]))\n",
        "\n",
        "UC_FRC_VSM_test_reshaped = np.tile(UC_FRC_VSM_test, (1, code_FRC_VSM_test.shape[0]))\n",
        "code_FRC_VSM_test_reshaped = np.tile(code_FRC_VSM_test, (1, UC_FRC_VSM_test.shape[0]))\n",
        "\n",
        "UC_RS_BM25_test_reshaped = np.tile(UC_RS_BM25_test, (1, code_RS_BM25_test.shape[0]))\n",
        "code_RS_BM25_test_reshaped = np.tile(code_RS_BM25_test, (1, UC_RS_BM25_test.shape[0]))\n",
        "\n",
        "UC_FRC_BM25_test_reshaped = np.tile(UC_FRC_BM25_test, (1, code_FRC_BM25_test.shape[0]))\n",
        "code_FRC_BM25_test_reshaped = np.tile(code_FRC_BM25_test, (1, UC_FRC_BM25_test.shape[0]))\n",
        "\n",
        "UC_RS_JM_test_reshaped = np.tile(UC_RS_JM_test, (1, code_RS_JM_test.shape[0]))\n",
        "code_RS_JM_test_reshaped = np.tile(code_RS_JM_test, (1, UC_RS_JM_test.shape[0]))\n",
        "\n",
        "UC_FRC_JM_test_reshaped = np.tile(UC_FRC_JM_test, (1, code_FRC_JM_test.shape[0]))\n",
        "code_FRC_JM_test_reshaped = np.tile(code_FRC_JM_test, (1, UC_FRC_JM_test.shape[0]))\n",
        "\n",
        "UC_RS_DP_test_reshaped = np.tile(UC_RS_DP_test, (1, code_RS_DP_test.shape[0]))\n",
        "code_RS_DP_test_reshaped = np.tile(code_RS_DP_test, (1, UC_RS_DP_test.shape[0]))\n",
        "\n",
        "UC_FRC_DP_test_reshaped = np.tile(UC_FRC_DP_test, (1, code_FRC_DP_test.shape[0]))\n",
        "code_FRC_DP_test_reshaped = np.tile(code_FRC_DP_test, (1, UC_FRC_DP_test.shape[0]))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "UC_CT_JensenShannon_test_reshaped = np.tile(UC_CT_JensenShannon_test, (1, code_CT_JensenShannon_test.shape[0]))\n",
        "code_CT_JensenShannon_test_reshaped = np.tile(code_CT_JensenShannon_test, (1, UC_CT_JensenShannon_test.shape[0]))\n",
        "\n",
        "UC_CT_VSM_test_reshaped = np.tile(UC_CT_VSM_test, (1, code_CT_VSM_test.shape[0]))\n",
        "code_CT_VSM_test_reshaped = np.tile(code_CT_VSM_test, (1, UC_CT_VSM_test.shape[0]))\n",
        "\n",
        "UC_CT_BM25_test_reshaped = np.tile(UC_CT_BM25_test, (1, code_CT_BM25_test.shape[0]))\n",
        "code_CT_BM25_test_reshaped = np.tile(code_CT_BM25_test, (1, UC_CT_BM25_test.shape[0]))\n",
        "\n",
        "UC_CT_JM_test_reshaped = np.tile(UC_CT_JM_test, (1, code_CT_JM_test.shape[0]))\n",
        "code_CT_JM_test_reshaped = np.tile(code_CT_JM_test, (1, UC_CT_JM_test.shape[0]))\n",
        "\n",
        "UC_CT_DP_test_reshaped = np.tile(UC_CT_DP_test, (1, code_CT_DP_test.shape[0]))\n",
        "code_CT_DP_test_reshaped = np.tile(code_CT_DP_test, (1, UC_CT_DP_test.shape[0]))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "UC_SAC_JS_test_reshaped = np.tile(UC_SAC_JS_test, (1, code_SAC_JS_test.shape[0]))\n",
        "code_SAC_JS_test_reshaped = np.tile(code_SAC_JS_test, (1, UC_SAC_JS_test.shape[0]))\n",
        "\n",
        "UC_SAC_VSM_test_reshaped = np.tile(UC_SAC_VSM_test, (1, code_SAC_VSM_test.shape[0]))\n",
        "code_SAC_VSM_test_reshaped = np.tile(code_SAC_VSM_test, (1, UC_SAC_VSM_test.shape[0]))\n",
        "\n",
        "UC_SAC_BM25_test_reshaped = np.tile(UC_SAC_BM25_test, (1, code_SAC_BM25_test.shape[0]))\n",
        "code_SAC_BM25_test_reshaped = np.tile(code_SAC_BM25_test, (1, UC_SAC_BM25_test.shape[0]))\n",
        "\n",
        "UC_SAC_JM_test_reshaped = np.tile(UC_SAC_JM_test, (1, code_SAC_JM_test.shape[0]))\n",
        "code_SAC_JM_test_reshaped = np.tile(code_SAC_JM_test, (1, UC_SAC_JM_test.shape[0]))\n",
        "\n",
        "UC_SAC_DP_test_reshaped = np.tile(UC_SAC_DP_test, (1, code_SAC_DP_test.shape[0]))\n",
        "code_SAC_DP_test_reshaped = np.tile(code_SAC_DP_test, (1, UC_SAC_DP_test.shape[0]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "UC_WIG_score_JensenShannon_test_reshaped = np.tile(UC_WIG_score_JensenShannon_test, (1, code_WIG_score_JensenShannon_test.shape[0]))\n",
        "code_WIG_score_JensenShannon_test_reshaped = np.tile(code_WIG_score_JensenShannon_test, (1, UC_WIG_score_JensenShannon_test.shape[0]))\n",
        "\n",
        "UC_WIG_score_VSM_test_reshaped = np.tile(UC_WIG_score_VSM_test, (1, code_WIG_score_VSM_test.shape[0]))\n",
        "code_WIG_score_VSM_test_reshaped = np.tile(code_WIG_score_VSM_test, (1, UC_WIG_score_VSM_test.shape[0]))\n",
        "\n",
        "UC_WIG_score_BM25_test_reshaped = np.tile(UC_WIG_score_BM25_test, (1, code_WIG_score_BM25_test.shape[0]))\n",
        "code_WIG_score_BM25_test_reshaped = np.tile(code_WIG_score_BM25_test, (1, UC_WIG_score_BM25_test.shape[0]))\n",
        "\n",
        "UC_WIG_score_JM_test_reshaped = np.tile(UC_WIG_score_JM_test, (1, code_WIG_score_JM_test.shape[0]))\n",
        "code_WIG_score_JM_test_reshaped = np.tile(code_WIG_score_JM_test, (1, UC_WIG_score_JM_test.shape[0]))\n",
        "\n",
        "UC_WIG_score_DP_test_reshaped = np.tile(UC_WIG_score_DP_test, (1, code_WIG_score_DP_test.shape[0]))\n",
        "code_WIG_score_DP_test_reshaped = np.tile(code_WIG_score_DP_test, (1, UC_WIG_score_DP_test.shape[0]))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "UC_NQC_JensenShannon_test_reshaped = np.tile(UC_NQC_JensenShannon_test, (1, code_NQC_JensenShannon_test.shape[0]))\n",
        "code_NQC_JensenShannon_test_reshaped = np.tile(code_NQC_JensenShannon_test, (1, UC_NQC_JensenShannon_test.shape[0]))\n",
        "\n",
        "UC_NQC_VSM_test_reshaped = np.tile(UC_NQC_VSM_test, (1, code_NQC_VSM_test.shape[0]))\n",
        "code_NQC_VSM_test_reshaped = np.tile(code_NQC_VSM_test, (1, UC_NQC_VSM_test.shape[0]))\n",
        "\n",
        "UC_NQC_BM25_test_reshaped = np.tile(UC_NQC_BM25_test, (1, code_NQC_BM25_test.shape[0]))\n",
        "code_NQC_BM25_test_reshaped = np.tile(code_NQC_BM25_test, (1, UC_NQC_BM25_test.shape[0]))\n",
        "\n",
        "UC_NQC_JM_test_reshaped = np.tile(UC_NQC_JM_test, (1, code_NQC_JM_test.shape[0]))\n",
        "code_NQC_JM_test_reshaped = np.tile(code_NQC_JM_test, (1, UC_NQC_JM_test.shape[0]))\n",
        "\n",
        "UC_NQC_DP_test_reshaped = np.tile(UC_NQC_DP_test, (1, code_NQC_DP_test.shape[0]))\n",
        "code_NQC_DP_test_reshaped = np.tile(code_NQC_DP_test, (1, UC_NQC_DP_test.shape[0]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "num_terms_code_test_reshaped = np.tile(num_terms_code_test, (num_terms_UC_test.shape[0], 1))\n",
        "num_terms_UC_test_reshaped = np.tile(num_terms_UC_test, (num_terms_code_test.shape[0], 1))\n",
        "\n",
        "num_unique_terms_UC_test_reshaped = np.tile(num_unique_terms_UC_test, (num_unique_terms_code_test.shape[0], 1))\n",
        "num_unique_terms_code_test_reshaped = np.tile(num_unique_terms_code_test, (num_unique_terms_UC_test.shape[0], 1))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "feature_matrix_test = np.stack([\n",
        "    cosine_similarity_UC_test,cosine_similarity_CC_test,LSA_similarities_UC_test,LSA_similarities_CC_test,\n",
        "    LDA_similarities_UC_test,LDA_similarities_CC_test,JS_UC_test,JS_CC_test,BM25_UC_test.T, BM25_CC_test, JM_UC_test.T, JM_CC_test, DP_UC_test.T, DP_CC_test, \n",
        "\n",
        "    avg_idf_uc_test_reshaped, avg_idf_code_test_reshaped.T, max_idf_uc_test_reshaped, max_idf_code_test_reshaped.T,dev_idf_uc_test_reshaped, dev_idf_code_test_reshaped.T, avg_ictf_uc_test_reshaped, avg_ictf_code_test_reshaped.T, max_ictf_uc_test_reshaped, max_ictf_code_test_reshaped.T, dev_ictf_uc_test_reshaped, dev_ictf_code_test_reshaped.T, avg_entropy_uc_test_reshaped, avg_entropy_code_test_reshaped.T, max_entropy_uc_test_reshaped, max_entropy_code_test_reshaped.T, med_entropy_uc_test_reshaped, med_entropy_code_test_reshaped.T, dev_entropy_uc_test_reshaped, dev_entropy_code_test_reshaped.T, avg_variance_uc_test_reshaped,avg_variance_code_test_reshaped.T,max_variance_uc_test_reshaped,max_variance_code_test_reshaped.T,sum_variance_uc_test_reshaped, sum_variance_code_test_reshaped.T, avg_scq_uc_test_reshaped, avg_scq_code_test_reshaped.T,  max_scq_uc_test_reshaped,  max_scq_code_test_reshaped.T,  sum_sqc_uc_test_reshaped,  sum_sqc_code_test_reshaped.T,avg_pmi_uc_test_reshaped, avg_pmi_code_test_reshaped.T,max_pmi_uc_test_reshaped,max_pmi_code_test_reshaped.T,qs_uc_test_reshaped,qs_code_test_reshaped.T,UC_SCS_test_reshaped,CC_SCS_test_reshaped.T,UC_CoherenceScore_test_reshaped,CC_CoherenceScore_test_reshaped.T,\n",
        "    \n",
        "    UC_FRC_DP_test_reshaped,code_FRC_DP_test_reshaped.T,UC_FRC_JM_test_reshaped,code_FRC_JM_test_reshaped.T,UC_FRC_BM25_test_reshaped,code_FRC_BM25_test_reshaped.T,UC_FRC_JS_test_reshaped,code_FRC_JS_test_reshaped.T,UC_FRC_VSM_test_reshaped,code_FRC_VSM_test_reshaped.T,\n",
        "    \n",
        "    UC_RS_DP_test_reshaped,code_RS_DP_test_reshaped.T,UC_RS_JM_test_reshaped,code_RS_JM_test_reshaped.T,UC_RS_BM25_test_reshaped,code_RS_BM25_test_reshaped.T,UC_RS_JS_test_reshaped,code_RS_JS_test_reshaped.T,UC_RS_VSM_test_reshaped,code_RS_VSM_test_reshaped.T,\n",
        "    \n",
        "    UC_CT_DP_test_reshaped,code_CT_DP_test_reshaped.T,UC_CT_JM_test_reshaped,code_CT_JM_test_reshaped.T,UC_CT_BM25_test_reshaped,code_CT_BM25_test_reshaped.T,UC_CT_JensenShannon_test_reshaped,code_CT_JensenShannon_test_reshaped.T,UC_CT_VSM_test_reshaped,code_CT_VSM_test_reshaped.T,\n",
        "    \n",
        "    UC_SAC_JM_test_reshaped,code_SAC_JM_test_reshaped.T,UC_SAC_BM25_test_reshaped,code_SAC_BM25_test_reshaped.T,UC_SAC_JS_test_reshaped,code_SAC_JS_test_reshaped.T,UC_SAC_VSM_test_reshaped,code_SAC_VSM_test_reshaped.T,UC_SAC_DP_test_reshaped,code_SAC_DP_test_reshaped.T\n",
        "    \n",
        "    ,UC_WIG_score_DP_test_reshaped,code_WIG_score_DP_test_reshaped.T,UC_WIG_score_JM_test_reshaped,code_WIG_score_JM_test_reshaped.T,UC_WIG_score_BM25_test_reshaped,code_WIG_score_BM25_test_reshaped.T,UC_WIG_score_JensenShannon_test_reshaped,code_WIG_score_JensenShannon_test_reshaped.T,UC_WIG_score_VSM_test_reshaped,code_WIG_score_VSM_test_reshaped.T,\n",
        "    \n",
        "    UC_NQC_DP_test_reshaped,code_NQC_DP_test_reshaped.T,UC_NQC_JM_test_reshaped,code_NQC_JM_test_reshaped.T,UC_NQC_BM25_test_reshaped,code_NQC_BM25_test_reshaped.T,UC_NQC_VSM_test_reshaped,code_NQC_VSM_test_reshaped.T,UC_NQC_JensenShannon_test_reshaped,code_NQC_JensenShannon_test_reshaped.T,\n",
        "    \n",
        "    num_terms_UC_test_reshaped.T,num_terms_code_test_reshaped,num_unique_terms_UC_test_reshaped.T,num_unique_terms_code_test_reshaped,num_overlapping_terms_test\n",
        "], axis=2)\n",
        "\n",
        "# Print the shape of the feature matrix\n",
        "print(feature_matrix_test.shape)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Feature Selection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# matrix shape = links * features \n",
        "# ----features------\n",
        "#|\n",
        "#links\n",
        "#|\n",
        "feature_matrix_train_reshaped = feature_matrix_train.reshape(feature_matrix_train.shape[0]*feature_matrix_train.shape[1], -1)\n",
        "print(feature_matrix_train_reshaped.shape)\n",
        "correlation_features_train=np.corrcoef(feature_matrix_train_reshaped,rowvar=False)\n",
        "print(correlation_features_train.shape)\n",
        "features_excluded_train=set()\n",
        "\n",
        "for i in range(correlation_features_train.shape[1]):\n",
        "    for j in range(i+1,correlation_features_train.shape[0]):\n",
        "        if (correlation_features_train[j][i] >= 0.9 ):\n",
        "            features_excluded_train.add(j)\n",
        "\n",
        "features_links_selected_train=np.delete(feature_matrix_train_reshaped, list(features_excluded_train), axis=1) \n",
        "print(feature_matrix_train_reshaped)\n",
        "print(features_links_selected_train.shape)\n",
        "features_links_selected_reshaped_train = features_links_selected_train.reshape(feature_matrix_train.shape[0], feature_matrix_train.shape[1], -1)\n",
        "print(features_links_selected_reshaped_train.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# matrix shape = links * features \n",
        "# ----features------\n",
        "#|\n",
        "#links\n",
        "#|\n",
        "feature_matrix_test_reshaped = feature_matrix_test.reshape(feature_matrix_test.shape[0]*feature_matrix_test.shape[1], -1)\n",
        "print(feature_matrix_test_reshaped.shape)\n",
        "correlation_features_test=np.corrcoef(feature_matrix_test_reshaped,rowvar=False)\n",
        "print(correlation_features_test.shape)\n",
        "features_excluded_test=set()\n",
        "\n",
        "for i in range(correlation_features_test.shape[1]):\n",
        "    for j in range(i+1,correlation_features_test.shape[0]):\n",
        "        if (correlation_features_test[j][i] >= 0.9 ):\n",
        "            features_excluded_test.add(j)\n",
        "\n",
        "features_links_selected_test=np.delete(feature_matrix_test_reshaped, list(features_excluded_train), axis=1) \n",
        "print(feature_matrix_test_reshaped)\n",
        "print(features_links_selected_test.shape)\n",
        "features_links_selected_reshaped_test = features_links_selected_test.reshape(feature_matrix_test.shape[0], feature_matrix_test.shape[1], -1)\n",
        "print(features_links_selected_reshaped_test.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Mapping Features to Labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "Features_train = list()\n",
        "DataSet_train = pd.read_csv('Dataset/teiid_dataset/train_modified.csv')\n",
        "for row in DataSet_train.index:\n",
        "    index_code = int(DataSet_train.loc[row, 'CC'])\n",
        "    index_UC = int(DataSet_train.loc[row, 'UC'])\n",
        "    Features_train.append(features_links_selected_reshaped_train[index_UC][index_code])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "Features_test = list()\n",
        "DataSet_test = pd.read_csv('Dataset/teiid_dataset/test_modified.csv')\n",
        "for row in DataSet_test.index:\n",
        "    index_code = int(DataSet_test.loc[row, 'CC'])\n",
        "    index_UC = int(DataSet_test.loc[row, 'UC'])\n",
        "    Features_test.append(features_links_selected_reshaped_test[index_UC][index_code])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# print(len(Features[]))\n",
        "# print(len(DataSet['Labels'].to_list()))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Data Imbalancing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from imblearn.over_sampling import BorderlineSMOTE \n",
        "smote = BorderlineSMOTE(random_state=42)\n",
        "Features_SMOTE_train, Labels_SMOTE_train = smote.fit_resample(Features_train, DataSet_train['Labels'].to_list())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "\n",
        "# train_features, train_labels = train_test_split(Features_SMOTE_train, Labels_SMOTE_train, test_size = 0, random_state = 42)\n",
        "print(type(Features_SMOTE_train))\n",
        "model_random_forest = RandomForestRegressor(n_estimators = 10, random_state = 42, verbose=2, n_jobs=4)\n",
        "model_random_forest.fit(Features_SMOTE_train, Labels_SMOTE_train)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import joblib\n",
        "joblib.dump(model_random_forest, 'Dataset/teiid_dataset/teiid_model.pkl')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "test_labels = DataSet_test['Labels'].to_list()\n",
        "predictions = model_random_forest.predict(Features_test)\n",
        "errors = abs(predictions - test_labels)\n",
        "print('mean Absolute Error:', round(np.mean(errors), 2) )\n",
        "\n",
        "acc=(test_labels==predictions).sum()\n",
        "print(acc/len(test_labels))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Loading Model and Testing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from joblib import load\n",
        "\n",
        "# Load the model\n",
        "model = load('pickles_teiid/RandomForst_131Features_2nd_trial_tehiid.joblib')\n",
        "\n",
        "# Assuming you have test data in variables X_test and y_test\n",
        "predictions = model.predict(test_features)\n",
        "\n",
        "# Calculate the accuracy of the model on the test data\n",
        "test_labels = DataSet_test['Labels'].to_list()\n",
        "errors = abs(predictions - test_labels)\n",
        "print('mean Absolute Error:', round(np.mean(errors), 2) )\n",
        "\n",
        "acc=(test_labels==predictions).sum()\n",
        "print('Accuracy:',acc/len(test_labels))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"test labels: \", test_labels)\n",
        "print(\"predictions: \")\n",
        "for prediction in predictions:\n",
        "    print(prediction)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# from joblib import dump\n",
        "\n",
        "# # Assuming you have trained a model named 'model'\n",
        "# # You can save it using dump\n",
        "# dump(model_random_forest, 'RandomForst_121Features_1st_trial.joblib')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import csv\n",
        "with open('./dataset/answerSet.csv', newline='') as csvfile:\n",
        "    reader = csv.reader(csvfile, delimiter=' ', quotechar='|')\n",
        "    valid_links_labels = []\n",
        "    for row in reader:\n",
        "        temp=row[0].split(\",\")\n",
        "        #match = re.search(rprint('UC(\\d+)\\.txt', temp[0])\n",
        "        valid_links_labels.append((temp[0],temp[1]))\n",
        "        # if (valid_links_labels.get(temp[1])==None):\n",
        "        # valid_links_labels[temp[1]]=[int(match.group(1))]\n",
        "        # else:\n",
        "        #     valid_links_labels[temp[1]].append(int(match.group(1)))\n",
        "\n",
        "# file_names = list(valid_links_labels.keys())\n",
        "# file_names.sort()\n",
        "# valid_links_labels_sorted = {i: valid_links_labels[i] for i in file_names}\n",
        "            \n",
        "# valid_links_labels_sorted)\n",
        "# len(valid_links_labels_sorted.keys()))\n",
        "print(valid_links_labels)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
