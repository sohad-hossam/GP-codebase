{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from treelib import Node, Tree\n",
    "from tree_sitter import Language, Parser\n",
    "import math\n",
    "import re\n",
    "import math\n",
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "# nltk.download() download_folder = C:/nltk_data \n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read the java code\n",
    "\n",
    "dataset_txt = open(\"dataset/railo.sqlite3/railo-master/railo-java/railo-core/src/railo/runtime/sql/exp/op/Operation1.java\", \"r\", encoding='utf-8').read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['package', 'railo', 'runtime', 'sql', 'exp', 'op', 'import', 'railo', 'runtime', 'sql', 'exp', '', 'Expression', 'import', 'railo', 'runtime', 'sql', 'exp', '', 'Expression', 'Support', 'public', 'class', '', 'Operation1', 'extends', '', 'Expression', 'Support', 'implements', '', 'Operation', 'private', '', 'Expression', 'exp', 'private', 'int', 'operator', '', 'override', 'public', '', 'Expression', 'get', 'Exp', '', '', 'return', 'exp', '', '', '', '', '', '', 'return', 'the', 'operator', '', 'public', 'int', 'get', 'Operator', '', '', 'return', 'operator', '', 'public', '', 'Operation1', '', 'Expression', 'exp', 'int', 'operator', '', 'this', 'exp', 'exp', 'this', 'operator', 'operator', '', 'public', '', 'String', 'to', 'String', 'boolean', 'no', 'Alias', '', 'if', '', 'has', 'Alias', '', '', 'no', 'Alias', '', 'if', 'operator', '', '', 'O', 'P', 'E', 'R', 'A', 'T', 'I', 'O', 'N1', '', 'I', 'S', '', 'N', 'U', 'L', 'L', 'operator', '', '', 'O', 'P', 'E', 'R', 'A', 'T', 'I', 'O', 'N1', '', 'I', 'S', '', 'N', 'O', 'T', '', 'N', 'U', 'L', 'L', '', 'return', 'exp', 'to', 'String', 'true', '', '', '', '', '', 'Operation2', 'to', 'String', 'operator', '', '', 'return', '', 'Operation2', 'to', 'String', 'operator', '', '', '', '', 'exp', 'to', 'String', 'true', '', '', 'return', 'to', 'String', 'true', '', '', 'as', '', 'get', 'Alias', '', '', '', '', '']\n",
      "['railo', 'runtim', 'sql', 'exp', 'op', 'railo', 'runtim', 'sql', 'exp', 'express', 'railo', 'runtim', 'sql', 'exp', 'express', 'support', 'oper', 'express', 'support', 'oper', 'express', 'exp', 'oper', 'overrid', 'express', 'get', 'exp', 'exp', 'oper', 'get', 'oper', 'oper', 'oper', 'express', 'exp', 'oper', 'exp', 'exp', 'oper', 'oper', 'string', 'string', 'alia', 'alia', 'alia', 'oper', 'p', 'e', 'r', 'n', 'n', 'u', 'l', 'l', 'oper', 'p', 'e', 'r', 'n', 'n', 'n', 'u', 'l', 'l', 'exp', 'string', 'true', 'oper', 'string', 'oper', 'oper', 'string', 'oper', 'exp', 'string', 'true', 'string', 'true', 'get', 'alia']\n"
     ]
    }
   ],
   "source": [
    "# 1) All the interpunction was removed. \n",
    "\n",
    "chars_to_remove = r'''(?x)\n",
    "(?<!^)(?=[A-Z])|_|\\s*;\\s*|\\s*,\\s*|\\s*\\.\\s*|  #Standalone Punctuation Marks\n",
    "\\s*\\+\\s*|\\s*-\\s*|\\s*\\/\\s*|\\s*\\*\\s*|  #arethmatic operations\n",
    "\\s*=\\s*|\\s*==\\s*|\\s*!=\\s*|\\s*>\\s*|\\s*>=\\s*|\\s*<\\s*|\\s*<=\\s*|\\s*&&\\s*|\n",
    "\\s*\\|\\|\\s*\n",
    "|\\s*!\\s*|\\s*\\\"\\s*|\\s*\\'\\s*|    #assignment \n",
    "\\s*\\(\\s*|\\s*\\)\\s*|\\s*{\\s*|\\s*}\\s*|\\s*[\\s*|\\s*]\\s*|\\s*@\\s*'''   #brackets\n",
    "SourceCodeCleaned =re.split(chars_to_remove,dataset_txt)\n",
    "\n",
    "print(SourceCodeCleaned)\n",
    "\n",
    "\n",
    "#print(SourceCodeLower)\n",
    "\n",
    "# 2) All numeric characters were removed. \n",
    "numeric_chars_to_remove = r\"[0-9]\" \n",
    "SourceCodeCleanedOfNumbers = [re.sub(numeric_chars_to_remove, \"\", x) for x in SourceCodeCleaned]\n",
    "#print(SourceCodeCleanedOfNumbers)\n",
    "\n",
    "#3) All sentences were tokenized with NLTK. \n",
    "#4) The stop words corpus from NLTK was used to eliminate all stop words. \n",
    "stop_words = set(stopwords.words('english'))\n",
    "words_tokenized=list()\n",
    "\n",
    "#5) All remaining terms were stemmed using the Porter Stemming Algorithm\n",
    "porter_stemmer = PorterStemmer()\n",
    "\n",
    "#6) remove keywords in java\n",
    "keywords_java={\n",
    "    \"abstract\", \"continue\", \"for\", \"new\", \"switch\",\n",
    "    \"assert\", \"default\", \"goto\", \"package\", \"synchronized\",\n",
    "    \"boolean\", \"do\", \"if\", \"private\", \"this\",\n",
    "    \"break\", \"double\", \"implements\", \"protected\", \"throw\",\n",
    "    \"byte\", \"else\", \"import\", \"public\", \"throws\",\n",
    "    \"case\", \"enum\", \"instanceof\", \"return\", \"transient\",\n",
    "    \"catch\", \"extends\", \"int\", \"short\", \"try\",\n",
    "    \"char\", \"final\", \"interface\", \"static\", \"void\",\n",
    "    \"class\", \"finally\", \"long\", \"strictfp\", \"volatile\",\"Override\",\"Deprecated\",\"SafeVarArgs\",\"SuppressWarnings\",\"FuntionalInterface\",\"Inherited\",\"Documented\",\"Target\",\"Retention\",\"Repeatable\"} #java non_primitive datatypes not added ex: \"List\"\n",
    "\n",
    "for sentence in SourceCodeCleanedOfNumbers:\n",
    "    #7) All words were lowercased. \n",
    "    sentence_lower=sentence.lower()\n",
    "    NTLKTokenized=word_tokenize(sentence_lower)\n",
    "    for word in NTLKTokenized:\n",
    "        if word not in stop_words and word != '' and word not in keywords_java:\n",
    "            word_stem=porter_stemmer.stem(word)\n",
    "            words_tokenized.append(word_stem)\n",
    "\n",
    "print(words_tokenized)\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
