{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imports import *\n",
    "from PreProcessor import *\n",
    "\n",
    "_PreProcessor = PreProcessor()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function_names_train,function_segments_train = _PreProcessor.setupDeepLearning(\"./Dataset/teiid_dataset/train_CC\",'CC','train')\n",
    "descriptions_train, summaries_train = _PreProcessor.setupDeepLearning(\"./Dataset/teiid_dataset/train_UC\",'UC','train')\n",
    "function_names_test,function_segments_test = _PreProcessor.setupDeepLearning(\"./Dataset/teiid_dataset/test_CC\",'CC','test')\n",
    "descriptions_test, summaries_test = _PreProcessor.setupDeepLearning(\"./Dataset/teiid_dataset/test_UC\",'UC','test')\n",
    "\n",
    "function_names_train_errai,function_segments_train_errai = _PreProcessor.setupDeepLearning(\"./Dataset/errai_dataset/train_CC\",'CC','train')\n",
    "descriptions_train_errai, summaries_train_errai = _PreProcessor.setupDeepLearning(\"./Dataset/errai_dataset/train_UC\",'UC','train')\n",
    "function_names_test_errai,function_segments_test_errai = _PreProcessor.setupDeepLearning(\"./Dataset/errai_dataset/test_CC\",'CC','test')\n",
    "descriptions_test_errai, summaries_test_errai = _PreProcessor.setupDeepLearning(\"./Dataset/errai_dataset/test_UC\",'UC','test')\n",
    "\n",
    "function_names_train_jboss,function_segments_train_jboss = _PreProcessor.setupDeepLearning(\"./Dataset/jboss_dataset/train_CC\",'CC','train')\n",
    "descriptions_train_jboss, summaries_train_jboss = _PreProcessor.setupDeepLearning(\"./Dataset/jboss_dataset/train_UC\",'UC','train')\n",
    "function_names_test_jboss,function_segments_test_jboss = _PreProcessor.setupDeepLearning(\"./Dataset/jboss_dataset/test_CC\",'CC','test')\n",
    "descriptions_test_jboss, summaries_test_jboss = _PreProcessor.setupDeepLearning(\"./Dataset/jboss_dataset/test_UC\",'UC','test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_PreProcessor.setUpUnknown(function_names_train,function_segments_train,\"CC\",'train')\n",
    "_PreProcessor.setUpUnknown(descriptions_train,summaries_train,\"UC\",'train  ')\n",
    "\n",
    "_PreProcessor.setUpUnknown(function_names_test,function_segments_test,\"CC\",'test')\n",
    "_PreProcessor.setUpUnknown(descriptions_test,summaries_test,\"UC\",'test')\n",
    "\n",
    "######################################################################################\n",
    "\n",
    "_PreProcessor.setUpUnknown(function_names_train_errai,function_segments_train_errai,\"CC\",'train')\n",
    "_PreProcessor.setUpUnknown(descriptions_train_errai,summaries_train_errai,\"UC\",'train')\n",
    "\n",
    "_PreProcessor.setUpUnknown(function_names_test_errai,function_segments_test_errai,\"CC\",'test')\n",
    "_PreProcessor.setUpUnknown(descriptions_test_errai,summaries_test_errai,\"UC\",'test')\n",
    "\n",
    "#####################################################################################\n",
    "\n",
    "_PreProcessor.setUpUnknown(function_names_train_jboss,function_segments_train_jboss,\"CC\",'train')\n",
    "_PreProcessor.setUpUnknown(descriptions_train_jboss,summaries_train_jboss,\"UC\",'train')\n",
    "\n",
    "_PreProcessor.setUpUnknown(function_names_test_jboss,function_segments_test_jboss,\"CC\",'test')\n",
    "_PreProcessor.setUpUnknown(descriptions_test_jboss,summaries_test_jboss,\"UC\",'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./pickles/DeepLearning/function_names_train.pkl', 'wb') as f:\n",
    "       pickle.dump(function_names_train, f)\n",
    "with open('./pickles/DeepLearning/function_segments_train.pkl', 'wb') as f:\n",
    "        pickle.dump(function_segments_train, f)\n",
    "with open('./pickles/DeepLearning/descriptions_train.pkl', 'wb') as f:\n",
    "        pickle.dump(descriptions_train, f)\n",
    "with open('./pickles/DeepLearning/summaries_train.pkl', 'wb') as f:\n",
    "        pickle.dump(summaries_train, f)\n",
    "\n",
    "with open('./pickles/DeepLearning/Vocab.pkl', 'wb') as f:\n",
    "        pickle.dump(_PreProcessor.Vocab, f)\n",
    "\n",
    "with open('./pickles/DeepLearning/function_names_test.pkl', 'wb') as f:\n",
    "       pickle.dump(function_names_test, f)\n",
    "with open('./pickles/DeepLearning/function_segments_test.pkl', 'wb') as f:\n",
    "        pickle.dump(function_segments_test, f)\n",
    "with open('./pickles/DeepLearning/descriptions_test.pkl', 'wb') as f:\n",
    "        pickle.dump(descriptions_test, f)\n",
    "with open('./pickles/DeepLearning/summaries_test.pkl', 'wb') as f:\n",
    "        pickle.dump(summaries_test, f)\n",
    "        \n",
    "with open('./pickles/DeepLearning/function_names_train_errai.pkl', 'wb') as f:\n",
    "       pickle.dump(function_names_train_errai, f)\n",
    "with open('./pickles/DeepLearning/function_segments_train_errai.pkl', 'wb') as f:\n",
    "        pickle.dump(function_segments_train_errai, f)\n",
    "with open('./pickles/DeepLearning/descriptions_train_errai.pkl', 'wb') as f:\n",
    "        pickle.dump(descriptions_train_errai, f)\n",
    "with open('./pickles/DeepLearning/summaries_train_errai.pkl', 'wb') as f:\n",
    "        pickle.dump(summaries_train_errai, f)\n",
    "\n",
    "with open('./pickles/DeepLearning/function_names_test_errai.pkl', 'wb') as f:\n",
    "        pickle.dump(function_names_test_errai, f)\n",
    "with open('./pickles/DeepLearning/function_segments_test_errai.pkl', 'wb') as f:\n",
    "       pickle.dump(function_segments_test_errai, f)\n",
    "with open('./pickles/DeepLearning/descriptions_test_errai.pkl', 'wb') as f:\n",
    "        pickle.dump(descriptions_test_errai, f)\n",
    "with open('./pickles/DeepLearning/summaries_test_errai.pkl', 'wb') as f:\n",
    "        pickle.dump(summaries_test_errai, f)\n",
    "\n",
    "with open('./pickles/DeepLearning/function_names_train_jboss.pkl', 'wb') as f:\n",
    "       pickle.dump(function_names_train_jboss, f)\n",
    "with open('./pickles/DeepLearning/function_segments_train_jboss.pkl', 'wb') as f:\n",
    "        pickle.dump(function_segments_train_jboss, f)\n",
    "with open('./pickles/DeepLearning/descriptions_train_jboss.pkl', 'wb') as f:\n",
    "        pickle.dump(descriptions_train_jboss, f)\n",
    "with open('./pickles/DeepLearning/summaries_train_jboss.pkl', 'wb') as f:\n",
    "        pickle.dump(summaries_train_jboss, f)\n",
    "\n",
    "with open('./pickles/DeepLearning/function_names_test_jboss.pkl', 'wb') as f:\n",
    "        pickle.dump(function_names_test_jboss, f)\n",
    "with open('./pickles/DeepLearning/function_segments_test_jboss.pkl', 'wb') as f:\n",
    "       pickle.dump(function_segments_test_jboss, f)\n",
    "with open('./pickles/DeepLearning/descriptions_test_jboss.pkl', 'wb') as f:\n",
    "        pickle.dump(descriptions_test_jboss, f)\n",
    "with open('./pickles/DeepLearning/summaries_test_jboss.pkl', 'wb') as f:\n",
    "        pickle.dump(summaries_test_jboss, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function_names_train = np.load('./pickles/DeepLearning/function_names_train.pkl',allow_pickle=True)\n",
    "function_segments_train = np.load('./pickles/DeepLearning/function_segments_train.pkl',allow_pickle=True)\n",
    "descriptions_train = np.load('./pickles/DeepLearning/descriptions_train.pkl',allow_pickle=True)\n",
    "summaries_train = np.load('./pickles/DeepLearning/summaries_train.pkl',allow_pickle=True)\n",
    "\n",
    "function_names_test = np.load('./pickles/DeepLearning/function_names_test.pkl',allow_pickle=True)\n",
    "function_segments_test = np.load('./pickles/DeepLearning/function_segments_test.pkl',allow_pickle=True)\n",
    "descriptions_test = np.load('./pickles/DeepLearning/descriptions_test.pkl',allow_pickle=True)\n",
    "summaries_test = np.load('./pickles/DeepLearning/summaries_test.pkl',allow_pickle=True)\n",
    "\n",
    "function_names_train_errai = np.load('./pickles/DeepLearning/function_names_train_errai.pkl',allow_pickle=True)\n",
    "function_segments_train_errai = np.load('./pickles/DeepLearning/function_segments_train_errai.pkl',allow_pickle=True)\n",
    "descriptions_train_errai = np.load('./pickles/DeepLearning/descriptions_train_errai.pkl',allow_pickle=True)\n",
    "summaries_train_errai = np.load('./pickles/DeepLearning/summaries_train_errai.pkl',allow_pickle=True)\n",
    "\n",
    "function_names_test_errai = np.load('./pickles/DeepLearning/function_names_test_errai.pkl',allow_pickle=True)\n",
    "function_segments_test_errai = np.load('./pickles/DeepLearning/function_segments_test_errai.pkl',allow_pickle=True)\n",
    "descriptions_test_errai = np.load('./pickles/DeepLearning/descriptions_test_errai.pkl',allow_pickle=True)\n",
    "summaries_test_errai = np.load('./pickles/DeepLearning/summaries_test_errai.pkl',allow_pickle=True)\n",
    "\n",
    "function_names_train_jboss = np.load('./pickles/DeepLearning/function_names_train_jboss.pkl',allow_pickle=True)\n",
    "function_segments_train_jboss = np.load('./pickles/DeepLearning/function_segments_train_jboss.pkl',allow_pickle=True)\n",
    "descriptions_train_jboss = np.load('./pickles/DeepLearning/descriptions_train_jboss.pkl',allow_pickle=True)\n",
    "summaries_train_jboss = np.load('./pickles/DeepLearning/summaries_train_jboss.pkl',allow_pickle=True)\n",
    "\n",
    "function_names_test_jboss = np.load('./pickles/DeepLearning/function_names_test_jboss.pkl',allow_pickle=True)\n",
    "function_segments_test_jboss = np.load('./pickles/DeepLearning/function_segments_test_jboss.pkl',allow_pickle=True)\n",
    "descriptions_test_jboss = np.load('./pickles/DeepLearning/descriptions_test_jboss.pkl',allow_pickle=True)\n",
    "summaries_test_jboss = np.load('./pickles/DeepLearning/summaries_test_jboss.pkl',allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# function_names_train.extend(function_names_train_errai); function_names_train.extend(function_names_train_jboss) \n",
    "# function_segments_train.extend(function_segments_train_errai); function_segments_train.extend(function_segments_train_jboss)\n",
    "\n",
    "# descriptions_train.extend(descriptions_train_errai); descriptions_train.extend(descriptions_train_jboss)\n",
    "# summaries_train.extend(summaries_train_errai); summaries_train.extend(summaries_train_jboss)\n",
    "\n",
    "# function_names_test.extend(function_names_test_errai); function_names_test.extend(function_names_test_jboss)\n",
    "# function_segments_test.extend(function_segments_test_errai); function_segments_test.extend(function_segments_test_jboss)\n",
    "\n",
    "# descriptions_test.extend(descriptions_test_errai); descriptions_test.extend(descriptions_test_jboss)\n",
    "# summaries_test.extend(summaries_test_errai); summaries_test.extend(summaries_test_jboss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CC_word2vec = _PreProcessor.word2VecProcessor(function_names_train, function_segments_train, 'CC')\n",
    "UC_word2vec = _PreProcessor.word2VecProcessor(summaries_train, descriptions_train, 'UC')\n",
    "\n",
    "word2vec_model = Word2Vec(sentences = CC_word2vec + UC_word2vec, vector_size=150, window=5, min_count=1, workers=4, epochs=10)\n",
    "\n",
    "word2vec_model.save(\"./Dataset/teiid_dataset/UC_CC_WORD2VEC\")\n",
    "word2vec_model = Word2Vec.load(\"./Dataset/teiid_dataset/UC_CC_WORD2VEC\")\n",
    "\n",
    "word2vec_vocab = word2vec_model.wv.index_to_key\n",
    "\n",
    "# Initialize an empty embedding matrix\n",
    "embedding_matrix = np.zeros((len(word2vec_vocab) + 1, word2vec_model.vector_size))\n",
    "\n",
    "# Fill the embedding matrix with the embeddings of each word\n",
    "for i, word in enumerate(word2vec_vocab):\n",
    "    embedding_vector = word2vec_model.wv[word]\n",
    "    if embedding_vector is not None:\n",
    "        embedding_matrix[i + 1] = embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./pickles/DeepLearning/word2vec_vocab.pkl', 'wb') as f:\n",
    "    pickle.dump(word2vec_vocab, f)\n",
    "with open('./pickles/DeepLearning/embedding_matrix.pkl', 'wb') as f:\n",
    "    pickle.dump(embedding_matrix, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_matrix = np.load('./Dataset/teiid_dataset/embedding_matrix.pkl',allow_pickle=True)\n",
    "word2vec_vocab = np.load('./Dataset/teiid_dataset/word2vec_vocab.pkl',allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(word2vec_vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Converting dataset to indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_PreProcessor.vocabToIndex(word2vec_vocab)\n",
    "\n",
    "#############################################################################\n",
    "\n",
    "_PreProcessor.dataSetToIndex(function_names_train,function_segments_train,\"CC\")\n",
    "_PreProcessor.dataSetToIndex(descriptions_train,summaries_train,\"UC\")\n",
    "\n",
    "_PreProcessor.dataSetToIndex(function_names_test,function_segments_test,\"CC\")\n",
    "_PreProcessor.dataSetToIndex(descriptions_test,summaries_test,\"UC\")\n",
    "\n",
    "############################################################################\n",
    "\n",
    "_PreProcessor.dataSetToIndex(function_names_train_errai,function_segments_train_errai,\"CC\")\n",
    "_PreProcessor.dataSetToIndex(descriptions_train_errai,summaries_train_errai,\"UC\")\n",
    "\n",
    "_PreProcessor.dataSetToIndex(function_names_test_errai,function_segments_test_errai,\"CC\")\n",
    "_PreProcessor.dataSetToIndex(descriptions_test_errai,summaries_test_errai,\"UC\")\n",
    "\n",
    "############################################################################\n",
    "\n",
    "_PreProcessor.dataSetToIndex(function_names_train_jboss,function_segments_train_jboss,\"CC\")\n",
    "_PreProcessor.dataSetToIndex(descriptions_train_jboss,summaries_train_jboss,\"UC\")\n",
    "\n",
    "_PreProcessor.dataSetToIndex(function_names_test_jboss,function_segments_test_jboss,\"CC\")\n",
    "_PreProcessor.dataSetToIndex(descriptions_test_jboss,summaries_test_jboss,\"UC\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, labels = _PreProcessor.setUpLabels(function_names_train,function_segments_train,descriptions_train,summaries_train,'Dataset/teiid_dataset/train_modified.csv')\n",
    "x_train_errai, labels_errai = _PreProcessor.setUpLabels(function_names_train_errai,function_segments_train_errai,descriptions_train_errai,summaries_train_errai,'Dataset/errai_dataset/train_modified.csv')\n",
    "x_train_jboss, labels_jboss = _PreProcessor.setUpLabels(function_names_train_jboss,function_segments_train_jboss,descriptions_train_jboss,summaries_train_jboss,'Dataset/jboss_dataset/train_modified.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test, labels_test = _PreProcessor.setUpLabels(function_names_test,function_segments_test,descriptions_test,summaries_test,'Dataset/teiid_dataset/test_modified.csv')\n",
    "x_test_errai, labels_test_errai = _PreProcessor.setUpLabels(function_names_test_errai,function_segments_test_errai,descriptions_test_errai,summaries_test_errai,'Dataset/errai_dataset/test_modified.csv')\n",
    "x_test_jboss, labels_test_jboss = _PreProcessor.setUpLabels(function_names_test_jboss,function_segments_test_jboss,descriptions_test_jboss,summaries_test_jboss,'Dataset/jboss_dataset/test_modified.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train.extend(x_train_errai)\n",
    "x_train.extend(x_train_jboss)\n",
    "\n",
    "x_test.extend(x_test_errai)\n",
    "x_test.extend(x_test_jboss)\n",
    "\n",
    "labels.extend(labels_errai)\n",
    "labels.extend(labels_jboss)\n",
    "\n",
    "labels_test.extend(labels_test_errai)\n",
    "labels_test.extend(labels_test_jboss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./pickles/DeepLearning/x_train.pkl', 'wb') as f:\n",
    "       pickle.dump(x_train, f)\n",
    "with open('./pickles/DeepLearning/labels.pkl', 'wb') as f:\n",
    "        pickle.dump(labels, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./pickles/DeepLearning/x_test.pkl', 'wb') as f:\n",
    "       pickle.dump(x_test, f)\n",
    "with open('./pickles/DeepLearning/labels_test.pkl', 'wb') as f:\n",
    "       pickle.dump(labels_test, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.load('./pickles/DeepLearning/x_train.pkl',allow_pickle=True)\n",
    "labels = np.load('./pickles/DeepLearning/labels.pkl',allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = np.load('./pickles/DeepLearning/x_test.pkl',allow_pickle=True)\n",
    "labels_test = np.load('./pickles/DeepLearning/labels_test.pkl',allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_small = []\n",
    "label_small = []\n",
    "counter_1 = 0\n",
    "counter_0 = 0\n",
    "while(counter_1 < 11 or counter_0 < 11):\n",
    "    index = random.randint(0, len(x_train))\n",
    "\n",
    "    if labels[index] == 1 and counter_1 < 11 :\n",
    "        x_train_small.append(x_train[index])\n",
    "        label_small.append(1)\n",
    "        counter_1 +=1\n",
    "\n",
    "    elif labels[index] == 0 and counter_0 < 11 :\n",
    "        x_train_small.append(x_train[index])\n",
    "        label_small.append(0)\n",
    "        counter_0 +=1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_pos_weights(class_counts):\n",
    "    pos_weights = np.ones_like(class_counts)\n",
    "    neg_counts = [len(labels)-pos_count for pos_count in class_counts]\n",
    "    for cdx, (pos_count, neg_count) in enumerate(zip(class_counts,  neg_counts)):\n",
    "        pos_weights[cdx] = neg_count / (pos_count + 1e-5)\n",
    "\n",
    "    return torch.as_tensor(pos_weights, dtype=torch.float)\n",
    "\n",
    "class_counts = [len(labels)-sum(labels), sum(labels)]\n",
    "pos_weights = calculate_pos_weights(class_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x_train_small)\n",
    "print(label_small)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TracibilityLinkDataset(Dataset):\n",
    "\n",
    "    def __init__(self, x_train, y_train):\n",
    "        \n",
    "\n",
    "        function_names__, function_segments__, descriptions__ , summaries__ = zip(*x_train)\n",
    "        function_names_padded = pad_sequence(function_names__, batch_first=True, padding_value=0)\n",
    "        function_segments_padded = pad_sequence(function_segments__, batch_first=True, padding_value = 0)\n",
    "        descriptions_padded = pad_sequence(descriptions__, batch_first=True, padding_value=0)\n",
    "        summaries_padded = pad_sequence(summaries__, batch_first=True, padding_value = 0)\n",
    "\n",
    "        x_train_padded = list()\n",
    "        for data in zip(function_names_padded, function_segments_padded, descriptions_padded, summaries_padded):\n",
    "            x_train_padded.append(list(data))\n",
    "\n",
    "\n",
    "        self.tensor_x_train = x_train_padded\n",
    "        self.tensor_y_train = torch.tensor(y_train)\n",
    "\n",
    "\n",
    "\n",
    "    # len and get item are very important --> used by dataloader\n",
    "    def __len__(self):\n",
    "        return len(self.tensor_y_train)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.tensor_x_train[idx], self.tensor_y_train[idx]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train_small = TracibilityLinkDataset(x_train_small, label_small)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_test = TracibilityLinkDataset(x_test, labels_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DLModel(nn.Module):\n",
    "\n",
    "  def __init__(self,embedding_matrix : np.array, embedding_dim : tuple,name_size: int, seg_size:int, summary_size:int,descript_size:int, hidden_size:int = 64, classes: int = 2):\n",
    "      super(DLModel, self).__init__()\n",
    "\n",
    "      # first embedding layer: input size --> vocab size, output size --> feature vector of vocab size(one hot encoding), weigths --> word2vec\n",
    "      # matrix (vocab * vocab)\n",
    "      # embedding_dim[0] -> vocab size, embedding_dim[1] -> 150 defined in word2vec\n",
    "      self.embedding = nn.Embedding(num_embeddings = embedding_dim[0], embedding_dim = embedding_dim[1], _weight = torch.tensor(embedding_matrix))\n",
    "      \n",
    "      self.lstm_CC = nn.LSTM(embedding_dim[1],hidden_size,batch_first=True, bidirectional=False)\n",
    "      self.lstm_post_flatten = nn.Linear((name_size+seg_size)*hidden_size+(summary_size+descript_size)*hidden_size,hidden_size)\n",
    "\n",
    "      self.linear = nn.Linear(hidden_size,classes)\n",
    "\n",
    "      self.softmax = nn.Softmax(dim=1)\n",
    "      # function_names_lstm.shape =  torch.Size([2, 4, 128])\n",
    "      # function_segments_lstm.shape =  torch.Size([2, 165, 128])\n",
    "      # descriptions_lstm.shape =  torch.Size([2, 200, 128])\n",
    "      # summaries_lstm.shape =  torch.Size([2, 12, 128])\n",
    "      # summaries_descrip_flatten.shape =  torch.Size([2, 27136])\n",
    "      # name_seg_flatten.shape =  torch.Size([2, 21632])\n",
    "      # torch.Size([2])\n",
    "      # torch.Size([2])\n",
    "      \n",
    "      # self.cosine_similarity = nn.CosineSimilarity(dim=1) # code = 1*(vocab_size)*(feature_vector) , req = code = 1*1000*200 \n",
    "\n",
    "      # self.sigmoid = nn.Sigmoid()\n",
    "    \n",
    "  def forward(self, function_names, function_segments, descriptions, summaries ):\n",
    "    #function_names.shape --> batch_no * no_tokens* 150\n",
    "    \n",
    "    function_names_embeddings  = self.embedding(function_names)\n",
    "    function_segments_embeddings = self.embedding(function_segments)\n",
    "    descriptions_embedding  = self.embedding(descriptions)\n",
    "    summaries_embedding = self.embedding(summaries)\n",
    "    \n",
    "    #function_names.shape --> batch_no * no_tokens* 150\n",
    "    \n",
    "    \n",
    "    function_names_lstm,_ = self.lstm_CC (function_names_embeddings.float())\n",
    "    function_segments_lstm,_ = self.lstm_CC (function_segments_embeddings.float())\n",
    "    descriptions_lstm,_ = self.lstm_CC (descriptions_embedding.float())\n",
    "    summaries_lstm,_ = self.lstm_CC (summaries_embedding.float())\n",
    "    \n",
    "    # print(\"function_names_lstm.shape = \",function_names_lstm.shape)\n",
    "    # print(\"function_segments_lstm.shape = \",function_segments_lstm.shape)\n",
    "    # print(\"descriptions_lstm.shape = \",descriptions_lstm.shape)\n",
    "    # print(\"summaries_lstm.shape = \",summaries_lstm.shape)\n",
    "\n",
    "    #function_names.shape --> batch_no * no_tokens* 150\n",
    "\n",
    "    concatenated_name_seg = torch.cat((function_names_lstm, function_segments_lstm), dim = 1)\n",
    "    summaries_descrip_seg = torch.cat((descriptions_lstm, summaries_lstm), dim = 1)\n",
    "\n",
    "\n",
    "    summaries_descrip_flatten = summaries_descrip_seg.view(summaries_descrip_seg.shape[0],-1)\n",
    "    name_seg_flatten = concatenated_name_seg.view(concatenated_name_seg.shape[0],-1) # batch_no * (feature_vector * no_tokens)\n",
    "\n",
    "\n",
    "    lstm_post_output = self.lstm_post_flatten(torch.cat([name_seg_flatten,summaries_descrip_flatten],axis=1).float())\n",
    "    # print(\"summaries_descrip_flatten.shape = \",summaries_descrip_flatten.shape)\n",
    "    # print(\"name_seg_flatten.shape = \",name_seg_flatten.shape)\n",
    "\n",
    "    # num_repeats = (name_seg_flatten.shape[1] + summaries_descrip_flatten.shape[1] - 1) // summaries_descrip_flatten.shape[1] \n",
    "\n",
    "    # inreasing th size of the req document to be the same as the code documet to allow for cosine simiraity \n",
    "    # summaries_descrip_flatten_tiled = summaries_descrip_flatten.repeat((1,num_repeats))\n",
    "    # summaries_descrip_flatten_tiled_segmented = summaries_descrip_flatten_tiled[:,:name_seg_flatten.shape[1]]\n",
    "    \n",
    "    linear_output = self.linear(lstm_post_output)\n",
    "    \n",
    "    # softmax_output = self.softmax(linear_output)\n",
    "\n",
    "    # consine_sim_code_req = self.cosine_similarity(name_seg_flatten,summaries_descrip_flatten_tiled_segmented)\n",
    "\n",
    "    return linear_output\n",
    "#     concatenated_tensor = torch.cat([function_names_lstm_output[0].reshape(batch_nu,-1), function_segments_lstm_output[0].reshape(batch_nu,-1), descriptions_lstm_output[0].reshape(batch_nu,-1) , summaries_lstm_output[0].reshape(batch_nu,-1)],axis=1)\n",
    "#     linear_output = self.linear(concatenated_tensor)\n",
    "    \n",
    "#     print(\"concatenated_tensor= \",linear_output.shape)\n",
    "\n",
    "#     function_names_attention = self.attention_layer_CC(function_names_embeddings.float(),function_names_embeddings.float(),function_names_embeddings.float())\n",
    "\n",
    "#     function_segments_attention = self.attention_layer_CC(function_segments_embeddings.float(),function_segments_embeddings.float(),function_segments_embeddings.float())\n",
    "   \n",
    "#     descriptions_attention = self.attention_layer_UC(descriptions_embedding.float(),descriptions_embedding.float(),descriptions_embedding.float())\n",
    "\n",
    "#     summaries_attention = self.attention_layer_UC(summaries_embedding.float(),summaries_embedding.float(),summaries_embedding.float())\n",
    "\n",
    "#     concatenated_name_seg = torch.cat((function_names_attention[0], function_segments_attention[0]), dim = 1)\n",
    "\n",
    "#     summaries_descrip_seg = torch.cat((descriptions_attention[0], summaries_attention[0]), dim = 1)\n",
    "\n",
    "#     names_seg_conv = self.conv_layer_2d(concatenated_name_seg.unsqueeze(1))\n",
    "\n",
    "#     # summaries_descrip_conv = self.conv_layer_2d(summaries_descrip_seg.unsqueeze(1))\n",
    "#     # print(\"summaries_descrip_seg.shape = \",summaries_descrip_seg.shape)\n",
    "\n",
    "# #     name_seg = self.pool_layer_2d (names_seg_conv)\n",
    "#     # print(\"name_seg.shape = \" , name_seg.shape)\n",
    "\n",
    "#     summaries_descrip_flatten = summaries_descrip_seg.view(summaries_descrip_seg.shape[0],-1)\n",
    "#     name_seg_flatten = names_seg_conv.squeeze(1).view(names_seg_conv.shape[0],-1) \n",
    "\n",
    "\n",
    "#     num_repeats = (name_seg_flatten.shape[1] + summaries_descrip_flatten.shape[1] - 1) // summaries_descrip_flatten.shape[1] \n",
    "\n",
    "#     #inreasing th size of the req document to be the same as the code documet to allow for cosine simiraity \n",
    "#     summaries_descrip_flatten_tiled = summaries_descrip_flatten.repeat((1,num_repeats))\n",
    "#     summaries_descrip_flatten_tiled_segmented = summaries_descrip_flatten_tiled[:,:name_seg_flatten.shape[1]]\n",
    "\n",
    "#     consine_sim_code_req = self.cosine_similarity(name_seg_flatten,summaries_descrip_flatten_tiled_segmented)\n",
    "    \n",
    "#     consine_sim_code_req_0_1 = self.sigmoid (consine_sim_code_req)\n",
    "#     summary_desc = self.pool_layer_2d (summaries_descrip_seg)\n",
    "#     print(\"summary_desc.shape = \",summary_desc.shape)\n",
    "\n",
    "#     print(torch.cuda.memory_reserved()/1024**3)\n",
    "    \n",
    "#     print(\"consine_sim_code_req.shape\", consine_sim_code_req.shape)\n",
    "#     print(consine_sim_code_req.shape)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "class JaccardLoss(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(JaccardLoss, self).__init__()\n",
    "\n",
    "    def forward(self, input, target):\n",
    "        intersection = torch.sum(input * target)\n",
    "        union = torch.sum(input) + torch.sum(target) - intersection\n",
    "        jaccard = (intersection + 1e-6) / (union + 1e-6)  # Adding epsilon for numerical stability\n",
    "        return 1 - jaccard  # Minimizing 1 - Jaccard is equivalent to maximizing Jaccard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "def weighted_binary_cross_entropy(output, target):\n",
    "        \n",
    "#     loss = weights[1] *(target * torch.log(output)) + \\\n",
    "#            weights[0] * ((1 - target) * torch.log(1 - output))\n",
    "#     output --> kber ,loss \n",
    "    loss = (target * torch.log(output)) + \\\n",
    "            ((1 - target) * torch.log(1 - output))\n",
    "\n",
    "    return torch.mean(loss)\n",
    "\n",
    "def customCollate(batch: list):\n",
    "    # batch --> tuple (x,y)\n",
    "    # x --> list of 4 lists\n",
    "    x_batch, y_batch = zip(*batch)\n",
    "\n",
    "    function_names, function_segments, descriptions , summaries = zip(*x_batch)\n",
    "\n",
    "    function_names_padded = pad_sequence(function_names, batch_first=True, padding_value=0)\n",
    "    function_segments_padded = pad_sequence(function_segments, batch_first=True, padding_value = 0)\n",
    "    descriptions_padded = pad_sequence(descriptions, batch_first=True, padding_value=0)\n",
    "    summaries_padded = pad_sequence(summaries, batch_first=True, padding_value = 0)\n",
    "\n",
    "    return  function_names_padded, function_segments_padded, descriptions_padded, summaries_padded, y_batch\n",
    "\n",
    "def train(model, train_dataset, batch_size=5, epochs=30 ,learning_rate=0.0001):\n",
    "    \n",
    "    weight = torch.as_tensor([1,50], dtype=torch.float)\n",
    "    # (1) create the dataloader of the training set IMPORTANT (make the shuffle=True)\n",
    "    train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size, shuffle=True)\n",
    "    \n",
    "    \n",
    "    # (2) make the criterion cross entropy loss\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "    # (3) create the optimizer (Adam)\n",
    "    optimizer = torch.optim.Adam(model.parameters(),lr=learning_rate)\n",
    "\n",
    "    \n",
    "    use_cuda = torch.cuda.is_available()\n",
    "    device = torch.device(\"cuda\" if use_cuda else \"cpu\") \n",
    "#     device=\"cpu\"\n",
    "    if use_cuda:\n",
    "        model = model.cuda()\n",
    "        criterion = criterion.cuda()\n",
    "   \n",
    "\n",
    "    for epoch_num in range(epochs):\n",
    "        total_acc_train = 0\n",
    "        total_loss_train = 0\n",
    "        n_samples = 0\n",
    "        y_size = 0\n",
    "        true_pos = 0\n",
    "        false_neg = 0\n",
    "        false_pos = 0 \n",
    "        true_neg = 0\n",
    "        for x_train, y_batch in tqdm(train_dataloader):\n",
    "            # torch.cuda.empty_cache()     \n",
    "            function_names_padded_tensor = torch.tensor(x_train[0], device=device)\n",
    "            function_segments_padded_tensor = torch.tensor(x_train[1], device=device)\n",
    "            descriptions_padded_tensor = torch.tensor(x_train[2], device=device)\n",
    "            fsummaries_padded_tensor = torch.tensor(x_train[3], device=device)\n",
    "            y_batch_tensor = torch.tensor(y_batch,dtype = torch.float32,device=device)\n",
    "            \n",
    "            output = model.forward(function_names_padded_tensor, function_segments_padded_tensor, descriptions_padded_tensor, fsummaries_padded_tensor)\n",
    "#             _,predicted=torch.max(output)  #512 * 104  for every word in every sentence we choose one tag form the seventen tag \n",
    "            output_0_1 = torch.tensor((output > 0.5), dtype=torch.float32)\n",
    "            \n",
    "            # for i,value in enumerate(output_0_1): #calc the fals negtive\n",
    "            #     if value == 0 and  y_batch_tensor[i] == 1:\n",
    "            #       false_neg+=1\n",
    "            #     elif value == 1 and  y_batch_tensor[i] == 1:\n",
    "            #       true_pos+=1\n",
    "            #     elif value == 1 and  y_batch_tensor[i] == 0:\n",
    "            #       false_pos += 1\n",
    "            #     else:\n",
    "            #       true_neg += 1\n",
    "            \n",
    "#             weights = torch.where(y_batch_tensor == 0, torch.tensor(class_weights[0]).to(device), torch.tensor(class_weights[1]).to(device)).to(device)\n",
    "            \n",
    "            _,predicted=torch.max(output,dim=1)\n",
    "            batch_loss = criterion(output,y_batch_tensor.long())\n",
    "            # batch_loss = criterion(output, y_batch_tensor)\n",
    "            # torch.cuda.empty_cache()\n",
    "            total_loss_train += batch_loss\n",
    "            # print(torch.cuda.memory_reserved()/1024**3)\n",
    "              \n",
    "\n",
    "            # (7) loss calculation (you need to think in this part how to calculate the loss correctly)\n",
    "            \n",
    "    #       (9) calculate the batch accuracy (just add the number of correct predictions)\n",
    "            acc = (predicted==y_batch_tensor).sum().item()\n",
    "            n_samples += y_batch_tensor.size(0)\n",
    "            total_acc_train += acc\n",
    "\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "    #       (11) do the backward pass\n",
    "            batch_loss.backward()\n",
    "            nn.utils.clip_grad_norm_(model.parameters(), max_norm=1)\n",
    "\n",
    "    #       (12) update the weights with your optimizer\n",
    "            optimizer.step()\n",
    "            # (10) zero your gradients\n",
    "            \n",
    "    #   epoch loss\n",
    "        epoch_loss = total_loss_train / n_samples\n",
    "\n",
    "    #   (13) calculate the accuracy\n",
    "        epoch_acc =100*total_acc_train/n_samples\n",
    "\n",
    "        print(\n",
    "           f'Epochs: {epoch_num + 1} | Train Loss: {epoch_loss} \\\n",
    "           | Train Accuracy: {epoch_acc}\\n')\n",
    "        print(\"true_pos = \", true_pos)\n",
    "        print(\"false_neg = \",false_neg)\n",
    "        print(\"false_pos = \",false_pos)\n",
    "        print(\"true_neg = \", true_neg)\n",
    "        \n",
    "\n",
    "  ##############################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/5 [00:00<?, ?it/s]C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_14616\\3258290520.py:59: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  function_names_padded_tensor = torch.tensor(x_train[0], device=device)\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_14616\\3258290520.py:60: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  function_segments_padded_tensor = torch.tensor(x_train[1], device=device)\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_14616\\3258290520.py:61: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  descriptions_padded_tensor = torch.tensor(x_train[2], device=device)\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_14616\\3258290520.py:62: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  fsummaries_padded_tensor = torch.tensor(x_train[3], device=device)\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_14616\\3258290520.py:63: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_batch_tensor = torch.tensor(y_batch,dtype = torch.float32,device=device)\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (1660x150 and 600x128)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[258], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m model \u001b[38;5;241m=\u001b[39m DLModel(embedding_matrix, embedding_matrix\u001b[38;5;241m.\u001b[39mshape,\u001b[38;5;28mlen\u001b[39m(dataset_train_small[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m]),\u001b[38;5;28mlen\u001b[39m(dataset_train_small[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m1\u001b[39m]),\u001b[38;5;28mlen\u001b[39m(dataset_train_small[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m2\u001b[39m]),\u001b[38;5;28mlen\u001b[39m(dataset_train_small[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m3\u001b[39m]), hidden_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m64\u001b[39m, classes\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m----> 2\u001b[0m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataset_train_small\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[257], line 65\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(model, train_dataset, batch_size, epochs, learning_rate)\u001b[0m\n\u001b[0;32m     62\u001b[0m             fsummaries_padded_tensor \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(x_train[\u001b[38;5;241m3\u001b[39m], device\u001b[38;5;241m=\u001b[39mdevice)\n\u001b[0;32m     63\u001b[0m             y_batch_tensor \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(y_batch,dtype \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mfloat32,device\u001b[38;5;241m=\u001b[39mdevice)\n\u001b[1;32m---> 65\u001b[0m             output \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunction_names_padded_tensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunction_segments_padded_tensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdescriptions_padded_tensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfsummaries_padded_tensor\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     66\u001b[0m \u001b[38;5;66;03m#             _,predicted=torch.max(output)  #512 * 104  for every word in every sentence we choose one tag form the seventen tag \u001b[39;00m\n\u001b[0;32m     67\u001b[0m             output_0_1 \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor((output \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0.5\u001b[39m), dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat32)\n",
      "Cell \u001b[1;32mIn[255], line 43\u001b[0m, in \u001b[0;36mDLModel.forward\u001b[1;34m(self, function_names, function_segments, descriptions, summaries)\u001b[0m\n\u001b[0;32m     40\u001b[0m concatenated_name_seg \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat((function_names_embeddings, function_segments_embeddings), dim \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     41\u001b[0m summaries_descrip_seg \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat((descriptions_embedding, summaries_embedding), dim \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m---> 43\u001b[0m function_names_lstm \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlstm_CC\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mconcatenated_name_seg\u001b[49m\u001b[43m,\u001b[49m\u001b[43msummaries_descrip_seg\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     45\u001b[0m lstm_post_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlstm_post_flatten(function_names_lstm)\n\u001b[0;32m     46\u001b[0m \u001b[38;5;66;03m# function_segments_lstm = self.lstm_CC (function_segments_embeddings.float())\u001b[39;00m\n\u001b[0;32m     47\u001b[0m \u001b[38;5;66;03m# descriptions_lstm = self.lstm_CC (descriptions_embedding.float())\u001b[39;00m\n\u001b[0;32m     48\u001b[0m \u001b[38;5;66;03m# summaries_lstm = self.lstm_CC (summaries_embedding.float())\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     69\u001b[0m \u001b[38;5;66;03m# summaries_descrip_flatten_tiled = summaries_descrip_flatten.repeat((1,num_repeats))\u001b[39;00m\n\u001b[0;32m     70\u001b[0m \u001b[38;5;66;03m# summaries_descrip_flatten_tiled_segmented = summaries_descrip_flatten_tiled[:,:name_seg_flatten.shape[1]]\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\HP\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\HP\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\HP\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\linear.py:116\u001b[0m, in \u001b[0;36mLinear.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    115\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 116\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (1660x150 and 600x128)"
     ]
    }
   ],
   "source": [
    "model = DLModel(embedding_matrix, embedding_matrix.shape,len(dataset_train_small[0][0][0]),len(dataset_train_small[0][0][1]),len(dataset_train_small[0][0][2]),len(dataset_train_small[0][0][3]), hidden_size=64, classes=2)\n",
    "train(model, dataset_train_small)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # import matplotlib.pyplot as plt\n",
    "# model = DLModel(embedding_matrix, embedding_matrix.shape)\n",
    "# weight = torch.as_tensor([50], dtype=torch.float)\n",
    "# def customCollate(batch: list):\n",
    "#     # batch --> tuple (x,y)\n",
    "#     # x --> list of 4 lists\n",
    "#     x_batch, y_batch = zip(*batch)\n",
    "#     function_names, function_segments, descriptions , summaries = zip(*x_batch)\n",
    "\n",
    "#     function_names_padded = pad_sequence(function_names, batch_first=True, padding_value=0)\n",
    "#     function_segments_padded = pad_sequence(function_segments, batch_first=True, padding_value = 0)\n",
    "#     descriptions_padded = pad_sequence(descriptions, batch_first=True, padding_value=0)\n",
    "#     summaries_padded = pad_sequence(summaries, batch_first=True, padding_value = 0)\n",
    "\n",
    "#     return  function_names_padded, function_segments_padded, descriptions_padded, summaries_padded, y_batch\n",
    "\n",
    "# criterion = torch.nn.BCEWithLogitsLoss(pos_weight=weight)\n",
    "# optimizer = torch.optim.Adam(model.parameters())\n",
    "# # use_cuda = torch.cuda.is_available()\n",
    "# #device = torch.device(\"cuda\" if use_cuda else \"cpu\") '\n",
    "# device=\"cpu\"\n",
    "# # if use_cuda:\n",
    "# #     model = model.cuda()\n",
    "# #     criterion = criterion.cuda()\n",
    "    \n",
    "# train_dataloader = torch.utils.data.DataLoader(dataset_train, 5, shuffle=True, collate_fn=customCollate)\n",
    "\n",
    "# # train(model, dataset_train)\n",
    "# # model.load_state_dict(torch.load('ModelBCEWithLogitsLoss_attentionLayer_1_epoch_weight60.pth'))\n",
    "# # model.train()\n",
    "# from ignite.engine import Engine, Events\n",
    "# from ignite.handlers import FastaiLRFinder\n",
    "\n",
    "# lr_finder = FastaiLRFinder()\n",
    "\n",
    "# trainer=Engine(train_step)\n",
    "# to_save = {\"model\": model, \"optimizer\": optimizer}\n",
    "\n",
    "# with lr_finder.attach(trainer, to_save=to_save) as trainer_with_lr_finder:\n",
    "#     trainer_with_lr_finder.run(train_dataloader)\n",
    "    \n",
    "\n",
    "\n",
    "# # def custom_plot(lr_finder, save_path='lr_finder_plot.png', figsize=(10, 6)):\n",
    "# #     fig, ax = plt.subplots(figsize=figsize)\n",
    "# #     lrs = lr_finder.get_results()[\"lr\"]\n",
    "# #     losses = lr_finder.get_results()[\"loss\"]\n",
    "# #     ax.plot(lrs, losses)\n",
    "# #     ax.set_xscale(\"log\")\n",
    "# #     ax.set_xlabel(\"Learning rate\")\n",
    "# #     ax.set_ylabel(\"Loss\")\n",
    "# #     ax.set_title(\"Learning rate vs. Loss\")\n",
    "# #     plt.savefig(save_path)\n",
    "# #     plt.show()\n",
    "\n",
    "# # # Use the custom plot function\n",
    "# # lr_finder.get_results()\n",
    "# # custom_plot(lr_finder, save_path='lr_finder_plot.png', figsize=(12, 8))\n",
    "# # suggested_lr = lr_finder.lr_suggestion()\n",
    "# # print(f\"Suggested learning rate: {suggested_lr}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "ModelBCEWithLogitsLoss_attentionLayer_1_epoch_weight60 --> \n",
    "Test:\n",
    "true_pos =  41\n",
    "false_neg =  25\n",
    "false_pos =  821\n",
    "true_neg =  940\n",
    "\n",
    "Test Accuracy: 53.694580078125\n",
    "\n",
    "Test Recall: 0.6212121212121212\n",
    "\n",
    "Test precesion: 0.04756380510440835\n",
    "--------------------------------------------\n",
    "ModelBCEWithLogitsLoss_attentionLayer_1_epoch_weight45 --> \n",
    "Test:\n",
    "true_pos =  6\n",
    "false_neg =  60\n",
    "false_pos =  185\n",
    "true_neg =  1576\n",
    "\n",
    "Test Accuracy: 86.59004211425781\n",
    "\n",
    "Test Recall: 0.09090909090909091\n",
    "\n",
    "Test precesion: 0.031413612565445025\n",
    "------------------------------------------------\n",
    "ModelBCEWithLogitsLoss_attentionLayer_1_epoch_weight50\n",
    "true_pos =  32\n",
    "false_neg =  34\n",
    "false_pos =  772\n",
    "true_neg =  989\n",
    "\n",
    "Test Accuracy: 55.88396453857422\n",
    "\n",
    "Test Recall: 0.48484848484848486\n",
    "\n",
    "Test precesion: 0.03980099502487562\n",
    "------------------------------------------------\n",
    "ModelBCEWithLogitsLoss_attentionLayer_1_epoch_weight70 -->\n",
    "\n",
    "true_pos =  37\n",
    "false_neg =  29\n",
    "false_pos =  971\n",
    "true_neg =  790\n",
    "\n",
    "Test Accuracy: 45.26546096801758\n",
    "\n",
    "Test Recall: 0.5606060606060606\n",
    "\n",
    "Test precesion: 0.03670634920634921\n",
    "-----------------------------------------------------\n",
    "ModelBCEWithLogitsLoss_attentionLayer_1_epoch_weight60 -->\n",
    "\n",
    "true_pos =  41\n",
    "false_neg =  25\n",
    "false_pos =  821\n",
    "true_neg =  940\n",
    "\n",
    "Test Accuracy: 53.694580078125\n",
    "\n",
    "Test Recall: 0.6212121212121212\n",
    "\n",
    "Test precesion: 0.04756380510440835\n",
    "----------------------------------------------------------\n",
    "NewModelBCEWithLogitsLoss_attentionLayer_1_epoch_weight100\n",
    "\n",
    "true_pos =  40\n",
    "false_neg =  26\n",
    "false_pos =  993\n",
    "true_neg =  768\n",
    "\n",
    "Test Accuracy: 44.22550582885742\n",
    "\n",
    "Test Recall: 0.6060606060606061\n",
    "\n",
    "Test precesion: 0.03872216844143272\n",
    "--------------------------------------------------------\n",
    "ModelBCEWithLogitsLoss_attentionLayer_20_epoch_weight50\n",
    "\n",
    "true_pos =  66\n",
    "false_neg =  0\n",
    "false_pos =  1761\n",
    "true_neg =  0\n",
    "\n",
    "Test Accuracy: 3.6124794483184814\n",
    "\n",
    "Test Recall: 1.0\n",
    "\n",
    "Test precesion: 0.0361247947454844\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'ModelBCEWithLogitsLoss_preprocessingUpdated_lstm_1_epoch_weight50.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load('/kaggle/input/functions-divided.pth'))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, test_dataset,batch_size=5):\n",
    "  \"\"\"\n",
    "  This function takes a NER model and evaluates its performance (accuracy) on a test data\n",
    "  Inputs:\n",
    "  - model: a NER model\n",
    "  - test_dataset: dataset of type NERDataset\n",
    "  \"\"\"\n",
    "  ########################### TODO: Replace the Nones in the following code ##########################\n",
    "\n",
    "  # (1) create the test data loader\n",
    "  test_dataloader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, collate_fn=customCollate , shuffle=False)\n",
    "\n",
    "  total_acc_test = 0\n",
    "  n_samples = 0\n",
    "\n",
    "  use_cuda = torch.cuda.is_available()\n",
    "    \n",
    "  device = torch.device(\"cuda\" if use_cuda else \"cpu\") \n",
    "    # device=\"cpu\"\n",
    "  if use_cuda:\n",
    "        model = model.cuda()\n",
    "  with torch.no_grad():\n",
    "    false_neg = 0\n",
    "    true_pos = 0\n",
    "    false_pos = 0\n",
    "    true_neg = 0\n",
    "    for function_names_padded, function_segments_padded, descriptions_padded, summaries_padded, y_batch in tqdm(test_dataloader):\n",
    "            function_names_padded_tensor = torch.tensor(function_names_padded, device=device)\n",
    "            function_segments_padded_tensor = torch.tensor(function_segments_padded, device=device)\n",
    "            descriptions_padded_tensor = torch.tensor(descriptions_padded, device=device)\n",
    "            fsummaries_padded_tensor = torch.tensor(summaries_padded, device=device)\n",
    "            y_batch_tensor = torch.tensor(y_batch,dtype = torch.float32,device=device)\n",
    "#             y_batch_tensor = torch.where(y_batch_tensor == 0 , torch.tensor(-1).to(device), torch.tensor(1).to(device)).to(device)\n",
    "            output = model.forward(function_names_padded_tensor, function_segments_padded_tensor, descriptions_padded_tensor, fsummaries_padded_tensor)\n",
    "            output_0_1 = torch.where(output < 0, torch.tensor(0).to(device), torch.tensor(1).to(device)).to(device)\n",
    "#             print(output)\n",
    "            for i,value in enumerate(output_0_1): #calc the fals negtive\n",
    "                if value == 0 and  y_batch_tensor[i] == 1:\n",
    "                  false_neg+=1\n",
    "                elif value == 1 and  y_batch_tensor[i] == 1:\n",
    "                  true_pos+=1\n",
    "                elif value == 1 and  y_batch_tensor[i] == 0:\n",
    "                  false_pos += 1\n",
    "                else:\n",
    "                  true_neg += 1\n",
    "                \n",
    "            n_true = sum((output_0_1 == y_batch_tensor))\n",
    "            n_samples += y_batch_tensor.size(0)\n",
    "            total_acc_test += n_true\n",
    "       \n",
    "    # (6) calculate the over all accuracy\n",
    "    acc_test =100*total_acc_test/n_samples\n",
    "  ##################################################################################################\n",
    "    print(\"true_pos = \", true_pos)\n",
    "    print(\"false_neg = \",false_neg)\n",
    "    print(\"false_pos = \",false_pos)\n",
    "    print(\"true_neg = \", true_neg)\n",
    "\n",
    "    recall = true_pos / (true_pos+false_neg)\n",
    "    precesion =  true_pos / (true_pos+false_pos)\n",
    "#     f1Score = (2*precesion*recall)/(precesion+recall)\n",
    "    print(f'\\nTest Accuracy: {acc_test}')\n",
    "    print(f'\\nTest Recall: {recall}') \n",
    "    print(f'\\nTest precesion: {precesion}') \n",
    "#     print(f'\\nF1 Score: {f1Score}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate(model, dataset_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
