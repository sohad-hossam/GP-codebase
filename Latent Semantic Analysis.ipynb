{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from VSM import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.18484167  0.32738271  0.32297029 ... -0.19927615  0.27820002\n",
      "   0.35132463]\n",
      " [ 0.28818638  0.58028285  0.51700986 ... -0.05964517  0.34315138\n",
      "   0.33729603]\n",
      " [ 0.40726157  0.32797793  0.20740166 ... -0.08974322  0.2810291\n",
      "   0.26557721]\n",
      " ...\n",
      " [ 0.46309584  0.22129585  0.1057154  ... -0.13916636  0.3056358\n",
      "   0.34840027]\n",
      " [ 0.2137096   0.39047185  0.33016153 ... -0.16891807  0.54138982\n",
      "   0.41260451]\n",
      " [ 0.52798522  0.07769876 -0.01366725 ...  0.17987839  0.35917726\n",
      "   0.64909034]]\n"
     ]
    }
   ],
   "source": [
    "num_components = min(tfidf_matrix_uc.shape[0], tfidf_matrix_code.shape[1])\n",
    "num_components = min(num_components, 100)\n",
    "LSA_model = TruncatedSVD(n_components=num_components)\n",
    "\n",
    "# if train_or_test == \"train\":\n",
    "LSA_data_useCases = LSA_model.fit_transform(tfidf_matrix_uc)\n",
    "LSA_data_codes = LSA_model.fit_transform(tfidf_matrix_code) \n",
    "# else:\n",
    "#     LSA_data_useCases = LSA_model.transform(tfidf_matrix_uc)\n",
    "#     LSA_data_codes = LSA_model.transform(tfidf_matrix_code) \n",
    "\n",
    "LSA_similraity_matrix = cosine_similarity(LSA_data_useCases, LSA_data_codes)\n",
    "print(LSA_similraity_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.18494935  0.32741298  0.32298728 ... -0.19926879  0.27823173\n",
      "   0.35124038]\n",
      " [ 0.28815624  0.58026943  0.5170166  ... -0.05960473  0.34314214\n",
      "   0.33720153]\n",
      " [ 0.40731432  0.32797995  0.20740593 ... -0.08971634  0.28103354\n",
      "   0.26550128]\n",
      " ...\n",
      " [ 0.46308373  0.22127783  0.10571241 ... -0.13907471  0.30562827\n",
      "   0.34828245]\n",
      " [ 0.21385299  0.39050639  0.3301778  ... -0.16892298  0.54141577\n",
      "   0.41249717]\n",
      " [ 0.52800108  0.07768726 -0.01367166 ...  0.1798517   0.35917281\n",
      "   0.64890433]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 0.18494935,  0.32741298,  0.32298728, ..., -0.19926879,\n",
       "         0.27823173,  0.35124038],\n",
       "       [ 0.28815624,  0.58026943,  0.5170166 , ..., -0.05960473,\n",
       "         0.34314214,  0.33720153],\n",
       "       [ 0.40731432,  0.32797995,  0.20740593, ..., -0.08971634,\n",
       "         0.28103354,  0.26550128],\n",
       "       ...,\n",
       "       [ 0.46308373,  0.22127783,  0.10571241, ..., -0.13907471,\n",
       "         0.30562827,  0.34828245],\n",
       "       [ 0.21385299,  0.39050639,  0.3301778 , ..., -0.16892298,\n",
       "         0.54141577,  0.41249717],\n",
       "       [ 0.52800108,  0.07768726, -0.01367166, ...,  0.1798517 ,\n",
       "         0.35917281,  0.64890433]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from FeatureExtraction import *\n",
    "\n",
    "test = FeatureExtraction()\n",
    "test.LSA(tfidf_matrix_uc, tfidf_matrix_code, \"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.18482137  0.3273921   0.32295519 ... -0.19927008  0.27819332\n",
      "   0.35132647]\n",
      " [ 0.28824105  0.58026967  0.5170505  ... -0.05965737  0.34313247\n",
      "   0.33729178]\n",
      " [ 0.40726529  0.32798009  0.20740789 ... -0.08973642  0.28103006\n",
      "   0.26557118]\n",
      " ...\n",
      " [ 0.46310731  0.22130393  0.10572647 ... -0.13913685  0.30565015\n",
      "   0.34834786]\n",
      " [ 0.21364449  0.39048035  0.33014368 ... -0.16890047  0.54140078\n",
      "   0.41261981]\n",
      " [ 0.52799292  0.07769306 -0.01365563 ...  0.17986966  0.35917951\n",
      "   0.64910979]]\n"
     ]
    }
   ],
   "source": [
    "#usecases (100*usecases_nu)\n",
    "#code (100*codes_nu)\n",
    "#LSA_similraity_matrix (usecases_nu*codes_nu)\n",
    "#d1,d2,d3,d4\n",
    "#u1,u2,u3,u4\n",
    "#u1*d1,u1*d2,u1*d3 ...\n",
    "#d1*u1,d1*u2,d1*u3 ...\n",
    "#each row coresspond between the use cases and each document\n",
    "# [[d1*c1 d1*c2],[d2*c1 d2*c2]]\n",
    "\n",
    "# LSA_data_codes=np.array([[1,2,3,4,5] , [6,7,8,9,10]])\n",
    "# LSA_data_useCases=np.array([[11,12,13,14,15] , [16,17,18,19,21],[2,5,9,11,42]])\n",
    "\n",
    "# LSA_data_codes_norm=np.repeat(np.linalg.norm(LSA_data_codes,axis=1),LSA_data_useCases.shape[0])\n",
    "# LSA_data_useCases_norm=np.repeat(np.linalg.norm(LSA_data_useCases,axis=1),LSA_data_codes.shape[0])\n",
    "\n",
    "# LSA_data_codes_norm=LSA_data_codes_norm.reshape(LSA_data_codes.shape[0],LSA_data_useCases.shape[0]).T \n",
    "# LSA_data_useCases_norm=LSA_data_useCases_norm.reshape(LSA_data_useCases.shape[0],LSA_data_codes.shape[0])\n",
    "\n",
    "# print(LSA_data_codes_norm)\n",
    "# print(LSA_data_useCases_norm)\n",
    "\n",
    "LSA_similraity_matrix=cosine_similarity(LSA_data_useCases, LSA_data_codes)\n",
    "\n",
    "print(LSA_similraity_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Jensen-Shannon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "UC_count_vectorizer = CountVectorizer(vocabulary=UCTokens)\n",
    "code_count_vectorizer = CountVectorizer(vocabulary=UCTokens)\n",
    "\n",
    "UC_count_matrix = UC_count_vectorizer.fit_transform(UC_documents)\n",
    "code_count_matrix = code_count_vectorizer.fit_transform(code_documents)\n",
    "\n",
    "UC_words_count = UC_count_matrix.sum(axis=1)\n",
    "code_words_count = code_count_matrix.sum(axis=1)\n",
    "\n",
    "UC_count_matrix /= UC_words_count\n",
    "code_count_matrix /= code_words_count\n",
    "\n",
    "# loop-approach\n",
    "# JS_matrix = np.zeros((UC_count_matrix.shape[0], code_count_matrix.shape[0]))\n",
    "# for i, UC_count_vector in enumerate(UC_count_matrix.toarray()):\n",
    "#     for j, code_count_vector in enumerate(code_count_matrix.toarray()):\n",
    "#         JS_matrix[i][j] = pow(jensenshannon(UC_count_vector, code_count_vector), 2)\n",
    "# print(JS_matrix[0])\n",
    "# repeat-approach\n",
    "UC_count_matrix = UC_count_matrix.toarray()    \n",
    "code_count_matrix = code_count_matrix.toarray()\n",
    "UC_count_matrix_repeated = np.repeat(UC_count_matrix, code_count_matrix.shape[0], axis=0)\n",
    "code_count_matrix_repeated = np.tile(code_count_matrix, (UC_count_matrix.shape[0],1))\n",
    "\n",
    "JS_matrix = pow(jensenshannon(UC_count_matrix_repeated, code_count_matrix_repeated, axis=1), 2)\n",
    "JS_matrix = JS_matrix.reshape(UC_count_matrix.shape[0], code_count_matrix.shape[0])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
